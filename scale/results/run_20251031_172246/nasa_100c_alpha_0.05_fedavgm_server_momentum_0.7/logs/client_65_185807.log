[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f320c621-5585-46d6-b9db-2e20320785a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2618a62-b75c-48f5-9f3b-f60dc9d0b578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 422fbada-ffbf-48d8-afe6-8f636758afae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd52ce47-f8ff-443e-8823-c0649daa018f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be74427-b954-45fc-a151-2babe6012b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05232f4f-b0b0-4635-9c1e-781f660c2ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f0ac1a-8c72-4e00-828a-5c378947f1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b75c6e-39c4-42de-a0c4-0d4216221227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414a3d51-5410-4480-95d3-7c0f6074e5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8313ac77-f0dc-45d2-b28c-3b01bbb99cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9bac61-203d-41c5-94c8-74ac29e3f94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39dc668e-455a-49d9-b827-90a0dbe475a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c404280-ab92-4780-9bfd-9dfafcda07f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7f69bfa-40f8-40c0-9d6b-38240cead7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09195e3f-e5a2-41c2-a9f3-0492134670f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aecff47-be00-47ab-aa86-c2dc2cef43d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5fd3397-9634-4268-8240-bf637164cb09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8069564-124a-4f4f-9359-1eef73487e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9076cf8-7b3a-4aa0-abfd-3b78390ee3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a784a7a5-503d-4df6-a061-0fce283756d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2e6c14-8e2a-46d3-a9f1-22143fe2e171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc0bdaf4-d404-4fef-8d4a-5ab301768a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45441ad9-7b4f-4cb3-a661-c71c14288a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4aa041-ae91-4b99-af91-3413d8d39617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9da5885-db0c-4e2f-a2bc-bd36c1f20490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddab6745-e705-4002-8322-a29903761d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc68fed1-efde-4560-99ce-df17fcb56907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ad30a4-dda7-4a6d-a45c-5a132ad5c8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31ff435-5236-497c-8e18-fbf65fa1e7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8574e7ca-15e3-477b-b470-c4b0dd5b29dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f310bb6-e719-417f-a089-28d08f6a6f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a3f0be-0b27-4713-a0f3-2dbda06e31f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ac8f88-a7ff-4de1-bbd0-c8475bf6fc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0563612-4bdd-4089-86b9-84bfcc3d0bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d793b915-7142-406f-899d-7b29ffb49c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca21edb-5145-4a3b-89b8-8d45625e2cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97cfa31-4bc7-4ab1-9808-ce1689988b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e7c63c-97d3-433a-8e7c-a6a32d03a5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122c12d6-7ca6-493d-97cc-40de3ed445d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b89563-002c-4c70-ad62-911d822a6275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e64d80f-1d92-4b4c-b4cc-8e7eb58348ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84937c2e-8b5f-478e-ad6f-10874a379fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8d3ddd-a40a-432f-88ef-a2cdc2191d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c70f5ad9-d286-4914-89c2-a57805d0e420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da739902-41d3-4a34-8a6a-c1c06a537f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75dbc7a2-354b-428c-850e-44a2881b88c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe016ca8-fc72-4c2d-a785-8099f6be86d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d60412ad-9b56-42cb-b657-c07305474a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b7de52d-65dc-41e2-8d3a-32418e4b234c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dbb7990-c618-46a2-b291-ea2d235ab8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f6be26-ae93-4176-af0f-8ccad1b6f3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6690815-06d2-4199-a75c-6ab852ee3e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f03093-e6ec-4cf3-bba2-b4e280b3cccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254f1908-673f-4af9-896a-dabed92f7d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf61887c-2bc6-4234-9eb4-9e2a8211342c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4043ae-d7c5-4d80-8dae-6ff6b6a6eb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f41131-0164-489c-94cd-952237c1fbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ed0df3-4e30-462e-af2f-f2b405e0789b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61669018-62d1-494e-8b56-1104b6bf0369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cf5ebab-e5cb-4d56-8b2f-6b3e205c6b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb68fc8-10e7-4c51-9a28-fcb827ff4a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff740dd-bdff-4644-87c6-6d691f8ef459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cdd022e-7f98-4dea-b2ad-decc24e68524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16bd4f81-0ec6-4ef2-9dd2-bd21100a186e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1758dfe3-0e13-4675-a497-156b05ba8a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db5a3a9-915c-4141-b407-06ee614f8f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25305168-c04d-40b1-8c5c-b7c55842162a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7def968-c0e8-4c19-bae6-522f02cabbcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11867fd2-0dbb-41a8-ad09-a08c4b7aaec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477093dc-aebe-41bc-8672-75262e09f663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc0aefe-d9a3-4199-b122-64517956c8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a836fb-22c1-4e6b-9ab2-8287d9129e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb616e59-aaed-4330-b0bd-e5a376590192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1fae6a-88e1-42f0-8cc8-05db3b4115e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e694c4c-86a9-4093-a744-f3d789c6dfac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736e5737-cde5-4ce0-aac4-297d1d1c71c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b1568a-c594-4f34-af5e-6c63eb3ece69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa5b0b20-08de-4732-bc58-cd4020ba41d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11dafda-ef04-47b3-b8ed-e7aa5908c3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a3abd7-0f1d-4b09-8822-7851ac6337ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35f3c22-d0b3-4a55-812a-70f9a1ce21a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d308f667-4c05-4f4f-accc-78f90ab3b7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69a132e-4240-469b-91e5-0809f293d21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ac6de6-9e32-401d-8950-a4ecee7e2882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed0a32e-0a69-46e0-893d-b43fb7e22916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85090eb-616f-43ce-ae8d-aea853059c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee23144-087f-4ada-b61f-8b7f62e9866d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e91d8c6c-0dfc-40e5-8701-c0a12952a9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ca92c4-d67e-45df-be3b-b23da141afbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22eca9fd-346d-4e17-8e99-d309de3ef749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ddfafb-9c69-440b-ae68-07f1bda3ccff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e53e81-6b13-4002-a480-75d08694ad3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe2da5a7-2970-4f37-8dff-3c7d7037a390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5ed172-2c9c-4965-a89e-4297b8aeb931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4086ee49-b7d1-4aff-8c35-c99ad6fa1f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5252e54b-3741-4d4c-bbce-be319f8d1459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a300c7fb-7882-4d9c-b49c-fab4f811b7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2f5d06-b7b0-448a-ae61-6ff4ad7eff29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b598a5c-306d-4baa-915a-075582b467f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bb5f94-fffa-4fdf-b9e6-b020aa928643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48348c5c-36c3-48f3-a834-c8caed3c0bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c633d359-e48b-4ea6-8bc6-b5d8b1a204b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4f114e-41bc-464b-9412-00c3c0558695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc71346-2877-4c4b-b770-0b8c5b871d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad7c97b-613c-4d57-b0ef-5d890f4d6226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a514c4-7222-4a3f-984c-993553f24393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ce7621-54a3-477b-9b77-96b8389cc597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d299103b-8576-4c91-9c0d-dae74edcd41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c9272e-ffe8-4719-8270-e5d0dcd8b187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665d0e33-5379-47e3-a0f5-179097665bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa3388b-9994-459e-b33d-0cdb1bd50fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf2b99e-e9bd-41e7-b232-2997d9cd4fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74b043ec-d359-4fcf-a9e7-4710bdc9d75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26001772-998b-4069-a588-902b3a1cf5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c914780-76ef-4744-9722-ee1d9613485b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a846d2-0abb-463c-aac2-519f3001613c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6441b5a2-5951-476b-af90-7ede9e29d65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c2b84eb-f47d-4e2c-a727-315678043574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12537954-73ce-4653-bd8f-2b0372c8f361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f969a8-28d7-428c-be4e-346932240ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f7313a-6195-427a-81a8-b35171d033d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446739ce-5c8d-40fb-a0c5-ad21a25cb90a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32798d3a-d903-473e-a4be-3da9ce54587c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5594e53c-dde0-4c04-a8e5-2e023ad032fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6090eb-cb9f-40d5-b9ee-37790ee79088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a9e39b7-1ae3-4c5c-93b4-ae02cd2d6578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9daec9b0-552c-4b87-8427-a82fe807b153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44455eb5-ffdf-4d91-9e14-075dd97e6f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21c8dcb7-ae43-4524-b619-ea96bd7b91bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 796c2a05-e3f0-4fd7-b172-4506306a9819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1cfc51-1fe4-4533-93bd-cef416a492f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 289d3ee7-74a8-4252-be8d-b48592667d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ea13bcf-a70f-42a3-97e7-ca262c362fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a552446-b355-4101-9cfc-50b362b10ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c91595e-f8ed-4fef-945a-c6a2ee54ff1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10c05f09-7366-4e25-b29f-8c78ca17fdf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2bab72-41a4-4008-8003-b258487c6361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546fb6d4-4637-4320-b3a6-106c2a390d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7d4a9e-40c2-40d9-b71c-6e783ffd17f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfdda9fd-6e66-48bd-961f-960e7466a3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a0b2941-f076-4957-82d6-3e085eb3d97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796d6cf4-2b82-4dc0-89c1-56ced0775624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eafcf94-b2c0-43c5-9b50-eed67c09ab03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 781e85da-187d-433d-944c-51858ea382b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e56f3c9-b834-4ee6-a400-f3aeee9317c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f74242ff-0a11-4b63-9da8-6a39e4739cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f85a4270-8429-4815-a50e-e24a33fbfc9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efa3da3-469c-4c2c-adba-cebcf3c3da0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a840400-5d4e-4a40-87fd-53e64cb64b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff12b1f-7ef4-425e-ad07-ffe01f67603e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e009f6-20ff-4438-95ea-ed738c9c5273
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_65
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_labels.txt

📊 Raw data loaded:
   Train: X=(1919, 24), y=(1919,)
   Test:  X=(480, 24), y=(480,)

⚠️  Limiting training data: 1919 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  471 samples, 5 features
✅ Client client_65 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 12 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0826 (↓), lr=0.001000
   • Epoch   2/100: train=0.0850, val=0.0823, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0840, val=0.0818 (↓), lr=0.001000
   • Epoch   4/100: train=0.0838, val=0.0820, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0833, val=0.0822, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0775, val=0.0846, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 12 Summary - Client client_65
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0214
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0169
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2436, R²: -0.0220

============================================================
🔄 Round 16 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0862 (↓), lr=0.000250
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0825, val=0.0865, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0866, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0817, val=0.0867, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0802, val=0.0880, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 16 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0014
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0073
============================================================


============================================================
🔄 Round 18 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0817 (↓), lr=0.000063
   • Epoch   2/100: train=0.0835, val=0.0817, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0833, val=0.0817, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0829, val=0.0818, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0822, val=0.0823, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 18 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0088
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0126
============================================================


============================================================
🔄 Round 19 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0793 (↓), lr=0.000016
   • Epoch   2/100: train=0.0841, val=0.0793, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0840, val=0.0793, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0839, val=0.0793, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0839, val=0.0793, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0836, val=0.0794, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 19 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0168
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0149
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2375, R²: 0.0271

📊 Round 19 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2378, R²: 0.0240

============================================================
🔄 Round 22 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0883 (↓), lr=0.000004
   • Epoch   2/100: train=0.0834, val=0.0881, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0832, val=0.0878, patience=2/15, lr=0.000004
   ✓ Epoch   4/100: train=0.0830, val=0.0877 (↓), lr=0.000004
   • Epoch   5/100: train=0.0828, val=0.0875, patience=1/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0822, val=0.0870, patience=2/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0819, val=0.0868, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 22 Summary - Client client_65
   Epochs: 24/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0181
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0288
============================================================


============================================================
🔄 Round 25 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 25 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0085
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0027
============================================================


============================================================
🔄 Round 26 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 26 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0112
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0159
============================================================


============================================================
🔄 Round 27 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 27 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0262
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0196
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2383, R²: 0.0296

📊 Round 27 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2384, R²: 0.0292

============================================================
🔄 Round 29 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 29 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0192
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0171
============================================================


============================================================
🔄 Round 31 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 31 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0100
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0263
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2387, R²: 0.0278

============================================================
🔄 Round 32 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 32 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0164
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0038
============================================================


============================================================
🔄 Round 37 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 37 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0114
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0114
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0265

============================================================
🔄 Round 42 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 42 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0199
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0233
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0265

📊 Round 42 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0265

📊 Round 42 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0266

📊 Round 42 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2390, R²: 0.0265

============================================================
🔄 Round 51 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 51 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0157
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0383
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0265

📊 Round 51 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0266

============================================================
🔄 Round 56 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 56 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0215
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0312
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0266

📊 Round 56 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0267

============================================================
🔄 Round 62 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 62 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0142
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0064
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0262

============================================================
🔄 Round 65 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 65 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0065
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0220
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0259

📊 Round 65 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0259

============================================================
🔄 Round 70 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 70 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0138
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0091
============================================================


============================================================
🔄 Round 72 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 72 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0051
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0250
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0260

============================================================
🔄 Round 73 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 73 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0143
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0137
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0260

============================================================
🔄 Round 74 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 74 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0138
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0327
============================================================


============================================================
🔄 Round 75 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 75 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0094
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0104
============================================================


============================================================
🔄 Round 77 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 77 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0137
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0052
============================================================


============================================================
🔄 Round 79 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 79 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0149
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0128
============================================================


============================================================
🔄 Round 80 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 80 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0106
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0041
============================================================


============================================================
🔄 Round 81 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 81 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0104
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0050
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0253

============================================================
🔄 Round 86 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 86 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0111
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0043
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0253

============================================================
🔄 Round 87 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 87 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0072
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0097
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0254

============================================================
🔄 Round 88 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 88 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0149
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0154
============================================================


============================================================
🔄 Round 90 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 90 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0121
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0129
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0256

============================================================
🔄 Round 91 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 91 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0021
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0383
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0256

============================================================
🔄 Round 93 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 93 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0043
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0565
============================================================


============================================================
🔄 Round 94 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 94 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0080
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0124
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0257

📊 Round 94 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0257

============================================================
🔄 Round 96 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 96 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0181
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0306
============================================================


============================================================
🔄 Round 99 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 99 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0103
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0035
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0253

============================================================
🔄 Round 105 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 105 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0125
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0107
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0253

📊 Round 105 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0253

📊 Round 105 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0253

============================================================
🔄 Round 108 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 108 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0086
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0005
============================================================


============================================================
🔄 Round 109 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 109 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0021
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0331
============================================================


============================================================
🔄 Round 110 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 110 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0124
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0069
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0254

📊 Round 110 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0254

📊 Round 110 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0254

============================================================
🔄 Round 114 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 114 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0120
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0073
============================================================


============================================================
🔄 Round 115 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 115 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0095
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0043
============================================================


============================================================
🔄 Round 116 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 116 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0100
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0013
============================================================


============================================================
🔄 Round 117 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 117 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0124
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0060
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2393, R²: 0.0252

============================================================
🔄 Round 121 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 121 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0078
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0110
============================================================


============================================================
🔄 Round 122 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 122 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0143
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0407
============================================================


============================================================
🔄 Round 127 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 127 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0103
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0161
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2393, R²: 0.0250

============================================================
🔄 Round 128 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 128 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0180
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0353
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2393, R²: 0.0250

============================================================
🔄 Round 129 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 129 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0103
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0004
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2393, R²: 0.0249

============================================================
🔄 Round 132 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 132 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0107
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0018
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2394, R²: 0.0248

📊 Round 132 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2394, R²: 0.0248

============================================================
🔄 Round 134 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 134 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0107
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0037
============================================================


============================================================
🔄 Round 135 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 135 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0044
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0192
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2394, R²: 0.0247

📊 Round 135 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2394, R²: 0.0244

============================================================
🔄 Round 140 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 140 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0013
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0339
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2395, R²: 0.0242

============================================================
🔄 Round 141 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 141 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0158
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0276
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2395, R²: 0.0241

📊 Round 141 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2395, R²: 0.0241

============================================================
🔄 Round 146 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 146 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0006
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0217
============================================================


============================================================
🔄 Round 147 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 147 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0140
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0223
============================================================


============================================================
🔄 Round 150 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 150 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0018
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0232
============================================================


============================================================
🔄 Round 151 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 151 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0092
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0025
============================================================


============================================================
🔄 Round 152 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 152 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0063
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0060
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0236

📊 Round 152 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0235

============================================================
🔄 Round 155 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 155 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0068
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0067
============================================================


============================================================
🔄 Round 156 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 156 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=0.0097
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0116
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0234

📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0234

============================================================
🔄 Round 158 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 158 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0017
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0191
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0233

============================================================
🔄 Round 159 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 159 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0158
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.1072
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0232

============================================================
🔄 Round 161 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 161 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0075
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0013
============================================================


============================================================
🔄 Round 162 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 162 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0055
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0021
============================================================


============================================================
🔄 Round 164 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 164 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0079
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0184
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2397, R²: 0.0229

============================================================
🔄 Round 166 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 166 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0132
   Val:   Loss=0.0929, RMSE=0.3049, R²=-0.0301
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2397, R²: 0.0229

============================================================
🔄 Round 169 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 169 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0165
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0818
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2397, R²: 0.0229

📊 Round 169 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2397, R²: 0.0229

============================================================
🔄 Round 171 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 171 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0016
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0340
============================================================


============================================================
🔄 Round 172 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 172 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0039
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0091
============================================================


============================================================
🔄 Round 174 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 174 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0000
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0242
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0231

📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0231

📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0231

📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0231

============================================================
🔄 Round 180 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 180 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0052
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0538
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0232

📊 Round 180 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0232

📊 Round 180 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0233

📊 Round 180 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0232

============================================================
🔄 Round 190 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 190 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0059
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0053
============================================================


============================================================
🔄 Round 191 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 191 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0024
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0414
============================================================


============================================================
🔄 Round 193 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 193 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0034
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0113
============================================================


============================================================
🔄 Round 194 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 194 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0038
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0144
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0234

📊 Round 194 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2396, R²: 0.0234

============================================================
🔄 Round 200 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 200 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0095
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0250
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0233

============================================================
🔄 Round 201 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 201 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0058
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0020
============================================================


============================================================
🔄 Round 202 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 202 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0065
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0004
============================================================


============================================================
🔄 Round 203 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 203 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0043
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0009
============================================================


============================================================
🔄 Round 204 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 204 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0065
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0008
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0232

📊 Round 204 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0231

📊 Round 204 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2397, R²: 0.0230

============================================================
🔄 Round 209 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 209 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0128
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0380
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2397, R²: 0.0229

❌ Client client_65 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
