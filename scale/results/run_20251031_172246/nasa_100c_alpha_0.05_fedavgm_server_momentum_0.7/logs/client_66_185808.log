[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ddb4beb-c52a-4bd9-bff7-f77e5c19445c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e160479-1ee2-4c36-807f-04da75cd3cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fbffa40-29d6-4b6a-b09b-1c04ed498fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4298391-5a91-43e3-82da-d3356f33e710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98307536-d6a7-4386-bd26-d375f7c21c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd2fdd4b-314c-4862-b66a-c22bf0ec1b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e087f5-3aee-470f-9e8f-423060ea7b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69de5a6d-359d-4197-a4bc-10f49434f15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a26946-15c8-41fb-b033-c60b6c5efe4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f931a18-5175-4da7-94b9-3d40c1535675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a0d9f81-fbb3-45a4-bd64-56d5e127de72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d1a63c-b1ce-44d2-8c18-8c29c0152aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 322f26a2-07aa-4607-9b55-33447fbf0948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 434c0dfc-ef4b-43c1-8c3b-1d5d93b44576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05957332-1cdf-4dd3-8ccd-ea97aba7acac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d88c784-6f75-455a-8fe7-60fb350327fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9998fe79-a41c-4de6-b7d6-071adea58ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8efccb27-baf3-40ff-aaf6-f3e0eba90fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047230f3-0e41-4613-a4f2-636e015fb025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff23fca-64fd-4e18-a553-5e5bcf01db3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e759a9bd-b460-45e1-bbd1-9106d3fc5acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8590da8f-7be0-4bae-bdfa-de329b96930f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 005ad757-88a1-4366-adf1-dcbc0da3a404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28dc1115-434a-4997-a0bf-0668ba907b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d7d79c6-6747-416e-8515-e093efecd0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 445c0055-93b9-4180-9de9-d506ea5a9c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3a3752-896c-45f4-87c9-3ce92d2a6c7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e530cc1-5356-4b34-8381-050ce259af67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f97b9021-7fc8-4bcd-a922-581aa19ff88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c265f2c5-6d0c-42a5-8f7c-6f0cf35da642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6a51d2-ec0f-45c8-945c-10a9a83ada72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13364efd-f04a-4bd1-a318-ae97a5cfee25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f284495c-8966-489b-83d5-d2042dda62e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7088f8-3ca6-4dd5-9bbc-b4b5ec089a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff6f8ac1-e6bb-46f7-bd33-47d3913307b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2e4b27-54ca-4abc-9298-27e3efacc76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7cbc6d-927a-4c11-9730-d2485ecc80ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad00f50-c6f0-4d2d-9319-da1a8ac76e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d851c23c-925a-406b-bb18-b88e730301a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d4c7fb-9ff9-4d90-b5fd-5d6d789a5342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d95ef5c3-1359-4630-a86e-ec371890cfd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21fd63ee-2047-4158-971c-12aebcd955fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f0cfb7-0c22-4e23-8c3c-21053c7f7709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f730584-c666-4697-a8ca-0df3e85398be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa804fdf-a22e-4cff-bf2a-e6f4b2472628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5868b4-4e09-4963-9645-a54e4eec2d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c509120-aaa2-4072-a7be-ba1a78c0d4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec01904-a40e-45c8-a6fd-e0ed0302cfb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63efbd30-5f48-409f-8724-b177f97b35ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7c1698-593c-4b23-98dc-aefaf3a9a19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5a9300-b1c1-4dfe-9297-2eb1d5d69007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af241744-cc48-4be1-ad75-7c826af14549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fa86d13-d2a7-4c73-b7cf-4bbd16e93b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c978538b-f70a-47d7-8c7f-2fa656784452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 363e021c-931d-48e5-9803-a5bd4423e723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e5d93a-c411-4ef3-a501-054a4df17290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c55ebcd-db83-4bd0-8373-1f4b8b46f1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd48873-15a5-4c4f-b849-f0ee410fc367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384fdf04-859e-425e-837e-7e31a4269d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39afed14-36de-416b-bb8f-1cb22ff10aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 897e3a51-66ae-4979-b105-4c37f0f5e833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf56995-756c-4120-a735-8c1ed05a844b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98a3662e-9cc4-413b-b46b-99acf8b2a721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84158ffd-03e4-480e-87a8-750914e721d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b6514b-d037-4ad6-b4ba-41c31c5185be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7514dca4-21ee-448f-a141-425f32ae098c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 847b8986-82b8-49c1-b5af-b846b8c3ee21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf083613-d20d-46f2-a538-7ff52345a5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77baf57b-9376-4394-8da0-54e8681398dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4781ef2-51bf-4ec4-9b00-14839d0dc4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc4a209-3d0d-4a5d-8930-e9776786c68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84965ac7-ae44-4b59-9410-c2b21ad545ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba278985-ed4a-414b-9056-5313db081ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af88985f-d0ed-40a4-ac7e-7cc77db660f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 870e2659-a1bb-482f-931f-75ad95745b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a8ca71-ca34-4c54-89cd-cc073c35c70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea11aa94-2848-49b3-9f49-d6f3b9c8c784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6418421-49dc-4788-8eca-a2e8b618d1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4842761-55b3-47f3-9405-abfe1a63c1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8e9ed23-35f4-4e98-aa59-03e216bdb785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d44cfe4-a4b4-4aaa-8c48-202473bf72b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0d0369-5de5-4262-aa05-05f7ee9e391f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f42fc0db-45ee-499d-b67c-4452ce6b9cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e6b68a-9d44-440f-a4c0-0914d861c2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a879213-2be3-44c0-b6e4-34e202792ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed3fa9b-1d97-47f2-b6e7-8b678bd5213b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f807f0-d25a-4baa-9e8a-3da7ecebe8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bc1997d-bd90-4419-9f01-9d2bcc4f6daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f615ba8e-9faa-40bf-943a-09bb105d8582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a442f2-db30-4f67-8103-4a06011da5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4777158-0a2a-4e5b-b6d9-ea3f90b014b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f882908-e776-41ae-bc7b-f256ef740a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2312121c-bee2-4bc9-91a4-39a3e5dd7751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc9caf03-c72d-4fa3-a675-f654273bb745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b33278-9706-466e-aee0-e0a2f7420dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f159875b-2366-4530-a157-5b7ccafc01c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1637271d-09b9-4ad7-bf38-4b529528f69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 132e7531-feab-40e9-ab32-cf813cd8a777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2ee15e2-f1a7-4eed-95df-b5d73648a7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379e4cee-c749-4618-93e7-cdfc5e8dfd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d07aa05-88b0-41b3-98c5-c1c425669eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2bbd4b-50e3-406e-b5cb-d7b5caa8d063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6094ebf-8cf2-4a19-a05e-d624cdc05098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc50feaa-b7e1-4256-8b08-765dcaf881ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f757d9c5-aa95-4caa-bc33-4b35d498750c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee29201-bada-4d15-bc4e-54d35cb6f06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15b50b1-e9dc-4cb4-be36-390706162b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bbe240f-bac7-400d-a5d9-62f0c47564c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e009c1f2-d20a-45c1-8120-a24cb393478a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7bf6b63-4826-47e9-8d6f-80747ed62968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c5a2733-a14a-4b25-b990-3f1d1e76d05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe222122-c53d-4a14-ae54-39422eb88d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c7ddb8-82c0-4d40-8f84-5b82624f3317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c60825de-ef12-495d-979a-5d4973bc0f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79c55cf-5504-4278-bf12-e8e85888af64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 253eeecc-71d5-4ba4-9206-f6c8fc2a0045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c1c21c-5084-433d-ab6f-ed122d0d8428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788b5937-fafc-45e0-97cb-a415885db519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18c13ae3-c1f4-43cb-880f-c275a6946818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4d4b60-976a-4e25-a167-0d541ce75298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de8db4a-d302-4dcb-bfa4-aa5b235d0d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e676ae70-362e-4230-9c94-5b0d36d11179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6306a3ea-3389-4e78-a194-e2c6cafe9790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38900e66-a563-4e51-b3e6-ec3479f55bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ebef151-bd6d-473d-9c5c-bfe5a3d9dd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd11987-8489-45f8-a990-ea72a7189f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc3f851-01d9-46a3-93fa-b3addea5e145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8132901b-93bf-4be7-b78c-2f1cd60d179e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588d04a0-6376-415f-83db-a090003d6d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7570c4ee-c258-4064-a2f4-bcb60d59cb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e030988-b6bc-41ff-9835-813deeab515e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296cced3-98d1-441a-9f65-9a3332ea29dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51221bf2-a23f-4515-81b1-d49aaf422261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 836334f1-d1ad-43db-a066-69ec48d931b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9d1615-cccf-459e-89ce-22c2ac543aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c7007c8-ccdd-49b2-b158-09cdf1c42a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2c996e-1729-44ec-be91-637986801386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f65636-9c95-4ef8-8802-ba55ab1d5bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e53c23-2e95-40de-b601-fd77a7ef55e9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_66
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_labels.txt

📊 Raw data loaded:
   Train: X=(1796, 24), y=(1796,)
   Test:  X=(450, 24), y=(450,)

⚠️  Limiting training data: 1796 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  441 samples, 5 features
✅ Client client_66 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0927, RMSE: 0.3044, MAE: 0.2613, R²: -0.0948

📊 Round 0 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2595, R²: -0.0857

============================================================
🔄 Round 19 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0829 (↓), lr=0.001000
   • Epoch   2/100: train=0.0830, val=0.0833, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0820, val=0.0838, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0812, val=0.0842, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0740, val=0.0896, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 19 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0175
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0160
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0927, RMSE: 0.3045, MAE: 0.2607, R²: -0.0952

📊 Round 19 Test Metrics:
   Loss: 0.0934, RMSE: 0.3056, MAE: 0.2616, R²: -0.1033

============================================================
🔄 Round 22 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0778 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0878, val=0.0771 (↓), lr=0.000250
   • Epoch   3/100: train=0.0864, val=0.0768, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0858, val=0.0769, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0840, val=0.0772, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 22 Summary - Client client_66
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0307
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0210
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0935, RMSE: 0.3059, MAE: 0.2618, R²: -0.1049

============================================================
🔄 Round 23 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0882 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0884, val=0.0872 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0875, val=0.0864 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0866, val=0.0856 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0858, val=0.0851 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0839, val=0.0839, patience=4/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0834, val=0.0838, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 23 Summary - Client client_66
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0202
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0463
============================================================


============================================================
🔄 Round 25 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0793 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   • Epoch   2/100: train=0.0909, val=0.0791, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0906, val=0.0791, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0904, val=0.0790, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0902, val=0.0790, patience=4/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0893, val=0.0789, patience=10/15, lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0887, val=0.0787, patience=5/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0884, val=0.0786, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 25 Summary - Client client_66
   Epochs: 31/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0583
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0452
============================================================


============================================================
🔄 Round 26 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.1013 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.1013, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.1013, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.1013, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.1012, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.1012, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1013)

============================================================
📊 Round 26 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0708
   Val:   Loss=0.1013, RMSE=0.3183, R²=-0.1109
============================================================


============================================================
🔄 Round 29 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 29 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0517
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.1044
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2579, R²: -0.0653

📊 Round 29 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2575, R²: -0.0613

📊 Round 29 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2574, R²: -0.0599

============================================================
🔄 Round 34 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 34 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0525
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0444
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0896, RMSE: 0.2993, MAE: 0.2572, R²: -0.0579

📊 Round 34 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2570, R²: -0.0563

============================================================
🔄 Round 38 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 38 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0443
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0829
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0562

📊 Round 38 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0561

============================================================
🔄 Round 40 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 40 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0441
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0685
============================================================


============================================================
🔄 Round 43 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 43 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0504
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0383
============================================================


============================================================
🔄 Round 44 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 44 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0440
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0700
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0561

📊 Round 44 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0561

============================================================
🔄 Round 46 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 46 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0421
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0790
============================================================


============================================================
🔄 Round 50 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 50 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0525
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0873
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0562

📊 Round 50 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2570, R²: -0.0564

📊 Round 50 Test Metrics:
   Loss: 0.0894, RMSE: 0.2991, MAE: 0.2570, R²: -0.0564

============================================================
🔄 Round 55 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 55 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0596
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0033
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2571, R²: -0.0567

============================================================
🔄 Round 59 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 59 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0501
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0428
============================================================


============================================================
🔄 Round 60 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 60 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0403
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0965
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2571, R²: -0.0569

📊 Round 60 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0557

============================================================
🔄 Round 64 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 64 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0422
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0696
============================================================


============================================================
🔄 Round 66 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 66 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0401
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0705
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2569, R²: -0.0548

============================================================
🔄 Round 69 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 69 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0483
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0402
============================================================


============================================================
🔄 Round 73 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 73 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0507
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0314
============================================================


============================================================
🔄 Round 74 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 74 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0394
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0782
============================================================


============================================================
🔄 Round 75 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 75 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0440
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0709
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2570, R²: -0.0558

📊 Round 75 Test Metrics:
   Loss: 0.0894, RMSE: 0.2989, MAE: 0.2570, R²: -0.0555

============================================================
🔄 Round 77 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 77 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0373
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0854
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0893, RMSE: 0.2989, MAE: 0.2570, R²: -0.0553

============================================================
🔄 Round 78 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 78 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0363
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0962
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0893, RMSE: 0.2989, MAE: 0.2569, R²: -0.0552

============================================================
🔄 Round 79 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 79 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0454
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0580
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0893, RMSE: 0.2989, MAE: 0.2569, R²: -0.0550

============================================================
🔄 Round 82 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 82 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0493
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0308
============================================================


============================================================
🔄 Round 85 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 85 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0454
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0453
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2567, R²: -0.0530

📊 Round 85 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2568, R²: -0.0538

📊 Round 85 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2569, R²: -0.0546

📊 Round 85 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2569, R²: -0.0546

============================================================
🔄 Round 94 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 94 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0361
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0918
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2569, R²: -0.0547

============================================================
🔄 Round 95 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 95 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0506
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0616
============================================================


============================================================
🔄 Round 96 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 96 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0453
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0532
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2569, R²: -0.0543

📊 Round 96 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2569, R²: -0.0543

============================================================
🔄 Round 99 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 99 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0435
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0620
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2569, R²: -0.0542

============================================================
🔄 Round 100 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 100 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0376
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0904
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2569, R²: -0.0540

📊 Round 100 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2568, R²: -0.0539

============================================================
🔄 Round 102 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 102 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0473
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0372
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2568, R²: -0.0538

📊 Round 102 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2568, R²: -0.0537

============================================================
🔄 Round 104 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 104 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0358
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0912
============================================================


============================================================
🔄 Round 105 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 105 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0441
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0540
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2568, R²: -0.0537

============================================================
🔄 Round 108 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 108 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0437
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0521
============================================================


============================================================
🔄 Round 109 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 109 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0443
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0647
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2569, R²: -0.0540

============================================================
🔄 Round 110 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 110 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0363
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0912
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2569, R²: -0.0540

============================================================
🔄 Round 111 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 111 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0391
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0702
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2568, R²: -0.0538

============================================================
🔄 Round 112 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 112 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0549
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0194
============================================================


============================================================
🔄 Round 114 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 114 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0469
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0417
============================================================


============================================================
🔄 Round 116 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 116 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0473
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0344
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0891, RMSE: 0.2986, MAE: 0.2567, R²: -0.0528

============================================================
🔄 Round 119 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 119 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0356
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0829
============================================================


============================================================
🔄 Round 120 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 120 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0485
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0271
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2566, R²: -0.0518

📊 Round 120 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2566, R²: -0.0517

============================================================
🔄 Round 124 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 124 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0364
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0757
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2566, R²: -0.0515

============================================================
🔄 Round 125 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 125 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0462
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0383
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2566, R²: -0.0514

============================================================
🔄 Round 126 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 126 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0384
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0599
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2566, R²: -0.0513

📊 Round 126 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2566, R²: -0.0514

============================================================
🔄 Round 133 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 133 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0398
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0549
============================================================


============================================================
🔄 Round 135 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 135 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0422
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0642
============================================================


============================================================
🔄 Round 136 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 136 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0468
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0266
============================================================


============================================================
🔄 Round 138 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 138 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0370
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0881
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0889, RMSE: 0.2981, MAE: 0.2564, R²: -0.0497

📊 Round 138 Test Metrics:
   Loss: 0.0889, RMSE: 0.2981, MAE: 0.2564, R²: -0.0495

============================================================
🔄 Round 141 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 141 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0330
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0903
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0888, RMSE: 0.2981, MAE: 0.2564, R²: -0.0494

============================================================
🔄 Round 142 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 142 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0470
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0241
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0888, RMSE: 0.2981, MAE: 0.2564, R²: -0.0494

============================================================
🔄 Round 144 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 144 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0374
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0544
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0888, RMSE: 0.2981, MAE: 0.2564, R²: -0.0493

📊 Round 144 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2564, R²: -0.0491

📊 Round 144 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2563, R²: -0.0487

📊 Round 144 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2563, R²: -0.0486

📊 Round 144 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2563, R²: -0.0486

📊 Round 144 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2563, R²: -0.0483

📊 Round 144 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2562, R²: -0.0474

============================================================
🔄 Round 167 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 167 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0488
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0154
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2562, R²: -0.0474

============================================================
🔄 Round 168 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 168 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0419
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0252
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2562, R²: -0.0476

============================================================
🔄 Round 170 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 170 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0337
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0671
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2563, R²: -0.0479

📊 Round 170 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2563, R²: -0.0482

============================================================
🔄 Round 180 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 180 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0422
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0297
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2563, R²: -0.0483

============================================================
🔄 Round 181 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 181 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0334
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0722
============================================================


============================================================
🔄 Round 182 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 182 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0454
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0229
============================================================


============================================================
🔄 Round 187 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 187 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0394
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0554
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2563, R²: -0.0486

============================================================
🔄 Round 189 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 189 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0356
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0624
============================================================


============================================================
🔄 Round 190 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 190 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0346
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0617
============================================================


============================================================
🔄 Round 191 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 191 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0377
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0522
============================================================


============================================================
🔄 Round 192 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 192 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0375
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0563
============================================================


============================================================
🔄 Round 193 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 193 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0378
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0488
============================================================


============================================================
🔄 Round 194 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 194 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0375
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0505
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2564, R²: -0.0489

📊 Round 194 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2564, R²: -0.0492

📊 Round 194 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2564, R²: -0.0490

📊 Round 194 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2563, R²: -0.0483

📊 Round 194 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2563, R²: -0.0484

============================================================
🔄 Round 207 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 207 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0396
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0372
============================================================


❌ Client client_66 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
