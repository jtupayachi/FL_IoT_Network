[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ac1a2fb-e7ea-4aed-b5de-3eff678dce9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2f1f46-0924-4636-af71-c0a3e76bd705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6fe9725-3262-428d-b0fb-46e1071e9ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3a5299-dc41-44e9-9f37-7a9e9a27973d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c18b74a-3cde-48b4-8395-0a4658684a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078e7d8e-a529-4cf7-aa36-d6021d849418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4717ba4b-adb6-44d5-ae12-e720cfbe6d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b17a818-1063-4ea1-8571-e0b8c563a9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb3a12d0-550d-464c-bcc9-ee06f7938559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae5e8ae-9edd-4247-b0b4-197c5d4193fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 341bc8ec-7049-4d1c-99b2-706e2fe46ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca0af517-ace3-4eba-a491-05badc949ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaf21374-ad76-4bd0-b0f4-bccd60197ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e9b563-9362-49c8-9510-6a1f42390a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06392781-e91c-408d-8900-74f55de0ba3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cbcf0c-9bba-4f68-aaa4-4a27225dec10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7977005-6aaf-4ba2-b430-a95f9c3c0056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a321fa-1ffb-4b5c-a198-a0b37a0b029f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5465096c-fc04-4db8-be51-87ba36005284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36d37a9-a657-47bf-8908-2bff2ca17497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83f8780-3fb5-42d8-871f-0341f63cc2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d0bd63b-3ad8-4f9c-ac26-02e06b4e66f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 741dd670-1f72-4b5b-a69f-5d1a2a185cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c7111cf-8ee6-4b09-bd18-c02f6f9d1747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a65647-3ff1-4dc1-865b-39c2dff7bc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b971e747-e660-4fef-95b6-01328ad82d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef5269c3-c9e7-4dba-b394-a308d014c366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc4fbac-0af3-48f7-a6f1-2bcedb486b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f3e58c2-5383-419a-9edc-6aa51d275bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf03d607-9c3b-42a7-a183-8d11a2bd51a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e10fc4d-2266-4d79-a3ab-56683d91b383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140d7b13-af9f-49fd-8fca-88ed5e5efe77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0722b86e-c85a-4a91-a2bc-1d135dd963fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90677681-df7d-4725-a05d-c97e93378eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26fd30c3-ad03-4d10-847d-0046b1c59dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be7385f9-cf5f-42fe-9888-9e2acaa3d006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16e9cba-88bc-48a8-95d8-6bb3c757efdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afac675b-f654-4065-a892-56a26aba724b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90f4e3d-b711-4f51-8053-2abd4b0bfbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae1a14c-b1b1-41e6-9c12-a1fbab65f65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1b56c3b-2e43-4685-bdae-58a107ea3f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd7b9be8-354c-43cb-996b-bbc4ba47c6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561de16c-a635-4ef9-a41f-0c21d51a95f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0e4387-3610-44d9-afd1-9b325d7cfd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cb2de5-ee09-4d4f-9ff2-c7e9fc66c67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d0eca8-5687-4e98-acc8-a56d9d26a3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2be8ea-97c0-4470-98f9-d0feea9bf502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fbdb535-9d60-429b-b4a0-838fee2cf3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b708d91-e488-41c1-8251-07dc6b14568a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d168341c-0c5c-4a66-93d4-630a1b1f3022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd3e3544-afde-42d4-b5bf-35856ee01ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98faae0e-c369-460d-a00a-933357bd12f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c273375-e39a-43e4-9b52-4720f598d4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4357e0-9d9d-4f76-b98c-29877485f8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbee930-9c23-45ec-97f5-995ce0f6e709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe44e39-36c6-4723-a9be-1a1ad1fe296f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c344513-7144-4bb1-a5e4-a68030fdecec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e4d235a-895f-4a4a-93b0-a7ac6771a64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1d1c52-9fc3-4afb-9e47-a7f1379bb8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448875ad-dd4f-478b-a237-6a844108c3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a30866a-0b5f-4312-8030-53c6b85e9c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae1ee0c-090c-4030-937e-2f598b18e817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f6ac4c-96aa-4cf6-8ec7-7ba8b5ab7203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d7e8bd-d0dd-4e87-8263-47383e6696d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408645e0-1b90-4f8f-842e-674501d9feec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5cc0aec-1ded-4997-9bcb-aea405e7d8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6771efd3-e164-46ff-88fa-282e1512d12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97d12f0-f0f7-48ee-ad0d-4ab68f4e6f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ddbe0d-b24a-4722-81e7-e2e099a1875a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65d6680-98ac-4bbe-8c27-ec1f997e4686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07fdcfe-41ad-473c-894c-79f25d1b6fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0000b1cf-1c69-4452-8c0f-9817e79ec59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df5e2f66-cf80-4efd-afc5-bd57e82b5306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 830be3a9-b887-4e23-9f2d-94efbaf481c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab001c4-6016-4790-a1f3-343cd2a80712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2235a680-fdf7-4ad4-9ce7-4261651e2cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 062af5ca-e3ee-4a67-b93b-b30f66dedbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40938597-7f44-4504-8b6c-b7e7e908f5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c42c98-45a0-4b86-a02c-78cbe37dd6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39dff7dc-163e-4270-a1a6-ff25cd229573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a18300-5eb6-4424-92ea-89ff1dfe1afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca08fd1-ec83-4950-8c84-ea69f85a1921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b84805e-6b4d-4aa0-a8f8-e3cf243fcf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7199a7ab-e05b-443c-a86b-7a00a589036a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fecb3981-4f64-4f8d-9bd5-e923da5aa51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7fc4ad-381c-492b-ab46-9fab39ea3814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 478a1a06-80a9-4e92-9927-146b0e504bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca057da-56f9-4e4e-a213-1fbc58782bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f572bae5-cf75-42da-874b-86b9b658c8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72b8c1c-ca1d-4878-aa5e-c24b0aa646a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a7325cc-a0c2-4254-9ea3-47e72f07343a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4773c9f-70f1-425c-acfb-2a497e83c225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 301e38f0-2c1b-4183-bfda-9165e6e13fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc5efab-41a3-4d43-beda-f6a92e500872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e5f762-25d1-496c-b948-6f63d3bcb5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a86fb09-3d5c-405d-b1e1-2bcffd0831b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c76e2135-6d8f-41a7-a8b0-f042eb4e6c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efaa0ee2-1db5-439d-8eab-059ac60b6b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d26fa0-62a7-483a-8cf3-06073f3b32f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c1190c-acaf-4f5d-a12e-2360abedf69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31141f73-ba23-4940-8444-989da214f6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf01db14-523b-4919-b73c-d6c40929bf9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d547f9-bcb7-4a54-bf43-7cf8e451482a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705d37c8-5a40-4ad5-99eb-57d43da83052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3737c6-7765-440f-8aba-61460b312ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ec4e35-6b43-4abb-9252-ce5b09d5360b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bf0392-1b00-4172-a49a-9967798e7431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8208b3df-4cd8-4835-9e46-b74d628208a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee1c270-1dfb-4962-b0de-20e2d91414e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27054482-4a16-4b9f-8163-b9b527d09f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705e6f66-4142-43b5-a440-07e882abe645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4de71cb-5633-4415-a7b0-5c4f3aa3011e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed134ad-ddfc-4b8c-b512-52ab78b5f553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d222b4-51c3-409d-8c71-e6ba5cdf83fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed35d6f0-1ad8-41b3-8ed0-902ec2935f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 983e4908-9bf6-45d9-88d8-5b4f7c5da6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21b0e12-bdd5-4c74-a5f1-d51b11046f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cc42555-c56c-48bb-a78e-aa1fb30bb653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc99e26a-b063-469a-a198-9dc435268ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff5c80f6-5f9e-4c9d-8b31-3160f402a741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c97e275b-5e58-4b22-a3bf-683f05cd2cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df32a12c-8695-4b97-aba8-97b2f69d6deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ff3ee8-049b-41b2-9fd6-7c2a72a38aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78b0897b-1281-4ffe-9acb-a0874c97f8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc375902-54b0-4f81-aa86-d46aed89a98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf44f49-d3bc-409c-8398-99c38bfb3cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4afd069-b08a-44e9-8f74-4bd306fe6472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d541bb-6f7e-428a-8ddb-5f6c6a5e5790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b02d1ebf-c18b-4f45-86e5-f4a8fe430b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5881ff-3a1f-4f64-82ee-00e9606bcffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de3c93fd-0815-48b1-9942-f225017099c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1b8d44-0ed0-43d9-a868-52d0bafaa443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77747048-4b85-4a93-a94c-300f20377c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c7208d-f283-4ffd-ad71-87848438d707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52282340-1153-4bb0-90e5-32cb6422fd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e949733f-bb26-496c-b440-9573e2445992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64e2ff4-350b-4869-93a6-59efbb5bfc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b9ae437-9377-48a5-88bb-833d1f7be341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c579d34-6e6c-4699-bcbe-9e3ce77b9978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9368efa-b31d-4cf0-a878-60a21bfe03e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2377b7-eb9d-402c-ae89-292de2960322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e4fecd-f1ab-49df-a689-1df8b1d30f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f48d1c-a028-4ed5-a92d-cb5551a5738f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6989bcea-59cd-46a3-92cd-045cc222066a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c88fa39-3dfd-4f56-a725-caebba2c15bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1b9e8e-f3db-4d6b-ae88-c8680e132f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e864361-f63a-4c24-bd03-9922c2fa504f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2176ea89-8f64-4df7-82ca-e026427b7786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abac565-811a-4799-9c75-25e9aaa23a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77a3ee1-2a39-47eb-a4f7-1325198724cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3dc396-bf88-414d-b13a-8164a23ac4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf950cc-1f75-4b6c-ae3a-af47d8946a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b682e7eb-09e2-4690-9525-77387e326287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f4b728-94ef-45b4-91c0-3105ba8742fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0071890-3b5c-46c1-976e-e01ba3ccc98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d35a1e35-33c5-4fdb-bce1-001a6f7e2f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9be1216f-6a8a-46a1-90f9-f75d0e0b425d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc04be8-b621-445f-b3c0-09d130623691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a2ed61-ab22-41bf-8bec-0ce4767b412d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48504681-ac90-4e8f-8552-154d323a98c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8a6693-4aac-4b42-ba38-dc9e2ad3f6a5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_67
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/test_labels.txt

📊 Raw data loaded:
   Train: X=(1552, 24), y=(1552,)
   Test:  X=(389, 24), y=(389,)

⚠️  Limiting training data: 1552 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  380 samples, 5 features
✅ Client client_67 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0857 (↓), lr=0.001000
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0820, val=0.0866, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0813, val=0.0865, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0807, val=0.0871, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0769, val=0.0924, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 16 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0220
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0808
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2484, R²: -0.0606

============================================================
🔄 Round 17 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0964 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0833, val=0.0956 (↓), lr=0.000250
   • Epoch   3/100: train=0.0825, val=0.0954, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0820, val=0.0952, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0816, val=0.0950 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0804, val=0.0947, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 17 Summary - Client client_67
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0145
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0475
============================================================


============================================================
🔄 Round 18 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0772 (↓), lr=0.000063
   • Epoch   2/100: train=0.0890, val=0.0767, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0883, val=0.0766 (↓), lr=0.000063
   • Epoch   4/100: train=0.0879, val=0.0765, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0877, val=0.0764, patience=2/15, lr=0.000063
   • Epoch  11/100: train=0.0868, val=0.0759, patience=2/15, lr=0.000063
   • Epoch  21/100: train=0.0859, val=0.0756, patience=12/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 18 Summary - Client client_67
   Epochs: 24/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0317
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0237
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2464, R²: -0.0485

📊 Round 18 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2464, R²: -0.0493

📊 Round 18 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2475, R²: -0.0574

============================================================
🔄 Round 27 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0920 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0834, val=0.0907 (↓), lr=0.000063
   • Epoch   3/100: train=0.0829, val=0.0907, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0827, val=0.0908, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0825, val=0.0909, patience=3/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0818, val=0.0911, patience=9/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 27 Summary - Client client_67
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0204
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0670
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2445, R²: -0.0262

📊 Round 27 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2442, R²: -0.0235

📊 Round 27 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2440, R²: -0.0219

============================================================
🔄 Round 32 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0888 (↓), lr=0.000016
   • Epoch   2/100: train=0.0838, val=0.0886, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0835, val=0.0886, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0833, val=0.0886, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0832, val=0.0886, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0829, val=0.0887, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 32 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0318
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0500
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2437, R²: -0.0201

📊 Round 32 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2437, R²: -0.0196

============================================================
🔄 Round 34 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0779 (↓), lr=0.000004
   • Epoch   2/100: train=0.0869, val=0.0778, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0868, val=0.0777, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0867, val=0.0777, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0866, val=0.0777, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0865, val=0.0776, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 34 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0407
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0199
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2436, R²: -0.0193

============================================================
🔄 Round 35 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 35 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0305
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0628
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2436, R²: -0.0190

============================================================
🔄 Round 36 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 36 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0309
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0548
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2436, R²: -0.0186

============================================================
🔄 Round 39 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 39 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0337
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0421
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2435, R²: -0.0185

============================================================
🔄 Round 40 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 40 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0282
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0589
============================================================


============================================================
🔄 Round 44 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 44 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0377
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0273
============================================================


============================================================
🔄 Round 45 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 45 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0276
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0615
============================================================


============================================================
🔄 Round 46 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 46 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0391
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0231
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2436, R²: -0.0184

📊 Round 46 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2436, R²: -0.0184

📊 Round 46 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2436, R²: -0.0183

📊 Round 46 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2436, R²: -0.0183

============================================================
🔄 Round 53 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 53 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0405
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0395
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2436, R²: -0.0183

============================================================
🔄 Round 58 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 58 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0312
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0529
============================================================


============================================================
🔄 Round 59 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 59 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0359
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0365
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2436, R²: -0.0184

============================================================
🔄 Round 60 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 60 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0329
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0555
============================================================


============================================================
🔄 Round 61 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 61 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0392
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0349
============================================================


============================================================
🔄 Round 62 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 62 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0395
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0138
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2436, R²: -0.0178

📊 Round 62 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2435, R²: -0.0176

============================================================
🔄 Round 67 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 67 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0218
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0799
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2435, R²: -0.0176

============================================================
🔄 Round 69 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 69 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0380
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0203
============================================================


============================================================
🔄 Round 71 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 71 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0348
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0417
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2435, R²: -0.0177

📊 Round 71 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2436, R²: -0.0177

============================================================
🔄 Round 76 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 76 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0327
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0422
============================================================


============================================================
🔄 Round 77 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 77 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0265
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0716
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2435, R²: -0.0175

============================================================
🔄 Round 78 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 78 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0315
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0512
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2435, R²: -0.0170

============================================================
🔄 Round 82 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 82 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0280
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0502
============================================================


============================================================
🔄 Round 83 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 83 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0354
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0424
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2434, R²: -0.0168

============================================================
🔄 Round 86 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 86 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0323
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0339
============================================================


============================================================
🔄 Round 88 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 88 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0294
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0609
============================================================


============================================================
🔄 Round 89 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 89 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0379
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0106
============================================================


============================================================
🔄 Round 90 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 90 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0320
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0426
============================================================


============================================================
🔄 Round 91 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 91 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0338
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0362
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2435, R²: -0.0170

============================================================
🔄 Round 93 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 93 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0352
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0255
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2436, R²: -0.0170

============================================================
🔄 Round 96 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 96 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0335
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0427
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2436, R²: -0.0170

============================================================
🔄 Round 97 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 97 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0318
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0389
============================================================


============================================================
🔄 Round 98 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 98 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0302
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0437
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2435, R²: -0.0168

============================================================
🔄 Round 102 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 102 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0398
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0186
============================================================


============================================================
🔄 Round 103 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 103 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0240
   Val:   Loss=0.0965, RMSE=0.3107, R²=-0.0640
============================================================


============================================================
🔄 Round 104 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 104 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0339
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0463
============================================================


============================================================
🔄 Round 105 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 105 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0252
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0589
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2435, R²: -0.0166

============================================================
🔄 Round 107 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 107 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0336
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0331
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2435, R²: -0.0167

============================================================
🔄 Round 111 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 111 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0328
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0331
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2436, R²: -0.0167

============================================================
🔄 Round 112 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 112 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0372
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0115
============================================================


============================================================
🔄 Round 113 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 113 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0367
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0196
============================================================


============================================================
🔄 Round 114 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 114 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0269
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0553
============================================================


============================================================
🔄 Round 117 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 117 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0310
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0354
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2435, R²: -0.0164

📊 Round 117 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2435, R²: -0.0163

============================================================
🔄 Round 124 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 124 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0269
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0476
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2434, R²: -0.0161

📊 Round 124 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2434, R²: -0.0161

============================================================
🔄 Round 126 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 126 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0323
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0254
============================================================


============================================================
🔄 Round 128 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 128 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0318
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0250
============================================================


============================================================
🔄 Round 129 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 129 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0297
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0423
============================================================


============================================================
🔄 Round 130 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 130 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0308
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0296
============================================================


============================================================
🔄 Round 132 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 132 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0274
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0485
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2434, R²: -0.0159

============================================================
🔄 Round 133 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 133 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0322
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0256
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2434, R²: -0.0158

============================================================
🔄 Round 137 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 137 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0230
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0570
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2434, R²: -0.0157

============================================================
🔄 Round 138 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 138 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0307
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0418
============================================================


============================================================
🔄 Round 140 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 140 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0265
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0447
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2433, R²: -0.0155

📊 Round 140 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2433, R²: -0.0155

============================================================
🔄 Round 144 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 144 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0299
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0306
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2434, R²: -0.0155

============================================================
🔄 Round 147 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 147 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0302
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0349
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2434, R²: -0.0155

📊 Round 147 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0154

============================================================
🔄 Round 149 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 149 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0260
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0455
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0152

============================================================
🔄 Round 155 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 155 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0326
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0160
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0151

============================================================
🔄 Round 159 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 159 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0299
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0412
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0150

📊 Round 159 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0150

============================================================
🔄 Round 162 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 162 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0277
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0361
============================================================


============================================================
🔄 Round 163 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 163 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0214
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0574
============================================================


============================================================
🔄 Round 164 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 164 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0342
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0256
============================================================


============================================================
🔄 Round 165 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 165 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0324
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0154
============================================================


============================================================
🔄 Round 166 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 166 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0287
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0296
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0148

📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0148

📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0149

📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0149

📊 Round 166 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0149

============================================================
🔄 Round 175 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 175 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0339
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0224
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0149

============================================================
🔄 Round 177 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 177 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0330
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0425
============================================================


============================================================
🔄 Round 178 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 178 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0301
   Val:   Loss=0.0966, RMSE=0.3107, R²=-0.0278
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2433, R²: -0.0149

============================================================
🔄 Round 179 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 179 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0293
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0387
============================================================


============================================================
🔄 Round 180 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 180 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0244
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0649
============================================================


============================================================
🔄 Round 181 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 181 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0327
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0143
============================================================


============================================================
🔄 Round 183 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 183 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0266
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0410
============================================================


============================================================
🔄 Round 184 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 184 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0295
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0298
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0150

============================================================
🔄 Round 185 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 185 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0231
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0574
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0150

============================================================
🔄 Round 188 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 188 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0326
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0156
============================================================


============================================================
🔄 Round 189 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 189 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0328
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0171
============================================================


============================================================
🔄 Round 190 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 190 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0315
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0283
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0150

📊 Round 190 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0150

============================================================
🔄 Round 192 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 192 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0300
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0321
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0150

============================================================
🔄 Round 193 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 193 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0271
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0583
============================================================


============================================================
🔄 Round 195 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 195 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0361
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0011
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0151

📊 Round 195 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0151

============================================================
🔄 Round 197 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 197 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0243
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0513
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0151

============================================================
🔄 Round 199 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 199 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0179
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0781
============================================================


============================================================
🔄 Round 200 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 200 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0280
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0344
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0150

============================================================
🔄 Round 201 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 201 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0325
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0156
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0149

============================================================
🔄 Round 202 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 202 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0263
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0409
============================================================


============================================================
🔄 Round 204 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 204 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0279
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0352
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0149

📊 Round 204 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0149

📊 Round 204 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0149

============================================================
🔄 Round 208 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 208 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0334
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0171
============================================================


============================================================
🔄 Round 209 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 209 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0323
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0190
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2433, R²: -0.0148

============================================================
🔄 Round 211 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 211 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0267
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0351
============================================================


❌ Client client_67 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
