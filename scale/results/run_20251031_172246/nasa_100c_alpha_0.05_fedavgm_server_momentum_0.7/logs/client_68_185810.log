[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35158b6d-78b4-403b-b3ae-3c954f4e4fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c83d305-46af-4c01-807d-76b55ea86461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cbe17ac-6750-48fa-a71b-89fbdb2d6f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef466e5-0fee-4975-a8e4-1f7dbc99926a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619cdcd3-f07d-4ead-9f7d-f64ad6a7f4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8251566-aed8-4fef-b77c-5b6cf9bf151b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca4864e-f05e-47f8-b6fb-9e8e90a6f93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 387e38ae-35cd-4658-917c-ba48587172c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77aa5d14-edb9-4b5a-9f4a-7ac5ad1bba3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b471ef-ceb3-4666-a175-c4f91387a5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5179516d-921e-4a50-88bf-4b56c61c7397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7eae51-b351-4fdc-a195-96b5460bbc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7ce72d-f2d4-48f6-8271-23514b08cabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55b55a7a-3307-4b7b-bd4e-ee00050bc522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6bfd8a-44d9-4f7b-84a9-4b74e4c001ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4790dc47-c3dd-4742-a79b-9ef37fe7d2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81bd696-6efc-4043-b422-487b43542c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145c980a-379b-4e33-88e5-044acba42680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a32f35aa-e4a9-45d6-881c-d91f47d5960b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94eec49-9d10-4b97-b5fb-77a5a013cacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7093da97-07cb-4feb-832d-1ab6ef14ace8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b0549b-fa9a-452c-bfd4-7da053558a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94dd87e-0abf-4363-a8fc-44be02800c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7537825c-51e2-4ef2-9134-90cb3b99a7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582ca36f-9dd6-458b-89f3-9bed3763f97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6073b587-5ab6-4eb3-9d77-d5087431e7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6318727-388d-4dfc-a03c-d26e52dcba4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417a8540-aa3c-4b98-8372-deb0d0907948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a249669-2db5-4fa6-8b18-bab6ba5da49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d08f6c3e-06ec-4ff1-a72e-9b2a7fea3bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7842f13b-2477-4bfd-bd59-526c08bf1e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea59ced-45a1-4627-b963-ec9ccc8c838a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a4e63d0-7a68-41ea-938a-d5563a91e6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f38ad6a6-a382-4098-b664-202bc53d62c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8913c084-9b93-49cb-b8f2-f6584dfcf11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c92048dc-75f9-4d56-93a6-e639c23f9345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb6f4719-725e-44b7-9dcf-7647912f3aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6a61be-15d3-46cd-9b6c-784bd7a096bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba4a255-ecaa-4f7f-b284-666f8ff11e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ad07d3-4e2f-4b35-98e5-3cdfdb88b8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12bce29-d4d5-48ed-87dc-8a389de6cad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb61c6b-bf9c-49ef-83dc-be8ff936b332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a420906a-d80a-43e6-8f14-3597732461ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba25a93-1956-45a1-8d81-485c2dcf8bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24011e75-0711-4508-812d-da2a3cd55a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b80e86-d32e-4ea9-adb1-4c7e5084a27c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 019287b1-2a33-43e5-98a7-4ca33d4be468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34c6131e-10d9-4860-b9f1-44cc34e12af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23e0dded-1447-49d8-908a-009511e211f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8c90a0-0530-46e0-b5ef-184b2fcd920c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6cc751f-ac96-403c-81fa-a5c3f3c644e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 176c4a71-d7ee-4498-a974-e54b736dc9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16aab29-65ca-441b-bb81-0758c3c47c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd9efc4-f29f-479a-9064-e7bf2f484d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fd56f8-fdf8-4bfb-9e94-ffc89486b85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e4acc2-737f-4e72-958b-c238b0cfe26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29fd58ae-34fb-4723-9761-c7c51174e801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0421c63b-d9d4-4096-94c9-da2682265157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7924b137-364b-4434-ad03-93b22e23d29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 338db66a-fdc0-4065-8421-c10017599bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7169b63-446b-4936-b881-8cbcbe1856b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8579e42a-0be1-4525-b16e-b441ece3ebce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ad7e84-2de3-45ea-a7e5-f52c29131d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4496597a-ccb9-4afc-a246-0ee4ad2ab0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4666b0e-c310-43c2-a66e-d7591d6347f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6406130-d366-4d7f-9fa3-82d07c581132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b039237-bf37-4d8b-be90-d2e32b49fb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e74af4-fa36-4fef-81c1-9cecf59ad273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1bedd8-e007-4475-93e0-6d23478506ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c4c5134-905c-43c3-850a-6f366ed07e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c019edf-e00e-48fe-aa8a-c70896b63d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f6b9cd-1a49-4301-bf34-b8463fa8f709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cc157fc-c033-4f17-9d99-2687e5341106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9206b55b-f781-4625-bb00-710b50cdf543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 280829e5-db89-4d4f-a862-74ca70076bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008f600c-4d82-40d6-9a25-2837ebf5644c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 370a567e-eacc-46ad-9528-2774c20ba0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b692d5-8b01-4174-afe1-8c8978e0be77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693ae451-2589-4c8f-a497-cc39d8c425ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf4e1d6-1c31-4b13-9581-45b19ee40228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 856d929c-243d-47dd-b9c7-c616592c0706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafc4335-4881-4ecd-823c-d7f764dcef6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2d6b45-5581-4e2f-a394-ea7aa9e225a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bec691fe-9050-42ad-ab00-b4cc2ca11537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa940ca-75bc-471f-8e61-2cf7604ec0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f28604-d3d0-4402-b8a9-2c30a2e85994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 742ad64a-4c98-4dc0-9f3f-00200a37e3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f65d52-14dc-4f1b-9bc3-df4573d3dfd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb7d22a-6056-4fe5-9ded-203a5156ae27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58865f59-f9a3-4cb1-b45c-23cc27bb6a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c9768fb-998c-4782-a3ac-69c9b9a6419a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ecd6743-ee7d-4cab-a89e-ff49d2ff4675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2015942f-60bd-4685-b016-b6fc5297787c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 183d0ae0-9c32-4d73-bdb2-e82bb894652b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7178940-4b62-4b33-8f0e-4af561ad0163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a70132f-1777-4e09-96d0-8ce2b75f51e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d866c74-ea33-4f9c-917b-044b27072476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c356343-3d1e-4983-a7e2-dc0ad9426e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec3f427-ca56-4018-95fc-b63e528b5c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e2e6f8e-6a88-45e6-9d21-6aaa1a084700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94f072f-338f-4af7-a365-878495e08efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5644546d-5134-48c0-bcbe-0b2d387ed7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3273330-2ab9-4158-a1c2-8984624fbc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33a4463-baf7-454a-8671-0e2be48aa7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc2caef-b40b-4f88-8fb3-9bbbcb6cb254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d12fe7c1-f004-4656-9a1b-0fdb02325781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996e1864-e54d-437b-9574-404a0f1d8fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ded09f-099d-4301-a964-1200ad397134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c75b71-c178-4ae0-b9c8-40597e2f04c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab42b3b2-ba71-4fb9-bf93-65cda0ad3cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14bd2c3a-895e-4548-a90f-048685e1fb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87d3fa9e-08e0-4a34-8f71-81b25edbfe7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d3d6fa-3ed0-4d69-8530-61665411c1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c118a4-9b12-4931-b735-4ec44fb70d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e322f0-ac37-4dfd-8e6d-5b09c374c0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787b8ca4-5c69-4812-aaab-ef26ed6517cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d64df65-1606-4469-8053-938071149777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be234c3-a09f-47fd-b723-a86ebe45357b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce60f650-f226-44d1-9832-464d552f0b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 797e855d-ccb7-4b30-b2e5-80305b879fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43bdf3e7-4bc9-4b6f-9a1f-4bbd1a3b990b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc85628-a5d0-44d3-8c31-477fe471e099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8396a8ea-f863-4a9c-950c-bb3b6b988226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a182fca-b88c-4682-a5d4-3dc7ee04eaa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9133d647-4a59-4533-b024-ff9a9a4c326d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f6ae7e-e900-4ffd-88a7-22f85b296a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21f58579-92c4-475c-8c9c-ea87d51eafd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77829ba7-8839-4a3f-ad5c-0b2090d3e495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a94102a-6a66-48ac-956b-21fd757b82df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a9f72d-8613-4f69-89b8-f34f619e19ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd722a0b-a0e8-4202-a239-5c14ff2284a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c975c3e1-dea3-4c61-a4d5-597c6c464186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a71d69f5-583d-4c15-9670-1d5f963d8e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c511fc-59ba-4c53-8ab6-665b5251bf64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d89c079e-0c2b-4c71-ae02-c8221ac7eb4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53db4f08-39ba-48b2-b48c-a34e8ea7bcbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2b88f7-76c8-4f58-82b4-93ea300e64fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5eb03a2-d084-4f77-8910-b15f49074c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c57a3b7-552b-45c0-9623-6b412f34470b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ffee48-c6d3-4c2c-908c-45849d558340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273ead12-d579-4452-a9fc-117821a983dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b37115-d6c8-4754-9acb-8cea7e8d46e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8921e952-9896-4411-af74-7786da89ac08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce23c56-d78e-4f0e-9136-e9cfd4d43aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b5913a-fa89-45b8-aa21-144db80fc13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a386a87a-e2f5-41ae-beb8-ae74cbfaa592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da06d29-504a-4772-9c63-ea2ab58652ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71a83a23-96c0-4fb6-b3ba-2f163f37474e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_68
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/test_labels.txt

📊 Raw data loaded:
   Train: X=(1040, 24), y=(1040,)
   Test:  X=(261, 24), y=(261,)

⚠️  Limiting training data: 1040 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  252 samples, 5 features
✅ Client client_68 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 17 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0872 (↓), lr=0.001000
   • Epoch   2/100: train=0.0840, val=0.0874, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0817, val=0.0875, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0809, val=0.0876, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0760, val=0.0877, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 17 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0014
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0015
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2473, R²: -0.0380

============================================================
🔄 Round 20 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0953 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0830, val=0.0947 (↓), lr=0.000250
   • Epoch   3/100: train=0.0827, val=0.0944, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0942, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0817, val=0.0941 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0802, val=0.0936, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0790, val=0.0936, patience=8/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 20 Summary - Client client_68
   Epochs: 28/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0320
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0034
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2507, R²: -0.0536

============================================================
🔄 Round 22 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0792 (↓), lr=0.000031
   • Epoch   2/100: train=0.0870, val=0.0789, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0867, val=0.0788, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0865, val=0.0787, patience=3/15, lr=0.000031
   ✓ Epoch   5/100: train=0.0864, val=0.0786 (↓), lr=0.000031
   • Epoch  11/100: train=0.0857, val=0.0784, patience=6/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 22 Summary - Client client_68
   Epochs: 20/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0115
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0121
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2512, R²: -0.0564

============================================================
🔄 Round 24 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0914 (↓), lr=0.000031
   • Epoch   2/100: train=0.0840, val=0.0912, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0837, val=0.0910, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   • Epoch   4/100: train=0.0835, val=0.0909, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0834, val=0.0909 (↓), lr=0.000016
   • Epoch  11/100: train=0.0831, val=0.0906, patience=6/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008
   📉 Epoch 20: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 24 Summary - Client client_68
   Epochs: 20/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0023
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0274
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2487, R²: -0.0374

📊 Round 24 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2470, R²: -0.0263

📊 Round 24 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2466, R²: -0.0241

============================================================
🔄 Round 28 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0756 (↓), lr=0.000004
   • Epoch   2/100: train=0.0877, val=0.0756, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0876, val=0.0756, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0876, val=0.0756, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0876, val=0.0756, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0875, val=0.0757, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 28 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0197
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0158
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2465, R²: -0.0237

============================================================
🔄 Round 29 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 29 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0136
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0193
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2464, R²: -0.0234

============================================================
🔄 Round 34 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 34 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0161
   Val:   Loss=0.0911, RMSE=0.3017, R²=-0.0043
============================================================


============================================================
🔄 Round 38 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 38 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0198
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0095
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2463, R²: -0.0225

============================================================
🔄 Round 45 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 45 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0143
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0065
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2463, R²: -0.0225

📊 Round 45 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2463, R²: -0.0225

============================================================
🔄 Round 49 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 49 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0148
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0041
============================================================


============================================================
🔄 Round 50 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 50 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0175
   Val:   Loss=0.0938, RMSE=0.3062, R²=0.0042
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2464, R²: -0.0225

📊 Round 50 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2464, R²: -0.0225

============================================================
🔄 Round 53 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 53 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0154
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0045
============================================================


============================================================
🔄 Round 54 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 54 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0153
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0060
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2464, R²: -0.0226

============================================================
🔄 Round 56 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 56 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0069
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0360
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2464, R²: -0.0226

📊 Round 56 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2464, R²: -0.0226

============================================================
🔄 Round 59 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 59 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0131
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0210
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2464, R²: -0.0226

============================================================
🔄 Round 60 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 60 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0117
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0271
============================================================


============================================================
🔄 Round 61 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 61 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0091
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0274
============================================================


============================================================
🔄 Round 62 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 62 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0127
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0137
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2464, R²: -0.0225

📊 Round 62 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0225

============================================================
🔄 Round 64 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 64 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0143
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0045
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0224

📊 Round 64 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0224

📊 Round 64 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0224

============================================================
🔄 Round 69 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 69 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0189
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0051
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0225

============================================================
🔄 Round 71 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 71 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0121
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0261
============================================================


============================================================
🔄 Round 75 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 75 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0086
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0337
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2465, R²: -0.0225

============================================================
🔄 Round 77 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 77 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0129
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0104
============================================================


============================================================
🔄 Round 80 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 80 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0120
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0140
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0223

📊 Round 80 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0223

📊 Round 80 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2464, R²: -0.0223

📊 Round 80 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0226

============================================================
🔄 Round 90 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 90 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0095
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0581
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0227

============================================================
🔄 Round 95 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 95 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0081
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0302
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0228

📊 Round 95 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0227

============================================================
🔄 Round 97 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 97 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0151
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0071
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0227

📊 Round 97 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0227

============================================================
🔄 Round 100 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 100 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0061
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0399
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0227

============================================================
🔄 Round 101 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 101 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0146
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0067
============================================================


============================================================
🔄 Round 102 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 102 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0058
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0396
============================================================


============================================================
🔄 Round 104 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 104 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0111
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0178
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0228

============================================================
🔄 Round 107 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 107 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0141
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0054
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0228

📊 Round 107 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0229

📊 Round 107 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0229

============================================================
🔄 Round 111 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 111 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0181
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0097
============================================================


============================================================
🔄 Round 112 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 112 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0117
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0160
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0230

📊 Round 112 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0230

============================================================
🔄 Round 120 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 120 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0169
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0076
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0230

============================================================
🔄 Round 121 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 121 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0084
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0517
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0230

📊 Round 121 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0230

📊 Round 121 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0230

============================================================
🔄 Round 124 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 124 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0160
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0235
============================================================


============================================================
🔄 Round 125 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 125 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0118
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0165
============================================================


============================================================
🔄 Round 127 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 127 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0136
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0137
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0230

📊 Round 127 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0231

============================================================
🔄 Round 133 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 133 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0126
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0317
============================================================


============================================================
🔄 Round 134 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 134 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0147
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0050
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0230

📊 Round 134 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0230

============================================================
🔄 Round 138 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 138 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0091
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0247
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0229

============================================================
🔄 Round 143 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 143 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0169
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0004
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0228

============================================================
🔄 Round 145 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 145 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0206
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0096
============================================================


============================================================
🔄 Round 147 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 147 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0150
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0031
============================================================


============================================================
🔄 Round 148 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 148 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0103
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0238
============================================================


============================================================
🔄 Round 150 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 150 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0089
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0257
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0227

============================================================
🔄 Round 154 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 154 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0113
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0171
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0227

============================================================
🔄 Round 156 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 156 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0117
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0214
============================================================


============================================================
🔄 Round 157 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 157 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0081
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0391
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0226

============================================================
🔄 Round 158 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 158 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0106
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0235
============================================================


============================================================
🔄 Round 161 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 161 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0167
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0051
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0226

📊 Round 161 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0225

============================================================
🔄 Round 164 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 164 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0123
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0116
============================================================


============================================================
🔄 Round 165 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 165 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0168
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0106
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0226

📊 Round 165 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0226

============================================================
🔄 Round 169 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 169 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0126
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0310
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2465, R²: -0.0226

============================================================
🔄 Round 170 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 170 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0125
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0345
============================================================


============================================================
🔄 Round 171 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 171 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0144
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0037
============================================================


============================================================
🔄 Round 175 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 175 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0146
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0059
============================================================


============================================================
🔄 Round 179 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 179 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0115
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0152
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0229

📊 Round 179 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0229

============================================================
🔄 Round 181 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 181 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0102
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0192
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0230

============================================================
🔄 Round 183 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 183 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0106
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0205
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0230

============================================================
🔄 Round 186 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 186 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0138
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0099
============================================================


============================================================
🔄 Round 187 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 187 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0145
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0278
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0231

============================================================
🔄 Round 188 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 188 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0114
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0208
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2466, R²: -0.0231

📊 Round 188 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2467, R²: -0.0231

📊 Round 188 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2467, R²: -0.0232

============================================================
🔄 Round 192 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 192 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0113
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0295
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2467, R²: -0.0232

📊 Round 192 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2467, R²: -0.0232

============================================================
🔄 Round 195 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 195 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0184
   Val:   Loss=0.0975, RMSE=0.3122, R²=0.0029
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2467, R²: -0.0233

============================================================
🔄 Round 197 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 197 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0143
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0172
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2467, R²: -0.0233

============================================================
🔄 Round 198 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 198 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0090
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0297
============================================================


============================================================
🔄 Round 200 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 200 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0141
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0046
============================================================


============================================================
🔄 Round 201 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 201 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0095
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0701
============================================================


============================================================
🔄 Round 202 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 202 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0101
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0331
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2467, R²: -0.0233

📊 Round 202 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2467, R²: -0.0233

📊 Round 202 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2467, R²: -0.0234

============================================================
🔄 Round 207 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 207 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0115
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0162
============================================================


============================================================
🔄 Round 208 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 208 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0089
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0244
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2467, R²: -0.0233

📊 Round 208 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2467, R²: -0.0233

❌ Client client_68 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
