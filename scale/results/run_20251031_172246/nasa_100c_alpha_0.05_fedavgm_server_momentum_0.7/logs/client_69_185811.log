[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fa98ef4-20a1-4cbd-b6ec-2ce72196166f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c27884d8-9f69-4411-8939-db768cf61701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14f7295a-bb70-4b95-8bd1-093da6c3e2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010a9d1c-9d72-480e-88f7-af7de10f17e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4593b24-88c6-4ffb-8e08-6948b06aa51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c47ab2fc-2867-468b-a79e-3b64b627c3c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936280ad-15e1-4032-935e-c39f7d01f301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9936a05-268f-4d44-ad0d-eaf3c2305ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdaeee76-2b15-4cd2-8986-ade443ede05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4898d40c-204a-4120-89d2-fd0d0111e91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e74339-74f4-4f2e-bc7c-83b250720dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bfa062-1584-432d-8b5b-f6b750a0405e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99fb1e0a-4f18-4ef6-88f2-045912ce31d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a48751-2417-4298-9a88-93f836ee1bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f4d254b-4cd5-41cc-8ac4-840b52d90e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59bd1c2-6465-4fdd-819d-937f3cf8047e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2b8e12-72c1-46df-899c-31770256cc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10bae25-c247-4e6c-837f-49aa57717942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7653c59-fa35-4798-a028-65fa8049126e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f991259-151d-4419-aa80-3a2b29541b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a769a184-9fe2-4325-8361-4930d75a925d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e6e690-9036-467d-9127-c13dababeb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 736b01c2-6814-4f06-bb75-0973a4a0b9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0572ddac-8137-4e0f-8ce3-ffb02cad8f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c6eeff-6396-4a02-8491-86d87aa529d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac3ca17-f00e-4666-bc82-49f3cfd654aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62073424-fae8-4219-9d46-251daf4a117c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c4cd31-aafc-4621-8c38-9496b8fb603d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15adebc2-cee3-420f-b66c-d3c3aead8006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b34960a-8e70-4680-ab9f-809438897389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b1a627-7d4d-403d-849e-37d0c05dafa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 727d715d-f862-496a-962b-1bf2a5f8124a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622b3fd5-412f-4dc7-861e-3dc9b3bf9b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65302e7a-2924-4284-a634-ed9c0e9c5296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0762f7-11a5-4e2c-a493-c1df02763290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3337a4f-4a77-442d-894a-02777d679af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78cd5dfd-4b51-4a37-883e-1db10ccc0ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ca79d0a-0685-4a93-9de9-455172ecaa6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d57eb6d-2629-4860-a165-b8ad23124a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8a2241-fa90-47bc-8725-dc229db0b945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84673400-d2b3-47b2-86c6-66dff764105f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed0fcc5-ecdf-4396-96b8-842e64627cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02812209-007a-49e9-84b3-fcc86385883d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c1cf14-1d11-443a-8759-d686ffa6df13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f57d23-00a8-438c-895b-ccafa48b4b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bff600b-4d91-4887-b6b1-64ab4eabbfc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b491d28-a8d0-44ab-86db-600ad57c8c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b08714-43a6-4cf5-8cee-a5dc42baf89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7568736-b8fb-42c9-9b80-934d58a22e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5657adfd-8d44-4eda-b56b-4beff80c5321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe41a52-2567-4c87-be5e-d48775af3331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c13af6e-d0f1-42fc-9527-69f6dfdda6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d94e959-7120-448c-973b-a8a1f0e4f21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01f02939-dbe9-4c8c-8093-1f5e265d984f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7bfead-6f6a-466b-9c1b-42a614c09aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d84287e7-8874-4f99-9c29-103627bd5689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b74705-6a84-48de-b7c9-0e23a43a378b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53252a2-2847-4561-8e9b-4606c764ec8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd2cec3-cfd9-4e11-908a-3f770fafc3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d804db26-2ff9-46f1-8cf9-b1a328c78792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f371a9b4-7263-469a-80a0-18082c43fd61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e6d2f1-3899-4683-9ac3-c8aeb4931c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f249b0-54b1-46fc-92ff-0b933e237d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c5d5f9-f205-4a4d-9bbf-ebd644a3c9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12c80d9-6101-41de-b53b-939dae8f3eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30fdba1d-b7e9-4e64-b9b4-93b1ff34d9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e496714-f778-4777-a714-bbf532a85e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a5d1669-9d4c-46e0-8eb8-39c506fd9f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2017134c-1dff-4181-8b8f-8776e43c93d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d72fc18-ca13-40de-a59b-75cba40e4bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c17c546-7677-427c-bf29-07e2a6397fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a8ac37-a125-463e-97ec-ca0dbabe2d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d1cd4e-0ba6-4b2b-8d0d-efdbed26dfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dff4aaf-417a-4d33-a8cb-f61f7fa6db12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af50857-02c4-4016-8d5f-d81e7f9f0913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16fc766f-791f-4b2f-831f-daf39766e5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d30d6d5-7e5d-4094-99af-27d22d8c210d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636161b8-51a5-4ca3-bb1f-b9961723d060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c4edc1-e45e-43fe-a765-43ad6c5e22c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176da0e3-aa63-4870-8b37-95102d28c38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60a56dc0-96c1-4113-93d0-ed46612c4f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2adc88ba-96a1-43bf-8424-8e4dfbcf808a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a16181-f2d9-47f9-a3ff-b2994943534e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4602f0f1-e314-4eed-95a4-215d05cb2bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c9dd7f-d757-412e-9805-05c90f63278d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b9bbb2-caa3-4ab5-8426-f21bf3719d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5523211-2dcb-40dd-a8f7-f00b2c6a002e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2533fe-467f-4510-a721-376f5f641894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023af2a6-1955-4732-abf1-05eea54e1889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c435f1-ad35-42a5-b1c3-0a7814f380ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686bbc2d-2842-46c0-94a3-93c7acfc1e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fdd2711-237e-4161-97e8-4191dd9474b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95cadcd-251b-41a4-b1df-0a5f7720bac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc0e530-f8d5-45d5-a143-0e45eeee6ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f6477e-bef6-46bb-a9b0-5b003744aa65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3793de00-5052-4b0e-8894-78d33fc32e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917daffa-2130-4c5d-8312-51abfbf5ea30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597c4e80-58a7-4050-932e-592e8703b83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6029f8-9c0d-4f05-a7be-5ef2477569e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf93823e-0cd7-412f-9267-7460790efd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e9c72cc-339f-4c89-a2c1-d6030b42aebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5261d7d-308d-4b7f-b440-80882f084315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a010d7ab-7477-4bc8-bd51-54529a0058d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6e480ef-a723-457f-b477-0c7d1d405fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aff628fb-97a8-4258-bb5a-52713e3c7e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d352eeaf-f0c2-472f-97b9-6e9566ba80ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56081c3e-35f9-40f2-80f7-a638c5d0efe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0edb0d-5979-4928-8c7b-1660e3ddf5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef2b574-8d81-44fb-b699-4c9989f96298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ee0b34-8128-4b31-aa80-0fff6b9051a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6ded04-5e63-40ae-aed6-2b88bf75f000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0815a565-1d2f-4229-941f-bdb3b7661681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72554904-391b-48b4-9821-dda190098a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a009f7-742e-4920-b5cf-8318c8adcb4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d0b193-d588-43e9-8914-426623db4d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ea1f00-64fe-4383-9e86-585b001327bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c686dcc-1003-403a-970e-6f4737977692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b05390b-41fa-4fe6-b4c7-1e1885bddc01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3f1ab9-9b1b-4f28-a596-fb48db93b513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936e97c6-56be-4ef4-82ce-b2a26a8d7ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08636bbc-fec6-4eef-8292-6bed21ab0412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cd565be-5be4-4289-be09-f29df0e62b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dafce16-c2e6-4de0-a259-33493778f80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a301294-5ae6-44ca-8fea-eb8bc491e93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf68d07e-1058-4f56-b8bc-651a3788b863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 948134c7-fa60-40aa-b3db-00ea54031660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ace94f4-f06a-4ec7-9dd8-4f3316e6f564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bc101ef-5a1b-44a9-81dd-3e0c36c7e75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703d869e-e1ec-4ae8-99bb-f2d92296089e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45388d76-a4fe-4381-a933-3ca9ce7714f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc624aa-e646-4dce-a60b-ac2bcd54baad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93937e33-efcf-4208-893b-5f89428d775d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f278dfaf-62aa-44f1-aa69-38535b53b1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 781923eb-744e-4a44-831f-620e395d7691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6dda04e-cc78-4418-b4af-b70e91fa55d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83c3d14c-a956-42c4-8d2a-7b00055e4f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a911ff5b-08bb-44f5-b77a-61bf4c7400e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a60a3f-ba95-4604-a433-8b9865ed8013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78782311-480a-49f5-8bd1-71e5fc0ff6f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced061a1-d328-481d-8246-f7f568c7ec60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bd4950-8508-450a-9325-a0f1bad0b57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752a203a-e736-4402-980e-cf322b27d1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04669f8-dd07-4562-9154-08246251e3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ac3c5e-9619-4b43-a824-5bee183424df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5109d4df-2613-48a6-9447-64aed384758c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48a1580-2314-497e-b7b1-8fc0d1b887df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf530b6-cb86-4d52-a23a-57fd3f8c9e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5807b730-6238-4d5d-ae52-13bf0c4fca3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f93115ab-80b8-4a06-b81c-627d17955fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c1bc90-57ca-4ab9-90fa-bb7a65df9293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1be273-98cc-4aba-9ecf-9ca6fe207015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac8685e-d815-45ff-8142-f44e89659c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b30be8-473e-4ee8-ad7d-d4fbabe4045d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b145bb-b665-4961-8672-4008461f0296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38d8692c-e936-4a93-b615-82a9be39701f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47753a09-4305-43fe-9856-65e274ec76b9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_69
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_labels.txt

📊 Raw data loaded:
   Train: X=(824, 24), y=(824,)
   Test:  X=(207, 24), y=(207,)

⚠️  Limiting training data: 824 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  198 samples, 5 features
✅ Client client_69 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2594, R²: -0.0402

============================================================
🔄 Round 15 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0903 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0824, val=0.0888 (↓), lr=0.001000
   • Epoch   3/100: train=0.0815, val=0.0886, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0810, val=0.0882 (↓), lr=0.001000
   • Epoch   5/100: train=0.0806, val=0.0881, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0765, val=0.0880, patience=7/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0613, val=0.0919, patience=8/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 15 Summary - Client client_69
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1160
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0113
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0928, RMSE: 0.3046, MAE: 0.2604, R²: -0.0505

📊 Round 15 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2582, R²: -0.0146

📊 Round 15 Test Metrics:
   Loss: 0.0895, RMSE: 0.2992, MAE: 0.2575, R²: -0.0136

============================================================
🔄 Round 22 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0811 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0838, val=0.0798 (↓), lr=0.000250
   • Epoch   3/100: train=0.0827, val=0.0797, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0819, val=0.0795, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0793, val=0.0801, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 22 Summary - Client client_69
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0127
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0378
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2574, R²: -0.0327

============================================================
🔄 Round 24 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0781 (↓), lr=0.000125
   • Epoch   2/100: train=0.0848, val=0.0780, patience=1/15, lr=0.000125
   ✓ Epoch   3/100: train=0.0838, val=0.0772 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0834, val=0.0766 (↓), lr=0.000125
   • Epoch   5/100: train=0.0830, val=0.0764, patience=1/15, lr=0.000125
   • Epoch  11/100: train=0.0816, val=0.0755, patience=4/15, lr=0.000125
   • Epoch  21/100: train=0.0800, val=0.0753, patience=9/15, lr=0.000125
   📉 Epoch 23: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 24 Summary - Client client_69
   Epochs: 27/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0182
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0760
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0906, RMSE: 0.3011, MAE: 0.2569, R²: -0.0259

============================================================
🔄 Round 26 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0827 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0837, val=0.0811 (↓), lr=0.000063
   • Epoch   3/100: train=0.0829, val=0.0807, patience=1/15, lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.0825, val=0.0805 (↓), lr=0.000031
   • Epoch   5/100: train=0.0822, val=0.0805, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0816, val=0.0804, patience=7/15, lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 26 Summary - Client client_69
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0105
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0085
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2559, R²: -0.0157

============================================================
🔄 Round 28 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0869, val=0.0764 (↓), lr=0.000008
   • Epoch   2/100: train=0.0861, val=0.0760, patience=1/15, lr=0.000008
   ✓ Epoch   3/100: train=0.0856, val=0.0757 (↓), lr=0.000008
   • Epoch   4/100: train=0.0852, val=0.0756, patience=1/15, lr=0.000008
   • Epoch   5/100: train=0.0848, val=0.0754, patience=2/15, lr=0.000008
   • Epoch  11/100: train=0.0839, val=0.0749, patience=5/15, lr=0.000008
   📉 Epoch 17: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0833, val=0.0749, patience=15/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 28 Summary - Client client_69
   Epochs: 21/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0048
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0127
============================================================


============================================================
🔄 Round 29 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0873 (↓), lr=0.000004
   • Epoch   2/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0830, val=0.0869, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   ✓ Epoch   4/100: train=0.0828, val=0.0867 (↓), lr=0.000002
   • Epoch   5/100: train=0.0826, val=0.0866, patience=1/15, lr=0.000002
   • Epoch  11/100: train=0.0821, val=0.0864, patience=7/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0817, val=0.0862, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0814, val=0.0860, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 29 Summary - Client client_69
   Epochs: 34/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0127
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0256
============================================================


============================================================
🔄 Round 32 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 32 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0164
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0140
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2551, R²: 0.0043

📊 Round 32 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2551, R²: 0.0050

📊 Round 32 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2552, R²: 0.0060

============================================================
🔄 Round 37 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 37 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0188
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0503
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2552, R²: 0.0060

============================================================
🔄 Round 38 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 38 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0002
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0215
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2552, R²: 0.0061

============================================================
🔄 Round 39 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 39 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0171
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0516
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2552, R²: 0.0059

============================================================
🔄 Round 41 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 41 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0007
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0217
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2552, R²: 0.0057

📊 Round 41 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2552, R²: 0.0057

============================================================
🔄 Round 45 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 45 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0031
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0702
============================================================


============================================================
🔄 Round 47 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 47 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0066
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0109
============================================================


============================================================
🔄 Round 48 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 48 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0099
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0010
============================================================


============================================================
🔄 Round 50 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 50 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0017
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0316
============================================================


============================================================
🔄 Round 51 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 51 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0132
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0256
============================================================


============================================================
🔄 Round 52 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 52 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0088
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0135
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2553, R²: 0.0047

============================================================
🔄 Round 56 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 56 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0053
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0048
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2553, R²: 0.0042

============================================================
🔄 Round 60 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 60 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0146
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0354
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2553, R²: 0.0039

📊 Round 60 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2553, R²: 0.0041

============================================================
🔄 Round 63 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 63 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0055
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0002
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2553, R²: 0.0045

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2553, R²: 0.0046

📊 Round 63 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2554, R²: 0.0047

============================================================
🔄 Round 66 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 66 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0084
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0192
============================================================


============================================================
🔄 Round 67 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 67 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0026
   Val:   Loss=0.1004, RMSE=0.3169, R²=-0.0277
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2554, R²: 0.0047

📊 Round 67 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2554, R²: 0.0045

============================================================
🔄 Round 69 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 69 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0052
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0405
============================================================


============================================================
🔄 Round 72 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 72 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0050
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0374
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2554, R²: 0.0039

============================================================
🔄 Round 73 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 73 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0016
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0240
============================================================


============================================================
🔄 Round 74 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 74 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0081
============================================================


============================================================
🔄 Round 75 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 75 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0066
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0035
============================================================


============================================================
🔄 Round 78 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 78 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0073
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0112
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2555, R²: 0.0036

============================================================
🔄 Round 81 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 81 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0147
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0455
============================================================


============================================================
🔄 Round 82 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 82 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0015
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0032
============================================================


============================================================
🔄 Round 84 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 84 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0009
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0137
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2556, R²: 0.0046

============================================================
🔄 Round 86 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 86 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0006
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0051
============================================================


============================================================
🔄 Round 87 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 87 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0046
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0097
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2556, R²: 0.0041

============================================================
🔄 Round 90 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 90 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0102
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0326
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2556, R²: 0.0028

📊 Round 90 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2556, R²: 0.0027

============================================================
🔄 Round 95 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 95 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0106
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0142
============================================================


============================================================
🔄 Round 97 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 97 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0072
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0544
============================================================


============================================================
🔄 Round 99 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 99 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0009
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0213
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2556, R²: 0.0030

============================================================
🔄 Round 101 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 101 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0021
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0215
============================================================


============================================================
🔄 Round 102 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 102 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0166
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0908
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2557, R²: 0.0030

📊 Round 102 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2557, R²: 0.0030

📊 Round 102 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2557, R²: 0.0029

============================================================
🔄 Round 106 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 106 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0136
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0410
============================================================


============================================================
🔄 Round 109 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 109 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0037
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0019
============================================================


============================================================
🔄 Round 110 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 110 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0064
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0502
============================================================


============================================================
🔄 Round 112 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 112 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0070
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0129
============================================================


============================================================
🔄 Round 114 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 114 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0106
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0275
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2557, R²: 0.0030

============================================================
🔄 Round 115 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 115 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0048
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0339
============================================================


============================================================
🔄 Round 116 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 116 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0172
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0285
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2557, R²: 0.0031

============================================================
🔄 Round 117 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 117 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0009
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0172
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2557, R²: 0.0033

============================================================
🔄 Round 123 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 123 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0050
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0371
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2557, R²: 0.0039

============================================================
🔄 Round 126 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 126 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0039
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0128
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2558, R²: 0.0040

============================================================
🔄 Round 127 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 127 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0001
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0080
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2558, R²: 0.0040

============================================================
🔄 Round 128 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 128 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0013
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0016
============================================================


============================================================
🔄 Round 129 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 129 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0090
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0179
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2558, R²: 0.0043

📊 Round 129 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2558, R²: 0.0044

============================================================
🔄 Round 137 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 137 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0014
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0049
============================================================


============================================================
🔄 Round 139 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 139 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0041
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0193
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2559, R²: 0.0046

============================================================
🔄 Round 140 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 140 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0037
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0077
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2559, R²: 0.0046

============================================================
🔄 Round 142 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 142 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0029
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0026
============================================================


============================================================
🔄 Round 144 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 144 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0016
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0023
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2559, R²: 0.0043

============================================================
🔄 Round 145 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 145 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0078
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0325
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2559, R²: 0.0042

============================================================
🔄 Round 146 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 146 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0013
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0025
============================================================


============================================================
🔄 Round 148 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 148 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0037
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0087
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2559, R²: 0.0042

============================================================
🔄 Round 149 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 149 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0019
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0158
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2559, R²: 0.0043

📊 Round 149 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2559, R²: 0.0044

📊 Round 149 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2560, R²: 0.0044

============================================================
🔄 Round 154 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 154 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0033
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0126
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2560, R²: 0.0045

📊 Round 154 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2560, R²: 0.0045

📊 Round 154 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2560, R²: 0.0047

📊 Round 154 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2560, R²: 0.0048

============================================================
🔄 Round 166 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 166 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0031
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0041
============================================================


============================================================
🔄 Round 167 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 167 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0096
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0266
============================================================


============================================================
🔄 Round 168 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 168 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0013
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0027
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2560, R²: 0.0046

============================================================
🔄 Round 170 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 170 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0047
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0049
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2560, R²: 0.0044

============================================================
🔄 Round 172 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 172 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0005
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0059
============================================================


============================================================
🔄 Round 174 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 174 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0098
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0251
============================================================


============================================================
🔄 Round 180 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 180 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0050
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0109
============================================================


============================================================
🔄 Round 181 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 181 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0074
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0336
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2560, R²: 0.0038

============================================================
🔄 Round 182 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 182 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0028
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0003
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2560, R²: 0.0037

============================================================
🔄 Round 184 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 184 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0037
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0085
============================================================


============================================================
🔄 Round 185 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 185 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0113
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0346
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2560, R²: 0.0035

============================================================
🔄 Round 190 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 190 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0062
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0222
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2560, R²: 0.0033

📊 Round 190 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0032

============================================================
🔄 Round 192 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 192 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0012
   Val:   Loss=0.0985, RMSE=0.3138, R²=0.0071
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0031

📊 Round 192 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0029

📊 Round 192 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0029

============================================================
🔄 Round 195 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 195 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0015
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0005
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0029

============================================================
🔄 Round 196 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 196 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0159
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0852
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0028

📊 Round 196 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0026

📊 Round 196 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0027

============================================================
🔄 Round 203 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 203 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0020
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0018
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2560, R²: 0.0033

============================================================
🔄 Round 205 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 205 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0043
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0074
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2560, R²: 0.0032

============================================================
🔄 Round 206 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 206 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0027
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0140
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2561, R²: 0.0034

============================================================
🔄 Round 207 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 207 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0040
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0016
============================================================


============================================================
🔄 Round 208 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 208 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0031
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0103
============================================================


============================================================
🔄 Round 209 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 209 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0029
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0008
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2561, R²: 0.0035

============================================================
🔄 Round 210 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 210 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0028
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0210
============================================================


❌ Client client_69 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
