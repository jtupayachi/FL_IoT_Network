[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3127f532-c9a9-42a5-977f-7b79bc4dbcb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0256077f-ed8f-47dd-a765-8f97cd5bd492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b214d1ff-d3d3-4be8-b674-6d7044b02f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f2bf784-e7a8-46ad-bf83-8ddd25d56309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 024d6028-3cec-4264-b9e9-eeea30869689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83d926df-0c47-4376-bbcf-7d9fde148349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8877bd84-6ede-4e20-bb6c-2afeadae72b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3202739c-82b7-411e-8c2d-e5a39ca6a81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d2d8a7-d802-4741-b102-8b15d394b5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27025ad-6bef-489d-8830-908c043141d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b75b14-0485-4f31-8fb3-132f79f421ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c4aac7-51d7-405e-9ed7-8f49690648ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2513339e-86df-4cf3-bc86-3012e6a361ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ae7e2b8-5aca-4d4f-90ea-acda2e44df9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d612c09-9b0d-40e3-823d-447dba38328b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45ec86ae-39c1-4eb8-a1c6-c9a22fc5d659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a4c582-0431-48bd-b241-5db633768df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac08614-5480-4d73-8531-3af37542454c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3401d4b-4063-49ee-84b5-c069124c4d94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eacad0d-17a4-464a-9abc-8a6ed34a79fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26317ff-fe16-4563-88a9-9e0218dac527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1afc900-263a-4188-b5d1-91eb5d1c625a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9603d5bc-2b62-48f9-b1cf-f5b569114204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac137c25-240e-40ca-8e30-d667eb12d7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0135b19-a78e-4ff3-b81f-ec6a42ad107d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47621d28-c230-48be-b43f-ce6d48d86a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c0ad2c-0a61-4201-b76c-482cb06192f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c7516f-5502-44ee-8ce2-2ec6a2dacaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a57ecd-d4f2-4ddd-bc6a-468afa1900c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc0022e-9851-49e4-9e9b-2ae89f4e8888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 717c3222-8cfd-4597-b070-347666ccbbc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e47afc-8d3c-4d07-91c2-8ca02614a452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce4213b-84b8-4ffa-ab78-107c8a0e0946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791e2ebf-249c-4d15-b3f5-f72653f00b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa11d2f-289c-443c-9ad7-adbd87da22f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12fde5b-4357-47bf-92c8-976b9e6705a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff4288d-2267-4662-8486-2a88d58e388d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082541c1-f8cf-4d26-bc50-ed3c5c75f878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cbde51d-8a0f-476e-b52b-49628ab4265b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20daf1a-85dc-4793-8814-d6195fce471d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7d9588c-571a-404d-87b2-3dea929651de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02e7e35-c399-4024-86cb-ef75945bba96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608a11cf-2086-44d0-b6a6-c49aa079d9f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3559e010-200f-4bed-9e2a-059d088662f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb3b1dd-5e7f-49e7-9898-687c953c17c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0627482c-f011-466b-8926-d92134b78f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32b284ba-3aa0-4d78-be34-6ba52a306aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b90d88-0264-4883-9c0c-b792852142a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a2f2c57-ad27-4388-9a5c-7bcadc58c7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1839ce78-1084-4243-aa67-b7c486659584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee60e95e-06ef-40fc-a4ab-7eb168b55ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d6cdf1-0194-4bfe-91d3-3b34ec240681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba61563e-23b1-41a0-94dc-ee9339017870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc718e0-e27c-4670-aea2-a8195f7666ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475e027a-458c-49ae-8a54-b499c99ae4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38112349-9ddd-41eb-9113-281907cb51cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df954d9d-34b6-4dc1-a1f5-f9d4bffa7b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d4345d4-d2bb-473e-b6fd-23f019c8697b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6bac7ce-5a6a-477b-994a-eb755dc8e694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023e71ca-1320-4b3a-9641-1b9599fcdad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498ec043-20e8-44c7-b5f7-5d54f0d9308c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75ffae7-a49a-4551-98f2-db21b6bcd607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0896577c-fd12-4708-96cc-dfde6d151367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8494b8cc-1e8f-45fb-9ae2-dd96983e0c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3feb1f-c3d1-4dcb-9337-1667c3fe7284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa291154-8a1e-4963-a922-765705f08154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbde97b7-179c-4608-9bdb-e0e369ad1c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1ede4a-4bdb-4b54-a9d6-80be3981f22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f91899-7c4b-4546-a5c1-bd49e7141449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce180d78-7aca-4869-9c2e-77731145780f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e94cfc-907e-4e4b-a400-4484f6d502d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d746ed04-6e1a-4e22-afe8-63605efc3b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9441781d-ce6c-43ab-bb50-b19993362a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a58335-9d45-4a7d-a007-e8c408e4a85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97c9f7d-3461-4446-868d-ce217e525fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 324b87bb-d400-421b-aadf-ead7fbc6e748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7cb77d7-0e1c-47c4-ba05-788846b8db44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59413048-56d1-4dc8-9281-e4a28028b6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33190a60-3328-4306-b51a-886a0deabc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e508e72-47cb-454b-bad7-4a8452828248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a950dac-6915-422d-81c2-55038d410baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a3719d2-4ccb-46a9-ab2d-13833161855c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b0f89a3-2bfa-45d1-9b54-d9a9ed07ca0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e1e243-e001-4538-ba2d-97901487b3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2cced6f-515f-4211-b728-28621770760c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44fb0eeb-7678-44ae-8a95-5938249cc8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 626a08aa-fa2a-4349-a1d4-9faa7d496ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a342ed-8eee-4d91-9fab-be66348ade4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3cbf56-2e32-4e11-bcf8-bd48ad8f7073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d857ed2e-2f28-4cfa-8255-6b4eb99f72e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de410cc-1c13-417c-8bcd-5bef0a9813bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4c127e-d114-4760-b792-6dde18a26802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c5435ea-3dde-4575-a75f-d9c7e3bf61db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 241793b2-8ca5-4c27-af31-66930a993ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa5905e-b925-4205-9792-ef965783164d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b4ee23-6b55-4f06-b215-ef4afda445b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc23004c-3110-48ef-8080-5c31b9d4d2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d9ce39-de6b-4ad1-abba-01877915e639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fddfca6a-5153-4d2f-8636-e4c4d44b5cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9202796f-ffcf-4ba6-a962-4027ba1380cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948391be-94f9-4260-8d0f-e85404f4eb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c523323-7eb6-4bd0-8f41-7574be962709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5161a44-cec7-47d3-b4d2-30d124f29ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67140c2a-2069-47b9-91c5-0c1fb20c30e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b647b6bb-13ab-476e-aa08-02ca9a9c16b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8965da14-f240-4249-b911-6b7064d97641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57491a88-fd32-4281-8409-162a46b1a7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42fc3c7c-0eb3-47d9-ba5f-5919049c4b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c3246e8-62a2-43db-84e2-90220d20a3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb023b5-4215-4708-8ca7-5b64c917aaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae70c229-1e1f-4474-95aa-989b679ff71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2334c839-c7fe-4b41-b55a-03daf105f724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 557eadc5-7bfc-4b2a-8e12-4b6094e3d810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea590f37-d937-4f8c-9131-790d258d0790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e85aeb4-ab17-4346-9d39-aa12e9419dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d4f429-584d-45ad-8900-7b950165864e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e26976c-2194-461d-b6a7-6bbd0f015585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b315bb-8fed-4211-9ecb-c5db8041e0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b6be35-60f5-4a41-9257-612127914f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611c789e-23de-4432-a398-f7d041e07ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5f79a4-26bd-4f9d-85d6-29eb86c02328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9cfd394-8149-4c33-a970-b0e8b8c071eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4899a65-e69e-41cf-ac32-e0fbcc24c87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b11c30-8284-4312-bdcb-a787ee7ddfe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 756a175b-68d7-4eb8-b91a-363dc0a369ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afff8a3-9c27-4f02-aa87-d27ef4999d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f408dd77-63e7-4c10-8674-b771e5d40feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68f18a9-a0ae-461e-bf4a-4572e13ff3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36cb4f95-6a12-41f3-bc5a-06bc4e873ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f34716-bade-4bfa-99da-5328239cb52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4b8d3f-2107-47ea-be92-05e0caecddbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41f827a-d2b1-4b0b-affd-ff73f33aedd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d264de-8d3e-4de8-9d6a-986ba0d6945e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d07d2e-7e27-4de9-b677-a2f0a8ab6745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879bacc5-ff35-4cab-88a8-a95b95f98f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c94bd1-8de2-4146-b3bb-63d2734fc502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69dc9ece-67ae-4278-a52a-8a42c5a08837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ef17f2-e086-41d9-88f3-4919b1a0cf09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c783cd44-41b4-4554-91e9-3ec8aa32dea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f8d35c-0241-49b5-812b-73213b31c637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 627d0442-f157-4b61-991f-10a4fb5cc576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 367c0f2a-fc63-423a-a3fb-01cea1cab34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c673f504-26ea-41de-a7f8-ba4c1cb9bb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ece312c-2b79-4968-a10e-149f57d14f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0517cff-3c82-49b2-b287-5d70aa2f6595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31553ce7-1563-4978-a1b0-996917041e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a4a3139-bdb9-4b4b-a6d8-81f7d70cfbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68b543f8-795f-415c-9837-2bda9e94a1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911c1cf3-ad6f-4b91-9d1c-72896bab713e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a485d5-48b0-41ed-a757-eaff03c4d3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd9d6b9-8da5-44bb-8dd4-4c87b0fb47c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50313dc8-2d51-48af-829a-82a1f9729255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14a1bd97-6a29-4432-8c7b-a5f56f17ae20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658794ef-4af5-41b9-b902-2bbb00c814b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b2f0d88-3733-47b1-a5d8-9900791296a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da35c2c8-29ff-4ead-aa7b-a16f4a9bfe64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a41bc8-cbf3-43e6-a515-aeb711f8d64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906700d8-ecf4-4b3a-98b7-f06083bc73b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3917d2-75c4-4f2a-aa5e-0b1bce032011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21efb7b0-67ce-4f41-9747-ec43d83cf4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3a7fa3-ab15-4204-a310-6aa03f99deb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56407b20-b3be-45b9-aa02-c06f18361251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e8f8d0a-c074-450f-84c8-849f9e0bdbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7623f1c4-4676-49ee-8a8b-98b420f17020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9f90b8e-1727-467e-9505-058ea6f194e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d5e0fb5-33f9-4cd7-970f-6ae507c1bd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac0f783-bd65-4ada-ad9a-beb738a80749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a146cd-2c08-4b14-8635-377877c5ccfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f2a3e7b-9a1c-4b30-9785-6ddbc217383f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c2a7016-45c1-4a62-9e50-b43b5646d630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a73eacd-0f82-4d6c-b4b0-e2e094452174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ef6001-7ccd-41ab-974f-8a253ac59387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb7dc95-3123-455d-940e-7109e76ee853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8282ee8-0b2d-4b52-8427-d9fc3a2933ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0000cc6-cae7-4a92-ac4e-51b50ebd49d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdacf94-985e-483f-a21d-f4c07f5755d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee90fbab-d4df-4053-8e37-8a7342b073aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427af34a-cf5e-4d1c-986d-acc9ea6ffcad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1b9dc88-1d28-4f62-a3e9-8c9484718d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e422d9e-0ca9-431b-8cd3-12100aafc284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49fa46f6-ca6a-4af3-873b-21d87b7c1214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc05078-c891-445e-857b-16400b01c049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d04f69-d299-43d0-bac8-25c4b65cf0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c8ddf90-cc9a-4118-a238-c9a5fd1bb06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a24c1c-f71d-48f7-b5a3-3b451b06f548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdbf52c1-cbd6-4929-8ee7-e77185988b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f5e0e2d-be8a-4794-90e1-c3c376e6ad3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf019dcb-a5a7-434d-b1cd-192efc115869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ab9571-7fb4-496e-9213-c20b47d7f9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bbaede0-7003-4b31-bca9-3442d464f6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15257765-0a24-4bfb-84da-6b709196ee2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af4df190-9710-49c8-837d-1bea54324775
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(1632, 24), y=(1632,)
   Test:  X=(409, 24), y=(409,)

⚠️  Limiting training data: 1632 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  400 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2229, val=0.0797 (↓), lr=0.001000
   • Epoch   2/100: train=0.0914, val=0.0874, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0808, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0805, val=0.0813, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 1 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0019
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0069
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.3406, RMSE: 0.5836, MAE: 0.5119, R²: -3.3422

============================================================
🔄 Round 4 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0993, val=0.0825 (↓), lr=0.000250
   • Epoch   2/100: train=0.0819, val=0.0825, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0808, val=0.0835, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0808, val=0.0831, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 4 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0084
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0044
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0885, RMSE: 0.2976, MAE: 0.2491, R²: -0.1287

============================================================
🔄 Round 5 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0791 (↓), lr=0.000063
   • Epoch   2/100: train=0.0852, val=0.0790, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0826, val=0.0799, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0811, val=0.0823, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 5 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0765
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0108
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1090, RMSE: 0.3301, MAE: 0.2712, R²: -0.3892

📊 Round 5 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2462, R²: -0.0458

============================================================
🔄 Round 12 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0738 (↓), lr=0.000016
   • Epoch   2/100: train=0.0852, val=0.0736, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0850, val=0.0734, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0848, val=0.0732 (↓), lr=0.000016
   • Epoch   5/100: train=0.0846, val=0.0731, patience=1/15, lr=0.000016
   • Epoch  11/100: train=0.0841, val=0.0728, patience=7/15, lr=0.000016
   • Epoch  21/100: train=0.0837, val=0.0727, patience=6/15, lr=0.000016
   📉 Epoch 27: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 12 Summary - Client client_6
   Epochs: 30/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0098
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0246
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2418, R²: -0.0295

============================================================
🔄 Round 13 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0797 (↓), lr=0.000008
   • Epoch   2/100: train=0.0845, val=0.0795, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0842, val=0.0792, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   ✓ Epoch   5/100: train=0.0841, val=0.0791 (↓), lr=0.000004
   • Epoch  11/100: train=0.0838, val=0.0788, patience=6/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 13 Summary - Client client_6
   Epochs: 20/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0302
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0165
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2414, R²: -0.0157

📊 Round 13 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: -0.0208

============================================================
🔄 Round 17 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0819, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 17 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0134
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0394
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2434, R²: -0.0274

============================================================
🔄 Round 18 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 18 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0171
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0056
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2439, R²: -0.0321

============================================================
🔄 Round 19 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 19 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0151
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0145
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2439, R²: -0.0304

============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0098
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0183
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2437, R²: -0.0258

============================================================
🔄 Round 21 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 21 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0132
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0254
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2434, R²: -0.0228

============================================================
🔄 Round 22 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 22 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0069
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0142
============================================================


============================================================
🔄 Round 23 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 23 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0008
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0358
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2428, R²: -0.0169

============================================================
🔄 Round 24 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 24 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0099
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0391
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2429, R²: -0.0155

============================================================
🔄 Round 25 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 25 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0067
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0167
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2429, R²: -0.0155

============================================================
🔄 Round 26 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 26 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0031
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0363
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2428, R²: -0.0156

📊 Round 26 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2427, R²: -0.0152

📊 Round 26 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2426, R²: -0.0144

============================================================
🔄 Round 29 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 29 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0003
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0241
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2426, R²: -0.0137

============================================================
🔄 Round 32 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 32 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0016
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0078
============================================================


============================================================
🔄 Round 33 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 33 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0059
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0093
============================================================


============================================================
🔄 Round 36 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 36 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0035
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0036
============================================================


============================================================
🔄 Round 38 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 38 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0070
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0159
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2425, R²: -0.0122

============================================================
🔄 Round 40 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 40 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0012
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0162
============================================================


============================================================
🔄 Round 41 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 41 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0005
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0097
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0119

📊 Round 41 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0118

============================================================
🔄 Round 44 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 44 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0023
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0217
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0118

📊 Round 44 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2425, R²: -0.0117

============================================================
🔄 Round 47 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 47 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0018
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0021
============================================================


============================================================
🔄 Round 50 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 50 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0011
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0074
============================================================


============================================================
🔄 Round 51 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 51 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0053
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0119
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0113

============================================================
🔄 Round 54 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 54 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0015
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0020
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0113

📊 Round 54 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2424, R²: -0.0112

📊 Round 54 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0111

============================================================
🔄 Round 60 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 60 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0014
   Val:   Loss=0.0908, RMSE=0.3012, R²=-0.0224
============================================================


============================================================
🔄 Round 61 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 61 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0112
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0292
============================================================


============================================================
🔄 Round 64 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 64 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0016
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0166
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0111

============================================================
🔄 Round 65 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 65 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0045
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0018
============================================================


============================================================
🔄 Round 66 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 66 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0054
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0005
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0110

📊 Round 66 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0109

============================================================
🔄 Round 69 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 69 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0004
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0243
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0108

📊 Round 69 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2424, R²: -0.0107

============================================================
🔄 Round 75 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 75 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0003
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0046
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0105

📊 Round 75 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0105

============================================================
🔄 Round 78 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 78 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0061
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0170
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0105

📊 Round 78 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0105

📊 Round 78 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2423, R²: -0.0106

============================================================
🔄 Round 82 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 82 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0002
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0077
============================================================


============================================================
🔄 Round 83 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 83 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0005
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0056
============================================================


============================================================
🔄 Round 84 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 84 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0056
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0139
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0105

============================================================
🔄 Round 88 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 88 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0046
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0131
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0103

============================================================
🔄 Round 89 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 89 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0005
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0203
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0101

============================================================
🔄 Round 92 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 92 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0074
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0278
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0100

============================================================
🔄 Round 93 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 93 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0015
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0170
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0100

📊 Round 93 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0099

============================================================
🔄 Round 97 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 97 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0033
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0072
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0099

📊 Round 97 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0099

📊 Round 97 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0099

============================================================
🔄 Round 102 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 102 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0006
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0108
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0099

============================================================
🔄 Round 103 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 103 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0090
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0326
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2423, R²: -0.0098

============================================================
🔄 Round 105 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 105 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0010
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0092
============================================================


============================================================
🔄 Round 106 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 106 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0031
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0059
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2423, R²: -0.0098

============================================================
🔄 Round 107 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 107 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0054
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0116
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2423, R²: -0.0097

📊 Round 107 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2423, R²: -0.0097

📊 Round 107 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2423, R²: -0.0096

============================================================
🔄 Round 110 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 110 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0025
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0147
============================================================


============================================================
🔄 Round 111 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 111 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0059
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0265
============================================================


============================================================
🔄 Round 112 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 112 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0037
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0187
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0097

============================================================
🔄 Round 113 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 113 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0017
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0167
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2423, R²: -0.0097

============================================================
🔄 Round 116 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 116 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0056
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0181
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0097

============================================================
🔄 Round 119 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 119 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0059
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0188
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

============================================================
🔄 Round 124 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 124 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0066
   Val:   Loss=0.0734, RMSE=0.2708, R²=0.0058
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

📊 Round 124 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

============================================================
🔄 Round 127 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 127 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0089
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0217
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

============================================================
🔄 Round 129 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 129 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0025
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0135
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

📊 Round 129 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

============================================================
🔄 Round 132 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 132 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0039
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0126
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

============================================================
🔄 Round 133 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 133 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0036
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0058
============================================================


============================================================
🔄 Round 134 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 134 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0005
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0033
============================================================


============================================================
🔄 Round 135 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 135 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0048
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0128
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

📊 Round 135 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

📊 Round 135 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

============================================================
🔄 Round 139 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 139 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0014
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0149
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0100

📊 Round 139 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

📊 Round 139 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

📊 Round 139 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0099

📊 Round 139 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2422, R²: -0.0098

============================================================
🔄 Round 145 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 145 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0019
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0125
============================================================


============================================================
🔄 Round 146 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 146 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0016
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0147
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0097

============================================================
🔄 Round 147 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 147 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0035
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0210
============================================================


============================================================
🔄 Round 148 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 148 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0028
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0078
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

📊 Round 148 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

============================================================
🔄 Round 150 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 150 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0027
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0155
============================================================


============================================================
🔄 Round 151 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 151 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0037
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0064
============================================================


============================================================
🔄 Round 152 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 152 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0023
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0287
============================================================


============================================================
🔄 Round 156 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 156 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0063
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0050
============================================================


============================================================
🔄 Round 157 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 157 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0018
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0123
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

📊 Round 157 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

📊 Round 157 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0098

============================================================
🔄 Round 165 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 165 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0023
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0036
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0097

📊 Round 165 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0097

============================================================
🔄 Round 167 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 167 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0011
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0114
============================================================


============================================================
🔄 Round 168 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 168 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0035
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0432
============================================================


============================================================
🔄 Round 169 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 169 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0024
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0193
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0096

============================================================
🔄 Round 170 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 170 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0014
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0133
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0095

============================================================
🔄 Round 172 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 172 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0054
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0046
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0094

📊 Round 172 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0094

============================================================
🔄 Round 175 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 175 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0034
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0194
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0094

============================================================
🔄 Round 178 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 178 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0070
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0210
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0093

============================================================
🔄 Round 180 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 180 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0030
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0055
============================================================


============================================================
🔄 Round 181 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 181 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0027
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0280
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0092

📊 Round 181 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0092

📊 Round 181 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0091

============================================================
🔄 Round 186 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 186 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0005
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0020
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2422, R²: -0.0091

📊 Round 186 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2422, R²: -0.0090

============================================================
🔄 Round 189 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 189 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0003
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0177
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2422, R²: -0.0090

📊 Round 189 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2422, R²: -0.0089

============================================================
🔄 Round 193 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 193 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0025
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0140
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0089

============================================================
🔄 Round 195 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 195 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0032
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0086
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0088

============================================================
🔄 Round 199 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 199 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0022
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0141
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0087

📊 Round 199 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0088

============================================================
🔄 Round 201 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 201 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0065
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0329
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0088

============================================================
🔄 Round 202 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 202 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0053
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0130
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0088

============================================================
🔄 Round 203 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 203 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0053
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0152
============================================================


============================================================
🔄 Round 204 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 204 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0027
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0093
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0087

📊 Round 204 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0088

📊 Round 204 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0088

📊 Round 204 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2421, R²: -0.0088

❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
