[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c098b37c-9a85-4cf0-8c64-6c7d5e1f2d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a5e3427-57d1-46c4-a791-02f5d03cd5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524eb19b-f75f-4ba0-91de-cb85b016a99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8149eb5d-f697-45b0-b34a-945dea4dc662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38848535-4d64-42f8-ad67-42af517b247e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b89de46-83de-46d7-8559-2f69b86180c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c9f8c2-da79-42b0-8f59-a168819813d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69be2fa0-0eb3-4fdc-8bcb-f20e3d1af812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7438531b-e404-4b4f-ae74-5694e9b010ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a7fca4f-3eb1-40a5-9640-ddce760c70d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89d7a31-351c-4763-9d6c-8cde7bbffed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5fff95-f0e2-4e47-a039-3815cba1cdc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a70a3940-0aba-455f-a781-ccad14483c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6f2526e-2422-4105-b1d6-c8abb519d1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff108db4-4cd9-493f-bf1e-c44bbd762d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cfa51bf-d461-4d24-bdbd-48d6ef1f4813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847ad2a7-8d48-4e08-b7ce-6c22b50c2c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 013a0cc0-1162-4f36-9931-2e88119805de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc26144a-5342-4060-b436-7d62486d0aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab3c79d-2f9b-4d26-8c1b-29d2741db531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1b9f64-1304-4025-acca-4ec429af58fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c235e6-0f6a-46eb-878c-ef1de8de73ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 966c14f1-b0f4-4ff8-874e-64ca40df12be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af4322e-0c50-43ee-a3d9-c530e8b8cf87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f21655c-1775-4811-aacf-db0f2e5b53c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a0e652e-24e8-42a4-b4f4-28a05a3d3258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e97dec0-17d9-42b5-8525-422513eb6425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f5fa1c-dfb2-44af-be76-399ba1727712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f1e078-0423-4323-975b-a20d0f3fce1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc95294a-f556-468b-b653-610851960f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1257cb39-cdd1-454b-88a3-dd8f2ce4afa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a952eab6-e4ec-4bb4-9a4d-c256b7f67b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f98a7e-468f-407e-947b-054218e70b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1f5c584-12f3-42d2-b1fe-b80e9f700979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78ac4c1-90fb-4519-9d09-924553638459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32eff50e-404c-4136-8a49-8db285514628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414cdea4-5bc0-4a26-98ad-991083106520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01b79a3-3c6a-4d7c-b2ca-4b0db465a79f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 360d09f4-9cbe-4a90-97cd-c57707034d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f476d0e7-728c-49c2-9783-3360f51ce141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec5a3d4-9d90-4d78-8dbb-9eb5f5ca9a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 511873af-6069-4194-a6e8-6462f2ca7539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f387eb6-bdd3-4894-b73f-10caaa7127d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 061bfc70-1470-46fc-bf08-56df7d5f7bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eb22674-29bf-4d66-b6d9-d28611224a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc2f9b44-e0f4-431b-9aeb-e5f66842be00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eb831da-600c-4856-bc84-bcb5f8979f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987883f8-748c-4e53-bbb9-08c276a44971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180eae1c-1cf8-4f85-8dd3-a404cead5ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa51a965-5d29-4544-b9fa-34055225b4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4508b9f5-1b84-421e-87ba-a26da09394e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3e55b2-6d41-40bf-91fb-22ac7029f6e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4efbd626-b57d-4ba3-8ab4-7c19913a342e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c93425-6823-4329-a621-add786888877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a092e125-4065-4d4e-87a4-a645c54e7727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab272e3-3e4d-4dc0-a961-d295d7cf4df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d7faf3-32fd-4298-92af-362b081a00c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 314b9ddc-6c0a-4f81-8241-1d3ecd7ca5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c7ef82-1871-4069-988b-55744bf4d759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c57cf1e-3800-400f-b411-b33e75fb4090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f84af2-4056-48a4-91e2-85397a0711b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488afcdb-70df-49a4-ae2a-fba5eb9c59a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090de7e6-df3b-4e15-8bd8-9f87e44a6428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73987ee0-a18e-4b51-a01f-dae3c8571baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24404bb6-b97a-417d-9c5f-41e4df4bcd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65bb175e-bf2e-4757-b80d-cdd594c99468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15005d20-4bf8-41b7-8b2c-0585bf074a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f177ba05-6a85-483c-a92a-361b93876c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec88fd7-4d5c-4b5e-ac14-4d20ad86f5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c074a19a-ad6c-4aaf-9992-c287938e8118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e19c8b-cec5-400b-b56e-741f4a7fa35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a596914a-7d07-4d38-b092-bd4e98647cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83da302b-64e3-435c-9344-d201186e083f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33a3d240-0932-4a71-988e-a56eec5db64c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6405f5c-51db-40cc-ba60-02c5ec478b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7aa908-4fb7-4e58-a34f-866bf13207a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b981d5b4-43da-4c53-8ee7-2781ab60e6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5151381b-4f8a-4a9d-b4b1-1e6579e19cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c15b914e-e8d5-47ad-bd79-7aa29e7ddb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f6b428-d849-49b4-9d90-5dc6ed89878f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a39b076-3233-467b-894b-74cbea27b660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc44ddc4-1636-4d4b-8007-ffe2bbe2f739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd6ed36-f5b8-4cf3-b530-83343b8cf7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 303d9e4d-c86a-4249-994b-89217bd6d215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc3a366-7646-4436-900b-fed7216f7bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2213efc8-f0e4-45d0-ab08-6bfa239d6a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd29cf74-e0ed-490d-bf95-d6a4d2338beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8915d2ce-bf6d-4896-937b-d97f208d5bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1a5975-1d14-475d-b788-6ab993874700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fbf0830-4453-4afa-be47-71554c185951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8248a3-aa0f-4898-8c6f-9dbd15c0aaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89598cb6-b817-4ae1-9590-71df5790dc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceadde34-2440-4452-b343-803fbf4e185b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d200a58b-772f-4e7d-a60a-0799fcbc64a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6882d347-f321-4052-bcb7-9094cddf7646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52d87672-70fa-4de7-a34c-e3240cf4dd5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 914855da-b7ee-4a5f-aa38-4ec8c40defe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7132dbd-c10f-468f-8b28-c1555d262526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b98a5a-8492-4926-a1e9-7cbee969b989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afce0bf9-2a10-4e60-b236-5e5924f52201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de38e4b3-19f2-44a2-9247-da4d2cc6d1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334029a4-98f6-4284-8196-6f9d47808c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49cee9b-68f6-4fa0-b4f3-2b8f243b021e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64f380d8-d22c-481d-8ab7-74db3e3bb886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f240c4b-4946-474e-bee2-5b0edfee0a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a30b4aa-96c4-4888-8c20-f1dca6b7c3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b048b271-fefb-4fc4-8f57-50327344657e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18e37a0-d0e7-4803-9332-91d2902c0eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305db314-1df7-4cb3-84f2-5f99bed27f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437756b4-0343-4ff8-a0ab-751cb41a4f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36741bc5-cfce-4530-b282-8c953ccdf63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14a9b42d-7435-44c7-b191-77a345e02afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80a8110-d232-44c9-aa3f-eda02d92ec1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a905983-7e8f-4297-9ae4-8e2207cb1460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47035fbf-c4d9-4ca1-ab7a-faf9c784eb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0876412b-9b95-447c-8611-a2388c8d40e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c39ec1-d3d6-4bd7-9574-4c253a55c13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d5f3f9-e696-443e-80e8-79abc43afd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4068320-4866-4ead-baaa-ed0a427ca18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4d1708-1e0e-4f46-a586-5d6d14aa8ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f75368-0339-4591-b046-d6fd5fad20c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04df12db-b66a-43bf-82fd-919b0c992473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872b7122-def6-4564-b80c-4414ef43385c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8337eea-590f-48ff-b482-cdfb25190605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de9b6d12-272b-413f-956b-dffdb407df6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9595a8-e851-447a-aea4-8e1f600a57c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205a0953-27f9-4600-9805-109e08310385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96959a5d-ba3c-4e72-a2d6-e73f3443083f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31631a58-6f2b-4c74-b1e5-8e9a59d1782d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6219fa18-5765-40c7-a326-47f4dc87d1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35be0ec7-27bc-4e19-be14-c0e855c5e7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a31be45e-5f77-4f98-b1f0-a13b369f85e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831df0d0-c68b-41c6-95eb-645c4a2fccfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2791312f-0793-4ffe-9529-26e9c653d3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c7d35b-fc17-4098-b9dd-daf8aaa70663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d5135eb-5461-47d7-8f40-0661bba4f83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2deca9c-5eda-4a5a-a5f4-bfc7b1630dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad975d3-d1f8-4be5-a0cc-8456b90d772d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a271ee7f-0b39-4d37-af54-61e713e7d771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020de5f1-332b-4ac1-87c2-bc4e490ab1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2412ba-4178-44d2-bb60-66526510eb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e6ac9d-c026-4049-b09c-f90f91caddab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6293d667-dcdc-4d8a-88b9-5e466c31e635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b20664-296a-4414-8b49-1f68c69ca576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65decc91-38a7-427d-8232-681a4bacacfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cfdc66c-55c6-4a22-be20-144d1a2e8b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b62014d0-1c18-4765-b4a2-3ce3429ebe3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab5d749-ce8a-4df8-ab66-514b7b5c0532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe9f5e57-622c-4bf2-8c27-dd6bd79eaec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e35f12c-8732-4110-b5ad-ce6d3fca47b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9503efb-2738-4864-be28-8bb77302bf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2131a1-5c3d-422d-89ff-3c15851b2b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b68bc0d5-abfb-4616-b2ac-6626569fe223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2263a01-876d-4ebc-aee6-21f16f8442fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a610cc-5535-42c4-8077-0d447ed2cdcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab76eb8-a3d8-48fc-96a4-70cf56625107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdca0041-a9f1-4f42-be0e-63842817090a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368959d7-13c3-4e1d-838b-60124c233588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f216f75-d436-4b32-b1c7-00b96f8ac109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221f5e7a-0128-4faa-8e1b-0d8a06635f19
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_70
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_labels.txt

📊 Raw data loaded:
   Train: X=(1108, 24), y=(1108,)
   Test:  X=(278, 24), y=(278,)

⚠️  Limiting training data: 1108 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  269 samples, 5 features
✅ Client client_70 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2515, R²: -0.0645

============================================================
🔄 Round 16 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0845 (↓), lr=0.001000
   • Epoch   2/100: train=0.0859, val=0.0854, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0824, val=0.0848, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0773, val=0.0879, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 16 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0012
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0360
============================================================


============================================================
🔄 Round 18 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0873 (↓), lr=0.000250
   • Epoch   2/100: train=0.0848, val=0.0871, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0840, val=0.0874, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0835, val=0.0876, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0831, val=0.0880, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0818, val=0.0890, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 18 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0125
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0396
============================================================


============================================================
🔄 Round 19 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0847 (↓), lr=0.000063
   • Epoch   2/100: train=0.0868, val=0.0844, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0862, val=0.0843, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0858, val=0.0843, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0856, val=0.0843, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0846, val=0.0843, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 19 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0209
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0660
============================================================


============================================================
🔄 Round 20 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0919 (↓), lr=0.000031
   • Epoch   2/100: train=0.0854, val=0.0915, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0851, val=0.0912 (↓), lr=0.000031
   • Epoch   4/100: train=0.0848, val=0.0910, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0845, val=0.0908, patience=2/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0839, val=0.0905, patience=4/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0835, val=0.0905, patience=14/15, lr=0.000008
   📉 Epoch 22: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 20 Summary - Client client_70
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0035
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0504
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2500, R²: -0.0670

============================================================
🔄 Round 21 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0937 (↓), lr=0.000004
   • Epoch   2/100: train=0.0849, val=0.0937, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0849, val=0.0936, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0848, val=0.0936, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0848, val=0.0935, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0847, val=0.0933, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0846, val=0.0931, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 21 Summary - Client client_70
   Epochs: 28/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0258
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.0482
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2498, R²: -0.0630

============================================================
🔄 Round 23 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 23 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0290
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0446
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2494, R²: -0.0577

============================================================
🔄 Round 24 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 24 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0226
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0551
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2491, R²: -0.0525

============================================================
🔄 Round 25 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 25 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0237
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0305
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2491, R²: -0.0522

============================================================
🔄 Round 26 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 26 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0275
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0100
============================================================


============================================================
🔄 Round 27 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 27 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0278
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0330
============================================================


============================================================
🔄 Round 28 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 28 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0224
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0152
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2489, R²: -0.0448

📊 Round 28 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2488, R²: -0.0426

📊 Round 28 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2488, R²: -0.0415

📊 Round 28 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2488, R²: -0.0402

📊 Round 28 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2487, R²: -0.0393

📊 Round 28 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2487, R²: -0.0390

============================================================
🔄 Round 37 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 37 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0112
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0359
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2487, R²: -0.0385

============================================================
🔄 Round 39 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 39 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0232
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0155
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2487, R²: -0.0382

============================================================
🔄 Round 40 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 40 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0142
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0178
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2487, R²: -0.0381

============================================================
🔄 Round 42 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 42 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0173
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0078
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2487, R²: -0.0379

📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2487, R²: -0.0377

📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2487, R²: -0.0376

============================================================
🔄 Round 49 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 49 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0158
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0105
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2487, R²: -0.0376

============================================================
🔄 Round 50 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 50 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0149
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0153
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2487, R²: -0.0374

============================================================
🔄 Round 54 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 54 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0158
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0101
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2487, R²: -0.0373

📊 Round 54 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2487, R²: -0.0373

📊 Round 54 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2487, R²: -0.0372

📊 Round 54 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2487, R²: -0.0371

============================================================
🔄 Round 62 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 62 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0136
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0211
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2487, R²: -0.0368

============================================================
🔄 Round 64 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 64 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0187
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0080
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2486, R²: -0.0367

============================================================
🔄 Round 66 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 66 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0145
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0184
============================================================


============================================================
🔄 Round 68 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 68 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0151
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0096
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2486, R²: -0.0364

============================================================
🔄 Round 70 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 70 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0188
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0045
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2486, R²: -0.0363

============================================================
🔄 Round 71 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 71 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0194
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0166
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2486, R²: -0.0360

📊 Round 71 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2486, R²: -0.0359

📊 Round 71 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2486, R²: -0.0358

============================================================
🔄 Round 78 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 78 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0085
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0532
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2486, R²: -0.0357

============================================================
🔄 Round 79 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 79 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0140
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0244
============================================================


============================================================
🔄 Round 82 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 82 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0172
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0014
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2485, R²: -0.0354

============================================================
🔄 Round 84 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 84 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0146
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0184
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2485, R²: -0.0352

📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2485, R²: -0.0352

============================================================
🔄 Round 86 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 86 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0149
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0064
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2485, R²: -0.0351

============================================================
🔄 Round 87 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 87 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0033
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.1201
============================================================


============================================================
🔄 Round 88 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 88 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0167
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0215
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2485, R²: -0.0351

============================================================
🔄 Round 89 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 89 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0079
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0341
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2485, R²: -0.0350

============================================================
🔄 Round 91 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 91 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0124
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0156
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2485, R²: -0.0349

============================================================
🔄 Round 92 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 92 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0095
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0351
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2485, R²: -0.0349

============================================================
🔄 Round 93 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 93 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0131
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0121
============================================================


============================================================
🔄 Round 94 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 94 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0112
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0228
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2485, R²: -0.0348

============================================================
🔄 Round 95 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 95 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0128
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0167
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2485, R²: -0.0345

📊 Round 95 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2485, R²: -0.0344

============================================================
🔄 Round 102 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 102 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0128
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0344
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2485, R²: -0.0344

📊 Round 102 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2485, R²: -0.0343

============================================================
🔄 Round 105 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 105 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0154
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0237
============================================================


============================================================
🔄 Round 106 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 106 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0117
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0159
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2485, R²: -0.0343

📊 Round 106 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2485, R²: -0.0343

============================================================
🔄 Round 110 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 110 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0170
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0031
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2485, R²: -0.0343

============================================================
🔄 Round 113 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 113 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0191
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0167
============================================================


============================================================
🔄 Round 115 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 115 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0156
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0012
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0342

============================================================
🔄 Round 117 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 117 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0084
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0295
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0342

📊 Round 117 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0342

📊 Round 117 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0342

📊 Round 117 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0342

============================================================
🔄 Round 123 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 123 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0167
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0033
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0341

============================================================
🔄 Round 125 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 125 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0098
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0287
============================================================


============================================================
🔄 Round 127 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 127 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0160
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0026
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0339

============================================================
🔄 Round 129 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 129 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0221
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0271
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0339

📊 Round 129 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2484, R²: -0.0337

📊 Round 129 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2483, R²: -0.0337

📊 Round 129 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2483, R²: -0.0336

📊 Round 129 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2483, R²: -0.0335

📊 Round 129 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2483, R²: -0.0334

============================================================
🔄 Round 141 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 141 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0064
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0398
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2483, R²: -0.0331

📊 Round 141 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2483, R²: -0.0330

============================================================
🔄 Round 150 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 150 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0088
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0358
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2483, R²: -0.0329

============================================================
🔄 Round 151 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 151 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0061
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0360
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2483, R²: -0.0328

📊 Round 151 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2483, R²: -0.0328

============================================================
🔄 Round 153 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 153 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0090
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0224
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2483, R²: -0.0328

📊 Round 153 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2483, R²: -0.0327

============================================================
🔄 Round 155 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 155 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0077
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0290
============================================================


============================================================
🔄 Round 156 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 156 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0160
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0116
============================================================


============================================================
🔄 Round 157 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 157 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0152
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0001
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2483, R²: -0.0326

📊 Round 157 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0325

============================================================
🔄 Round 162 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 162 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0142
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0004
============================================================


============================================================
🔄 Round 163 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 163 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0110
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0152
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2482, R²: -0.0324

============================================================
🔄 Round 167 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 167 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0110
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0140
============================================================


============================================================
🔄 Round 168 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 168 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0136
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0077
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0323

============================================================
🔄 Round 169 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 169 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0102
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0165
============================================================


============================================================
🔄 Round 170 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 170 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0125
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0063
============================================================


============================================================
🔄 Round 172 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 172 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0115
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0139
============================================================


============================================================
🔄 Round 173 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 173 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0091
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0215
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0321

============================================================
🔄 Round 176 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 176 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0110
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0230
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0321

============================================================
🔄 Round 178 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 178 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0156
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0206
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0321

============================================================
🔄 Round 180 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 180 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0134
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0106
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0321

📊 Round 180 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0321

============================================================
🔄 Round 184 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 184 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0129
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0075
============================================================


============================================================
🔄 Round 185 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 185 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0095
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0173
============================================================


============================================================
🔄 Round 187 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 187 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0143
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0031
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0320

============================================================
🔄 Round 188 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 188 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0091
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0199
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2482, R²: -0.0320

============================================================
🔄 Round 190 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 190 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0213
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0218
============================================================


============================================================
🔄 Round 194 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 194 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0145
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0006
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2483, R²: -0.0320

============================================================
🔄 Round 195 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 195 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0070
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0421
============================================================


============================================================
🔄 Round 196 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 196 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0058
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0325
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2483, R²: -0.0320

📊 Round 196 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2483, R²: -0.0320

============================================================
🔄 Round 200 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 200 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0112
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0196
============================================================


============================================================
🔄 Round 206 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 206 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0120
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0136
============================================================


============================================================
🔄 Round 209 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 209 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0066
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0342
============================================================


============================================================
🔄 Round 210 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 210 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0085
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0203
============================================================


❌ Client client_70 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
