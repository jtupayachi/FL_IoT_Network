[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a79af73-be81-4988-9603-549a5f99a288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b037eb50-1fd2-4b3b-85be-94f61fa6a460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f08ba4-c203-4ded-98cd-4b158cd2ef48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60067627-172d-4eca-b067-77c76781ea0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22c4392-4d00-474a-aa7d-fd1d9c5f57fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7510ed3-da8c-4da0-b9c7-46444c9c4932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8f54f0-6a4f-4f61-9a47-e7212692483a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0335b560-27fd-41ed-8464-903686a752ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70744c7c-bfaf-46f3-a49d-fd74ca8a5968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4450767-4390-433d-b793-92fd52270581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d657b8-7eb4-4e14-abcb-c5e9f5bf2ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7904f4ad-601c-418b-a90e-33a85677398a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a70b12-554f-4beb-bdc0-69d3ce85060b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa28e84-ada0-40ae-b585-a168f97c1f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f34dd7-b92b-461f-ad09-6d3d377a1bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15743293-d92c-4e60-9d8b-a94b53b7875d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f3c24f-b469-475d-8466-62096b586b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba97852-b8e2-44eb-a877-5d460cff032c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4093f483-a25a-45ec-a998-8a758ddce597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de15cfa-f98d-4594-b61f-be75e310fca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38087855-e7c1-474d-93ce-0d8c2c9a57d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0aa6001-0f36-4fb0-8fd2-2eb969ea9bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d188f22a-42c8-4f73-be21-7a952d4c0663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6446be-2d13-4733-834c-e7c3c6282b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ebed7d-7db9-471c-9251-1d539422d25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 111270a2-15d1-4655-85a9-5c2e5b4dbf36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53feb3da-0673-4a4c-b3af-f59ce0d1253a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f007b0ba-4e5a-4f76-95ef-2b2c17c8d90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e773c8b8-957a-4a9a-a573-aca668887712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5e947d-40fc-4891-8513-afed477ed0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44dea567-917b-4399-afc1-706958a49ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e478c4-91e1-4d23-af6a-44dfa265bf95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd470df-5a40-41b1-9cf2-f82ebad14b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8474ea3f-5f2e-492e-ab9c-d4ad0e3c4f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611fc771-e396-4211-b9d1-b46898421746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296b9610-f324-4d3f-8959-2c47c27511e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918b0748-4463-489c-aaed-0f711be07775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f8b568-19ab-4b38-b203-75a5a98a4cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a4932d-a034-4ebf-b070-b3a196910ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b35b67-4ebb-4ad6-81bc-a595bf6ccfa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0b1683d-e5bb-4041-8a11-ecdf657137ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8214cdf4-a5b5-40ff-b633-6bbcf1a52b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ce0c72-a875-4b44-9294-90932fb24ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614a2e24-46cb-4b59-94df-441e7238d2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ac1e44-25e1-4e0a-a2e6-15c978e81f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95239a24-daed-4b32-8494-a550a5153cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7bdf85-489e-485f-a855-b22c8be0c096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ccfbb09-a158-4c58-9842-ab5180d319fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fef6d1b-8705-44d1-8ed9-b962235f6ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9879debf-f87b-497c-81e3-03d62c479bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 397b7b18-7af8-4787-adc2-0ad990c6f93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade854fa-ade7-4f0c-9a54-2c5d2cfa60e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca61a8a-25aa-4386-9d73-c1e9b75e0b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f48ac6-a929-439c-b464-8743b437d866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecda1c37-7437-4fc4-a333-e615c5764b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ccdf2dd-04da-4a88-a1f8-aac22bb8ca22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7106030-2e61-435d-829b-6898bf7473c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c38468-b3fc-4ba4-8a62-36a6ea888272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83eb636-2da2-49a7-b207-12430c441381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7dfeb6b-c500-4d34-a72d-7a951dee89ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1036407-18b5-461b-a0cc-a0bc64d83508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a8d387-0f60-4afb-b570-afb8c5f692f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 757c8d2d-d742-4ffc-8e66-92d6fc44f295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 138088c4-cb82-4bfe-b87a-98c634b4c46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aa7eb6a-4eb8-4580-a881-5975e52e06d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 910c5629-3d0e-4e6e-9ecb-66c03f12f566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf31c310-5fc6-4df8-9d34-9f30838bbeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b256470-4451-4a71-b1f3-6aed55b20acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff600729-89c9-42f7-b1d2-c6a9bf184493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 106cda53-1982-49b6-bbc6-0a8c3fb759f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0d4eac-9448-4d28-832b-f650193ec207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c32f50f0-9061-4f6e-a218-ca388c63a9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce5bd829-34fb-4bc0-a81a-d560aae998e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da771a7f-9f5a-4d22-a337-ea4a32b2cc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e762b1-2797-4ff5-b6ba-8f753b2b18fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee32236-eb8d-4e78-8698-ccb5c4eaac29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cbf558f-5a84-402c-afc6-5b760159f78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244610ca-657c-4027-a9f0-b74498aeec6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5dc5a76-393f-4a00-ba16-0f009ffa4bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ffedda-7aa5-4ec9-a1da-e03177b6da5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e37786ba-dbf2-4087-b1e1-61ffc2f0de80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e2601b3-9453-45a1-a145-ae46bb8a1ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b4a10c-f201-49e4-adc9-2639e99e00f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 286129ef-f9a7-4d76-bfae-ea11a4944832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390d9217-eb6c-4f3f-a091-1bff584b2941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c253fe9-d72a-4cfe-be8b-ee6993433785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42738590-2eda-4236-8868-328169fb1ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ca38349-ef02-4dde-9c08-274fc29f8dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff973e0-b895-4425-b067-425400b48212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9e8bd0-33b1-44ce-9097-84559956fd4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22749037-38c1-4388-8937-123728a7cd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91f0d4d-4e59-4990-a034-6e11705534a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a29d932-3e7e-4a19-9255-d43b220a4f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b8d011-6260-418f-ae87-9f11f338a102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b5f28f-4730-4d8c-8a88-a6d4bb3cd6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e95dc30-99c8-444b-a0cd-4d0ba97d0920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c067d2d-42cb-4a81-8c79-b4a6d61daeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b704db-d960-41cb-af69-ae2f9761dd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be98eadf-6d57-465b-971e-619ae1f0f591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a118f9-6f6d-4f37-920a-f82482d83d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f16dab-df98-4cae-a2e4-3af81a66527b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70310608-f5a3-432f-986e-bdf471d7e35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 197f251d-17dc-40af-842f-3177e9999351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 038c631b-2ffe-4120-b986-51ec353d67bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 742f193c-42fc-4b45-b187-e8b6052a8531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5c4040-b576-4baa-bc65-f288505a0b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64905aff-076b-4f55-a60a-7d82b313604f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138c25d3-6713-4faa-9701-e1fbee03d505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab694be-c5b7-42e6-806f-c0322b0048a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bb8b9e-59f9-48af-b6db-c41fe3f48f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed737f3-dc29-496e-8717-8f2c4fae69f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0acb99-a670-40a4-9737-cf582eceffbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deed061d-59d7-4211-9ea7-68747e671f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b77cd93d-2b03-40e1-a619-db807b4e1fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa2c01d-cad3-4d64-aadf-06c9e9ca3889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3cd9d94-c1a6-45d2-8e2c-51f4a62bf6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0600439-3174-4763-a806-2de981126964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271c5f55-44a9-445f-b06c-999bb7d42575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e1fbd7-5f45-4cfe-bc36-367b9b457294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 141bc802-99e7-4a2e-b5a9-1e3daaae0d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901b80b2-5c38-4eb6-8330-a682c03d3326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811173cb-2abb-423b-8ea4-533fcbdd25ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196ffc5e-988a-43dc-b21b-e09c1c7571cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0254302-bf4d-4bf0-be41-3966f1a027cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 497b7b97-8aff-4efc-922b-b1c50e7d230d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69965a2b-11a9-45e8-92a4-0b1ca4720c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bff658e-ff7e-489e-87cd-5d02c1fe3cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6842888a-df85-4e9e-8bd6-9caeaf8bd0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 467f3127-db11-4639-9b72-195561d43fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1626517c-8aaa-401b-8d6c-e93dd054e655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aee2ffb-9628-4bfe-bd0a-64d4389d0a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faff6640-5ce5-4d3a-9d99-0baefb4fb506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 365aa8c2-f0b3-49fc-bb34-0c0966fe5c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eaf8fab-4dca-4897-bb3b-63ba3f58b7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea48e4f-d1a1-4553-b68d-72a03f4c815a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c436c0ec-7f1d-4b1e-bba7-c26a13968808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff3ca8a-41a1-46a5-8ade-f43c1e90052e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87da274-2739-46da-be04-045efbd9a210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9dd3be1-052b-45d8-b264-43893814dc06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c7d89a-15c5-49cd-8a6e-a39dc031515f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae5725c9-ce78-4a0e-8cff-515d9b68e77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e72249-9eb9-484d-95c0-7233c6b407a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b08a38e-99e1-4c9c-bcf4-bda70f55d804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600805fa-8567-4678-b026-b3ab86c144dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19adbab-204a-4dfd-b8ec-c04c71e3e626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a37709b-14ba-42d4-9381-2dcf3bdabb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef95c15f-3dab-45a6-ab13-32473ee15b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be40b63-a94c-4ffa-8164-6a003d917abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 914f80ad-830d-40e2-8f01-b3c7b4899f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dadb00e8-8656-45fc-9978-6cde9af913b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58b0ddb8-4c81-4c6a-801d-0ac70454bdee
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_71
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/test_labels.txt

📊 Raw data loaded:
   Train: X=(1127, 24), y=(1127,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1127 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_71 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2530, R²: 0.0564

📊 Round 0 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2491, R²: 0.0748

============================================================
🔄 Round 22 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0708 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0711, val=0.0693 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0685, val=0.0685 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0676, val=0.0669 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0658, val=0.0663 (↓), lr=0.001000
   • Epoch  11/100: train=0.0590, val=0.0627, patience=1/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0461, val=0.0691, patience=8/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0623)

============================================================
📊 Round 22 Summary - Client client_71
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0560, RMSE=0.2366, R²=0.3299
   Val:   Loss=0.0623, RMSE=0.2496, R²=0.2936
============================================================


============================================================
🔄 Round 23 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0753 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0742, val=0.0734 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0726, val=0.0722 (↓), lr=0.000250
   • Epoch   4/100: train=0.0716, val=0.0719, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0708, val=0.0717 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0681, val=0.0707, patience=3/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0663, val=0.0701, patience=8/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0654, val=0.0699, patience=8/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 23 Summary - Client client_71
   Epochs: 38/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0658, RMSE=0.2566, R²=0.2169
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.1704
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2481, R²: 0.0820

============================================================
🔄 Round 26 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0781, val=0.0667 (↓), lr=0.000008
   • Epoch   2/100: train=0.0778, val=0.0667, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0776, val=0.0667, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0774, val=0.0666, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0772, val=0.0666, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0763, val=0.0664, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0667)

============================================================
📊 Round 26 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.1059
   Val:   Loss=0.0667, RMSE=0.2583, R²=0.1038
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2516, R²: 0.0691

============================================================
🔄 Round 30 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0777, val=0.0732 (↓), lr=0.000002
   • Epoch   2/100: train=0.0777, val=0.0732, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0776, val=0.0732, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0776, val=0.0731, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0775, val=0.0731, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0772, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 30 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0938
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0794
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2529, R²: 0.0625

📊 Round 30 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2530, R²: 0.0618

📊 Round 30 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2532, R²: 0.0607

============================================================
🔄 Round 39 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 39 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0872
   Val:   Loss=0.0664, RMSE=0.2577, R²=0.0723
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2532, R²: 0.0603

📊 Round 39 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2532, R²: 0.0605

📊 Round 39 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2532, R²: 0.0605

============================================================
🔄 Round 45 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 45 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0872
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0775
============================================================


============================================================
🔄 Round 46 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 46 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0860
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0809
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0610

📊 Round 46 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0610

============================================================
🔄 Round 52 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 52 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0842
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0813
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2530, R²: 0.0613

============================================================
🔄 Round 54 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 54 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0855
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0868
============================================================


============================================================
🔄 Round 55 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 55 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0918
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0453
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2530, R²: 0.0615

============================================================
🔄 Round 56 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 56 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0882
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0784
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2530, R²: 0.0616

============================================================
🔄 Round 57 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 57 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0805
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1106
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2530, R²: 0.0617

📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2529, R²: 0.0619

============================================================
🔄 Round 59 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 59 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0961
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0419
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2530, R²: 0.0612

📊 Round 59 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0609

📊 Round 59 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2531, R²: 0.0607

============================================================
🔄 Round 65 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 65 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0900
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0659
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2532, R²: 0.0604

============================================================
🔄 Round 67 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0819, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0757, val=0.0815, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0756, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0754, val=0.0807, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0752, val=0.0803, patience=11/15, lr=0.000001
   • Epoch  61/100: train=0.0750, val=0.0799, patience=8/15, lr=0.000001
   • Epoch  71/100: train=0.0748, val=0.0794, patience=6/15, lr=0.000001
   • Epoch  81/100: train=0.0746, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0744, val=0.0786, patience=1/15, lr=0.000001

============================================================
📊 Round 67 Summary - Client client_71
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.1044
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.1423
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2532, R²: 0.0605

📊 Round 67 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0609

📊 Round 67 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0611

📊 Round 67 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2530, R²: 0.0613

============================================================
🔄 Round 73 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 73 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0814
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.0928
============================================================


============================================================
🔄 Round 74 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 74 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0843
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0951
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2530, R²: 0.0615

============================================================
🔄 Round 77 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0695, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0786, val=0.0692, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0783, val=0.0689, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 77 Summary - Client client_71
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0777
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.1466
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2530, R²: 0.0611

============================================================
🔄 Round 79 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 79 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0821
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0970
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0610

📊 Round 79 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2533, R²: 0.0598

📊 Round 79 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2533, R²: 0.0595

📊 Round 79 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2533, R²: 0.0594

============================================================
🔄 Round 86 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0774, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0767, val=0.0770, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.0765, val=0.0765, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0763, val=0.0761, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0761, val=0.0757, patience=11/15, lr=0.000001
   • Epoch  61/100: train=0.0758, val=0.0753, patience=9/15, lr=0.000001
   • Epoch  71/100: train=0.0756, val=0.0748, patience=7/15, lr=0.000001
   • Epoch  81/100: train=0.0754, val=0.0744, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.0751, val=0.0740, patience=2/15, lr=0.000001

============================================================
📊 Round 86 Summary - Client client_71
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0939
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.1867
============================================================


============================================================
🔄 Round 87 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 87 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0831
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0889
============================================================


============================================================
🔄 Round 88 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 88 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0886
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0666
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0609

📊 Round 88 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0611

============================================================
🔄 Round 92 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 92 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0846
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0851
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2530, R²: 0.0616

============================================================
🔄 Round 94 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0636 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0636, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0636, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0636, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0636, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0635, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0636)

============================================================
📊 Round 94 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0869
   Val:   Loss=0.0636, RMSE=0.2523, R²=0.0781
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2529, R²: 0.0619

📊 Round 94 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2529, R²: 0.0621

============================================================
🔄 Round 96 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 96 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0906
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0578
============================================================


============================================================
🔄 Round 97 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 97 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0862
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0891
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2530, R²: 0.0616

============================================================
🔄 Round 100 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 100 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0889
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0732
============================================================


============================================================
🔄 Round 101 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 101 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0906
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0685
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2530, R²: 0.0614

============================================================
🔄 Round 106 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 106 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0823
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.1010
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2530, R²: 0.0615

============================================================
🔄 Round 107 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 107 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0869
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0818
============================================================


============================================================
🔄 Round 109 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 109 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0850
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0857
============================================================


============================================================
🔄 Round 111 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 111 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0849
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0941
============================================================


============================================================
🔄 Round 113 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 113 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0859
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0891
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2530, R²: 0.0615

============================================================
🔄 Round 115 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 115 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0961
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0129
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2530, R²: 0.0613

📊 Round 115 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2530, R²: 0.0612

============================================================
🔄 Round 118 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 118 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0937
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0479
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2531, R²: 0.0611

============================================================
🔄 Round 119 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 119 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0875
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0732
============================================================


============================================================
🔄 Round 120 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 120 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0810
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.1028
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2531, R²: 0.0607

============================================================
🔄 Round 121 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 121 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0883
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0661
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2532, R²: 0.0602

============================================================
🔄 Round 123 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 123 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0879
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0721
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2532, R²: 0.0599

============================================================
🔄 Round 127 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 127 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0804
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0962
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2532, R²: 0.0602

📊 Round 127 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2533, R²: 0.0598

📊 Round 127 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2533, R²: 0.0594

============================================================
🔄 Round 135 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 135 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0865
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0715
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2534, R²: 0.0590

============================================================
🔄 Round 138 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 138 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0935
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0309
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2535, R²: 0.0580

============================================================
🔄 Round 142 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 142 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0791
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0889
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2535, R²: 0.0580

============================================================
🔄 Round 144 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 144 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0861
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0652
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2535, R²: 0.0582

📊 Round 144 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2535, R²: 0.0583

============================================================
🔄 Round 147 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 147 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0877
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0631
============================================================


============================================================
🔄 Round 148 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 148 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0883
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0415
============================================================


============================================================
🔄 Round 149 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 149 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0883
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0577
============================================================


============================================================
🔄 Round 150 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 150 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0814
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0784
============================================================


============================================================
🔄 Round 152 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 152 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0837
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0702
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2536, R²: 0.0574

============================================================
🔄 Round 153 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 153 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0821
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0788
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2536, R²: 0.0574

📊 Round 153 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2536, R²: 0.0574

📊 Round 153 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2537, R²: 0.0571

📊 Round 153 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2537, R²: 0.0569

📊 Round 153 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2538, R²: 0.0567

============================================================
🔄 Round 161 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 161 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0773
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0908
============================================================


============================================================
🔄 Round 162 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 162 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0792
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0857
============================================================


============================================================
🔄 Round 164 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 164 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0862
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0542
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2538, R²: 0.0561

============================================================
🔄 Round 166 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 166 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0803
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0768
============================================================


============================================================
🔄 Round 167 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 167 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0752
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0970
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2538, R²: 0.0563

📊 Round 167 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2538, R²: 0.0564

============================================================
🔄 Round 169 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 169 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0878
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0503
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2538, R²: 0.0566

============================================================
🔄 Round 171 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 171 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0890
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0289
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2537, R²: 0.0569

📊 Round 171 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2537, R²: 0.0571

📊 Round 171 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2536, R²: 0.0573

============================================================
🔄 Round 174 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 174 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0804
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0538
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2536, R²: 0.0574

📊 Round 174 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2536, R²: 0.0575

============================================================
🔄 Round 177 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 177 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0876
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0518
============================================================


============================================================
🔄 Round 179 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 179 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0652
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.1329
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2535, R²: 0.0580

============================================================
🔄 Round 181 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 181 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0803
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0867
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2535, R²: 0.0584

📊 Round 181 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2535, R²: 0.0585

============================================================
🔄 Round 185 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 185 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0887
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0567
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2535, R²: 0.0585

📊 Round 185 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2534, R²: 0.0585

============================================================
🔄 Round 191 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 191 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0800
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0768
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2534, R²: 0.0590

📊 Round 191 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2534, R²: 0.0591

============================================================
🔄 Round 194 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 194 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0854
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0721
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2533, R²: 0.0593

📊 Round 194 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2533, R²: 0.0595

📊 Round 194 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2533, R²: 0.0597

============================================================
🔄 Round 199 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 199 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0861
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0735
============================================================


============================================================
🔄 Round 202 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 202 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0764
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0853
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2534, R²: 0.0587

📊 Round 202 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2534, R²: 0.0588

📊 Round 202 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2534, R²: 0.0589

============================================================
🔄 Round 209 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 209 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0832
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0777
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0813, RMSE: 0.2850, MAE: 0.2535, R²: 0.0582

📊 Round 209 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2535, R²: 0.0581

❌ Client client_71 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
