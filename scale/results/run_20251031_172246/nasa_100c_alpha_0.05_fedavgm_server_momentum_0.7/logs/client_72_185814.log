[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d12d337-030c-43ce-81c0-6a0a6bb67e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 595bdb4f-d43a-461c-9463-ad7ad12a50c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52d03b1-0202-4974-86ac-4843da406797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae7d4f8-55d8-405e-b74c-67100d1659ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f649ba46-d044-4639-8b39-b7504abbf108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b30f72-9238-4230-ba4c-696988270119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0b95fa-32ec-4643-b4f7-c97e6e2bbab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e0fade-da23-4aff-a988-ba4d5e00cfe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c17690-1883-4b87-8a01-abf41870815c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6310c423-e3f0-4ab0-bebf-d096772667b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f824c23-be54-4ef0-95fa-587a20f0457e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1570ce8b-4387-4556-a811-db4af8142eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea39a26-a3fb-4d1c-884e-1267bdb0e4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de156df-7a45-440b-a3c7-707e789cbc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af90b35-8ace-47f8-871f-384a4c36e165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751234d5-58ca-46a2-868a-efdfe7a5e315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e1800c-dacf-4e62-a68b-d29a900b35a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f693bcc-22e3-420a-8a02-50bac40addb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20334f0a-675e-4c1a-bb0d-bda2a9c07ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fbf20f9-fdf6-4751-9f02-78d43928e917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16730327-ea73-4958-a580-a039f7dfd1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421617e9-f468-4e07-8c6c-fb5092e05465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd95908-d907-47fe-a38e-d79c5f0b53d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db00aca3-981c-4eb3-9cb8-35d457fe68cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ea5b0d-739c-4632-841d-489a78a85ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdded3b3-d982-4419-a8b9-6e4e852652f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 950716ad-653a-49af-bd45-8c6c860a28f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25c51f89-e990-46bc-857a-01c0149b2d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423b70c9-4559-423e-b6f2-bbfc50c427ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3520b8a5-cd97-4d2b-bd77-56149d0af7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75897f4f-8ea3-444e-9d54-f6292e23f1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384fdfaa-d6b8-407f-974d-949822b105d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09d530fe-2622-4df2-93d1-244382052626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b2798d3-bfc4-4cac-b591-d8e1a715eec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8129390c-71c5-4a69-bfdc-dace41c805ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4fee41e-55d8-49c4-b6a6-f7c950b6fed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38859096-ce15-47be-afe3-12ad968de524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6f91f3-dbd6-491e-8cd4-dd216196695d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d4b824-0d99-4b4a-afec-9a14387777d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4989f0-13a2-47e1-a6ba-e4b674dab18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79c499f-3cd5-4a71-8af0-25f9060bd31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2f0704-e5c5-4981-972b-edf5727dcead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19a8907-1602-47d0-b5a8-f7e14bb21cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8ac062-0434-4626-990f-2191e6abdbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e3cc7b-5721-4447-9a26-d07593a08425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f8a716-be2f-4d1c-b7f8-207c5d81b82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e939ed3c-7ec9-453c-aa51-74926be34bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9c19b9-0660-4afb-b4b2-362cbc67b358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac4bb228-ed8f-491f-a232-3f26b785e280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 565e9b05-4bc6-46f9-9b9f-8e91a0ff4625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0559fc0-2593-4b31-9e25-4ba06073913a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d48605-973b-4585-a7c2-08d70dc5be33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde91dbf-7d1b-4985-b30c-9daded3f0581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34671dbd-07a0-4cf6-9a71-621f3644d496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6af2aff-0e5f-4f7c-a375-b06fbd76dde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff92e3d1-a436-4666-8138-39f8026800b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13d48d5-3b4b-49d2-a903-e9c2bf4460ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7bf7cb3-6b98-4eed-bfc6-53586185333b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c5de360-85ce-4170-9318-9eb9511286bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d7fc78c-61d9-45b2-829b-91e4e7c71200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b246749-3651-44eb-acde-5343a981cda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca98398-73b2-4f52-a93e-49f7c2a1fc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36033316-3694-4c1b-a099-00e582e5f827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29745ed9-9aca-49ac-ac9c-4d123aa9b769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd458eb-c4db-4b27-9431-18b1dfc50335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 599ff9cb-ab44-4e5f-8f2b-6b8fb46ccd52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a291bfa3-222a-4156-ac80-466f585ea11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15262b01-cb00-4303-b2c9-ce082fc01e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2473b7-139f-4220-9211-731eb771bb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb99f2db-31e7-4671-9d95-6235fdfc5b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a9d341-394c-4e47-a037-f1db22c1776e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fbd6502-47d8-42c1-8ceb-a94dc91dbee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1999a63f-015f-40bb-9f24-50232491120a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be61070-4688-4bc9-bbf9-bb5b46a2ad6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48643a1d-b100-453e-8c26-cb69e179228d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7c439d-4d5f-47d6-aff4-f4d7550cfdb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 794dd7e8-8625-441a-a051-b0fd4f239d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea03946-6431-4880-921b-05e899967e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e3c322a-148c-46d6-aafe-6bd4b197fdb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0ab47c-f9ad-4952-98d6-cbfa7596c3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ebe43a-d5f5-4fef-ab48-76be52222e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a32bbb-7ed5-4606-8a8b-026eecebba60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9498e3fe-34f2-41c2-bf6a-744c115d62e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db5f0539-ab2b-4d54-9c1a-c60eec6afbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22778ea5-c5c1-4b4e-b367-fb6008e2d39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec34522f-766a-4ba5-83c1-7d2d564977f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd96f501-0236-4ab6-87a1-f4f0f809501e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161b1500-c8b9-4c51-8efd-20864e224005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe9d4b6-8ff0-4032-9d61-d184d572e421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d7fe34-0e63-43b2-a64b-e83550aa0166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d75b59-d624-4c67-80be-75258c05186a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26c7b6d3-09e8-477d-8eb7-34e9fab27f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0751d22-61fb-475b-89a8-9dfe20be2324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d4eae88-1282-488f-8e23-0ee0487f1cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59013069-6b91-4ce8-ad12-f1b2c6277a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e3f6cc-7274-4fab-97c8-28ead8762083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf61cc82-1556-405c-827a-ff5dfbbe1b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf1eb18e-c360-45de-b37d-7ccdb483bab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752feaa0-d269-4b5b-83b1-609fe881b7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 887695ec-f12a-45eb-9b49-5078bd2ee6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f0f447-f866-44e6-a565-77f3e274cc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a649df-1459-47f2-bf8f-ce9bcbae0050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b103e9-bb27-4f79-8d4d-f46d970495b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b502bf77-43f8-4f09-ba8d-edb9e3ba801a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8008087-5ed1-465d-90e8-d4c7878b7f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53c28cd-8c5f-4821-b17a-107bef65d1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e14cd39-0f60-4727-9edb-a94df65847b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab212a6-b953-4af5-b69e-9ce278f218bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437dfdd5-a5c3-4730-a049-50487351ac2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a57231-c0fe-4cc8-9d88-77c8fbb4f482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7438b6d-164a-40a3-8483-bb27f26a67da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b434cf7b-e7fc-48bc-bcba-52dd66135c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069b69b4-a4b5-4753-a73e-e5782768b6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4300a98e-82c0-4f83-894e-fe5d42e312bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372d5d42-2aa2-436c-b16a-242622ee5929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29adfce1-8c82-452c-a834-cb0a17528e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad260fa-6fd2-4fdd-802b-351b0b03b0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c73e87-d746-43cd-bc73-9645a8425265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80ae262b-7e5f-4d85-a43b-b1f82a487706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a59a44-cbf0-4e13-a68e-c3e7f001b726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 613cbf81-70cd-49d6-b886-ab8023a2fadc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98dd33d0-ee29-4fa7-bfb0-4fe9d411f888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0ff4eb-38f0-4e45-9045-916c65411de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbedf835-f258-45d4-b3bc-2cb140201a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907a9228-1cfd-430e-9a44-da6da097e7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e0272bb-c6ab-4563-9d4c-1aa047609295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b880df-0687-4e93-8efc-8698f5ea9c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d45f392-0b6c-4943-a642-35deea84e42b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e617b3-da70-4dcb-919d-5d3341fb976a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8543b2a7-a790-419d-8da0-fe8fd759fdf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ac12d7-9f57-4e94-a3ce-a03e0c4b3fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adee5886-f055-4374-9100-9e4cf92ea825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 645cc15d-39cc-4f0d-96ca-7787f76dd5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09da4106-3684-452f-91b3-ffc01e1de518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fb17423-8340-431a-9e1b-07e0ee35b764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c994baec-8d9a-4496-b64b-2bcda607236d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7eec58c-f011-403d-a908-8ac71b764fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60282d4e-aa5e-4829-9b3d-dd7849d3d3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af73c77-d625-4bae-8dc3-5c263e28de5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861eefeb-5ef9-4f6b-86d7-cb24d6edc4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6bf2de8-4938-41f9-a6fd-c84561f49f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2f57a5-3f9f-40b4-a7b0-2b99737741cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa789c1-9337-40a6-bea6-0647e6be4869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa661cbc-e9e0-444b-8f43-e85aba5cd304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5dd1ab-601b-46da-a38b-4809d5f1cc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82747364-1781-4320-8efa-e774922024f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d628fd02-0547-46e2-99f9-c01b0f2ea2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b38b78-f35b-4a53-bc8a-75172cb3f8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd00ae4-21b4-49d0-9c31-92efd04036f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4656270-78d6-496d-96e4-809045d32a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e259b80d-2c47-4e6a-b160-0ee60b8f31be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0cf9c1-9a43-4ea4-89d2-44de5e334e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa328023-fde3-48d1-95d7-1c662256011f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26cb94ea-78f2-438a-9710-a5db894094a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bcadc54-be21-4c49-add6-3d34752739cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 875a6966-8d9c-4e5a-8f5f-8873b4b70a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a662a854-be4a-49f6-bdcc-6f3504dcfee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc03c39-277d-4743-b986-8dc15b3c8c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c43502-c610-4041-88a4-3023f8dc1857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe07d8e1-24d3-446f-8133-ed1adf1b2397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788c18e1-4f93-4c10-9d5b-f435d10ed123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8759b29-4cd0-4ced-a2b0-65d611395331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce07eb9e-5ec8-4a01-921d-393178482bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e84d986b-5045-4fbc-a704-e54f208cf6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c00a726-4006-4291-a814-42d392d0a273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 970c6ced-7324-4b5c-a2a4-62ebcc272cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 767734cd-4e53-40ef-84bd-683079fff77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07811e8b-38b6-40eb-b9d3-a64dc4066821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 421e620d-ce5d-47a6-92c0-1eb23fd9cf03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2adfd77c-c10c-4594-83dc-cd517233f45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3067d300-52ac-48fe-bcc6-ecd2362f3a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 165d93d9-148a-4f0e-8e90-f895b76a2602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 284aeb07-3f52-42ee-95c5-299039e12007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f3949b-12ef-43a4-8343-b0980b4d706d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_72
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_labels.txt

📊 Raw data loaded:
   Train: X=(2172, 24), y=(2172,)
   Test:  X=(543, 24), y=(543,)

⚠️  Limiting training data: 2172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  534 samples, 5 features
✅ Client client_72 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2469, R²: -0.0147

============================================================
🔄 Round 17 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.001000
   • Epoch   2/100: train=0.0804, val=0.0875, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0794, val=0.0880, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0784, val=0.0883, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0770, val=0.0887, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0693, val=0.0916, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 17 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0376
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0101
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2453, R²: 0.0147

============================================================
🔄 Round 19 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0899 (↓), lr=0.000250
   • Epoch   2/100: train=0.0808, val=0.0901, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0804, val=0.0895, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0801, val=0.0895, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0798, val=0.0895, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0785, val=0.0896, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 19 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0216
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0181
============================================================


============================================================
🔄 Round 20 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0855 (↓), lr=0.000063
   • Epoch   2/100: train=0.0820, val=0.0851, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0819, val=0.0850, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0817, val=0.0849 (↓), lr=0.000063
   • Epoch   5/100: train=0.0816, val=0.0849, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0810, val=0.0847, patience=7/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 20 Summary - Client client_72
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0356
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0012
============================================================


============================================================
🔄 Round 21 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0935 (↓), lr=0.000063
   • Epoch   2/100: train=0.0798, val=0.0932, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0796, val=0.0930 (↓), lr=0.000063
   • Epoch   4/100: train=0.0794, val=0.0929, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0793, val=0.0928, patience=2/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0787, val=0.0929, patience=8/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 21 Summary - Client client_72
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0355
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0050
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2433, R²: 0.0190

============================================================
🔄 Round 24 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0819 (↓), lr=0.000016
   • Epoch   2/100: train=0.0827, val=0.0820, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0824, val=0.0821, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0822, val=0.0822, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0821, val=0.0822, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0818, val=0.0823, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 24 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0267
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0323
============================================================


============================================================
🔄 Round 25 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0792 (↓), lr=0.000004
   • Epoch   2/100: train=0.0830, val=0.0792, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0830, val=0.0792, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0830, val=0.0792, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0829, val=0.0792, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0828, val=0.0791, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 25 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0266
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0419
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2435, R²: 0.0232

📊 Round 25 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2440, R²: 0.0206

📊 Round 25 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2451, R²: 0.0140

============================================================
🔄 Round 30 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0825, val=0.0825, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0825, val=0.0825, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0825, val=0.0825, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0824, val=0.0825, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0823, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 30 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0282
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0031
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2452, R²: 0.0132

============================================================
🔄 Round 31 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 31 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0201
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0121
============================================================


============================================================
🔄 Round 33 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 33 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0194
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0240
============================================================


============================================================
🔄 Round 34 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 34 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0165
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0337
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0117

============================================================
🔄 Round 35 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 35 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0196
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0161
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0115

============================================================
🔄 Round 36 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 36 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0239
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0001
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0114

📊 Round 36 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0113

============================================================
🔄 Round 39 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 39 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0197
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.0124
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0113

============================================================
🔄 Round 41 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 41 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0186
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0224
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0114

============================================================
🔄 Round 45 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 45 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0271
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0139
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0115

============================================================
🔄 Round 46 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 46 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0170
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0307
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0115

📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0116

📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0116

============================================================
🔄 Round 49 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 49 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0236
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0007
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0116

============================================================
🔄 Round 51 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 51 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0207
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0133
============================================================


============================================================
🔄 Round 53 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 53 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0183
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0219
============================================================


============================================================
🔄 Round 54 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 54 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0191
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0234
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0118

============================================================
🔄 Round 55 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 55 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0241
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0016
============================================================


============================================================
🔄 Round 56 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 56 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0235
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0019
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0119

============================================================
🔄 Round 58 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 58 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0126
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0341
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0120

📊 Round 58 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0120

📊 Round 58 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0120

============================================================
🔄 Round 66 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 66 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0170
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0149
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0115

📊 Round 66 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0116

📊 Round 66 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0117

============================================================
🔄 Round 70 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 70 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0162
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0325
============================================================


============================================================
🔄 Round 71 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 71 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0187
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0138
============================================================


============================================================
🔄 Round 74 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 74 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0220
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0087
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0119

============================================================
🔄 Round 79 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 79 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0184
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0227
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0119

============================================================
🔄 Round 81 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 81 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0255
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0126
============================================================


============================================================
🔄 Round 82 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 82 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0194
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0048
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0116

============================================================
🔄 Round 83 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 83 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0228
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0014
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0115

📊 Round 83 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0116

📊 Round 83 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0118

📊 Round 83 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0119

============================================================
🔄 Round 89 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 89 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0146
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0379
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0120

📊 Round 89 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0120

============================================================
🔄 Round 92 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 92 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0173
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0245
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0122

============================================================
🔄 Round 95 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 95 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0181
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0262
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2452, R²: 0.0123

📊 Round 95 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0122

📊 Round 95 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0122

============================================================
🔄 Round 100 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 100 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0200
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0023
============================================================


============================================================
🔄 Round 101 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 101 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0252
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0071
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0121

============================================================
🔄 Round 102 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 102 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0212
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0125
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0121

============================================================
🔄 Round 104 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 104 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0253
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0025
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0121

📊 Round 104 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0122

============================================================
🔄 Round 109 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 109 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0193
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0193
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2452, R²: 0.0123

📊 Round 109 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2452, R²: 0.0123

📊 Round 109 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0122

============================================================
🔄 Round 114 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 114 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0238
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0001
============================================================


============================================================
🔄 Round 115 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 115 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0246
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0039
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0121

📊 Round 115 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0121

============================================================
🔄 Round 118 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 118 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0178
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0251
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0121

📊 Round 118 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0120

============================================================
🔄 Round 120 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 120 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0121
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0378
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2452, R²: 0.0120

📊 Round 120 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2453, R²: 0.0119

============================================================
🔄 Round 123 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 123 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0205
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0082
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0118

============================================================
🔄 Round 124 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 124 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0188
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0169
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0118

📊 Round 124 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0118

📊 Round 124 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0117

============================================================
🔄 Round 127 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 127 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0256
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0167
============================================================


============================================================
🔄 Round 128 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 128 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0279
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0221
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0118

============================================================
🔄 Round 133 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 133 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0168
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0213
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0116

📊 Round 133 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0116

============================================================
🔄 Round 135 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 135 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0251
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0082
============================================================


============================================================
🔄 Round 136 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 136 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0230
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0114
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0115

📊 Round 136 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0114

============================================================
🔄 Round 138 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 138 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0158
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0164
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0112

============================================================
🔄 Round 142 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 142 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0141
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0074
============================================================


============================================================
🔄 Round 143 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 143 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0224
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0074
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2454, R²: 0.0112

📊 Round 143 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0112

============================================================
🔄 Round 145 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 145 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0096
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0464
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0113

📊 Round 145 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2453, R²: 0.0111

📊 Round 145 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2454, R²: 0.0111

============================================================
🔄 Round 150 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 150 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0125
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0357
============================================================


============================================================
🔄 Round 151 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 151 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0117
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0410
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0109

📊 Round 151 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0109

📊 Round 151 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0109

📊 Round 151 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0109

============================================================
🔄 Round 160 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 160 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0167
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0093
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0107

============================================================
🔄 Round 163 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 163 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0218
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0163
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0105

============================================================
🔄 Round 167 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 167 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0130
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0262
============================================================


============================================================
🔄 Round 169 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 169 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0222
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0077
============================================================


============================================================
🔄 Round 170 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 170 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0105
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0228
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0106

📊 Round 170 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0107

============================================================
🔄 Round 173 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 173 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0222
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0016
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0108

📊 Round 173 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2454, R²: 0.0108

============================================================
🔄 Round 176 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 176 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0258
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0174
============================================================


============================================================
🔄 Round 177 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 177 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0192
   Val:   Loss=0.0776, RMSE=0.2787, R²=0.0114
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2453, R²: 0.0109

📊 Round 177 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2453, R²: 0.0109

📊 Round 177 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2453, R²: 0.0110

============================================================
🔄 Round 181 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 181 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0171
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0203
============================================================


============================================================
🔄 Round 182 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 182 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0192
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0052
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2453, R²: 0.0110

============================================================
🔄 Round 183 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 183 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0192
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0068
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2453, R²: 0.0111

============================================================
🔄 Round 185 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 185 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0219
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0017
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2453, R²: 0.0111

📊 Round 185 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2453, R²: 0.0111

============================================================
🔄 Round 189 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 189 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0159
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0262
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2453, R²: 0.0111

============================================================
🔄 Round 192 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 192 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0166
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0251
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0112

============================================================
🔄 Round 193 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 193 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0210
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0212
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2453, R²: 0.0113

============================================================
🔄 Round 196 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 196 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0209
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0056
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2452, R²: 0.0113

============================================================
🔄 Round 197 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 197 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0162
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0276
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2452, R²: 0.0114

============================================================
🔄 Round 198 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 198 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0186
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0166
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2452, R²: 0.0114

============================================================
🔄 Round 200 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 200 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0128
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0338
============================================================


============================================================
🔄 Round 201 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 201 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0252
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0108
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2453, R²: 0.0111

============================================================
🔄 Round 204 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 204 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0227
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0018
============================================================


============================================================
🔄 Round 205 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 205 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0213
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0040
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2453, R²: 0.0111

============================================================
🔄 Round 206 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 206 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0178
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0183
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2453, R²: 0.0110

============================================================
🔄 Round 208 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 208 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0140
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0292
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2453, R²: 0.0110

❌ Client client_72 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
