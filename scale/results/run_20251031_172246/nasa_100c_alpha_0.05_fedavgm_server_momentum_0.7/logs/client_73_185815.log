[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854d4e91-f836-4442-b9c5-139aedbefeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6021dd5-727e-4391-8577-5417891b3979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da57472e-c080-4819-94fc-e6484ee7ba39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55789d72-1cc4-45d3-908a-8d49e9cdbf16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc54e44-d8c4-4d0a-a4c0-ea869616fdd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9405c276-0178-4ff4-b799-7aa6f0b07567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cfb4363-bebd-4cbe-a8b6-d3f969df6c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e20c0a1-e130-43fa-b57a-7ed279ad2cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4f4e177-d61d-4bf9-a939-83b7d8e8b176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86a13611-7a99-4186-81e9-5d6173204e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ada755c-6d2b-4693-9d48-1f6dbb299430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 739e38ce-3cd9-4372-8dcf-39ef192bf04f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c465ba0d-bde3-4523-957a-1f2bc1a826a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c75b45e0-38b9-48b2-987a-3b4861ab10b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245c4cf0-d751-491a-9d38-598940ef6e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0da357-9262-4aa5-80b8-1ab173b080eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18bb3cdb-2a1b-4f89-b7cf-eedef6d9886d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4f7433-dd93-4266-bb57-e92869372a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5db257cb-55e5-4b24-ab8f-1107e2bce3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53a35c6-1ebb-4188-83c1-ac6c0532dc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a55fe8e5-bc3f-4ea0-865e-0cf7eda0725d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02013e04-b5f6-4629-af55-b056a34be014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6f3c45a-f281-49e1-af81-17136b09e2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0c7bbd-fc7d-4b12-adf0-02a1f50d1810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe7d0e7-d405-4074-9015-d652e397e8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bfbab2-60fd-4ac1-bde9-a44b859ace82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b220997-3471-4886-ae5d-b39254c38b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cba55ee-c872-46aa-861b-b1ed3517c3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857cb1e0-16ed-40a4-8b4e-3b703b4fdce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dfede65-4df6-4ff1-9c95-c3cd206b6356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2504f51e-5f78-4596-abf3-53dbb9beeeec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c3aa969-08ea-439e-bff4-32eef943e2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b456350-7993-49c3-b3fd-7aebe470e578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff6c0ca9-91b6-4294-9300-7202acee80f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d5ae2f-a793-4b2a-8c37-3885f6e5a59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d665dd1-3d8d-47cc-811f-4d6412f194c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ee4a3f-76d6-4f54-98a6-8b48c18e7f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f962e59d-67ae-4504-bd17-2edbc14ffa99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6fbd635-424a-43f1-9e5d-c0ecfd47d08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f11ff12-7fd2-444a-b40e-3db33e557b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8bd8f32-6bbf-4956-bff8-4c65c51011f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ba6de0-d644-4ef9-9ce5-029368bfd2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d2be67-836c-458c-85e9-d0f5db8e530a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message debf3894-fc5e-4f74-a955-7f103f5b0b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f1e412a-9145-4c9a-84e5-a9f32553be04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13f62b9-6fd1-4adf-b6d4-c57ad93b859c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d63506-cd21-493c-811b-11ede3d1de85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 387f711c-0fac-4a2f-b6c8-bafc510a9c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2608c2a-0ee7-499f-97fe-f69987113018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557208e3-257c-4c3b-aa8f-3514e75fb71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e977325c-6698-4a54-87f5-704228b37950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7294ca61-de10-4c6c-8998-d1f252edad89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7738ca-e759-4eaf-a6cc-861c9595573d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c47c8f91-69a5-40eb-bf97-2c608b6a909a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc84068a-0273-4609-b74c-738a4ee2481d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661987eb-3f38-49cd-ac12-cce4716168de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97c8b7ac-3746-4fc0-8aa5-def7066cf259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ccedea-462e-42db-a890-eab89963ef8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9c61ea-cf9b-4894-90c3-7e426e860a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 994918b9-a765-46c7-a6e3-631042d4f4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 323bd434-bd1c-4969-9577-96cbb823b455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 267b3bbb-93ba-4ab2-a18d-0c55a2ca195b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bab9b13f-a5c8-4345-a57b-6beb61d73e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc4473c3-ca8f-48ab-b5db-821594db9cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb419e8d-d724-4db1-9d69-0c658c5b6671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10401528-4325-42dd-aea2-40fbcabbe2c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5795c0-96da-4372-9721-186be45bf58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3963be72-8d44-4e6b-9921-e5d43c35a8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 916daf79-3bd3-481c-9490-950022f28ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa332be-5421-439a-a421-aa3eb74b9c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a3874d-a8c4-462b-9ed5-f4237bea2bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d44dae6-25df-40c9-bed7-2121ee4dd4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97f60fbc-db51-48c9-a695-6d596ce5b12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a65a4ba-277e-451c-a2da-6a9b6b8de943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13eb118f-4f9e-4744-8ed7-d3fb8dd78320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ec4a37b-5418-4a4f-ae99-4c6c5c370042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c045cef-71f0-403c-9259-4f76c6c5060c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a072e32-51bf-4968-a889-51530373df63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98e827c-f2e7-46ee-b681-705ef108b0c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081a34fc-fab2-4cfe-9964-5ceb9b60cc66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d97fb69-2391-4f57-8767-91c51177c182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e66adb2-ef63-470c-859f-0b32b3eb9e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92cfcc77-f08b-4833-9387-2414323fad11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7cab8ff-dfb8-40c5-a4e2-7d4ce22e9ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce171b4a-a2d8-49a7-9c90-15ce18bf3302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cd67d6-e07b-4020-84d8-1d7b7a80c345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a1df98-d81b-44b8-81ec-450b9c538af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564212b7-fe4c-49ff-b8d5-47ec61fb050d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7daddd5-8ce1-4b00-b104-c04cbb927540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bef81a8-9b57-4985-ab69-8561e3c30ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 439d40fc-1165-412f-9d76-eca1bf8b6315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c12783d-9782-46b6-8353-564e321b7054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb61ae7-b336-4a3b-bb14-0341bb49af8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 654cd49c-2e48-4e85-b3f2-67bd316f66a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6520e850-ebf2-42b2-9e8b-304a48078745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce631e4-01cd-4422-b2c9-14a79621f2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd5bcf82-3179-49dc-ab99-dc6a3d26d00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754ae135-101a-4f1c-9544-14cbe384f48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 382dd68f-a9db-4bde-b989-2de972dc80ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695a4473-095d-4bf0-8b0d-712938b571aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e853ec8-c55b-4428-a72d-17d3bd6dff9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dff1082-7593-4eea-8be2-9d9b02d550c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b19d36-3a76-4303-a4cc-82891cf3bb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13551855-3d07-4b0e-97a1-f9632e71d609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602ddb17-8a06-4d91-8f82-dffbfa5eae70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3188f8ea-a360-4980-9064-df1ea1fa6b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa37e751-b234-41e6-b6dd-ce12d8750039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b78f9f77-b139-4f3a-8321-089a906ca3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efcf41b8-981d-4d1b-8de2-fbdf51fe79dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8645f7b-add0-4091-99f2-7c1ea558712b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4cf449-cfe2-42fc-8df8-53eb31b62625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a86180d-055e-4236-b9f9-d2ca1698b7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603ef82c-3ea6-4f23-a500-c960916a3674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c36780-7c4b-4406-8a7d-2dc28d5d0f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4736a962-720e-4a2f-a358-fe2f4cbf6a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 853f955e-8bb3-4950-b45a-887dd56606d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75645f18-bffa-4771-b8bd-cac49545e9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb03b33-c8f6-4fc1-912d-8540324b9054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 364ef9e5-4d0e-4ad1-afa8-e79f07c11d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56322411-b8bc-4465-a54a-1d8ba5877c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412b0e04-13ee-4d94-a738-6e18d6ffd131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e7de04-1cd5-480f-8bab-9aa6aff39c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f7aa76-ac8e-4834-b672-361d56ae885f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9bed992-8934-4410-b098-3e5dbc4e94a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 306e0793-e014-4d6f-98fa-69637b9404b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980730f3-0c8c-40bd-9abf-472097764d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 694608a9-6d71-40a5-81b5-3d29bf1f8135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6f949c-847f-487e-9c4d-221a7cb9620c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f33d686-d811-47f4-bab0-934134c71fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0a9723-80c5-4d95-8034-ef1916356c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e991924f-c427-446d-9464-79ee5ff32414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d794790d-04d2-495f-a7fe-e0264637636d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9137110-a1fb-4433-9c57-8860e22a0771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31fae583-4181-4187-8e39-a73db3736242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a356ccb-7cb2-4b8b-a7fc-f80f60306213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86548060-2b6a-4870-9b23-f534c7338ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f95c3cfe-1706-4011-ac43-3409465e62f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e87865-7c88-4788-aa9b-68deda1b2f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ddf093-9119-4f3b-a7da-a24cc111e074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4347ee5-d0a6-4c14-8677-93a3671dcb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4005047-37ba-42d6-9454-045161e5ae1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196727d2-dcab-46d0-82ce-f5498bc78a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56aa83f0-533f-423e-8ba2-55565a20f47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54bf4111-cb29-42f0-a944-34e8b120846b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc1314d-bbee-4b05-9432-7d35cc5404b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea8f18f-b093-4de4-b16a-a4ce22d0a0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e5c1f9c-d84d-4ff9-9e92-4143534d3e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f5980f9-7da1-4e96-8c66-bd551efcd3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ca89d6-3385-453c-bb9f-25a7e19480cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47519536-5ed7-4261-b42b-5343607e4625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e530e48-2acd-487d-bb4e-595e6a86be0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdc7291-b6bf-4c20-aeab-d13e48fc2d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ef0a504-9e46-4752-a909-9e9570d8791e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eed3ecf-2c90-4751-99ad-f9a7efa01acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52fcfe5a-ffbe-4c8d-9426-94d35201d134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2bed1b0-0af5-4b5c-961d-358f0fc3a6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e3bf8f-c5a4-41c3-9b92-26cc0234a27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 953d090d-c0cd-4fcb-87e4-b2c0c95ef199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3157c527-b040-400a-b38c-0bddc69317ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19306b00-c050-4ab9-9b8b-06f8e1a31ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35cca69d-f4b0-477b-a250-5a0df371be0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5091eee7-ac04-407f-a37b-a53c4a4b39af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d676a7-dc9a-4194-9744-2914b9bf89dd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_73
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_labels.txt

📊 Raw data loaded:
   Train: X=(1311, 24), y=(1311,)
   Test:  X=(328, 24), y=(328,)

⚠️  Limiting training data: 1311 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  319 samples, 5 features
✅ Client client_73 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2310, R²: 0.0852

📊 Round 0 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2303, R²: 0.0908

============================================================
🔄 Round 17 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0762 (↓), lr=0.001000
   • Epoch   2/100: train=0.0767, val=0.0776, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0755, val=0.0773, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0745, val=0.0775, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0740, val=0.0784, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0691, val=0.0832, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 17 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0827
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0275
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0754, RMSE: 0.2746, MAE: 0.2308, R²: 0.0897

📊 Round 17 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2319, R²: 0.0826

============================================================
🔄 Round 19 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0724 (↓), lr=0.000250
   • Epoch   2/100: train=0.0783, val=0.0729, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0777, val=0.0725, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0771, val=0.0728, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0767, val=0.0732, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0750, val=0.0743, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 19 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0644
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0421
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2324, R²: 0.0774

📊 Round 19 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2339, R²: 0.0629

============================================================
🔄 Round 22 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0826 (↓), lr=0.000063
   • Epoch   2/100: train=0.0767, val=0.0831, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0764, val=0.0834, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0762, val=0.0834, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0760, val=0.0834, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0752, val=0.0834, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 22 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0552
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0313
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2354, R²: 0.0510

============================================================
🔄 Round 25 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0695 (↓), lr=0.000016
   • Epoch   2/100: train=0.0802, val=0.0694, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0801, val=0.0693, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0800, val=0.0692, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0800, val=0.0691, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0797, val=0.0687, patience=5/15, lr=0.000016
   • Epoch  21/100: train=0.0792, val=0.0683, patience=5/15, lr=0.000016
   • Epoch  31/100: train=0.0789, val=0.0681, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 25 Summary - Client client_73
   Epochs: 31/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0552
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0744
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2361, R²: 0.0498

============================================================
🔄 Round 27 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0853 (↓), lr=0.000016
   • Epoch   2/100: train=0.0768, val=0.0853, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0767, val=0.0852, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0766, val=0.0852, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0765, val=0.0851, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0762, val=0.0850, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 27 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0495
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0372
============================================================


============================================================
🔄 Round 28 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0847 (↓), lr=0.000004
   • Epoch   2/100: train=0.0768, val=0.0847, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0768, val=0.0847, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0768, val=0.0847, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0767, val=0.0846, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0767, val=0.0846, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 28 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0464
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0574
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2369, R²: 0.0491

============================================================
🔄 Round 29 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 29 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0423
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0711
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2370, R²: 0.0490

============================================================
🔄 Round 30 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 30 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0479
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0344
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2373, R²: 0.0490

============================================================
🔄 Round 35 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 35 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0449
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0416
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2374, R²: 0.0491

============================================================
🔄 Round 37 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 37 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0471
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0366
============================================================


============================================================
🔄 Round 38 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 38 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0421
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0568
============================================================


============================================================
🔄 Round 43 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 43 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0396
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0515
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0489

📊 Round 43 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0488

============================================================
🔄 Round 47 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 47 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0451
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0502
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0486

============================================================
🔄 Round 49 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 49 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0425
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0550
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0487

============================================================
🔄 Round 52 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 52 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0446
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0320
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0486

============================================================
🔄 Round 53 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 53 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0425
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0611
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0485

============================================================
🔄 Round 54 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 54 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0437
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0193
============================================================


============================================================
🔄 Round 55 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 55 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0524
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0026
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2375, R²: 0.0485

📊 Round 55 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2375, R²: 0.0484

============================================================
🔄 Round 57 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 57 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0467
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0447
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2375, R²: 0.0484

📊 Round 57 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2375, R²: 0.0484

📊 Round 57 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2375, R²: 0.0484

============================================================
🔄 Round 61 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0646 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0646, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0646, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0646, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0646, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0646)

============================================================
📊 Round 61 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0427
   Val:   Loss=0.0646, RMSE=0.2542, R²=0.0654
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0487

📊 Round 61 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0487

============================================================
🔄 Round 64 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 64 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0449
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0536
============================================================


============================================================
🔄 Round 65 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 65 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0474
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0103
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0489

============================================================
🔄 Round 66 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 66 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0451
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0381
============================================================


============================================================
🔄 Round 67 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 67 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0467
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0383
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0490

📊 Round 67 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0490

📊 Round 67 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0489

============================================================
🔄 Round 71 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 71 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0470
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0449
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2375, R²: 0.0489

============================================================
🔄 Round 72 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 72 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0489
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0167
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2376, R²: 0.0487

============================================================
🔄 Round 76 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 76 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0526
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0125
============================================================


============================================================
🔄 Round 77 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 77 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0505
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0281
============================================================


============================================================
🔄 Round 78 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 78 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0473
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0406
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0489

============================================================
🔄 Round 81 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 81 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0471
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0447
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0493

============================================================
🔄 Round 83 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 83 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0425
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0631
============================================================


============================================================
🔄 Round 84 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 84 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0446
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0558
============================================================


============================================================
🔄 Round 87 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 87 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0514
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0275
============================================================


============================================================
🔄 Round 89 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 89 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0407
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0577
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0493

============================================================
🔄 Round 93 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 93 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0457
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0501
============================================================


============================================================
🔄 Round 94 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 94 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0441
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0566
============================================================


============================================================
🔄 Round 98 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 98 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0440
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0547
============================================================


============================================================
🔄 Round 99 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 99 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0447
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0478
============================================================


============================================================
🔄 Round 100 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 100 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0443
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0550
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0492

📊 Round 100 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0492

============================================================
🔄 Round 102 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 102 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0515
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0029
============================================================


============================================================
🔄 Round 104 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 104 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0508
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0294
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0493

============================================================
🔄 Round 107 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 107 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0462
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0443
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0493

📊 Round 107 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0493

============================================================
🔄 Round 109 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 109 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0471
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0437
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0493

============================================================
🔄 Round 111 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 111 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0384
   Val:   Loss=0.0704, RMSE=0.2652, R²=0.0766
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0494

📊 Round 111 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2375, R²: 0.0494

📊 Round 111 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2375, R²: 0.0496

============================================================
🔄 Round 116 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 116 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0454
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0522
============================================================


============================================================
🔄 Round 117 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 117 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0463
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0191
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2375, R²: 0.0498

📊 Round 117 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2375, R²: 0.0500

============================================================
🔄 Round 121 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 121 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0473
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0458
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0504

============================================================
🔄 Round 126 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 126 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0546
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0177
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0505

📊 Round 126 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0505

============================================================
🔄 Round 137 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 137 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0488
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0410
============================================================


============================================================
🔄 Round 139 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 139 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0471
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0471
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

============================================================
🔄 Round 141 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 141 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0495
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0305
============================================================


============================================================
🔄 Round 143 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 143 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0518
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0214
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0509

============================================================
🔄 Round 144 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 144 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0460
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0490
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0508

============================================================
🔄 Round 146 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 146 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0447
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0569
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0507

============================================================
🔄 Round 149 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 149 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0510
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0271
============================================================


============================================================
🔄 Round 150 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 150 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0470
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0456
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0787, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

============================================================
🔄 Round 152 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 152 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0536
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0224
============================================================


============================================================
🔄 Round 153 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 153 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0492
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0135
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

============================================================
🔄 Round 155 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 155 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0504
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0300
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

📊 Round 155 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0510

============================================================
🔄 Round 158 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 158 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0455
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0398
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0511

============================================================
🔄 Round 161 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 161 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0511
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0155
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0511

============================================================
🔄 Round 162 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 162 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0462
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0488
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0513

============================================================
🔄 Round 165 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 165 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0406
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0760
============================================================


============================================================
🔄 Round 166 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 166 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0427
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0579
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0512

============================================================
🔄 Round 168 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 168 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0550
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0172
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0512

============================================================
🔄 Round 170 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 170 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0556
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0096
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0511

📊 Round 170 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0511

============================================================
🔄 Round 174 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 174 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0433
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0601
============================================================


============================================================
🔄 Round 175 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 175 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0501
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0356
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

📊 Round 175 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

============================================================
🔄 Round 178 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 178 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0465
   Val:   Loss=0.0959, RMSE=0.3096, R²=0.0474
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

============================================================
🔄 Round 180 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 180 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0433
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0584
============================================================


============================================================
🔄 Round 184 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 184 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0468
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0443
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0508

============================================================
🔄 Round 187 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 187 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0488
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0258
============================================================


============================================================
🔄 Round 189 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 189 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0462
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0495
============================================================


============================================================
🔄 Round 190 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 190 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0446
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0473
============================================================


============================================================
🔄 Round 191 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 191 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0430
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0451
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0508

============================================================
🔄 Round 194 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 194 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0464
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0457
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0508

============================================================
🔄 Round 196 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 196 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0497
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0333
============================================================


============================================================
🔄 Round 197 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 197 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0416
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0644
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0508

============================================================
🔄 Round 199 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 199 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0298
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0875
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2375, R²: 0.0508

📊 Round 199 Test Metrics:
   Loss: 0.0787, RMSE: 0.2804, MAE: 0.2375, R²: 0.0509

============================================================
🔄 Round 201 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 201 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0464
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0430
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0511

============================================================
🔄 Round 203 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 203 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0446
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0468
============================================================


============================================================
🔄 Round 205 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 205 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0480
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0368
============================================================


============================================================
🔄 Round 206 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 206 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0470
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0464
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0512

============================================================
🔄 Round 207 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 207 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0445
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0423
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0512

📊 Round 207 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0513

============================================================
🔄 Round 210 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 210 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0481
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0417
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2375, R²: 0.0513

============================================================
🔄 Round 211 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 211 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0533
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0099
============================================================


❌ Client client_73 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
