[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e84eca6-0817-423f-adbd-976bc8c58dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7289779-c83e-4de2-93c7-0343a84cbdd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0f9df0-3d4a-4442-a73d-99ff69a1adc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e009922-f3ea-4ee3-9948-a6795b988b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96416816-6e74-402f-bfd1-b86d6b5c4822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e2c635-9884-4cb0-8bc9-1e5e09c776be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b8d1db-d6e9-4ff4-8c07-b992af66858f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a215086-228f-4d79-ab15-39e0f9d39c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c329c3e3-73a9-43f5-9443-32ee4ba14fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80274530-d154-4084-a7b7-8b8fbdf015d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d4119d4-ea64-4af2-beee-d3cf10cd7e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c116127c-dbb0-488f-a0f2-cdb60a03b86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d071d305-8398-48f9-b86a-edaa25dd19f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 273fd20a-183a-499e-b722-8a1f36310bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1abd0bb-3bae-467a-b659-05453c443e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3656fc83-e17d-4bf2-8a5a-9b897d5dc902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b19241c-6257-468a-9a4a-bfc31d4dc211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ca09b9-1308-4f90-afb9-9639156876f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b933964e-aaca-4a86-bea2-7dfe78914246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c207fd14-05f4-4ed1-87b1-a953c1ec6fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194aa540-ce45-4837-8a23-3a9a0a7324af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa2a5b37-f9e0-453a-868f-4829966d3fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a5810e-6d98-47c8-8b84-67a791b07b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2925bf-db50-4608-a41b-5c43b1be4bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3520e48-8901-4353-b38b-8974c3fcb6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d24184e-88f6-4e9f-954c-497bcf542da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6864343-f368-4466-990c-d302cbf5a60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 517e7982-eccb-48ea-ac10-f6ace3f06150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb536267-b888-400e-af12-f6e19ae80bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd2a2e31-f225-42e3-a03d-3390b9754e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5298972-2613-4970-8bfc-5387086a89eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e53411b6-0f1b-4210-a30a-1170af053743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c901a63-706e-4294-8a75-3c49ee05bb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1289e55-039b-4674-8219-02ed914a102a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452f89df-871b-4ccf-b8c8-332843d91bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f23bee83-db2c-43a1-9775-6d292ab25ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 316a23ba-93da-4774-9542-686bdc08dd97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac816507-c60b-4a58-9b31-5eb1b3153f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8e5ddbb-07f6-43f9-9014-6276907bb8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f326a1c8-439c-42b5-b9d3-0d96dc4c6a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b71bb5-40c0-476f-a19e-98ccc91ef650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8096ca26-53d5-4fff-958c-31192a7ff811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec6fe6a-a8f2-450a-86ec-b2af3518bd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49226f16-01b2-41dd-a4f9-3bd9160b0f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b892f46-66a5-4fe4-803a-17b3e8b744c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 589cc73b-52db-4556-b3c0-eb99a14618c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4181bb54-662d-47d3-ac9d-10bf7c74612c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c275ded-227e-4b62-9d87-43f742f91262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df160c41-7f47-4260-85f7-69638fed27df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e18ca6-5575-4e34-b9d9-584768aa39d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495d221f-7dfc-4ddf-8b74-2fca7dcae377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d709f1-9c72-4fd3-af98-fd8a81dd993b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1b474c-019e-401f-adc9-ffdd83d08f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64cef29a-9719-4911-b188-7340f6f5d6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cefa93-67d6-4ca1-af01-88ffea542ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef52ad6-6870-4abc-bd73-40be008e4239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63243cc-275a-4c4c-92ed-cab75cede9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 675df943-724d-446a-9db0-9c8c821cdc66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f27f9cde-c072-4f21-a111-a5b5daae2d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e93ead98-05ca-4d04-a317-d60603b7a680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fedd480-ae48-4dc4-97a3-10ea3a0fb686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8daa4b9-13f8-49c7-90d6-157f041bdc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 681e8224-1def-4a9e-84b8-2833e50a9fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ed5eeea-9575-4fa6-be8f-572c7d98a331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3fbfe43-3ea1-4957-991a-11fb1c1aca28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12d603d-90ab-4b33-8938-eebeb493b166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e95167-ede9-4ddd-ab72-55300d1501d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d18892a-4c1c-4519-a788-6a2361556f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b32afe3-56a5-409c-8b1d-9baa65d89b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 152cba41-fc66-4b30-b84e-4d5c334f2d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676d79ef-48ad-49bd-adc3-19e6b04ba2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c3c218-815c-4d48-a823-125d7e55a87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2348b3ab-6604-47c8-9890-035755d0af41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d8f9cb-4a55-4de9-a061-3c53f169bc75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bb9566-8220-4211-9203-762cc1cd550f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57a31692-af93-4ad7-a2bb-64b0169d2e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b11700c-48b8-4145-a8ce-9f84a8b573e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a794b400-534c-49ac-8da4-a93ea3930549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1dc72da-6536-4b03-ad50-ebda87f1b8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03709890-2d70-4273-9fff-fe89bdb29f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd01339-08ea-4549-9200-77d2c01badb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e459c4b5-50fa-45f6-bad1-8ba231947053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e6b90a2-e965-41c5-8134-edf05b0a116b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a0f614-1c10-4fd9-9ab4-c96c8441861d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55953a15-63a5-44a0-a2c5-9f24f7e3bf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce128648-e099-48b3-8161-aa0ca51ed5c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8890b53a-0264-4a83-9a94-ea57182c6f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64305ba9-00a9-4076-9fb3-d615dddf98d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1050600-d4fa-4e8f-8016-48598f50f063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bcb0bb-971a-4b4d-aa84-8d3f7a8f6468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71623bc6-9f64-477a-be7d-fd203de247fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef020ff-eaca-408d-8166-c8062ab978e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4f0b673-b59d-4bda-a6bf-27d601641f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0e47626-22d7-4835-b5a2-a1fbbe122234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca399009-4c08-4620-8866-1d273433941a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39f013b-8d51-40d5-b2f5-468f82e74af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c09a335-6f8b-44ca-8907-c46a177470f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00cb673-8424-48cf-a8fe-c6705f45a4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01cb2f22-709d-47bf-9134-d7c3e54929a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c87a32a-1fb5-4346-9dd4-2572a3da9e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b458b58-62fd-4677-aa6d-5f570be6a4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1437bb47-3cfc-4bb2-9fbb-2820ee74e55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43272b5e-33c6-4635-b740-cda67021dc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36160cd7-7fca-4c0c-90f6-3395934185e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c61cd8-77ce-42e4-8414-c367042d7db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330a52c1-88dd-42e9-97e6-e830d7c25bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896bef9d-556e-4155-a97a-5adca83f8861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39fff86-bd55-4af6-9153-ac90c80c8434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe0eed1-bc90-4f86-9278-d7e2fd6bdab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38565fdf-e394-4cc7-9660-4bf1a335797a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b02dc364-af40-4c4c-bbd8-48f5eef155a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48898e86-2429-4b85-9462-028d287a0a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f7556c-1c2b-4011-a20b-97b241f92fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee91baf-1b39-4485-b6ab-ba72506b5999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e356080a-60f9-4093-9f9a-3f6b168b1a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83f94f53-74b0-46e0-967d-aac4bcf4d186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f161ee30-dc98-4acc-bc79-26f4abf90ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64da0046-e2d9-4b9a-94d5-1dfaac72ffd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276a545c-3759-4128-bfe8-ccd3fd30a3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a03dcc-05bd-44b8-8144-2807cf234e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca3792f-5f02-48f3-ac87-80fa639fe729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a1ada1f-a474-4b1e-aecf-3f63dc23c6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdeeb48e-1347-4dce-a68d-33f5c6a95e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e43600-a0e4-433d-8daa-9fbfcb2ff99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f316dd0-cc84-46b1-90c3-18b8561a6bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fffec57-502b-459f-8f5c-6365cc018795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c872c1-f25d-4b7c-a626-70d02d942788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43459d32-09e3-43b9-a3d0-eb555310a52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154fe80e-e437-4350-a31b-60a081248902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5807d9bf-eb47-49cd-9967-387399d2d183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213fc0f8-8052-4dfa-ad2c-039d2fec1e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b318ec2d-65da-40b5-9163-94062a59b3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e7f282-3fd1-4006-8ca7-f86b3ec57965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc0eac00-257b-47d7-9615-bc493b9ae7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661abe89-778b-4e77-8a87-5773f53ea24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d42a3cf2-5db6-4113-a711-df352ae0dc20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bb4137-a4d5-45bf-9114-c9c538e99b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd5b185-c2b6-4f7b-bd1c-3ad8dc3dbe3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2ee4475-d8eb-44ab-aad7-7e008657d7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24c30717-1906-4faf-b50f-f540f20bfd9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42a2f89c-43ae-4289-a059-5ec8292834d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440be32a-8016-4804-9f1b-a7092bc8014f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b1aa96-f49d-4da4-8148-cac50c667146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda0a031-d562-4077-8b78-4533472c268d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c23cf26-93c1-4354-8bbe-084d1d202de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b50f8284-ab03-483b-93c0-f84aca0ca9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9797ec9-94ec-46c5-903f-9354d976ab16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d38b14f5-7800-40c6-97ba-97514cba368b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7758f296-3d82-4b41-9085-420811768df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 886b0832-3a63-4d77-9454-0c92c8b40c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c17400-ffed-42f9-89b4-d273668213f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23543025-2fd4-4d3b-9069-984f88f451dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e8ced0-b58a-4981-95d2-2256b150d239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe598d5f-7896-4c6f-b147-a8698e8066d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996f2468-02ec-45b9-a5a4-6c68fd4c9b96
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_74
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_labels.txt

📊 Raw data loaded:
   Train: X=(1660, 24), y=(1660,)
   Test:  X=(416, 24), y=(416,)

⚠️  Limiting training data: 1660 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  407 samples, 5 features
✅ Client client_74 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0775 (↓), lr=0.001000
   • Epoch   2/100: train=0.0781, val=0.0779, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0774, val=0.0776, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0765, val=0.0782, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0758, val=0.0789, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0710, val=0.0817, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 16 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0165
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0179
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2480, R²: 0.0006

📊 Round 16 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2495, R²: -0.0122

============================================================
🔄 Round 18 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0741 (↓), lr=0.000250
   • Epoch   2/100: train=0.0797, val=0.0744, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0795, val=0.0743, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0791, val=0.0743, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0788, val=0.0743, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0777, val=0.0740, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 18 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0091
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0072
============================================================


============================================================
🔄 Round 20 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0839 (↓), lr=0.000063
   • Epoch   2/100: train=0.0772, val=0.0836, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0769, val=0.0834, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0767, val=0.0834, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0765, val=0.0835, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0759, val=0.0838, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 20 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0083
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0236
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2480, R²: -0.0011

============================================================
🔄 Round 21 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0811 (↓), lr=0.000016
   • Epoch   2/100: train=0.0778, val=0.0810, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0777, val=0.0809, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0777, val=0.0808, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0776, val=0.0807, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0774, val=0.0806, patience=3/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0772, val=0.0806, patience=13/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 21 Summary - Client client_74
   Epochs: 23/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0108
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0054
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2473, R²: 0.0048

============================================================
🔄 Round 23 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0788, val=0.0767 (↓), lr=0.000002
   • Epoch   2/100: train=0.0788, val=0.0767, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0788, val=0.0767, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0788, val=0.0767, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0788, val=0.0767, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0788, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 23 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0104
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0033
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2479, R²: 0.0001

============================================================
🔄 Round 28 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 28 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0025
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0212
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: -0.0042

============================================================
🔄 Round 30 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 30 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0075
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0361
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: -0.0046

📊 Round 30 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: -0.0049

============================================================
🔄 Round 32 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 32 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0053
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0130
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2485, R²: -0.0053

📊 Round 32 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2485, R²: -0.0055

📊 Round 32 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2485, R²: -0.0055

============================================================
🔄 Round 37 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 37 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0004
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0030
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2485, R²: -0.0054

📊 Round 37 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2485, R²: -0.0052

============================================================
🔄 Round 41 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 41 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0037
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0049
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0049

📊 Round 41 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: -0.0047

📊 Round 41 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: -0.0044

============================================================
🔄 Round 50 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 50 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0045
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0115
============================================================


============================================================
🔄 Round 51 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 51 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0029
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0006
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: -0.0042

============================================================
🔄 Round 52 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 52 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0005
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0072
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: -0.0042

============================================================
🔄 Round 53 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 53 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=-0.0010
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0106
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: -0.0041

============================================================
🔄 Round 54 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 54 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0013
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0220
============================================================


============================================================
🔄 Round 56 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 56 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0026
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0005
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0038

============================================================
🔄 Round 58 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 58 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0015
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0192
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0037

============================================================
🔄 Round 60 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 60 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0031
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0090
============================================================


============================================================
🔄 Round 61 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 61 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0022
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0119
============================================================


============================================================
🔄 Round 67 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 67 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0061
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0337
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: -0.0040

============================================================
🔄 Round 70 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 70 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0021
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0150
============================================================


============================================================
🔄 Round 71 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 71 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0049
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0072
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0037

📊 Round 71 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0036

============================================================
🔄 Round 75 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 75 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0009
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0037
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2484, R²: -0.0035

============================================================
🔄 Round 76 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 76 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0064
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0116
============================================================


============================================================
🔄 Round 79 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 79 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0000
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0106
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0037

============================================================
🔄 Round 80 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 80 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0088
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0357
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: -0.0040

============================================================
🔄 Round 82 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 82 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0089
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0227
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: -0.0041

📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0042

============================================================
🔄 Round 86 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 86 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0042
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0112
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0042

📊 Round 86 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0042

============================================================
🔄 Round 90 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 90 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0027
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0024
============================================================


============================================================
🔄 Round 92 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 92 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0063
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0089
============================================================


============================================================
🔄 Round 94 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 94 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0025
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0033
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2484, R²: -0.0035

============================================================
🔄 Round 96 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 96 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0004
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0068
============================================================


============================================================
🔄 Round 98 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 98 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0079
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0227
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2484, R²: -0.0035

============================================================
🔄 Round 99 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 99 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0011
   Val:   Loss=0.0680, RMSE=0.2608, R²=-0.0037
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2484, R²: -0.0035

============================================================
🔄 Round 100 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 100 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0004
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0117
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0036

============================================================
🔄 Round 101 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 101 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0025
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0036
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0036

============================================================
🔄 Round 104 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 104 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0003
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0093
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0036

📊 Round 104 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2484, R²: -0.0035

============================================================
🔄 Round 110 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 110 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0013
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0141
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2484, R²: -0.0035

============================================================
🔄 Round 111 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 111 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0065
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0234
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0036

============================================================
🔄 Round 112 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 112 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0036
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0017
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2484, R²: -0.0037

============================================================
🔄 Round 114 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 114 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0010
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0168
============================================================


============================================================
🔄 Round 119 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 119 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0059
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0307
============================================================


============================================================
🔄 Round 121 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 121 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0062
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0226
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0044

📊 Round 121 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0046

📊 Round 121 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0046

============================================================
🔄 Round 124 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 124 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0026
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0231
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0047

📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0047

📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0047

============================================================
🔄 Round 129 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 129 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0034
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0121
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0046

📊 Round 129 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0045

============================================================
🔄 Round 131 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0640 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0640, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0640, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0640, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0640, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0640, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0640)

============================================================
📊 Round 131 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0036
   Val:   Loss=0.0640, RMSE=0.2530, R²=-0.0182
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0045

============================================================
🔄 Round 133 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 133 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=-0.0058
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0248
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0047

============================================================
🔄 Round 134 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 134 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0006
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0065
============================================================


============================================================
🔄 Round 135 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 135 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0007
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0194
============================================================


============================================================
🔄 Round 138 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 138 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0023
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0009
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2486, R²: -0.0050

============================================================
🔄 Round 142 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 142 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0008
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0179
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0048

============================================================
🔄 Round 145 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 145 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=-0.0070
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0360
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0046

============================================================
🔄 Round 148 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 148 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0055
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0095
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0047

============================================================
🔄 Round 150 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 150 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0046
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0004
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0047

📊 Round 150 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0047

============================================================
🔄 Round 155 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 155 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0096
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0208
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0046

============================================================
🔄 Round 160 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 160 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0004
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0101
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0047

============================================================
🔄 Round 161 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 161 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0054
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0104
============================================================


============================================================
🔄 Round 164 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 164 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0060
   Val:   Loss=0.0688, RMSE=0.2624, R²=-0.0192
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0048

============================================================
🔄 Round 165 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 165 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0012
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0102
============================================================


============================================================
🔄 Round 167 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 167 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0050
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0053
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0047

📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0046

📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2486, R²: -0.0046

============================================================
🔄 Round 171 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 171 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0052
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0058
============================================================


============================================================
🔄 Round 172 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 172 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0084
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0192
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0043

📊 Round 172 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0043

📊 Round 172 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2485, R²: -0.0043

============================================================
🔄 Round 179 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 179 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0009
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0097
============================================================


============================================================
🔄 Round 182 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 182 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0026
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0054
============================================================


============================================================
🔄 Round 183 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 183 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0006
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0138
============================================================


============================================================
🔄 Round 184 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 184 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0049
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0023
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0040

📊 Round 184 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0040

============================================================
🔄 Round 187 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 187 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0110
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0465
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0039

============================================================
🔄 Round 189 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 189 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0051
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0053
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0039

📊 Round 189 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0039

============================================================
🔄 Round 192 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 192 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0044
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2485, R²: -0.0039

============================================================
🔄 Round 194 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 194 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0016
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0115
============================================================


============================================================
🔄 Round 195 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 195 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0035
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0033
============================================================


============================================================
🔄 Round 196 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 196 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0024
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0067
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2485, R²: -0.0038

============================================================
🔄 Round 197 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 197 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0028
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0062
============================================================


============================================================
🔄 Round 200 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 200 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0043
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0011
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2485, R²: -0.0038

📊 Round 200 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0040

📊 Round 200 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0040

📊 Round 200 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0040

📊 Round 200 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0041

📊 Round 200 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0042

============================================================
🔄 Round 210 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 210 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0011
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0088
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2485, R²: -0.0042

❌ Client client_74 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
