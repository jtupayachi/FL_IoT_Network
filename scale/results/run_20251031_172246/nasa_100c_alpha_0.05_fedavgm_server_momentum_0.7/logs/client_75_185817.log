[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce5f11b-350d-4ec2-9ac0-e7e6ec1d88dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ebc5dd0-99d1-4e09-a09e-184fd5d1c1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7411e20b-3beb-4eb5-9e5e-2747b6039a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afbc6f62-ef28-4cbf-8de4-b1d239956d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5acf4234-11fb-4e05-b280-0824c0577300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4a3845-5383-4e3e-9cfa-6efc399bebb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6598f710-c798-40d6-a356-1981612dd7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07fd797-d623-4a2b-b43b-59fa4cd8006e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53b6341-67c6-4a8c-b5c7-85fef0a24e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c3117d-9642-443d-84b4-899d68404460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d292f1f-7f3e-437e-91a3-4de97f001d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9f4d2b-98bd-41ce-b4e5-c792ef47fce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33338995-c752-4d55-9987-4e74bf116233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f6acd2-25a1-4adb-a150-18d5e47c0e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 704bff0a-133b-4d4d-abb6-6807783470e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55ef5094-9d2c-469e-9dfe-518ec65c6f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a08a02-9bf5-4849-ab43-0d6088cb8d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17fa5790-8b2f-404f-8d26-6a7561c0d6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e87b97-fc06-435a-b172-b3b31cdbb9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4a8eb7-144e-4819-8e7d-b76a209f7040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e62d97-a6ca-442c-acc2-92d8ebbfbe16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a8ccbf-9d92-4e08-9198-1fbe1c104879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07f6676-1121-407c-8dc6-b3509b7d0c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353dafa0-90dd-46b8-885a-aa6257126640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9cd49c-6e84-4526-b744-9336018aa58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96d2a33a-ca04-45d5-9201-aba60b573569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00270ee0-222b-47a7-97b6-82ec47ccfa03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eceef54-c3cf-4d6a-bc1b-d4f9e1a24d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d3007b-df5a-4f61-84cd-391771021b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e95a34b2-72c0-4cec-b360-a5062091c586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa59eb9-6bbe-4b00-a1c0-835b322baf4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a70b4d-4b73-4d0f-b636-6156355ac071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb0a130-c622-4bb2-8267-65d75477ac24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7abc76-e480-4a1a-b8eb-0fdc215cd190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfde0ccd-9961-4ebb-96a4-fa7dcd7b4740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e95ad3fe-f8ef-4a9d-a1c2-dfdd02ecbd66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e82e009-ae10-4152-8a0e-af37c45fb7bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e30431-d596-4917-bdc8-ab574eb75d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6781ab-00dd-4a64-bdd6-4c8994986e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fbd9af8-335e-401d-9642-1e311df54e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15104935-b86e-42c9-b198-10e8d2f2ed9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b641ba-d84a-41bf-a0b8-ee774be8eebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0ca5483-b3d2-4f8a-bb8d-d7fc3a4b7c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2d027b-8dd0-46e9-96ee-7955a4b24573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8431bdbc-2997-410a-97c8-671dff286a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1405a123-0b5f-4604-836c-4e5c5e556620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ffec18-8613-41c1-a2e0-1b5af706657f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90832883-153e-4d60-84d7-7e9e96680d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fbd6d4-93b5-4ed6-ae28-4e329829f57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d532748-921e-49da-9cab-9edea2235e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9759f9ca-d1c3-47a7-9f9b-eabae1489c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f5a5d7-cd16-43e8-be5f-e520350393fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9aa2ae-dd65-4ef1-8b97-cf3661938ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f90865-8ad0-412d-8d24-98b4de9aacdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad6b031-fdf1-448a-99d9-d00b69953e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fce08d9-7c4b-4bc7-9b7a-86fe409a9c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db1689e-00da-4cde-ba7c-896bc09fbeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7375467d-f8f0-4ccb-b9da-0127d11c8683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e728d4cf-0895-4bd8-bedf-a4599ffd7899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe7fc8f-569f-4ce5-99a0-706c5ff195d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce4da8a-e98a-4017-8e03-3ddd07147945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0f17c4f-7475-4420-a13a-02cb5925bd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0f72ae-1f5c-41a2-a7c4-d21e90fa5e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c12198-15e2-414e-a307-9e78a4fc93a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c59224-6182-4a81-b675-6a9584891547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e70754fb-c52e-487b-bee1-062e7c7575a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520aee85-630c-4889-8540-7284662b1e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569ae27a-b51c-43e6-929f-d7305b62039a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f085e538-74ab-41b1-9478-6af31bfb2568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f53311a-12bd-42a1-8672-7d99d916db36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d66c50c-dc81-4df6-a2b2-9d32941cc51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9210a33-6480-4f03-932b-3cbc4e6890c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d2cd7e-7bf6-4591-8fdb-c26de204dc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9e27f2-801a-43ea-acd9-b2dc8a0de9ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91c33df-0955-4cea-baf1-f48df78e24f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8342d93-aa53-4a58-a068-66ae3ac59a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50c2d27-c9be-4e1a-94d8-74979223ef7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299b47fb-b63a-4603-b79c-fa302637e57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760962f4-57c2-499f-97e7-d6b8aee0973b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6a92aa1-d27e-43c8-95c5-e6901fdf7486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 380a4564-4733-437b-8359-904657d33ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17397fa2-6e51-45fa-bb58-15256b08360c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f91b7f3-8b86-4e78-bbda-7ca610f41e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d82104-85b7-4cb6-9696-580bd56ea10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6dd94f-422a-4e94-90ed-65d4c2e2110c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bcc35fc-4e5c-4c3e-9eaf-69ed4d357f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 288151ec-b7c7-41af-92d1-1d0f16ccc6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ff7333-26e0-414e-8f19-fa6b47cd4384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025b7421-110b-4e24-be3f-7177c923eae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc3d506-6a55-4f66-8748-4f244fa0ae93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df1103d-4693-4536-b10b-b975009db3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd348e29-9981-4ba5-8eb2-d0e2da99d7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ca7a3b-a0e4-4973-a17a-9f547c07ee23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9d80fe-ab26-4ec7-a359-3c5b9651189e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16de6576-26a2-4c97-9320-14b082559f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fbde4de-1c99-4263-bcb1-7f11997e2230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ae1b4d-2b08-437d-9c3c-4ce93621ef13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 828352ed-3d74-48e4-b5b2-e182ffd3d58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed08ec7-c178-4c83-9f33-faf354af721d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa06c333-02b3-45d3-b904-d0121357dd86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 893bbd1c-6b5f-44f3-854e-57d9270a2b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42a668a-6b1a-4f63-8f6c-4a4e210d5159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d411e5fd-a87d-4f7d-9c85-728a1797a7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d5cbe2-b7f7-4975-86fe-05f7ae702fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df4197c-9dc5-43de-9e86-749e175cea50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ff5268-a8d6-48fd-aabe-e00f7c83d68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71eca875-74d0-40b3-9219-3c35bc5d2e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd775890-fe6c-4877-950d-4b5e5bbf9fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc0db892-4b40-4aea-84eb-cce448c18ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383766e1-765d-449f-991f-f54fc87816a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5633f779-801f-4620-a592-7f89fd5e474d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f49c62-0ff9-42b1-af19-2aa9540077e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ed8105-e846-4a88-ad50-597c9c330a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f174143-e61f-48e8-a2ba-e477e3aa8c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce53d36-3d39-4efa-b72a-a3192523e9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43ac51ef-576d-4aaf-8754-9a7e97f69e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4845be4-f5bc-4cba-a1dc-181b1334c245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d1d8b3-62ff-4153-89bf-ea6e4ab3b17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa2eb3a4-a360-42b4-b621-3dcb907382b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2bb732f-9c06-4aad-9104-784e6eb464ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e84ba17-4c08-4722-aa8f-a54ecc71b84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f583ef-2912-46f3-b69d-e5f8e84c29dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e883709d-20f4-4778-a517-645745d26107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd9e82b6-19dc-4bac-a5b6-dae0db61586b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 925d11f1-7c32-4098-b83c-59aa62bbe5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 275971b3-7ab6-4a85-9d3f-447344fe7e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a9b2fd1-ee1b-4234-85ac-8ae18f60ce14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8de3e81-9f42-4b80-9950-9434a95fe90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c5386b9-e557-4c9a-be2b-60348cc91d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee5108c-8055-4004-a4c3-3686276ee317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1ca0b2-56e8-4b2d-8881-126783f1302f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87245c8a-c2a6-469b-9fd5-68d57ba9e121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2880947-75b6-4c0b-b463-2a287e75f678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662b226d-3287-442e-be13-fd51e20aae83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af7b3c9-9398-4143-a4a6-817eeb66fa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9d49db-f4bf-4d4b-925a-9e977beb1343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dabde13-647f-4924-800d-7c9e840edf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4982382e-d45f-4afe-9b9c-ebb503f27bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9858fc21-2f91-41aa-9c6d-d7d70cc5288a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae705fe-f43c-4f68-80b5-f102fc1f2bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43949d2-a4fb-42f1-bc1d-784c271826a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafda04c-2f88-40f5-a0b9-bb95ce7bb28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422497ff-2919-4db4-9637-7593d400fae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23ca0e4-b556-43a4-acb9-7da9c39bf3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c92c1386-8ad5-42a0-b997-cf37357f0b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b7c951-c55f-4897-af43-e3169943de08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115402e3-02f1-4fb4-b399-10f8b72b4ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bf030f-c91a-4c8e-8216-11cbe0ca2ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ac7f29-65c9-40e6-a755-e4a684391981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fca4e1d3-07ad-4d8d-9229-7cbd6d705f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e837d2-24ac-4dff-ac00-82d72d69b6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2abac8-1041-4e89-9299-6b9f8f60296d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1210202-9c02-449b-a1fb-bc6417469094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd64a5e-66c1-4275-8d99-be54102b63a0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_75
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_labels.txt

📊 Raw data loaded:
   Train: X=(883, 24), y=(883,)
   Test:  X=(221, 24), y=(221,)

⚠️  Limiting training data: 883 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  212 samples, 5 features
✅ Client client_75 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2348, R²: 0.0644

📊 Round 0 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2346, R²: 0.0672

============================================================
🔄 Round 18 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0818 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0744, val=0.0809 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0737, val=0.0804 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0731, val=0.0799 (↓), lr=0.001000
   • Epoch   5/100: train=0.0725, val=0.0798, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0690, val=0.0798, patience=7/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 18 Summary - Client client_75
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1338
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0800
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2346, R²: 0.0665

============================================================
🔄 Round 22 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0751, val=0.0824 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0738, val=0.0818 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0733, val=0.0811 (↓), lr=0.000250
   • Epoch   4/100: train=0.0730, val=0.0814, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0726, val=0.0813, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0710, val=0.0817, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 22 Summary - Client client_75
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1128
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0802
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2304, R²: 0.0860

============================================================
🔄 Round 24 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0748 (↓), lr=0.000063
   • Epoch   2/100: train=0.0766, val=0.0747, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0764, val=0.0746, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0761, val=0.0745, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0759, val=0.0744, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0753, val=0.0741, patience=4/15, lr=0.000063
   • Epoch  21/100: train=0.0744, val=0.0734, patience=6/15, lr=0.000063
   • Epoch  31/100: train=0.0737, val=0.0728, patience=8/15, lr=0.000063
   • Epoch  41/100: train=0.0730, val=0.0723, patience=9/15, lr=0.000063
   • Epoch  51/100: train=0.0724, val=0.0720, patience=7/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 24 Summary - Client client_75
   Epochs: 59/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1393
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.1146
============================================================


============================================================
🔄 Round 25 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0801 (↓), lr=0.000063
   • Epoch   2/100: train=0.0755, val=0.0801, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0752, val=0.0800, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0749, val=0.0799, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0746, val=0.0798, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0739, val=0.0796, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 25 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0901
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0703
============================================================


============================================================
🔄 Round 26 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0734 (↓), lr=0.000016
   • Epoch   2/100: train=0.0773, val=0.0734, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0772, val=0.0733, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0771, val=0.0733, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0770, val=0.0733, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0766, val=0.0732, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 26 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0970
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0313
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2322, R²: 0.0771

============================================================
🔄 Round 28 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0789 (↓), lr=0.000004
   • Epoch   2/100: train=0.0766, val=0.0789, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0765, val=0.0789, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0765, val=0.0789, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0765, val=0.0789, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0764, val=0.0788, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 28 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0766
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.1043
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2327, R²: 0.0747

============================================================
🔄 Round 32 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 32 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0737
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0979
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0752, RMSE: 0.2741, MAE: 0.2329, R²: 0.0735

============================================================
🔄 Round 34 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 34 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0799
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0687
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2330, R²: 0.0734

============================================================
🔄 Round 37 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 37 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0865
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0444
============================================================


============================================================
🔄 Round 38 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 38 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0757
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0813
============================================================


============================================================
🔄 Round 39 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 39 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0674
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.1184
============================================================


============================================================
🔄 Round 40 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 40 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0896
   Val:   Loss=0.0921, RMSE=0.3036, R²=0.0320
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2330, R²: 0.0733

============================================================
🔄 Round 42 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 42 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0768
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0810
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2330, R²: 0.0733

============================================================
🔄 Round 44 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 44 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0688
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.1073
============================================================


============================================================
🔄 Round 45 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 45 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0814
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0617
============================================================


============================================================
🔄 Round 49 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 49 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0820
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0364
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0752, RMSE: 0.2741, MAE: 0.2330, R²: 0.0734

============================================================
🔄 Round 50 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 50 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0720
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0924
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0752, RMSE: 0.2741, MAE: 0.2330, R²: 0.0734

📊 Round 50 Test Metrics:
   Loss: 0.0752, RMSE: 0.2741, MAE: 0.2330, R²: 0.0735

============================================================
🔄 Round 54 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 54 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0831
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0489
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2330, R²: 0.0735

============================================================
🔄 Round 55 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 55 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0824
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0599
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2330, R²: 0.0736

============================================================
🔄 Round 58 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 58 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0830
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0611
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2330, R²: 0.0737

============================================================
🔄 Round 60 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 60 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0750
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0914
============================================================


============================================================
🔄 Round 61 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 61 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0794
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0731
============================================================


============================================================
🔄 Round 64 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 64 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0789
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0727
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2330, R²: 0.0733

============================================================
🔄 Round 65 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 65 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0764
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0831
============================================================


============================================================
🔄 Round 66 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 66 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0739
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0847
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0732

============================================================
🔄 Round 68 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 68 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0761
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0781
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0732

============================================================
🔄 Round 69 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 69 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0721
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0999
============================================================


============================================================
🔄 Round 73 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 73 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0861
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0334
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0733

============================================================
🔄 Round 78 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 78 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0801
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0674
============================================================


============================================================
🔄 Round 79 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 79 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0778
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0672
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0732

============================================================
🔄 Round 80 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 80 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0806
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0475
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0731

============================================================
🔄 Round 81 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 81 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0756
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0846
============================================================


============================================================
🔄 Round 83 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 83 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0757
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0734
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2332, R²: 0.0727

📊 Round 83 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0730

============================================================
🔄 Round 90 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 90 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0699
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1016
============================================================


============================================================
🔄 Round 91 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 91 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0835
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0370
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0732

📊 Round 91 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0733

============================================================
🔄 Round 95 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 95 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0706
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0965
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0733

📊 Round 95 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0732

============================================================
🔄 Round 97 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 97 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0782
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0605
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0731

============================================================
🔄 Round 103 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 103 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0722
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0874
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0730

📊 Round 103 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0731

============================================================
🔄 Round 108 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 108 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0733
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0724
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0732

============================================================
🔄 Round 109 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 109 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0742
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0799
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2331, R²: 0.0732

============================================================
🔄 Round 110 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 110 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0719
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0970
============================================================


============================================================
🔄 Round 113 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 113 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0613
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.1288
============================================================


============================================================
🔄 Round 114 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 114 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0820
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0524
============================================================


============================================================
🔄 Round 116 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 116 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0822
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0586
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0731

============================================================
🔄 Round 118 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 118 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0644
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.1304
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0730

📊 Round 118 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0730

============================================================
🔄 Round 123 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 123 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0742
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0871
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0728

============================================================
🔄 Round 126 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 126 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0743
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0851
============================================================


============================================================
🔄 Round 127 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 127 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0667
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.1096
============================================================


============================================================
🔄 Round 128 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 128 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0822
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0543
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0728

📊 Round 128 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0729

============================================================
🔄 Round 130 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 130 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0696
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0991
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0729

============================================================
🔄 Round 131 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 131 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0816
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0555
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0729

📊 Round 131 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0728

📊 Round 131 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0727

📊 Round 131 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2332, R²: 0.0727

📊 Round 131 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2332, R²: 0.0726

============================================================
🔄 Round 137 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 137 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0797
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0482
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2332, R²: 0.0725

📊 Round 137 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0724

📊 Round 137 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0723

📊 Round 137 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0724

============================================================
🔄 Round 144 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 144 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0808
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0246
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0724

📊 Round 144 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0724

============================================================
🔄 Round 146 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 146 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0695
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.1017
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0725

📊 Round 146 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0725

📊 Round 146 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0723

📊 Round 146 Test Metrics:
   Loss: 0.0753, RMSE: 0.2743, MAE: 0.2333, R²: 0.0723

📊 Round 146 Test Metrics:
   Loss: 0.0753, RMSE: 0.2743, MAE: 0.2333, R²: 0.0721

📊 Round 146 Test Metrics:
   Loss: 0.0753, RMSE: 0.2743, MAE: 0.2333, R²: 0.0721

📊 Round 146 Test Metrics:
   Loss: 0.0753, RMSE: 0.2743, MAE: 0.2333, R²: 0.0721

============================================================
🔄 Round 158 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 158 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0780
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0654
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0719

📊 Round 158 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0719

============================================================
🔄 Round 161 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 161 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0666
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.1108
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0718

============================================================
🔄 Round 163 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 163 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0693
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0756
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0717

============================================================
🔄 Round 165 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 165 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0749
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0741
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0717

📊 Round 165 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0717

============================================================
🔄 Round 170 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 170 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0728
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0799
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0718

============================================================
🔄 Round 171 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 171 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0725
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0865
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0720

📊 Round 171 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2334, R²: 0.0720

============================================================
🔄 Round 176 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 176 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0702
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.1015
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0753, RMSE: 0.2743, MAE: 0.2333, R²: 0.0721

============================================================
🔄 Round 179 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 179 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0597
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.1310
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0753, RMSE: 0.2743, MAE: 0.2333, R²: 0.0722

============================================================
🔄 Round 181 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 181 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0811
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0523
============================================================


============================================================
🔄 Round 182 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 182 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0711
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0927
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0723

📊 Round 182 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0723

============================================================
🔄 Round 187 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 187 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0688
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0955
============================================================


============================================================
🔄 Round 188 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 188 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0756
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0777
============================================================


============================================================
🔄 Round 189 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 189 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0834
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0472
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0724

📊 Round 189 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0725

============================================================
🔄 Round 197 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 197 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0771
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0730
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2332, R²: 0.0727

📊 Round 197 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2332, R²: 0.0727

============================================================
🔄 Round 202 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 202 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0737
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0835
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0725

============================================================
🔄 Round 203 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 203 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0752
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0756
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0725

📊 Round 203 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0725

📊 Round 203 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0725

📊 Round 203 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0724

============================================================
🔄 Round 207 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 207 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0783
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0639
============================================================


============================================================
🔄 Round 209 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 209 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0778
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0689
============================================================


============================================================
🔄 Round 210 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 210 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0773
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0702
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2333, R²: 0.0723

❌ Client client_75 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
