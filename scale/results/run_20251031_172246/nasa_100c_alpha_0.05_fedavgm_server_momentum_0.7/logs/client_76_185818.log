[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a458a9eb-61fd-456a-ba72-70c8916d9985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d16c29-84c0-4f5a-ad8a-e7c3f0033bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e410af34-8047-4535-9936-e4f948aabc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46dc33dc-ab3f-43f8-8a70-17dcc2120319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0f27ea-1d8f-4154-ba48-b5d18d0bd2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37cfad0e-3c83-404b-a357-ea0ce609cb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6536494b-3a9f-4118-b9e4-4916ea4d0eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89316f5e-9940-4080-a342-cfcf90f85a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05541c28-8905-42c7-8bbb-446830788013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b47e9be-c0c4-4c14-b8d3-02310dd7def1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa03ef89-fe20-4ff3-9436-ccdb545e89c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bfa735e-14d2-4ab3-b531-31bd31594172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a2dc55-2c80-4e9c-af4b-0818be9b7bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7bee2fe-0751-4d94-b4f6-91cbcd1b10de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389627a9-55e0-45d9-9961-b3c5cfd48234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2178078-65cd-4e8d-9e9d-8eaa7530ca7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8fc2d4-92c3-4d00-b9d2-ab6a9600e57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b04003-66e1-41f4-813b-fe07af99165a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62973559-4886-47f1-a976-ab5ae6107676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb44f496-118b-4234-8c20-1b7608a241d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456ca3e8-19c1-4e0c-9745-5617b5a9884c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4de16e1-7bcc-41cc-83b5-1bb15919c061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5d4732-4343-4d00-bb42-dea04831ca3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7be20b0-41eb-469c-857e-5dda6a307660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e515f1-0cbf-491d-b107-2ac428bf3756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66456c81-9102-4ea2-a62e-e367c05b576c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e81cff5-cf81-4641-a2c3-49041efd5296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ef75a5-4bc2-4273-b5a9-8437c6efe07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe8daf91-1415-4b11-af08-2c81ddc80c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27a5ab8-3cb6-42bb-aebf-c509ed8ba991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d531e6-2d74-4d79-a034-086541113cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31f9425-0733-4777-8ebf-1b337b339275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc15c8a-cd09-4c60-8a0f-efed01a862b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c848ed4d-bd65-462c-ab80-73b902e56609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd106a1-b8f4-4560-92a0-92de6e5d349c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ae26f6-cdb7-40c8-a48a-44db29186a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8f6332-028e-4bc8-9326-e333f58dd520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3624d80-477f-4b1d-844e-4bf6a1e6dc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95f79ed-9ffc-48a5-8a1d-fd15a35b9260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8577031-8e72-40e9-b968-29d61907ac33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046069e8-0fc3-40cf-8f61-03b99fc9f33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae9c9386-8799-4360-acd2-004984c68b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed9034a0-2e2e-4cff-be35-50697e652da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04112893-e44a-41bd-b841-228105c246e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2aacc6d-5af6-4331-bdb1-79c2de5a8208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cce0a42-cfd6-49d0-8ac0-9db7a604d7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00848797-3ee7-4337-8365-6daeb7f0a157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d3db7a-3212-4817-a9c2-abb7dca145e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beeecfae-2cf3-4463-bcd7-c3bade0b7231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f81034e-fb86-40ff-8d98-9bb1ba90c518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec9f934-d398-4251-b8e9-5d4988509612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05af2327-9fd4-401d-8184-ecf047ffcbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e92d005-b140-402c-8cde-23db82858d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633f8104-a6a5-4e07-9310-3eef3cc3ad07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fad3db-8487-426b-8419-62ec3e12cbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7e702d-a6e3-4bf2-8d66-62044aba69a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd28cd84-629d-43a6-baab-f405a6d95635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e985f3-f95d-4640-a1da-118422d17e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e72aa62-7ed6-44a3-8c29-47365840dd66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2496864-616d-4ad1-b98a-9310ee9608a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ace4e65-1660-4dec-8748-2141836e21ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545cdd7a-4e41-4f4a-a4a9-95f5ba42ad3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92d32980-1420-4ea1-a215-d40e8ca2b8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba44a68-8d27-46a3-b20d-7af09e8df4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41b00b4-0f32-4d56-9e8f-00d13fb27c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a0bedeb-830f-414d-a00d-88a5b9e29275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b096bcf4-f33e-434e-b986-c3c9ff4be2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58c63f1-cfa5-43b0-97fc-fc1ed269859d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81794b49-6ed5-4e44-a365-7de05185c64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f72f391-01bb-4e2d-b91e-63a7595d0e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbdeac73-48f8-400a-82a7-2b20dccc1723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 251fa637-ebd0-4598-885b-b8c479b46fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea621233-1679-4ee0-b560-a5474c6c1d94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cca3094-cc1f-488e-9904-9a3fd3452f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98c7624-081c-4414-a70d-954c5335d7bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35ad667-9d6b-4240-8773-71e57af77ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ccdce47-766d-4ae5-9b07-65f2ed14fd2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c8d77a2-d7f8-48ab-b199-9c27a880a9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08b3061-624d-441c-bf5c-6abbc94b37ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbc7c690-9a12-438f-81df-7bffe834b193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message becf5a20-d047-490f-86dd-abf3d877f171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d530c538-471c-44e8-8f85-117aff4255a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6afdb84-8355-4552-b3c4-9618c1e4a66e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afc8dda-50be-4ae5-9372-b5bc273b8df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95446e4f-6a33-4669-bf21-1aef56add4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a61cbb-7a61-42b7-a53c-1c63f8b8467c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e014c2-8912-492d-8f39-1bd8c6b5d96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9399e7e8-6072-400b-867a-f0fcab954712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f6c28a2-ed89-4666-9d53-dcb3e8292179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db86c44-27df-45ac-af95-354bfd66c98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3360c439-98eb-496a-aba7-1806ddf5ad65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81560abe-85d9-452d-84c9-a441c254a59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27859eeb-f39d-4add-86ef-585ca49990d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd5f2da-d76b-413c-b54a-cdd45ac3ddcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf769f96-51a9-423f-b5cc-3213c9d6fc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e493ed34-daa0-44b0-b01a-42f5a8998017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8cf80d-b13b-4a87-9f64-4c841a3ae50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7f2191-618e-4799-b070-53600030f13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecca3931-0c03-42ae-86f2-929e13afa127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe39106-7c74-44c5-a721-2b0e761a2f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12eb1fe-b68f-4dd1-a724-de9f4de9407b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbce4a18-3a36-469b-a506-de3bf5abb4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dafe48f-a7c2-4d03-8095-cb95002ff3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b690bb28-2d60-4335-b458-dd48ec0657db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14852a8d-9399-4660-b5e1-68b6aed94c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0b120f-2e8a-4b2d-98e4-acf29e4fae23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd6823e-e2ab-4916-97bc-4f8ff8fbd148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa4fe8a-d211-4f80-b61f-3a4b75255b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1712df7b-4a7e-4666-9450-2b6568eb2a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13de43b-6a07-40e7-abbc-670f1a8153ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e70729-813e-4f0c-8f49-3c4c5ab88163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0e1409-5b90-46b9-b0c2-c4e5dcaccd6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da966adc-e14f-4578-b61e-04610b370de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1354fe6-73c1-4659-ae9b-f43be11d6508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af7d17d-1202-4bb0-8c78-775db7438370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c915fee-6ca2-43b7-8f87-9f4d61ebe8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf42b2f-5c41-46d7-8703-5094503f7dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d91337-d681-4227-af72-9d2a279b2495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1434717c-3463-4f81-8b77-92f670f1d133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd30953f-34d0-4bc8-aa4c-b9352e5029ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fec1f12-f561-41d4-838a-fd5fece308db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4617cd85-2174-46e6-9847-9b94cd486c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bee0b3d-c0d1-4c96-b5b2-304ba06af90e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cced747-16d1-48a1-b60a-68cb10c7eb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77b30a3-5233-47d6-820e-91b954b4903a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588e4da3-1f09-4f9a-9fcf-1e14cb8d0ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039aeda4-7ff5-4dfe-bcf5-bc834f23fbe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f143c6f0-4680-4dee-b94a-b4da47602b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb8d779-72e3-4e83-85d4-08547984d8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555fde1b-7a15-442c-8094-a78b7ea475d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6573922b-2f30-4873-97b9-6257fcbce6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e88b7b86-e633-4bbf-b554-e3e547a1c375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b024207-bc9e-4a28-8799-b642e2aa0293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b558456e-8810-46fe-9525-d0f8987e0b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b68031c-c404-44f7-b018-5455f305d4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a5531a-3425-4c58-bcb2-894d8c90f884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ba3d76f-44a8-4f30-b347-ee121097bb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e926f78-bf9f-4399-93c8-cef67601bcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44c06b8d-42d2-4063-929b-e90665d3eb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 731973c5-55b0-4830-9286-e67927b65225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b363bae-010a-4f63-8ad9-8d0b7871b23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 652d904e-dc9f-49b7-95cd-ae5764c053d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a2759f-2b34-4f30-8fd3-7fac21a6c649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a76190-1a2f-4534-967d-54ed6ceef25e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0564f7ea-dc25-4539-9a14-f34e3947d46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9b8ca9-9d44-4f94-91b0-fada07fcb6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d60e7e7-807f-466d-9f15-bcdb7669c7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f368ccf2-a155-4c08-842f-ee2835e0b834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841d3aee-b3e0-4f30-bde1-7b52aaf2d19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc612f94-e4f1-488a-b60f-405b8a8340eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a96b9d-2306-46d0-8b7b-4eeb2b6bc2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc94253-9a52-49a3-9f2b-086d3059f19d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_76
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_labels.txt

📊 Raw data loaded:
   Train: X=(608, 24), y=(608,)
   Test:  X=(152, 24), y=(152,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 599 samples, 5 features
   Test:  143 samples, 5 features
✅ Client client_76 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2396, R²: 0.0853

============================================================
🔄 Round 16 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0795 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0671, val=0.0779 (↓), lr=0.001000
   • Epoch   3/100: train=0.0646, val=0.0775, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0621, val=0.0766 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0599, val=0.0757 (↓), lr=0.001000
   • Epoch  11/100: train=0.0509, val=0.0774, patience=6/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 16 Summary - Client client_76
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0578, RMSE=0.2405, R²=0.2854
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.1886
============================================================


============================================================
🔄 Round 17 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0633 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0767, val=0.0626 (↓), lr=0.000250
   • Epoch   3/100: train=0.0754, val=0.0623, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0740, val=0.0617 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0725, val=0.0612 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0679, val=0.0600 (↓), lr=0.000250
   • Epoch  21/100: train=0.0630, val=0.0579, patience=1/15, lr=0.000250
   • Epoch  31/100: train=0.0588, val=0.0566, patience=3/15, lr=0.000250
   • Epoch  41/100: train=0.0549, val=0.0566, patience=6/15, lr=0.000250
   📉 Epoch 42: LR reduced 0.000250 → 0.000125
   📉 Epoch 50: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0564)

============================================================
📊 Round 17 Summary - Client client_76
   Epochs: 50/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0566, RMSE=0.2378, R²=0.3500
   Val:   Loss=0.0564, RMSE=0.2375, R²=0.1837
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2372, R²: 0.0971

============================================================
🔄 Round 18 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0800 (↓), lr=0.000063
   • Epoch   2/100: train=0.0748, val=0.0801, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0743, val=0.0801, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0739, val=0.0801, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0735, val=0.0799, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0715, val=0.0786, patience=2/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0700, val=0.0775, patience=4/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0692, val=0.0770, patience=6/15, lr=0.000008
   📉 Epoch 32: LR reduced 0.000008 → 0.000004
   📉 Epoch 40: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 18 Summary - Client client_76
   Epochs: 40/100 (early stopped)
   LR: 0.000063 → 0.000002 (5 reductions)
   Train: Loss=0.0695, RMSE=0.2636, R²=0.1515
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.1289
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2394, R²: 0.0801

============================================================
🔄 Round 23 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0683 (↓), lr=0.000002
   • Epoch   2/100: train=0.0754, val=0.0682, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0754, val=0.0682, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0753, val=0.0682, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0752, val=0.0681, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0749, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 23 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.1096
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.1101
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2398, R²: 0.0767

============================================================
🔄 Round 25 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 25 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.1084
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0349
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2409, R²: 0.0671

============================================================
🔄 Round 29 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 29 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0744
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0911
============================================================


============================================================
🔄 Round 30 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 30 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0761
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0708
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2418, R²: 0.0589

📊 Round 30 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2419, R²: 0.0583

============================================================
🔄 Round 36 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 36 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0700
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0365
============================================================


============================================================
🔄 Round 37 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 37 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0712
   Val:   Loss=0.0665, RMSE=0.2578, R²=0.0675
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2420, R²: 0.0579

📊 Round 37 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2420, R²: 0.0576

📊 Round 37 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2421, R²: 0.0575

📊 Round 37 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2421, R²: 0.0574

============================================================
🔄 Round 43 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 43 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0685
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0844
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2421, R²: 0.0574

============================================================
🔄 Round 45 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 45 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0648
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0949
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2421, R²: 0.0572

📊 Round 45 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2421, R²: 0.0571

============================================================
🔄 Round 50 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 50 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0817
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0216
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2422, R²: 0.0570

============================================================
🔄 Round 52 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 52 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0726
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0690
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2422, R²: 0.0569

============================================================
🔄 Round 53 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 53 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0691
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0833
============================================================


============================================================
🔄 Round 54 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 54 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0671
   Val:   Loss=0.0654, RMSE=0.2558, R²=0.0894
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2422, R²: 0.0568

============================================================
🔄 Round 58 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 58 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0627
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.1146
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2422, R²: 0.0567

📊 Round 58 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2422, R²: 0.0567

📊 Round 58 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2423, R²: 0.0566

============================================================
🔄 Round 63 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 63 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0641
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0975
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2423, R²: 0.0565

============================================================
🔄 Round 67 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 67 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0743
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0619
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2423, R²: 0.0562

📊 Round 67 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2424, R²: 0.0561

============================================================
🔄 Round 70 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 70 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0770
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0527
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2424, R²: 0.0561

============================================================
🔄 Round 71 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 71 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0772
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0497
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2424, R²: 0.0560

============================================================
🔄 Round 72 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 72 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0786
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0477
============================================================


============================================================
🔄 Round 73 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 73 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0729
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0514
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2424, R²: 0.0559

============================================================
🔄 Round 74 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 74 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0747
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0648
============================================================


============================================================
🔄 Round 75 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 75 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0727
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0601
============================================================


============================================================
🔄 Round 79 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 79 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0748
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0603
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2425, R²: 0.0554

============================================================
🔄 Round 84 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 84 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0739
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0628
============================================================


============================================================
🔄 Round 85 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 85 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0665
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0875
============================================================


============================================================
🔄 Round 86 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 86 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0796
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0314
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2425, R²: 0.0553

============================================================
🔄 Round 88 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 88 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0666
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0802
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2425, R²: 0.0553

============================================================
🔄 Round 91 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 91 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0669
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0751
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2426, R²: 0.0551

============================================================
🔄 Round 93 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 93 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0710
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0626
============================================================


============================================================
🔄 Round 95 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 95 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0588
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1285
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2426, R²: 0.0547

============================================================
🔄 Round 100 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 100 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0644
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.1044
============================================================


============================================================
🔄 Round 101 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 101 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0674
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0655
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0546

============================================================
🔄 Round 103 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 103 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0749
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0634
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0546

============================================================
🔄 Round 106 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 106 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0673
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0838
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0545

============================================================
🔄 Round 110 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 110 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0688
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0369
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0546

============================================================
🔄 Round 113 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 113 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0803
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0434
============================================================


============================================================
🔄 Round 115 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 115 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0715
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0698
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0545

============================================================
🔄 Round 120 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 120 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0668
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0848
============================================================


============================================================
🔄 Round 121 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 121 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0785
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0447
============================================================


============================================================
🔄 Round 122 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 122 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0607
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.1114
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0546

============================================================
🔄 Round 124 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 124 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0701
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0787
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0546

📊 Round 124 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0546

============================================================
🔄 Round 126 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 126 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0682
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0807
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0546

============================================================
🔄 Round 128 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 128 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0744
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0611
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2427, R²: 0.0545

============================================================
🔄 Round 129 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 129 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0609
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.1091
============================================================


============================================================
🔄 Round 130 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 130 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0714
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0648
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2427, R²: 0.0543

📊 Round 130 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2427, R²: 0.0543

📊 Round 130 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2427, R²: 0.0543

📊 Round 130 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2427, R²: 0.0543

============================================================
🔄 Round 138 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 138 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0668
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0892
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2428, R²: 0.0542

============================================================
🔄 Round 141 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 141 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0768
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0512
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2428, R²: 0.0541

============================================================
🔄 Round 143 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 143 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0709
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0456
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2428, R²: 0.0539

============================================================
🔄 Round 145 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 145 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0682
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0821
============================================================


============================================================
🔄 Round 146 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 146 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0770
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0361
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2428, R²: 0.0538

============================================================
🔄 Round 147 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 147 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0742
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0447
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2428, R²: 0.0538

============================================================
🔄 Round 148 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 148 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0687
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0804
============================================================


============================================================
🔄 Round 150 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 150 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0744
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0607
============================================================


============================================================
🔄 Round 151 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 151 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0669
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0909
============================================================


============================================================
🔄 Round 152 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 152 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0717
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0708
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2429, R²: 0.0536

📊 Round 152 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2429, R²: 0.0535

============================================================
🔄 Round 155 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 155 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0776
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0380
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2429, R²: 0.0535

📊 Round 155 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2429, R²: 0.0534

============================================================
🔄 Round 161 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 161 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0776
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0404
============================================================


============================================================
🔄 Round 163 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 163 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0723
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0560
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2430, R²: 0.0533

============================================================
🔄 Round 164 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 164 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0700
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0707
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2430, R²: 0.0532

📊 Round 164 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0531

============================================================
🔄 Round 169 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 169 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.0753
   Val:   Loss=0.0970, RMSE=0.3115, R²=0.0526
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0531

============================================================
🔄 Round 170 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 170 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0722
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0679
============================================================


============================================================
🔄 Round 171 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 171 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0783
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0391
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0530

============================================================
🔄 Round 172 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 172 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0732
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0640
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0530

============================================================
🔄 Round 173 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 173 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0690
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0822
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0530

📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0529

📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0529

📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0529

📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0529

============================================================
🔄 Round 181 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 181 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0742
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0548
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0528

📊 Round 181 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0528

📊 Round 181 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2430, R²: 0.0527

============================================================
🔄 Round 186 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 186 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0587
   Val:   Loss=0.0664, RMSE=0.2577, R²=0.1165
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2431, R²: 0.0527

============================================================
🔄 Round 187 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 187 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0782
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0483
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2431, R²: 0.0527

📊 Round 187 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2431, R²: 0.0527

📊 Round 187 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2431, R²: 0.0527

📊 Round 187 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2431, R²: 0.0526

📊 Round 187 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2431, R²: 0.0526

============================================================
🔄 Round 203 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 203 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0761
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0580
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2431, R²: 0.0525

============================================================
🔄 Round 204 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 204 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0627
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.1057
============================================================


============================================================
🔄 Round 205 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 205 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0765
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0432
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2431, R²: 0.0525

============================================================
🔄 Round 207 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 207 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0725
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0713
============================================================


============================================================
🔄 Round 208 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 208 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0777
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0521
============================================================


============================================================
🔄 Round 210 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 210 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0621
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0988
============================================================


============================================================
🔄 Round 211 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 211 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0644
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0856
============================================================


❌ Client client_76 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
