[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2727b5-4115-4e46-83c3-ba6917b6dfb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15aed850-ff5c-46cc-9455-e3ee4b605042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1762168a-9e36-4798-8069-9de9571810ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d41866cf-534d-427d-96ae-4fbe6059789c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed69e7d-6f24-478a-bf2a-b5c7b3701359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450a864c-043f-4a89-9cbf-88b0861f36bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26febd7e-e9f5-416e-bf73-0afb7f64a71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4074deeb-0133-4e26-9ae3-feb4e7ec3f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c94e22-1244-486f-8015-555c81fcc32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98843315-0f3e-425b-b7a1-77e5c7d23d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1537245-a27c-479c-a506-2198d6a63406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107815bd-9bd2-4371-b1b3-901e487f25a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 985029c2-975d-4f07-aa51-e48dc54396ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9aeda5a-625e-47a9-abdb-fe96f27b1b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d4c592-adca-4ef5-8b6b-32fa2f87d7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed1a3ef-ddc0-40c0-aafa-bae4977dd0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a15c24f1-4fdd-4685-bdb8-0b97c6cc9f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dced2928-71f3-4da2-ae56-44729fe0d376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1aa2b5a-6979-41de-be18-d07d00591f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd73ad8-0f95-416c-8205-b44457443896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32cbb1ee-3cf2-4d27-b422-b141d34fb7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b21cbf-b1d1-4735-b933-172be3d12ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d996dc8-b30b-4cc7-ad09-d345aa7fdf80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d1b58fb-ee60-456f-afca-e98a64a6bb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5ab6f06-e83b-4cb8-943e-2d4d5bf3ef96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5460adf0-324b-41d2-8fb6-48b84cbd5233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb4246d-499b-4971-b3cf-722e071dc1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac830161-b53b-41d4-bf08-1ae0274acb95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e72e7f7-d577-444e-83e5-26aba488617c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9cf5a8e-2742-4c0a-87fd-d5f361748f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9690b51b-5577-45bd-b5c4-53ea476b5687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f592e8-e5c8-4844-bf7c-a4b3d633f322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd60ad5-9bfd-4292-a1d8-cfa28ea6cb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9170285-f7f2-4a8e-9aa5-0ca83d371132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61496e3-bfd6-42df-8d5c-4563e3cc0c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 461b2e7c-38bb-477c-968d-d9354ea6f90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b214d8-6317-4679-b2e7-f808d3f10d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbc7e37-a415-4c26-ad0d-0a2a9aaba452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30f2323-492f-452d-a76c-f234254e3b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06effd5-2519-41e2-b875-da08c12bd80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b447646-4a77-4e27-90a8-ff22e59a3ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6425a1f-d1c7-4d99-bd9b-67ddf576140a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d64f2d-9b2f-49a5-a052-c106ee5deb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274fac29-1aea-45ec-bb78-769c7137f9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2c2580-71b9-43b0-a0af-3109a73f6095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d33c17-20e3-4856-b3ba-151347902e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c21bdc5-eaf4-440e-8940-b7a0922a75fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39348e20-4d6f-4166-ae74-95281bc6a210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fffc2eb-89cc-4be9-ba9f-3863cf618557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826cd871-c8a6-4053-9823-f01fbf2d27f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 007887f7-348f-4d4a-af0d-6e5ffaea895e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb4d9f9-dc3a-4396-ad9b-420d60b355af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b2bfaa-2e94-4510-beda-d29259af2fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f297c4-0429-45da-aa0e-e42d385057f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7b0494-2342-43fa-b6b6-9c2bedfcdf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f24794e-872e-4940-a31e-4df138af06f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e2eef2-deb3-4e5b-b4c0-17137eccaf1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1aa76c2-990d-4219-8a7a-e3475d550e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03032103-3d3e-4ed6-a455-05d4210444fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc6d592b-b01e-4e22-b581-a8d0d898b569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e81c3c1-6594-436b-9379-ca370c061331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b970061c-dfcd-4953-938c-2dd040dbff34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed8a6c5d-51c3-4910-92d2-9f783778ab9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c770d5c-9452-4c95-82ab-d97c026db0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 337a51e6-86f8-4e70-a856-d2cfbbc4cc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf6d49e-373d-4d7d-95c4-2311eef551bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d497c8d7-53ac-4b63-911f-bb153d3d19c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af9d7515-78f8-46e1-99c6-fe89c591fae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a75511cb-e867-48a8-922b-9f548ec08b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 331b2234-2d66-4f70-88ad-da4eb601307d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f75bd8-9338-4ae8-ac09-a7591eca70f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d83dc5c5-98b4-4d84-8432-8278962142a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542962c2-e69f-4634-8f4f-5c3678951fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ee8926-8299-4d23-81ff-a7d6e6144716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7c11a9-d1ad-40f1-8b05-cbf155c7f88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e405b363-9cad-420e-81a5-012be253cd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504fcd7a-c6e3-47c3-92cc-a040357cf759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4071cd-691e-43a9-aef5-0f4aac428455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eacf51a3-3ecd-486c-9b2b-093c4054f2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45382786-53a4-408f-9aeb-046c0aaa4941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69bb01f-6452-46d7-88f8-4ab4b2604c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48477e88-0a6a-4b2a-bf55-675874e0442f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb2cb62-daa4-457b-8678-c148b8489cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fafa3af-e08d-47bc-8e2d-a8df007daf02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5162af4d-8ba6-408d-8b2b-17502d7849eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 949a7965-99cf-48c1-a73e-4df4bbc4551e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772e7489-7488-48d9-8e20-2a2803947a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 902f822a-1002-4943-8906-d67cdb2ba887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606792e6-63b3-41ed-9b67-940719c034d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4aa54e-9ef8-4f83-8b69-c3308942f9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4452131a-31b8-4eac-81b0-76b3d313938c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d9474c-36db-4496-b19c-4c3f78dcc370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d9af17-adc0-4dd2-a722-aad833d5ee68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c0ee08-38c5-488e-947b-27d6df803caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85278a4c-3b38-4a3e-97a8-0a21ce79267d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7df61f7d-d9d5-4d31-8b85-d37727d2e418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7094001-c04d-4226-b289-8997ca3e5a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a91966-1108-4715-bb9a-df2bc35074ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4fc1407-53e3-4fb6-b91c-32ff886cce56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472e5e7c-60f1-4a02-8488-f0090ae8c61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d76e65a-75f7-4972-8350-e81062ea1cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b472f6-40a0-49b4-b740-a294fa3c5c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3601a25a-aec5-47e9-9a2b-12d53fc60ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d65be6-e79d-4355-b58f-b9359a32ceb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68db7077-c0d0-4473-b0ec-e4d11f0a3e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e0cd05-c310-4a74-b014-e07c759d9c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f37a424-e1da-49a3-b295-220cde082b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be7397d1-953b-4815-97c3-ef7ccb4b9677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f1244f-4b61-41ba-ae47-317da34d3956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b323eca-7953-4cce-896f-6323340b0819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e2d796-9807-494d-80c6-42733d0a7134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb7b2940-ea93-4ba7-b98d-a1a4d2551aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c14c54e-6328-4e6e-84e3-484acb9882ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f0550b-8ff2-41cc-9eef-5ddd3042ae3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83daef3c-b991-4208-a3af-16834daadaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d6169c-ec02-415f-89b9-a9a20566228a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe0fa617-5dc6-451b-8873-54eda1a64d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19b59e3-bf70-4f4f-af06-4e2359fcaac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2387cf4e-edd8-4d5e-b889-2a2e289a4cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14aa4534-fdd5-4412-a331-2837e69a1552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1193ebae-2af4-494e-8c1f-92339c0fdaf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3801f4-ac84-432a-9cde-143c20ce783d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a05c180-be80-4035-8e1d-50e0a404fec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed05e09f-b5f1-49a3-948a-0ee38e1b9010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8473e0-d0b0-4a14-959a-f1d42dab959a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12cf5dc4-de51-40d5-91f8-e340bb551ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31940142-f7ac-4f15-b8af-9100c79cff3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88faca01-f704-479a-8fc4-ac311f63a25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0853bd6-9973-4e3b-a8ba-75fc1db46fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3676b8cd-e7f0-4b16-b672-491b1bced70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0494a7e5-1ad3-4f9a-b524-3a2aab651721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d6575e0-300a-4ea1-ad97-277a66f4b2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cb44131-342c-4260-b6e6-c6c973bcdfe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c174e86-ff86-48cd-9538-19eaa8ec9ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee39397-49cc-4e47-a9da-3eb10b8d8f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a696f4b-9ac8-49b5-a36b-89b3500aeed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fb105f6-979f-4321-9f30-c90714856577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347853b3-5f60-418b-9987-5ac0c4fd98ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da22cd1b-0b39-4cad-a874-fe23576b3923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d326c00-f128-4bbe-b078-19faa0cbbc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48cc0674-3387-4a6b-a5cd-90849ff3fba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a463c20-3b88-4ddf-92a8-8bb124b9df13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee66a3a-7aec-4161-a7d9-47cf465524c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a4c0a3-d54f-424d-86d0-c16e20eda3d1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_77
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_labels.txt

📊 Raw data loaded:
   Train: X=(1518, 24), y=(1518,)
   Test:  X=(380, 24), y=(380,)

⚠️  Limiting training data: 1518 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  371 samples, 5 features
✅ Client client_77 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0756 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0736, val=0.0748 (↓), lr=0.001000
   • Epoch   3/100: train=0.0719, val=0.0745, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0707, val=0.0748, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0696, val=0.0753, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0621, val=0.0783, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 16 Summary - Client client_77
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1228
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0758
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2476, R²: 0.0524

📊 Round 16 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2479, R²: 0.0534

============================================================
🔄 Round 21 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0765 (↓), lr=0.000250
   • Epoch   2/100: train=0.0732, val=0.0763, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0719, val=0.0768, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0711, val=0.0766, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0704, val=0.0764, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0681, val=0.0759, patience=3/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0668, val=0.0763, patience=13/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 21 Summary - Client client_77
   Epochs: 23/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0684, RMSE=0.2615, R²=0.1632
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0707
============================================================


============================================================
🔄 Round 25 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0750, val=0.0756 (↓), lr=0.000031
   • Epoch   2/100: train=0.0743, val=0.0755, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0738, val=0.0754, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0734, val=0.0752, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0729, val=0.0751, patience=4/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0712, val=0.0748, patience=5/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0704, val=0.0751, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 25 Summary - Client client_77
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.1169
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0723
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2454, R²: 0.0640

📊 Round 25 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2458, R²: 0.0637

============================================================
🔄 Round 30 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0791 (↓), lr=0.000008
   • Epoch   2/100: train=0.0750, val=0.0790, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0748, val=0.0789, patience=2/15, lr=0.000008
   📉 Epoch 4: LR reduced 0.000008 → 0.000004
   • Epoch   4/100: train=0.0746, val=0.0789, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0745, val=0.0788, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0740, val=0.0786, patience=10/15, lr=0.000004
   📉 Epoch 12: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 30 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0760
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0490
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2458, R²: 0.0635

============================================================
🔄 Round 31 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0677 (↓), lr=0.000002
   • Epoch   2/100: train=0.0783, val=0.0676, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0783, val=0.0676, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0782, val=0.0676, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0782, val=0.0676, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0780, val=0.0675, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 31 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0602
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0850
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2459, R²: 0.0632

📊 Round 31 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0628

============================================================
🔄 Round 36 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0748 (↓), lr=0.000002
   • Epoch   2/100: train=0.0769, val=0.0748, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0768, val=0.0748, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0768, val=0.0747, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0768, val=0.0747, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0767, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 36 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0555
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.1039
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0626

============================================================
🔄 Round 40 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 40 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0519
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0972
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0628

============================================================
🔄 Round 43 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 43 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0566
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.1000
============================================================


============================================================
🔄 Round 44 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 44 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0722
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0329
============================================================


============================================================
🔄 Round 45 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 45 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0624
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0775
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0629

============================================================
🔄 Round 48 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 48 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0670
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0600
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0630

📊 Round 48 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0630

📊 Round 48 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0630

============================================================
🔄 Round 52 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 52 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0628
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0720
============================================================


============================================================
🔄 Round 55 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 55 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0695
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0502
============================================================


============================================================
🔄 Round 56 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 56 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0631
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0758
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2459, R²: 0.0631

📊 Round 56 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2459, R²: 0.0632

============================================================
🔄 Round 59 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 59 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0673
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0619
============================================================


============================================================
🔄 Round 62 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 62 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0636
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0763
============================================================


============================================================
🔄 Round 63 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 63 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0509
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.1214
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0627

============================================================
🔄 Round 65 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 65 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0500
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.1268
============================================================


============================================================
🔄 Round 66 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 66 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0652
   Val:   Loss=0.0677, RMSE=0.2603, R²=0.0650
============================================================


============================================================
🔄 Round 67 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 67 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0665
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0332
============================================================


============================================================
🔄 Round 68 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 68 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0633
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0656
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0626

📊 Round 68 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0627

============================================================
🔄 Round 71 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 71 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0678
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0587
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0628

============================================================
🔄 Round 73 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 73 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0624
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0715
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2459, R²: 0.0630

============================================================
🔄 Round 75 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 75 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0592
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0927
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2459, R²: 0.0630

============================================================
🔄 Round 76 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 76 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0593
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0565
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0629

============================================================
🔄 Round 77 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 77 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0703
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0483
============================================================


============================================================
🔄 Round 78 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 78 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0608
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0834
============================================================


============================================================
🔄 Round 79 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 79 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0607
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0879
============================================================


============================================================
🔄 Round 80 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 80 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0592
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0968
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2461, R²: 0.0622

============================================================
🔄 Round 83 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 83 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0681
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0516
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2461, R²: 0.0621

============================================================
🔄 Round 84 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 84 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0606
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0699
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2461, R²: 0.0622

📊 Round 84 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0625

📊 Round 84 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0626

============================================================
🔄 Round 92 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 92 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0728
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0279
============================================================


============================================================
🔄 Round 94 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 94 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0681
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0497
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0627

📊 Round 94 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0627

============================================================
🔄 Round 98 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 98 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0656
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0709
============================================================


============================================================
🔄 Round 99 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 99 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0757
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0219
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0627

============================================================
🔄 Round 100 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 100 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0665
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0645
============================================================


============================================================
🔄 Round 102 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 102 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0576
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0928
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0625

============================================================
🔄 Round 106 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 106 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0699
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0513
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0625

============================================================
🔄 Round 109 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 109 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0570
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0791
============================================================


============================================================
🔄 Round 112 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 112 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0571
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.1022
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2460, R²: 0.0625

============================================================
🔄 Round 115 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 115 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0704
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0512
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2460, R²: 0.0623

📊 Round 115 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2460, R²: 0.0623

📊 Round 115 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2460, R²: 0.0622

============================================================
🔄 Round 120 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 120 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0697
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0476
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2461, R²: 0.0618

============================================================
🔄 Round 122 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 122 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0564
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0947
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2461, R²: 0.0616

📊 Round 122 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0616

📊 Round 122 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0615

============================================================
🔄 Round 129 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 129 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0737
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0301
============================================================


============================================================
🔄 Round 131 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 131 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0753
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0356
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0615

============================================================
🔄 Round 133 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 133 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0688
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0399
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0614

============================================================
🔄 Round 134 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 134 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0622
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0762
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0613

============================================================
🔄 Round 137 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 137 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0640
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0686
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0612

============================================================
🔄 Round 138 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 138 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0619
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0744
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0611

📊 Round 138 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2463, R²: 0.0610

📊 Round 138 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2462, R²: 0.0611

📊 Round 138 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0612

============================================================
🔄 Round 149 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 149 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0680
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0485
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0609

============================================================
🔄 Round 154 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 154 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0677
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0470
============================================================


============================================================
🔄 Round 156 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 156 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0631
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0580
============================================================


============================================================
🔄 Round 159 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 159 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0661
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0349
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0606

============================================================
🔄 Round 162 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 162 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0636
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0334
============================================================


============================================================
🔄 Round 163 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 163 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.0675
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0278
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2464, R²: 0.0604

============================================================
🔄 Round 167 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 167 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0594
   Val:   Loss=0.0688, RMSE=0.2622, R²=0.0764
============================================================


============================================================
🔄 Round 169 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 169 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0716
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0178
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0605

📊 Round 169 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0606

============================================================
🔄 Round 172 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 172 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0726
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0065
============================================================


============================================================
🔄 Round 176 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 176 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0691
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0378
============================================================


============================================================
🔄 Round 177 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 177 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0642
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0540
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0608

============================================================
🔄 Round 178 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 178 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0616
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0682
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0609

📊 Round 178 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0609

============================================================
🔄 Round 180 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 180 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0619
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0711
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0609

============================================================
🔄 Round 183 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 183 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0584
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0868
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2462, R²: 0.0610

📊 Round 183 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2462, R²: 0.0611

============================================================
🔄 Round 185 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 185 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0740
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0257
============================================================


============================================================
🔄 Round 186 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 186 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0641
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0648
============================================================


============================================================
🔄 Round 187 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 187 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0603
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0770
============================================================


============================================================
🔄 Round 189 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 189 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0691
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0425
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0611

============================================================
🔄 Round 191 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 191 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0590
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0892
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0612

📊 Round 191 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0612

📊 Round 191 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0612

============================================================
🔄 Round 195 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 195 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0574
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0921
============================================================


============================================================
🔄 Round 196 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 196 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0660
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0392
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0613

============================================================
🔄 Round 197 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 197 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0738
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0286
============================================================


============================================================
🔄 Round 199 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 199 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0613
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0806
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2462, R²: 0.0613

============================================================
🔄 Round 202 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 202 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0653
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0436
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2462, R²: 0.0610

📊 Round 202 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2462, R²: 0.0610

============================================================
🔄 Round 207 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 207 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0614
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0470
============================================================


============================================================
🔄 Round 208 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 208 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0475
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.1177
============================================================


============================================================
🔄 Round 209 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 209 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0653
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0454
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2463, R²: 0.0608

❌ Client client_77 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
