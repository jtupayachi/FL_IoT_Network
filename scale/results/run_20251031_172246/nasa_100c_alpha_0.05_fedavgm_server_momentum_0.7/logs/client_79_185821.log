[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca33c5c6-8992-4f26-bb50-34950e1746cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9fc0578-ba31-437f-972e-92937b67a74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7a5ca4-c25f-4a14-8990-d57d0adc9339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fbd9ed8-f00b-44cb-b57c-0d573f449ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199665c8-5a0a-4b4d-98a9-3e152cc02b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c1bd19-8a4d-475d-9f9c-fa63c5ad0430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc6ebaf-e608-43a5-a77a-96ebab0504a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b195c246-884f-421f-8242-7dba4a80e6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa3b820d-baff-4eea-a862-d1d2e37399fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfffb3f9-4620-4bfd-9db1-b20b543863c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9cd8cc2-df66-464d-98b7-59e3aef9a4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31452dba-ef16-442f-b21b-0d108f20ae35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69dfd694-d8e8-4e34-b057-f3c3e7f16db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1f0772-cbcb-4c96-bb97-73b6d7186d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7685c92e-8412-451a-8e82-bcc88c1f702b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808794b4-4622-4d6c-b238-df9d3a5840ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012d1849-89f6-4e92-9391-1ad176b3d85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601d758a-684a-4803-83a3-493ce3a83a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d83986-7e66-401c-9491-4b2578621930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2238db67-4a8b-40ad-a8aa-b4fd6f7778c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e30797-8f34-4d0d-ab0d-f561defae726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91690b24-1b11-4517-91cd-72f3cbb6e5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a2982ab-383b-4f0d-9ecf-6291c7f92f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 634cc81a-87b2-4d95-8f24-f11591972ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ccfc4c-8338-4155-9701-3ff733584686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7519b232-f2a3-4c58-9288-b6a576138706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 053fc510-c9a8-49e6-85d7-6f845e607a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8deac043-714c-4eb3-8eaf-29dcd905834d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83037071-df7c-4be8-9732-a69293db3718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55998b2d-8020-451f-bc48-3cc99bfbf8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22d3a46-84d4-44f6-8216-7ae05843e9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516b1016-9c04-4056-9601-ff0dbcf35865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e4c9106-1c82-4b15-9b04-92157ffefef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d83aa0-191d-4d74-bcd9-3a03901eadec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c32a90-2ac9-44b9-b0d4-dcf1c9f2addd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee0f8a29-6d37-4e39-95f4-3538ca747996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9f1968-52e2-4b98-be31-ee9da7142ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6ff98be-6350-4ee5-9b2d-29bd7856db2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0603bb-82eb-4de6-8920-59f52c3d1b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 948eb291-a5b0-4d04-86f5-3ae44aa00f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede0e8d8-f4e9-4600-a4d3-fe30e2efd804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc92539-f588-4155-80e4-e9c20f54439a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c17f607-2908-4a15-945c-17ae9e724ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc8438f-cbf3-4d9d-8df8-48859efe6ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2524088-20b2-4caf-b98d-2491e58ad37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f954d560-d203-42a9-aa1f-05e70298f0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e55f6db1-680a-4e10-948f-7ec3ae16f12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54dd6f4-805e-4647-9e32-8ca9b1825ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd2d249-68c9-47b7-a0a8-be5de4a64612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c4105b-3a5c-456d-8533-942ed4357ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bebf44c2-a4bb-4581-8b15-a7b4c53591ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4a764e-8905-4d21-a7ee-02bdcf448bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7bca07a-3933-41c4-a7f9-14c18a6f8b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cecc84a-d3d4-487d-9fe0-ba3a498ce5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161ddf95-4500-43ba-8a4e-5fb1c6b5c8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e86eafd-dbfd-4539-b904-f1114d6c42fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc60d3ea-6a5e-4105-a5ce-c966ba79f600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 796652d0-065a-4302-9926-5c56f8ed458d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cee869a-9800-499d-8ef7-9f3bb352302f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6446f72-1aab-4cff-be9e-1acec30f8bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58277113-4783-483d-86dc-0fdcea3a29c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1c6699-da47-4352-8eb0-992ca0418715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aefde17-d6e7-4184-8aca-b14194722440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3acce76-ecc3-4430-b664-82e619142e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90d55a8b-c966-4059-b3c8-063bf7c334d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac8c15d-28f9-4a67-89fc-da5774932827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bc9f0b4-17a8-4ebd-b83b-a85df520a1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82da9bf7-b9f3-4e72-a926-646861a8b91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7652a1c7-f7f0-4487-810c-d756fee12018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f69739-b15a-4efb-a5d4-79c1bc41da97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b8ddf3-8c64-4165-bdd6-ab9aeb7bff2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8202b298-71f1-4451-9f91-3f8445d45388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b791074-951b-4a55-8d51-b212a8125d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54df4575-2711-46ed-a857-ac864ff5f6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f405fe14-f4ea-4785-a649-7c667b738bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c6bb7ea-005c-459d-a5f7-b490639a3642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e925ed-2b35-4e70-819e-65db57879021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c98af92-2e76-48fd-8280-423eaeed5e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12677818-1b37-40a8-aadf-a96e9d957af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afdf511-4d5a-4420-8562-a0d5475e3434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9aea669-c987-4efc-8ce2-109b185fc949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7eafc2-ec32-497e-8445-0c75ed32e750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0321bc-472a-4540-bdaa-c1fcaba58f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13a0b33-aa17-46a2-b650-a926f1e15c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d5941c-885f-4487-9a39-64b1444ff589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88040152-506e-4296-b296-9efcfbc5708b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 914186b9-ef7d-4ad4-a147-e593f96ebd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe1ac07-0f1c-4236-9bac-fc15edf9f834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d24d4dc-dc8d-4a17-9675-13fbfd2e3dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b26cdf64-b36c-4f20-b213-c131a49026ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ffeda3-cbb2-4f15-b626-929254ac59d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65040af-1c49-4d64-9471-2726c9de17a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3501ff-f7b8-4997-9f82-304378352668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c64928b-9b7a-4d8d-9586-9e3d3b930439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b4c046e-7eaa-4fdd-8a1d-e955bd3477fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602ac314-d446-44ef-a7f2-771d90c855a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35480d56-e680-47b8-a73b-872f590e79a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f02c288-8725-493a-adcb-2887edf6c049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c905d9a-b666-4ce4-a6a9-7799f5d17afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4df243b-5274-4f12-ac6e-8ad299099257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9be055e-c076-4799-ad2d-b55dbbab6974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35800d19-1b53-4ac7-8845-9356aff7c31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47661cb-a3d8-4ab0-85fa-8ec987a089c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004a387b-aa13-437a-a0fe-e36688e5f7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d56f541d-fdf7-4baa-b450-58a2ddf49ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba580964-f9ac-4019-a0c6-42d4ca0adf86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249a0619-00fa-49d7-b4bf-01dd1759c368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6934e548-1045-490e-a4bf-9de7026b282f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d32c4dbc-74ce-4755-ac50-bb71eda1e33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47bd4826-a634-4e25-9997-03f2c227061f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6894de4c-a5ba-4fe7-920f-db9317275cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf51ae3-5fda-4e12-ad87-3399759f028a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e09033cb-0c18-4566-b1dc-bc62913cea47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24812358-7c1a-4c1f-8870-9e145a6a4baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b495006-ed92-4d40-964e-670f788563f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd8c5da-2ee5-4206-940a-97c9d714a497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bbda297-de22-46c9-b16d-a4c995e5ee4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eaf62df-59ef-4139-b72f-e9579abfdf7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 246495ea-d61d-4bf2-9deb-03ff420fea20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a36b371e-1d62-4512-9f3f-ae2117bc6e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39118f5d-ff9d-4360-a894-3bf2cfcdfc1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6999f39d-e77c-4eb7-9478-5fc7931a9f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986107e0-9a3b-4cb9-8a76-c60548dd31bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e589291-dd56-4ba7-9b63-d123e5141481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74fc77cd-f489-4895-9c28-79206c76bf53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60a8caf5-0ff6-40be-8f28-ff17dbf8f0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c3d319b-09fe-4521-bea4-b395814ea760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036e2977-79b7-4fa7-b393-d5f35fba892e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561441b8-0830-4fad-a7e3-71417fd0a02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e687fc-72a7-4ee4-af0d-fc365932c5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12beb730-2acc-4654-abfd-e5157bdee1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aacb044-8eb9-4ddd-b374-b8b2698a8394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f28a746e-8c4b-4b32-883b-6a4abb9d0fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e825d257-857f-4a1a-b308-ed4cfcd43b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6df0a394-d069-4e92-b64b-e0b6d9c56a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd6405d-83c0-4017-8494-445dab33a694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6f78fa-037a-49f0-8fae-d5c20bd317aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90419cc7-5e0e-4d4b-a32e-9858d6a1a976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef38ced-b55c-4c06-a98d-e06be5fd6d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46760e8f-3162-4418-ac4a-ef8cf3d2b403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d709eec-4b80-4a37-af31-b9c0edd34680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c22c2d6-f18f-4a6b-86c8-295dd5344bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a551d48-5260-4476-8b6d-71dd39ade4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cecec287-807d-4bd9-ad65-ad0d71d451ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0756fa61-fa97-4e3c-8296-972d0b0e5afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6efabc58-4629-40c1-9fe9-6ac3faffeddd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_79
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_labels.txt

📊 Raw data loaded:
   Train: X=(1288, 24), y=(1288,)
   Test:  X=(322, 24), y=(322,)

⚠️  Limiting training data: 1288 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  313 samples, 5 features
✅ Client client_79 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2484, R²: -0.0035

============================================================
🔄 Round 17 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0761 (↓), lr=0.001000
   • Epoch   2/100: train=0.0830, val=0.0765, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0816, val=0.0766, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0808, val=0.0771, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0798, val=0.0780, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0741, val=0.0812, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 17 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0142
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0154
============================================================


============================================================
🔄 Round 18 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.000250
   • Epoch   2/100: train=0.0823, val=0.0838, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0813, val=0.0845, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0807, val=0.0850, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0803, val=0.0853, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0789, val=0.0864, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 18 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0014
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0075
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2476, R²: -0.0170

============================================================
🔄 Round 20 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0747 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0857, val=0.0735 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0849, val=0.0728 (↓), lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0726, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0843, val=0.0725, patience=2/15, lr=0.000063
   • Epoch  11/100: train=0.0836, val=0.0724, patience=8/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 20 Summary - Client client_79
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0044
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0331
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2488, R²: -0.0202

📊 Round 20 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2500, R²: -0.0247

============================================================
🔄 Round 23 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0813, val=0.0869 (↓), lr=0.000031
   • Epoch   2/100: train=0.0810, val=0.0866, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0808, val=0.0865, patience=2/15, lr=0.000031
   ✓ Epoch   4/100: train=0.0807, val=0.0863 (↓), lr=0.000031
   • Epoch   5/100: train=0.0806, val=0.0863, patience=1/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0801, val=0.0859, patience=7/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0798, val=0.0857, patience=8/15, lr=0.000008
   📉 Epoch 25: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 23 Summary - Client client_79
   Epochs: 28/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0243
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0093
============================================================


============================================================
🔄 Round 24 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0935 (↓), lr=0.000004
   • Epoch   2/100: train=0.0800, val=0.0935, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0799, val=0.0934, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0799, val=0.0933, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0798, val=0.0932, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0796, val=0.0931, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 24 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0107
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0269
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2481, R²: -0.0113

📊 Round 24 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2478, R²: -0.0099

============================================================
🔄 Round 30 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 30 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0028
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0001
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2477, R²: -0.0077

============================================================
🔄 Round 33 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 33 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0005
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0126
============================================================


============================================================
🔄 Round 34 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 34 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0008
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0230
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2477, R²: -0.0076

============================================================
🔄 Round 36 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 36 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0098
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0776
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2477, R²: -0.0074

📊 Round 36 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2477, R²: -0.0072

============================================================
🔄 Round 41 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 41 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0020
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0139
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2477, R²: -0.0071

📊 Round 41 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2477, R²: -0.0070

📊 Round 41 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2477, R²: -0.0070

📊 Round 41 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2477, R²: -0.0068

============================================================
🔄 Round 48 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 48 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0058
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0276
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2477, R²: -0.0067

📊 Round 48 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2477, R²: -0.0067

📊 Round 48 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2477, R²: -0.0066

============================================================
🔄 Round 56 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 56 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0055
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0128
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2477, R²: -0.0064

📊 Round 56 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2477, R²: -0.0064

============================================================
🔄 Round 59 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 59 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0003
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0008
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2477, R²: -0.0062

============================================================
🔄 Round 62 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 62 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0028
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0119
============================================================


============================================================
🔄 Round 68 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 68 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0063
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0248
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2477, R²: -0.0058

============================================================
🔄 Round 70 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 70 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0058
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0298
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2477, R²: -0.0057

============================================================
🔄 Round 76 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 76 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0072
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0178
============================================================


============================================================
🔄 Round 79 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 79 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0064
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0347
============================================================


============================================================
🔄 Round 80 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 80 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0041
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0139
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2476, R²: -0.0054

============================================================
🔄 Round 81 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 81 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0076
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0218
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2476, R²: -0.0054

📊 Round 81 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2476, R²: -0.0052

📊 Round 81 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2476, R²: -0.0052

📊 Round 81 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0050

📊 Round 81 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0049

============================================================
🔄 Round 92 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 92 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0074
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0303
============================================================


============================================================
🔄 Round 93 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 93 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0029
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0110
============================================================


============================================================
🔄 Round 94 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 94 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0001
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0232
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0048

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0047

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0047

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0047

============================================================
🔄 Round 98 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 98 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0006
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0016
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0046

============================================================
🔄 Round 100 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 100 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0021
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0116
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0046

📊 Round 100 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2476, R²: -0.0046

📊 Round 100 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0046

============================================================
🔄 Round 104 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 104 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0016
   Val:   Loss=0.0974, RMSE=0.3122, R²=-0.0137
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0045

📊 Round 104 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0045

📊 Round 104 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0045

============================================================
🔄 Round 110 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 110 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0049
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0156
============================================================


============================================================
🔄 Round 113 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 113 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0009
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0019
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0045

📊 Round 113 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0044

============================================================
🔄 Round 117 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 117 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0001
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0008
============================================================


============================================================
🔄 Round 118 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 118 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0016
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0040
============================================================


============================================================
🔄 Round 122 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 122 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0061
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0045

📊 Round 122 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0045

============================================================
🔄 Round 125 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 125 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0009
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0052
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0044

============================================================
🔄 Round 130 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 130 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0031
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0086
============================================================


============================================================
🔄 Round 131 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 131 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0014
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0006
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0044

============================================================
🔄 Round 132 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 132 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0098
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0560
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2476, R²: -0.0043

============================================================
🔄 Round 135 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 135 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0007
   Val:   Loss=0.0696, RMSE=0.2638, R²=-0.0119
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0043

============================================================
🔄 Round 140 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 140 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0060
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0042

============================================================
🔄 Round 142 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 142 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0020
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0117
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0041

============================================================
🔄 Round 144 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 144 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0053
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0106
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0041

📊 Round 144 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0040

============================================================
🔄 Round 147 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 147 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0046
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0252
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2476, R²: -0.0040

============================================================
🔄 Round 148 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 148 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0009
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0004
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0040

============================================================
🔄 Round 149 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 149 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0012
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0147
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0039

============================================================
🔄 Round 150 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 150 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0106
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0309
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0039

📊 Round 150 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0038

============================================================
🔄 Round 154 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 154 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0011
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0002
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0038

============================================================
🔄 Round 157 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 157 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0009
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0108
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0038

============================================================
🔄 Round 158 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 158 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0090
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0405
============================================================


============================================================
🔄 Round 160 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 160 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0068
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0216
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2475, R²: -0.0037

============================================================
🔄 Round 161 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 161 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0026
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0153
============================================================


============================================================
🔄 Round 162 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 162 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0017
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0073
============================================================


============================================================
🔄 Round 166 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 166 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0088
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0412
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2475, R²: -0.0036

============================================================
🔄 Round 168 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 168 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0036
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0096
============================================================


============================================================
🔄 Round 170 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 170 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0025
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0050
============================================================


============================================================
🔄 Round 173 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 173 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0040
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0141
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2475, R²: -0.0035

📊 Round 173 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2475, R²: -0.0034

============================================================
🔄 Round 177 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 177 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0007
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0008
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2475, R²: -0.0034

============================================================
🔄 Round 180 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 180 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0022
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0154
============================================================


============================================================
🔄 Round 181 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 181 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0056
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0040
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0034

============================================================
🔄 Round 182 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 182 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0044
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0204
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0034

============================================================
🔄 Round 183 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 183 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0016
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0079
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0033

============================================================
🔄 Round 185 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 185 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0103
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0259
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0033

============================================================
🔄 Round 186 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 186 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0062
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0430
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0033

============================================================
🔄 Round 187 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 187 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0036
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0189
============================================================


============================================================
🔄 Round 189 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 189 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0018
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0073
============================================================


============================================================
🔄 Round 190 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 190 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0085
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0309
============================================================


============================================================
🔄 Round 192 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 192 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0034
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0112
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0032

📊 Round 192 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0032

============================================================
🔄 Round 195 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 195 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0070
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0280
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0032

============================================================
🔄 Round 200 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 200 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0051
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0211
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0031

📊 Round 200 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0031

============================================================
🔄 Round 205 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 205 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0006
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0053
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0031

============================================================
🔄 Round 206 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 206 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0000
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0149
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0031

============================================================
🔄 Round 208 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 208 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0011
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0032
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0031

📊 Round 208 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2475, R²: -0.0031

❌ Client client_79 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
