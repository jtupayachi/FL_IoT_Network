[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9fe6ff-b439-416c-b77f-241632021dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b4490a1-71fb-477d-b762-b12e3666a027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ce52be-2b00-43aa-aff5-23e3a832f543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f9b51d1-1aa5-48eb-9ba8-a4e925f872e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9136035-9742-40ca-9637-8fc5d3eee966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06ec9977-9723-4e64-b3cb-fe5e1f04e742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 837e85b5-a64d-487c-b503-4289563f1fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b68a1c-be49-4e1c-9f64-b52794bf9900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f6370f0-b58d-45c2-957d-d3a6dbbe6639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2abf057-2aa1-43b6-a7ba-52165e2eb4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c35b1b-511a-46cb-8787-6a21357b9696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f9ba809-53db-40e3-97b9-ae00f4d385b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40c43dd8-f784-40a8-8907-995b1d05aa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85bc4831-8f5b-4d23-956d-39efddab1760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9464dd3-8958-47af-81f9-8160fabb1f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a43490-99e1-45af-93ee-590227aa57ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cb8db7b-f81f-4bd5-bc86-8bcb6fcb9347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eccd695b-4025-4e3b-b283-5267e55bc9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68debaaa-6f43-412b-a7f7-e40e4b05adbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf7685b-9053-41f9-8286-48208446dcb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf4366b-124c-4188-b623-545d59ed1d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 201d9e7f-6c52-4de3-bd31-12ad51bad161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ec2924-3748-4e74-87a7-915b761e2327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 991747d2-7c96-4dbb-9f17-bd875aef785b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b73c262-08e6-44de-8350-835c0e537b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e4ab0f-73ad-491c-89b7-6c523a98dbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4eb004-75b2-4b5f-85f7-e8932c64f52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d2ebbe2-8354-4c20-8a7d-6b7965ddb81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237b80ac-3b6e-44cc-bcfa-184439b537e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f705fa3-6441-4b2d-87cd-04e0127a9a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffcd5a14-fc26-43c6-8d83-b079d9f34aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896d3466-b284-4db1-b7cc-108c9bda34a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 188783e5-f630-43dc-8c67-7a440342b46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b09011-2543-417c-93da-b884abea3432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c380d32a-8e76-4780-aeee-f3af1ff2b06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4fd60a3-f90c-4f59-a522-e4e131732067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a98dd90-c92b-4c13-b972-6502c7eac432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5d6739-f707-436c-9b8f-2185799e928c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83549936-ab53-4a5a-92a2-f616f123e693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f541be3a-1ecb-4f80-a843-8893a99c7b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c21b8e63-4093-4c19-87a5-7fd5d80afcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e142ca-273f-4855-8f4b-1de3fd236b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2ade36-4173-4f63-8576-90ae219ea334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdfb850c-c969-4d83-9ed7-aa814800b44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8687a78f-7a55-434c-b080-b9578ca815c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f457a5-e75e-4995-b23b-5674ca0283ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2aa160e-1439-43ef-9c62-1bf7af94581c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff599e1-92bb-4d2e-9803-3a210e407443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ec710d0-208c-405f-8c93-87a749a1aabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71203914-db45-4af4-8a76-6b74abb29d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34fbc7c-fe1f-4084-b65d-04b880a07db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf79058-da9e-43bc-9b6b-0bfe6dc2c914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dc38294-d6bf-4655-91f9-fa57711fd493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f83c1d5-90ba-4dca-a699-31726c9616d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27c1054-70a4-4842-9cf3-3905ebf8920b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca8fc00-c494-4490-b141-7c82ea81747b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5e24f4b-0c4b-43cc-8414-87b658050ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b561f6-61dc-4db3-8079-c72c55397fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eaec4ec-7508-4556-a749-fa963e975b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd707c2-9b71-4458-a656-eabb615e2dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0b72ca-05a9-4de7-af1f-58f8fc68b647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d1d2fc-779d-4faf-bb34-fed51b4a0285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56977f33-fa5d-4f0f-bc71-007a83bd6ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac39ad34-2076-480f-ae28-ea75ee708844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba68704-02c2-46c2-a871-30a5da00c7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a371f3eb-95b5-4b07-ba77-930b13b584ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e2700f-fea0-4f21-bfcc-ee6884928783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81e65d4-603e-4654-828a-5e48be22fc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9efb36c6-cd49-4e66-8c1f-b5926e4c126a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6511ae7-dabb-44f5-a5d5-e19243ab5255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de050309-d87a-4da2-8054-ef5b5ca1d602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a148dac6-3c0d-4feb-afb7-2edffb74df31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 503d86e8-0633-413a-99a9-bd210ef2f4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca2fa3a-64dc-4ec9-9a89-db5ebde2d930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71955235-f76f-4344-94ef-a757e0c303e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea6e11a5-00a0-433b-89fb-b95ea24f02db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97bf5c0d-5d6c-4bda-8681-34a31782d68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a4ec8b-a862-4d1f-9b60-66f7c8169a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7823d7-7aa7-4d72-9578-d5c2c4a17e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b995bd-fbfb-41ef-a425-8c22c1d22227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 574cd392-3285-4c51-ad57-bf825ff021da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b0c9d3-6303-4660-911a-687dd07047a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d89d59-e080-4cd0-a7fa-7a08244761ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9554d51-146f-4756-acb2-04bfa8a75931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d038b388-45a6-4297-8a6c-ce049e90125f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceaa84ab-8782-485e-879d-530858425ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4217fe66-ed25-41a7-bf42-43d52f526dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd7c8e42-f9e4-43b3-9dfb-987885826760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd92de92-2598-4695-91ea-8d1b2e316cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d24d973b-f45a-431b-8714-2e0afbd4b995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d7282b2-3717-4655-b2d8-7799b7012677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 156fc140-0b69-4732-8127-2c4bde355e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f6f720-3116-49aa-aaf3-9595a468dd08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751d2e75-5ae4-483e-83ad-edf5a99358bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885c1d89-31c9-46b3-b3f8-756c045cbfe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac86889-d330-4d17-9563-e2fef798353a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0659ff0-2727-4cfd-8090-ac57c2eead7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce34978-ab9a-481d-816d-3143a35a656e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca20ffb-480c-4c96-888f-9eeaff348bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 786ba277-2bbb-4e97-a9d7-94dc6dde470d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34aff52d-a229-4300-b506-c1a397ffab82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddeba5e-fb63-4d89-af27-9ffc90640ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13a05751-a3a4-43b1-a394-a235581e16b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a706fa-92f7-4311-8447-7aba72b3ecc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc2583c-6260-4041-95aa-ef23a7c71f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5adb45f7-9e6d-4434-a84d-2177d533f7f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0a2003-834b-4d06-8fa5-25710ca4b198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f331ff0b-e49f-4afa-953b-be661659fd10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a278922f-5510-4043-88da-2199c80916cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 889152c2-4f67-4146-9024-f72f8d449d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1930cce-3ad6-46ed-b4ea-03dc8d335448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1e642e-9003-4c66-92bd-922bb882b765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8c4a1a-ce02-4eac-b87e-585821b9104c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63aee4a9-2353-4b36-b68b-96af011a8a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf5c3a62-12a5-4939-832d-17debbefc2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aabf8657-20c8-4131-ad21-e4b86b5669dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63953933-3289-4a3e-882c-11a58cc64021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2cf9d3d-9985-4fdd-9fe5-76b9b06991f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894d9abe-1a62-49e5-9bfc-e653981c884f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dcd82ce-341c-4aad-9676-0e922a0ddcc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bb8718-5e4d-438a-a702-45bc7a932a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89fa979-604c-4d93-91dd-a18474c70577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba2490a-afb7-4c3f-97a7-239f0c81c81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf025b9-baa7-422b-a6bf-a06da151b812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2299e5b0-a66a-4e8a-a212-43b0f1b706e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b3d874c-b30a-4877-9185-9129ad08297c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0b6e55a-c0fa-481d-a9d6-04f3af05a466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc43b253-638c-4c53-8ed9-d1272ca5c8e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d6c47a-7640-4deb-8f6d-459cc198a4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c7c23f9-1488-4ab7-b228-9b7657caeece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67083dec-bb6c-463c-9ed2-ae4173591655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d219789-89df-489d-99a2-485c893020f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 738f0869-fe11-454a-941e-e6f323d6bdca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8761eee9-4c13-4eda-883b-3af5c21f6966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de3dd7b-5ca4-4892-bb53-fd2c07c0bf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6759def-67e7-4f15-a69c-4b3d623f3a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc5a454a-dac4-42b4-b66b-8198fd27da0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050e52d8-950e-4c24-9dc4-2c118a06003a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b37056f-1993-4a49-ad3c-2a43707b24f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318fc4d7-663c-42e8-acc4-f6f54750f208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15b0563-6da7-49ea-8f08-cefdc4b02db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e58d19a8-91de-47a5-b184-2e407606b265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ef3724f-d366-4d08-9cfd-af8a97a5072e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54aab832-a0a3-4535-a1f3-4a3ed8a17c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9b6791-1563-40f7-8c1c-174151b261c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128c245e-d6f7-4d1b-9bb8-519a3353417f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4dcdcb6-615e-4ed4-805b-f73e57361ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message befc5235-c558-4a12-bf5a-b82dcec7c964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ddc732-76f1-4893-bd99-5dedd9a85494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e58cfd-7d67-4045-903b-0376f83a8ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d80e03-dd5e-451b-962d-d00b8ca864dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a885729d-957a-41f1-8017-64b6e228849b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c819cbb-e12d-4541-b08c-8aa45fa8b280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab4684f-ef69-47ce-b78a-8185a8f52cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 977b2059-7e62-4e43-9f89-515a0e101616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcd3c520-35e8-4699-85e8-bb85c281cfb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb44924-37c3-44a7-9d64-d0a6684af047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9d7b00-2d59-48f7-8a8e-99a718208860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aff17bc-057a-4e3b-b2ec-73d084dd0208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26560317-4562-452c-bc1a-c7ef6009da32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd5c7c8-08e6-4a2c-83e3-afc673b5d041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76efd39-94f9-4554-8d10-334aba1cb770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2276d43-73ab-4d8c-a5af-b3657e8eee69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d105291-1dfb-417b-875e-3cbeac248df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6aee816-c4b3-435a-ae05-51f7f30fbcc8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(1690, 24), y=(1690,)
   Test:  X=(423, 24), y=(423,)

⚠️  Limiting training data: 1690 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  414 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2149, val=0.0792 (↓), lr=0.001000
   • Epoch   2/100: train=0.0924, val=0.0871, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0840, val=0.0802, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0789, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0828, val=0.0791, patience=4/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 1 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0150
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0109
============================================================


============================================================
🔄 Round 3 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1570, val=0.0977 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   ✓ Epoch   2/100: train=0.0901, val=0.0870 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0835, val=0.0838 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0829, val=0.0832 (↓), lr=0.000250
   • Epoch   5/100: train=0.0827, val=0.0832, patience=1/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0819, val=0.0830, patience=7/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 3 Summary - Client client_7
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0084
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0167
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0979, RMSE: 0.3130, MAE: 0.2632, R²: -0.1535

📊 Round 3 Test Metrics:
   Loss: 0.1217, RMSE: 0.3488, MAE: 0.2874, R²: -0.4333

============================================================
🔄 Round 8 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0866 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0813, val=0.0859 (↓), lr=0.000063
   • Epoch   3/100: train=0.0808, val=0.0856, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0803, val=0.0854 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0798, val=0.0855, patience=6/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 8 Summary - Client client_7
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0271
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0261
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2579, R²: -0.0332

📊 Round 8 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2549, R²: -0.0049

📊 Round 8 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2419, R²: 0.0642

============================================================
🔄 Round 14 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0852 (↓), lr=0.000016
   • Epoch   2/100: train=0.0763, val=0.0850, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0761, val=0.0849, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0759, val=0.0848, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0759, val=0.0848, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0755, val=0.0845, patience=4/15, lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0752, val=0.0844, patience=14/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 14 Summary - Client client_7
   Epochs: 22/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0770
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0437
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2384, R²: 0.0880

📊 Round 14 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2355, R²: 0.1004

============================================================
🔄 Round 17 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0820 (↓), lr=0.000002
   • Epoch   2/100: train=0.0758, val=0.0820, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0758, val=0.0820, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0757, val=0.0819, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0757, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 17 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0734
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0774
============================================================


============================================================
🔄 Round 18 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 18 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0652
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0979
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2367, R²: 0.0881

📊 Round 18 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2359, R²: 0.0931

============================================================
🔄 Round 23 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 23 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0870
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0232
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2352, R²: 0.0974

📊 Round 23 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2359, R²: 0.0953

📊 Round 23 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2370, R²: 0.0894

============================================================
🔄 Round 32 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 32 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0684
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0611
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2378, R²: 0.0861

============================================================
🔄 Round 34 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 34 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0652
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0570
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0857

============================================================
🔄 Round 37 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 37 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0539
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.1144
============================================================


============================================================
🔄 Round 38 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 38 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0808
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0073
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0858

📊 Round 38 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0858

📊 Round 38 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0859

📊 Round 38 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0859

============================================================
🔄 Round 45 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 45 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0699
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0488
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0860

============================================================
🔄 Round 47 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 47 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0732
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0294
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0861

📊 Round 47 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0861

📊 Round 47 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0861

📊 Round 47 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2380, R²: 0.0861

============================================================
🔄 Round 55 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 55 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0566
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.1067
============================================================


============================================================
🔄 Round 56 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 56 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0630
   Val:   Loss=0.0744, RMSE=0.2729, R²=0.0819
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2380, R²: 0.0863

============================================================
🔄 Round 57 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 57 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0629
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0831
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2380, R²: 0.0864

============================================================
🔄 Round 62 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 62 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0798
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0015
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2380, R²: 0.0862

============================================================
🔄 Round 63 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 63 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0741
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0336
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2381, R²: 0.0860

============================================================
🔄 Round 67 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 67 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0604
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0878
============================================================


============================================================
🔄 Round 69 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 69 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0613
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0879
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2381, R²: 0.0862

============================================================
🔄 Round 70 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 70 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0743
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0355
============================================================


============================================================
🔄 Round 71 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 71 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0673
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0485
============================================================


============================================================
🔄 Round 72 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 72 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0617
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0130
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2380, R²: 0.0865

============================================================
🔄 Round 76 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 76 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0654
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0703
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2381, R²: 0.0861

📊 Round 76 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2382, R²: 0.0860

============================================================
🔄 Round 82 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 82 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0655
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0629
============================================================


============================================================
🔄 Round 83 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 83 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0636
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0735
============================================================


============================================================
🔄 Round 84 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 84 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0735
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0389
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2382, R²: 0.0857

============================================================
🔄 Round 85 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 85 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0663
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0617
============================================================


============================================================
🔄 Round 86 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 86 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0642
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0695
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2381, R²: 0.0862

📊 Round 86 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2381, R²: 0.0863

============================================================
🔄 Round 92 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 92 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0594
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0921
============================================================


============================================================
🔄 Round 94 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 94 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0632
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0757
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2381, R²: 0.0864

============================================================
🔄 Round 96 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 96 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0739
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0315
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2381, R²: 0.0864

============================================================
🔄 Round 99 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 99 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0526
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0968
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2382, R²: 0.0863

============================================================
🔄 Round 104 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 104 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0621
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0802
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2382, R²: 0.0862

============================================================
🔄 Round 107 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 107 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0717
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0394
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2382, R²: 0.0863

📊 Round 107 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2382, R²: 0.0862

============================================================
🔄 Round 113 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 113 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0630
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0707
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2382, R²: 0.0861

============================================================
🔄 Round 114 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 114 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0671
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0575
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2382, R²: 0.0860

============================================================
🔄 Round 116 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 116 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0588
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0909
============================================================


============================================================
🔄 Round 117 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 117 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0531
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.1180
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2383, R²: 0.0856

============================================================
🔄 Round 122 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 122 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0760
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0177
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2383, R²: 0.0855

============================================================
🔄 Round 123 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 123 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0700
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0526
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2383, R²: 0.0854

📊 Round 123 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2384, R²: 0.0853

📊 Round 123 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2384, R²: 0.0853

============================================================
🔄 Round 132 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 132 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0639
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0671
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2384, R²: 0.0853

============================================================
🔄 Round 133 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 133 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0725
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0347
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2384, R²: 0.0852

📊 Round 133 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2384, R²: 0.0852

📊 Round 133 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0849

============================================================
🔄 Round 139 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 139 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0604
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0849
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0848

📊 Round 139 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2385, R²: 0.0848

📊 Round 139 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0848

📊 Round 139 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0849

============================================================
🔄 Round 146 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 146 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0615
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0801
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2385, R²: 0.0850

============================================================
🔄 Round 147 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 147 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0643
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0639
============================================================


============================================================
🔄 Round 148 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 148 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0649
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0646
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0849

📊 Round 148 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0848

📊 Round 148 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0848

📊 Round 148 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0847

============================================================
🔄 Round 152 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 152 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0720
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0362
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0847

============================================================
🔄 Round 153 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 153 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0724
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0378
============================================================


============================================================
🔄 Round 154 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 154 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0710
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0392
============================================================


============================================================
🔄 Round 155 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 155 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0570
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0901
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2386, R²: 0.0847

============================================================
🔄 Round 159 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 159 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0558
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0892
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0845

============================================================
🔄 Round 160 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 160 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0686
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0375
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0845

============================================================
🔄 Round 161 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 161 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0644
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0661
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0845

📊 Round 161 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0844

============================================================
🔄 Round 165 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 165 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0709
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0381
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0843

============================================================
🔄 Round 166 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 166 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0628
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0662
============================================================


============================================================
🔄 Round 167 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 167 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0678
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0504
============================================================


============================================================
🔄 Round 168 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 168 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0658
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0587
============================================================


============================================================
🔄 Round 169 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 169 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0649
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0629
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0845

📊 Round 169 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0846

============================================================
🔄 Round 173 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 173 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0603
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0781
============================================================


============================================================
🔄 Round 174 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 174 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0637
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0673
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0847

============================================================
🔄 Round 179 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 179 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0698
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0434
============================================================


============================================================
🔄 Round 181 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 181 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0641
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0630
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0849

============================================================
🔄 Round 183 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 183 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0719
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0359
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0849

============================================================
🔄 Round 184 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 184 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0600
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0829
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0850

============================================================
🔄 Round 185 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 185 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0599
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0787
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0850

============================================================
🔄 Round 186 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 186 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0609
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0807
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0850

============================================================
🔄 Round 188 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 188 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0691
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0406
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0850

============================================================
🔄 Round 190 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 190 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0632
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0714
============================================================


============================================================
🔄 Round 191 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 191 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0640
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0638
============================================================


============================================================
🔄 Round 192 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 192 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0722
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0273
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0851

📊 Round 192 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0851

📊 Round 192 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0851

📊 Round 192 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0852

📊 Round 192 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0852

============================================================
🔄 Round 199 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 199 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0698
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0450
============================================================


============================================================
🔄 Round 202 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 202 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0635
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0457
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2387, R²: 0.0849

============================================================
🔄 Round 203 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 203 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0598
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0858
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2387, R²: 0.0849

============================================================
🔄 Round 204 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 204 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0667
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0430
============================================================


============================================================
🔄 Round 205 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 205 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0677
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0526
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0849

============================================================
🔄 Round 206 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 206 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0588
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0892
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2387, R²: 0.0848

============================================================
🔄 Round 208 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 208 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0576
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0808
============================================================


============================================================
🔄 Round 209 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 209 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0710
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0025
============================================================


============================================================
🔄 Round 210 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 210 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0662
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0471
============================================================


❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
