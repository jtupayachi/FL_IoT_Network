[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e04c39-ac78-4a76-83f4-55ee105036f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd935cf9-9ff0-4b79-ad45-887a530ecfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4004c976-1b30-46d2-b844-90f6820c092a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b117159-f01a-40e5-8343-137c1430d3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080c5bae-a1c3-4810-8a1f-30149c539a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be35a6a9-de32-4ea5-9353-4d3f1eecbbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc18bb0c-f7a0-4cb4-9621-faee74fad87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a5e9c5-930a-4d0f-8f0e-352dd505a9c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538630dc-e9bd-41e4-86f5-60815b3999ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7416e28b-d217-4d4c-aeaf-8a89b8158fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c524fff8-874a-432e-954d-c9f60185a453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01811b6d-f076-41ea-a43c-3365344f7ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de563cf3-35f3-4933-895e-bdfe17012e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f4e143-342a-442f-a395-e897b70922a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5287508c-233b-4e50-a735-c25c4faf7fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e2d95f9-97eb-479d-b64a-7375119e0d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca3d1432-00c2-44ab-89ad-3bc4f119dd8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66eab629-314f-418b-9c76-57ea6acc5caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbefd6cc-c3be-43ab-8387-a82babad9f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5190da21-37f4-4391-b43b-0d6fa44270e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e639a7b1-a4a7-4cdf-bdc9-3032f8db0a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5327b601-eea3-4485-9d6b-558d96f40d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91278132-9dcb-4cdb-a07f-58b277a9c8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ec7c43-289b-4db3-9eb8-c5bffd259797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1784db3-01bb-416c-9282-3e5bcd1b8cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfd2432-e796-4d9b-96ba-c857bdec83ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa7eecf0-60ed-476c-9309-af5441b43741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b35f784-1e38-4179-9391-429420ba5321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e82bfb-2825-459e-a541-6512daa4a22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10e8448-4f57-458f-ba47-6857cda8706e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 060e2080-234c-47ac-b08e-e3857373efcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19921b9-d65b-4720-afba-80fd6f174d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3f8e2b-90f1-41d4-9e64-bb88601cb0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9e6490-6cb4-48fb-a973-e000bf63e149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d551ef3d-ad1d-495c-80f7-cc20ddd51b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4604cb-a112-4d80-a866-a27fe96edcbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6e2cf0b-704f-4975-8f4c-ea0e6aa90db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cdc6a5f-a298-4f9e-b52f-ab0a619d16e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa151265-d656-4bfb-895e-9ecc8e646591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a3c9a7-13a5-4e22-9532-b581d665d93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c237f3e6-3f07-4c21-94b3-667ff9687eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0748dec8-82b5-4560-b94b-dcfb4a8dc0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dbcb3ce-b8a4-48cb-9980-6cdbcc28f64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfca580e-24ea-45f8-ad34-20ce26d39ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bff84e4-fbf4-4c78-af8f-2ffee12ebca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7691894-106b-4fa7-ad74-7d240821bec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5f437f-052e-4ea8-8120-50c2c87e5bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b9bd4ec-b338-4fce-b71a-cc7e683b87b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fefd9759-9079-44aa-8812-e11063729e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5408ec-32a0-456a-9efa-9182adf0dc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e15bbe-809c-4734-abc3-8e58b90ee2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da25e71-0141-4c84-8b65-c87e3f5b80dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0506298b-d103-4c4e-931d-d3dedd6cd8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ab61e5-0ba5-41ce-a98b-b4ef34dc1a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a8ac98-1aa5-4128-ac6f-207aefe3a856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f31194-99bc-407a-9d21-a4ef83f4ff65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041c1164-ebd5-4321-a83c-5087f24b31a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14d4290f-7b07-403b-af96-dd9f0a0c978b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e10440d2-72f0-4b3e-b3a6-76208ebf456b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6e5080f-5bf6-42b6-9da0-cbb1ee21cc59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d63f72-1d49-48f5-8e82-2d0635912c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cdca802-a1bf-4f4c-b0f2-70850b8d4edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28106950-0606-4dbb-aa13-7da772106019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c71d2d-2f35-48b8-9cef-c5c94a4e9498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad2edfa-d469-4e14-a813-4f9950f05eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec35794-b045-4c6b-8176-a89be1963a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2b1f9bd-a3ab-46d1-b807-78b5b0975edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7488590-4182-4c53-8249-3b5d7184f44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cebd66a3-1a3b-4eb4-ab31-6f3d4fbbe249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c027ad5c-a522-4a73-a022-208a1b0faeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c50e3db-10a3-4273-b8cf-2455661678ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4486e621-6968-4007-a34f-c46b504aed15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10623c0-e7a6-4c7c-bea8-3b60ca0db2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc4e030-a3d1-4f5e-9418-46a6d9c7e839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5806e840-1b90-49a9-b5e6-e2ccee5ef98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f26a71-623c-4633-873c-969762a8d496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279e8d71-929a-4b74-9082-77e8ff0d982c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46cd4627-e192-400e-a3f6-713940408736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c92984ff-dcc3-4bb4-ba3f-bac459694514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4797f341-3ea9-4f2a-bbf5-036ee9915881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285348ff-7928-4395-916e-388e6c63df65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e365117c-edae-4a04-a51e-7588daaa2208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91e5233-f08a-43c4-b1b8-ecddb8cc8019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87424699-b60e-41d1-aad4-d59c94dd4554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3580c8e2-54fb-4160-9a2d-25472266a5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 953ca27d-f39b-4842-bbef-491bdc68215c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8e28ed-042f-4d0c-8b0b-dd6bf22d1b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf2805e-dd05-4cbd-9c87-48443a66ee6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ffa268-372b-42c0-b6e4-6005eb371100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d113ba2-ea41-4dc1-9cbe-f655b6a29a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf1c3bd-0980-413e-a1e1-e664bf56e1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d46bd9fd-2f0c-44a6-82ac-ce1a6f5b052d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b67f5b9-d222-4d87-bb6a-6751347627dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c165b849-eb46-40d8-95c3-77a0a85249a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1249b108-030f-4d4d-8d5c-bbf0b1dd5566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca980e9-cb6f-4fcf-a6f7-1ca39f2f1d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8e7a30f-304f-48b4-8923-420555f56d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2782060a-7cfd-4fe7-8aac-e2513a65d8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 721ccd4f-83b4-4ff7-8cc4-84ba81e48851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d2c30d4-17b5-454e-b79f-65e396203cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37dcbd4f-8a55-464e-bfc6-e45fdcb68d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e52be08-dbbf-47d8-9449-afe083c2faf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcfff44b-8353-4c18-a2d7-6ba12f8bc601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed80d17-528f-4d46-8145-6c940347849e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc04bf9-94f1-45b7-b801-e21d8c1a7c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b0ff281-d8e5-4de6-946e-fa4bdb484c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1de358-7fb2-49fd-9f4d-7814d7363c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3ea9d3-4d73-49d3-a9eb-5ebc0e94886d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2aeb80-5434-4cf3-94e7-40534410a5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9cd483-a1bf-43eb-815f-1ce31d53e5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9544c13-f083-4261-99f9-fc73b15c4e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc03780-8faf-48d4-bee8-ef5dcbc36207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67bda309-fac5-4731-a5bc-4b3e729a3e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 369fb919-cf5a-42a2-935e-3f405b772b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e5c9f6-1a50-495c-a144-ad139324dbc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10eff504-97f0-4ba7-966f-84e2c81e2bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ec0480-a510-4d41-9bf3-ae90c658dfea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbbf6e3-01f4-4165-9eb3-8444cee2ce1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84adc587-3191-49b1-b695-8213c5304d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41710add-5bce-4910-9d33-b81f5bdf9d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ebaa07-ccf0-44f4-abdd-372b136ff093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d071521-82d2-4b49-a66a-928dcdbab950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d9060e-a4be-4e9d-96d6-7ad2c94c1ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d945a5c-414f-41be-85a8-e5c4577a22ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03981a86-4b26-4750-9882-99604b394781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d9e692-a054-4214-b820-c9a589723399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68bf062e-c834-4f5e-93c8-27389282ff6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51e91d95-0719-467e-842a-0273a297aed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61320ea0-b8a9-423e-9c79-b8b76ba9d6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c57df9-52ee-40b2-aebb-1a7f5e5a6376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8126dc7-d7f2-40d4-a108-5158c3f2f35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 955a783c-d80d-4d88-8a1f-4becde63db59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfd4b1a-0e4f-4744-a8bd-0755d099d203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03235563-951d-4957-91bd-d3ca2bac2c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9302741d-093a-4d17-8bf8-7399e60d1295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb14e4c-3eee-4425-822c-d74334e1c83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e15b950-d338-4bcb-8dd7-9e337d303f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df514204-85b3-4bc6-a936-d03b571065d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f433a9-4ae8-464d-8633-175edf24717b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc010cc-7c2f-434e-8810-1bc1d3f7a573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f564be39-cebd-40bd-889b-1968917e7bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f87571-b673-4e11-8fe2-edb7ba972c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c9e166-9824-45ae-babf-6f87c6d0bfa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f138af5-8697-461c-926d-b66bdbc2433a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b7979a-8aa9-40e7-80ed-e83d46bf7c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba50c52f-e484-4be6-b68c-0c2de4e3ddc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3199c8-06b4-4a0a-9d6c-4397184b841b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf3f196-83a3-4bde-be77-5daeba875bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f753f9-b484-4af3-a53a-0258f7019596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb521bf5-33ec-4a15-9f01-be5d2222ac4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453b7b3b-5afa-4aef-81c1-3e231cbe97af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41ff590-3fb5-454b-9d70-41395ccde5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb02244c-3e36-4c3c-95f8-967b7f87ae5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee2bd48-44ce-4e4c-b427-30bf73dc9931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cebe84e7-1b1d-4c92-aa87-ceac89ddb06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c999d99a-1f5b-49c6-aea8-1c76bcde3c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68528a19-72f2-4920-b307-ab8d1c485f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547744f0-d33b-4111-85a8-8200d035f6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be3e7cd8-87f6-4f78-a687-3a98d2577260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1014d934-08e9-45ca-8c25-376eedbe1125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5c0fb3-e018-4457-a05d-288f1c3a3b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a790c23-ad42-4e92-8338-351991507a47
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_81
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_labels.txt

📊 Raw data loaded:
   Train: X=(1208, 24), y=(1208,)
   Test:  X=(303, 24), y=(303,)

⚠️  Limiting training data: 1208 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  294 samples, 5 features
✅ Client client_81 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2477, R²: 0.0170

============================================================
🔄 Round 19 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0822 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0755, val=0.0816 (↓), lr=0.001000
   • Epoch   3/100: train=0.0738, val=0.0814, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0717, val=0.0807 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0700, val=0.0793 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0609, val=0.0728 (↓), lr=0.001000
   📉 Epoch 20: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0443, val=0.0761, patience=8/15, lr=0.000500
   📉 Epoch 28: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 19 Summary - Client client_81
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0546, RMSE=0.2337, R²=0.3165
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.1980
============================================================


============================================================
🔄 Round 20 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0747 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0792, val=0.0742 (↓), lr=0.000250
   • Epoch   3/100: train=0.0782, val=0.0738, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0774, val=0.0733 (↓), lr=0.000250
   • Epoch   5/100: train=0.0767, val=0.0730, patience=1/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0727, val=0.0717, patience=4/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0694, val=0.0714, patience=14/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 20 Summary - Client client_81
   Epochs: 22/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.0982
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0958
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0375

============================================================
🔄 Round 22 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0742 (↓), lr=0.000063
   📉 Epoch 2: LR reduced 0.000063 → 0.000031
   • Epoch   2/100: train=0.0786, val=0.0747, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0781, val=0.0748, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0778, val=0.0748, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0776, val=0.0747, patience=4/15, lr=0.000031
   📉 Epoch 10: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0764, val=0.0745, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 22 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0383
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0528
============================================================


============================================================
🔄 Round 24 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0771 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   • Epoch   2/100: train=0.0780, val=0.0768, patience=1/15, lr=0.000008
   ✓ Epoch   3/100: train=0.0778, val=0.0766 (↓), lr=0.000008
   • Epoch   4/100: train=0.0776, val=0.0765, patience=1/15, lr=0.000008
   • Epoch   5/100: train=0.0775, val=0.0763, patience=2/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0770, val=0.0757, patience=4/15, lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0767, val=0.0754, patience=6/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 24 Summary - Client client_81
   Epochs: 30/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0570
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0805
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2463, R²: 0.0386

============================================================
🔄 Round 26 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 26 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0327
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0223
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2480, R²: 0.0259

============================================================
🔄 Round 28 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 28 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0191
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0279
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2487, R²: 0.0190

============================================================
🔄 Round 31 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 31 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0152
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0253
============================================================


============================================================
🔄 Round 33 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 33 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0187
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0036
============================================================


============================================================
🔄 Round 34 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 34 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0132
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0259
============================================================


============================================================
🔄 Round 35 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 35 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0172
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0046
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2489, R²: 0.0179

============================================================
🔄 Round 39 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 39 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0152
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0044
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2489, R²: 0.0179

============================================================
🔄 Round 41 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 41 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0116
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0271
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2489, R²: 0.0180

============================================================
🔄 Round 43 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 43 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0169
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0080
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0180

📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0180

📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0180

📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0180

============================================================
🔄 Round 48 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 48 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0191
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0010
============================================================


============================================================
🔄 Round 49 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 49 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0103
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0043
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0181

============================================================
🔄 Round 51 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 51 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0210
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0101
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0181

============================================================
🔄 Round 53 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 53 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0118
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0331
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0182

============================================================
🔄 Round 54 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 54 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0173
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0126
============================================================


============================================================
🔄 Round 55 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 55 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0206
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0139
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0182

📊 Round 55 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0182

============================================================
🔄 Round 57 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 57 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0097
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0434
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0183

============================================================
🔄 Round 60 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 60 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0149
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0245
============================================================


============================================================
🔄 Round 62 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 62 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0189
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0088
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0183

📊 Round 62 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0183

============================================================
🔄 Round 66 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 66 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0180
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0095
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0183

📊 Round 66 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0183

📊 Round 66 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2490, R²: 0.0184

============================================================
🔄 Round 70 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 70 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0142
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0135
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2490, R²: 0.0184

📊 Round 70 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2490, R²: 0.0185

📊 Round 70 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2490, R²: 0.0185

============================================================
🔄 Round 77 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 77 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0122
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0355
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2490, R²: 0.0185

📊 Round 77 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0186

============================================================
🔄 Round 80 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 80 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0135
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0316
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0186

============================================================
🔄 Round 82 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 82 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0209
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0230
============================================================


============================================================
🔄 Round 83 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 83 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0169
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0130
============================================================


============================================================
🔄 Round 84 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 84 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0173
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0097
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0186

============================================================
🔄 Round 85 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 85 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0179
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0022
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0186

📊 Round 85 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0187

📊 Round 85 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0188

📊 Round 85 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0189

============================================================
🔄 Round 92 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 92 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0146
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0244
============================================================


============================================================
🔄 Round 93 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 93 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0198
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0047
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0189

============================================================
🔄 Round 94 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 94 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0190
   Val:   Loss=0.0773, RMSE=0.2779, R²=0.0027
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0190

============================================================
🔄 Round 96 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 96 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0181
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0133
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0190

📊 Round 96 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0190

============================================================
🔄 Round 100 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 100 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0235
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0105
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0190

📊 Round 100 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0190

============================================================
🔄 Round 103 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 103 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0152
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0203
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0190

============================================================
🔄 Round 105 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 105 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0182
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0141
============================================================


============================================================
🔄 Round 106 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 106 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0154
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0226
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0191

📊 Round 106 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0192

📊 Round 106 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0192

============================================================
🔄 Round 114 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 114 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0270
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0374
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0192

============================================================
🔄 Round 116 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 116 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0163
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0228
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0192

📊 Round 116 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2490, R²: 0.0192

============================================================
🔄 Round 122 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 122 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0108
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0389
============================================================


============================================================
🔄 Round 124 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 124 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0176
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0150
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2489, R²: 0.0192

============================================================
🔄 Round 126 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 126 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0229
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0209
============================================================


============================================================
🔄 Round 127 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 127 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0141
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0262
============================================================


============================================================
🔄 Round 128 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 128 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0185
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0058
============================================================


============================================================
🔄 Round 129 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 129 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0150
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0106
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

============================================================
🔄 Round 131 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 131 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0145
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0286
============================================================


============================================================
🔄 Round 133 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 133 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0117
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0121
============================================================


============================================================
🔄 Round 134 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 134 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0181
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0087
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2489, R²: 0.0193

📊 Round 134 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2489, R²: 0.0192

============================================================
🔄 Round 138 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 138 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0120
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0360
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2489, R²: 0.0192

📊 Round 138 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0192

============================================================
🔄 Round 143 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 143 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0183
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0046
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

📊 Round 143 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

============================================================
🔄 Round 146 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 146 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0125
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0352
============================================================


============================================================
🔄 Round 147 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 147 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0187
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0099
============================================================


============================================================
🔄 Round 148 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 148 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0206
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0076
============================================================


============================================================
🔄 Round 149 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 149 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0170
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0160
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

============================================================
🔄 Round 152 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 152 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0095
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0473
============================================================


============================================================
🔄 Round 153 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 153 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0158
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0180
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

============================================================
🔄 Round 157 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 157 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0152
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0221
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

============================================================
🔄 Round 158 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 158 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0225
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0070
============================================================


============================================================
🔄 Round 159 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 159 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0146
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0184
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

📊 Round 159 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

============================================================
🔄 Round 165 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 165 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0175
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0080
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

============================================================
🔄 Round 166 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 166 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0241
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0253
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0193

📊 Round 166 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0194

============================================================
🔄 Round 168 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 168 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0141
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0160
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0194

📊 Round 168 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0194

============================================================
🔄 Round 172 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 172 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0133
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0203
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0195

📊 Round 172 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0195

============================================================
🔄 Round 177 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 177 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0134
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0289
============================================================


============================================================
🔄 Round 178 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 178 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0145
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0267
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0196

============================================================
🔄 Round 179 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 179 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0192
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0030
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2490, R²: 0.0196

📊 Round 179 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0196

============================================================
🔄 Round 183 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 183 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0199
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0021
============================================================


============================================================
🔄 Round 184 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 184 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0147
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0278
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0197

📊 Round 184 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0197

============================================================
🔄 Round 187 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 187 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0189
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0082
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0197

============================================================
🔄 Round 188 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 188 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0110
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0256
============================================================


============================================================
🔄 Round 189 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 189 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0178
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0159
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0198

📊 Round 189 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0199

============================================================
🔄 Round 195 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 195 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0205
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0001
============================================================


============================================================
🔄 Round 196 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 196 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0160
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0223
============================================================


============================================================
🔄 Round 197 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 197 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0129
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0391
============================================================


============================================================
🔄 Round 198 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 198 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0105
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0381
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0199

============================================================
🔄 Round 201 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 201 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0162
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0223
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0199

📊 Round 201 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0199

============================================================
🔄 Round 206 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 206 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0235
   Val:   Loss=0.0703, RMSE=0.2651, R²=-0.0168
============================================================


============================================================
🔄 Round 207 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 207 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0185
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0130
============================================================


============================================================
🔄 Round 208 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 208 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0142
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0253
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2490, R²: 0.0199

============================================================
🔄 Round 209 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 209 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0191
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0088
============================================================


============================================================
🔄 Round 210 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 210 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0147
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0073
============================================================


============================================================
🔄 Round 211 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 211 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0150
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0260
============================================================


❌ Client client_81 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
