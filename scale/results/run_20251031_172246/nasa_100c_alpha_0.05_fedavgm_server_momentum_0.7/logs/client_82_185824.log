[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d5b06d-7f19-43ec-adea-74381e9447a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 134a357b-c715-407f-ae14-33a957939c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dcd91ab-f07f-4cc0-ad9e-efeaccd88a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbea83e6-e4c1-40f8-bf16-963a19b7e2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72110462-0e01-46a6-9fe5-e504828cb3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f841ed4-ffd6-419c-a506-2e1c59b5ea50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce79c5a-fdb0-4b68-9010-ed4ac4c0b8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0735fc1-9130-47ae-bbd3-a713188db9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7870bcee-f06d-4cda-bdeb-40d9d09cce62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74175669-4fa8-4a76-96ce-72d9763633f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d77cfee8-eb34-467e-8ae3-93054ae9261f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7899176a-3b73-4bfe-b557-311631273607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9270b7-3ddb-49ba-9aa7-af4094913d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b115d14-84e5-4fbe-a71b-6b260f43c1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab65a69a-e639-46ce-9649-ac05e2ee334f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00f2da9-7d57-460a-ba10-8b72034497ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685d343d-e0e0-45bb-8560-7342c52c7dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b96456-29e2-483f-a0b1-1cda7845fe95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e8c0cb-5870-40f0-9bda-c044a11c3018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2398c068-48a7-4d19-aa9b-251a51fdccfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f5b70b-9c8f-45a5-9a9b-85af05465da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee9203a-32f8-40a1-9868-ab42396f7ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ccfa0e9-eb12-4723-a806-e5d01b35470d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8982313-026a-4a1c-8c07-483c5ece63af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a07863-edd4-49e4-ac04-b2a1beffe7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a77f44-0b7e-4aa7-9d7e-562a5e076b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13b004f3-9c16-4598-b2e3-e434f3041963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c3c7d2-c30a-497e-bd81-66821d14627b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be62a40b-ee2f-4761-bf18-bab185c8b3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11d98cd4-7527-41b2-b3ee-bd6f394791a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d341bc5-885f-40ab-bae8-b91e3ff64610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f07b86fa-8f05-4947-8f9f-e586647c3b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883aa709-b0f4-4730-b14d-4847494e5664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53f2b1e-2d26-44a7-8cac-0b25265a747f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ba8bfd-7161-453f-a27f-c445f3c60682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9434bb7-0914-4450-b8a9-ff1b98add699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebc15205-edcb-4008-8417-bf742c49d289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e224bdb0-8b45-4311-b0ff-a4335a8d37e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10d3007f-0fbc-41f0-97bd-92aee6677e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a08713d2-f20c-4334-b370-a8f89e44b529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc2f624-a717-4c90-a5b1-e9cbdeb30c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd8c8c0-d8f5-40a6-b263-5cfa99adbcb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783666c1-58d7-47ba-89c6-cd4329144ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12990016-6d3b-4c1f-9179-1dcd5b28a02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed9e1ec0-a5ae-421c-849b-acbc0e30bef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a51dd5b-e9e7-4202-a2e4-931bb8133ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea0f27a-77fd-40bb-8f26-0815b7d10bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd467517-1153-4972-a3d4-3134cb34d258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484c26c0-1a84-4828-9f01-9b33b74f80c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0097a932-e1e6-4be4-a660-6cda9b0460a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42015756-8bc2-426d-b2fa-1e56dbddd12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39cd7bf-48cc-489e-86f6-0d871d556b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a488d91c-6ea1-401a-ba0c-c28502fbf919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e04a71-2f52-4a15-a5c8-86712429acf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6883e95e-5328-4575-a439-0cbdfe05673c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b64b95-f85b-4c22-878a-84092e91173e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876a1340-7b46-4ee0-905b-ccc8b30c43df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb40ea9-7aad-4fc5-b625-f0000f6b7571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f2b43cc-c52c-4959-a36a-c6c4ea5c05ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c22f9434-e6b7-47fb-be68-b5a75126afed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 224274c6-e9b4-4a23-8817-b656bdfa4f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb42445-8575-4aa0-9512-eef9ee944304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73243df0-b9cf-49b2-863b-3d48f7b7c37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e5caa3-12bb-44df-99e6-221906ab6933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f7fa1d7-352c-458f-80ea-3daa990e4d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b073758-d85f-4618-b928-d7aeee44c8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 290ffa71-3772-4df5-872d-dc6c570b0259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 747bd54d-5721-4208-8ce0-d28ad261d0e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e53c847e-c511-414f-9466-1be9c4ec3758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60458d44-9a94-4d8f-a423-fea6bbd30549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 369d3575-378e-4b18-ba50-17e73d89fa37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dcdcb59-b4e5-45b4-8a3a-7e66ab630d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbcbe1e3-f90c-4ed5-ab8e-e4164f3101dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e2e396-a5d6-4aff-bf2b-82a2f5b7746c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1369b07-01b6-47f8-b62d-342f3ffeea21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c68ef6-1d81-44d5-a0a8-851a0e1a6fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025b4c4c-cd15-486d-b4a8-58a5f3dc720e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a73d094-00bf-41d6-92cf-5daa3a8a8e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d2f84ae-67ce-412a-a463-ebce795280c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644e7787-b4e7-48b2-b493-3bd890037450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e44ce13-fc78-41ce-be6f-6e31899d4268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af56de6b-0b0f-4639-804d-b8809053b318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479c7d24-5791-449e-ae7e-515e63058e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93befe3a-4912-4cdc-b69c-a5c36e0dd346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2a1522a-bb1a-4548-b00b-b1ad02fc3ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 266e7d66-045d-4f31-bc80-5142033ac38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13d4cab-b58a-461b-a7b8-20e9a5c3f425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2911784-37cd-4a77-b8cf-e3c82cd95c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37df5382-ae98-4af8-a06f-7f695ada2c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2afefbdb-77f9-4d7c-8032-ef53ea7fc2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec6c7b5-6dd0-4965-af24-a010f97f485d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ccc4378-8ae6-4f02-8ce7-eb1b015445e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c1cdf8-f758-4d8d-9e67-92537f1dbbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6b66a30-f8e8-4528-a068-d4df33990197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e12f285-7ae9-44a5-ac92-72086aee8b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663bbb73-5d01-4a7a-a486-138c5b70db6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7ab165-4c7b-484d-971e-7d1db425700c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a53655-b446-4da8-9c19-42d1accad23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c18850-3257-48f1-b31e-c40b56d30206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fbc4356-33f4-4c12-9374-7a9e7addc246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8394bfa8-e434-413e-9881-6a58f1d2992d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d173e5ef-84b7-4437-b905-c01a33b9eea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f0eac3-ac13-4a47-9840-57c89c601ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648088d3-58ac-472c-b358-6f366ec30771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bc7acb-891a-423f-bcc6-2cdef1bed307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 684b20df-83c2-42d5-842f-a697fa3950e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de9af8f-f509-4278-be79-f6ae605b8165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daca969b-de8d-412a-bdb8-c4b2fb682ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47e2328d-692c-43e1-a715-7934c4360894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 715b5a9c-d8dc-4d56-b088-eca995c30aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ff87ae-82e3-4902-9896-9bd7fc7c8e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd68b0cd-63d4-4363-a441-6101b15cdd6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6eefb5-c397-4310-8d97-e814e6994824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44308708-ee3b-4ce6-b8c4-979972f189c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d1f8d8a-709c-4c16-80e1-2780ec06a041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19242b41-bf57-49f9-bc9a-582f9562302a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d69213-9777-49b4-81ec-b34945cf8828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 591c2180-934b-4b18-9b84-bf3100efe39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 252d0af4-7d64-4993-a453-fd9de71f7509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38300a10-71d1-42c5-9483-ac8e52feb034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef2741e-4d1c-4a9a-a42b-1a4e3986933f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 949cc49a-f11f-4993-9993-5406a78c5f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ca8b9b-c373-444a-a9a4-5603753e9b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00797c24-a5cb-4e3e-b314-6fe2496c7beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6fd51af-c81e-4ade-9922-2c685e79bb15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5800929f-5211-4b6b-bc42-00067f0e918d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc34c3d5-9ab7-49cc-9ca8-6cc7fb8fdd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4a2dd4e-da48-4b24-ba43-3577083bf475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc61701f-0177-4015-87d0-37b2b3a8a348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c992bcc4-18c0-45e0-9086-5e746a34ab19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97460567-828a-4a9d-aeea-558922d7efbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 994c9dc0-5187-4edf-82f8-cefe1e79db50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 549ec511-efd9-46d4-a19a-c9e43a45aa32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02584830-4e6e-4e8b-8030-8b2ab8c3e8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd29c35-face-493f-b04c-3f34f6b09b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c29437c-2875-4e3e-8e98-6d31dc222b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11042d1-c161-499f-952e-a916faa9e1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 513b9ad8-19b2-4e1c-8d6a-0eedd6c8384b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0ce482-5170-49c2-899f-0554991e1924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15d511a-b359-40c3-be26-6f48345853c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22aabf5d-8fe7-4414-b676-0201cb4f0c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816f32df-8c28-4d21-aab9-ee313d45ffb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c27ced5-8ce8-4610-ad1d-d2bbad2ebdd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2efca432-1ab1-48cb-898a-5440b019c56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37032dc7-2413-4fb0-9c5f-f1c1ca09289c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af979297-dd7d-41e4-a90f-1901ebfea9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24a1b606-409e-4680-98fe-b838ff494df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60074fd7-6315-46f3-9e5f-8b92c19ca03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43ed2b0-550d-43d0-9239-80098fa64ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d22298-aa50-47e4-92e4-f9ea6031376d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239b2541-8c08-45c5-9aa6-53905039206b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d5651ff-a561-4f35-a2b1-d47bb61930e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce850d85-20f9-470b-931b-8947a92ac07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d34e053-937c-49e5-91d7-2effe141f43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b98e442-3b98-4581-835a-3f4c526d487c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4266ff-5a9e-42b0-ad44-513af2b40d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d7b0c6-ec5c-46e8-b19d-93cffe6fbd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f714bb4-4fcc-4dfa-9ae3-00756ce47ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eed5222-0467-4dc1-bfb6-2f929d91b50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cdf7dde-a6ee-4a5b-9d92-44ac95f7da50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa8e08e-29fb-4284-8e29-6c269b983a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed39e4fa-37b1-4a30-b11e-343cdca3655a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6a5202e-759a-4bec-aae6-0e7f1b4ddf1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528037d6-0298-4b95-bfde-bb045bef0f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5cbfac-a5ad-4643-bc7f-812056d18ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df8dc3f-30d3-46fd-b676-c4993ddc91b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a7b61e-6c16-4538-ada3-1d557a1daaaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34595b53-11e3-4b7e-970c-b99ef1abb1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ee209f-d751-4c75-9c70-7daee4d78b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa23119f-ff98-4d86-8d79-5a43c1d0bf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0ac971-131c-4200-a397-2be25b4c5ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69647ad5-c1ff-4108-82f0-e634d75c9c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212acebc-63d5-4f91-b543-0e51f21fbad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39cbecac-6424-42b4-8d2d-c7cccdeee82e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_82
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_labels.txt

📊 Raw data loaded:
   Train: X=(1604, 24), y=(1604,)
   Test:  X=(401, 24), y=(401,)

⚠️  Limiting training data: 1604 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  392 samples, 5 features
✅ Client client_82 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2534, R²: 0.0010

============================================================
🔄 Round 16 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0799 (↓), lr=0.001000
   • Epoch   2/100: train=0.0832, val=0.0804, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0809, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0815, val=0.0813, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0749, val=0.0868, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 16 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0337
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0778
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2524, R²: 0.0071

============================================================
🔄 Round 18 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0796 (↓), lr=0.000250
   • Epoch   2/100: train=0.0823, val=0.0801, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0819, val=0.0801, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0815, val=0.0802, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0799, val=0.0811, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 18 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0288
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0194
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2537, R²: -0.0033

📊 Round 18 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2528, R²: 0.0029

============================================================
🔄 Round 21 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0766 (↓), lr=0.000063
   • Epoch   2/100: train=0.0832, val=0.0764, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0830, val=0.0763, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0829, val=0.0762, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0820, val=0.0760, patience=3/15, lr=0.000063
   • Epoch  21/100: train=0.0811, val=0.0758, patience=13/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 21 Summary - Client client_82
   Epochs: 23/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0479
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0023
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2511, R²: 0.0163

============================================================
🔄 Round 22 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0920 (↓), lr=0.000031
   • Epoch   2/100: train=0.0797, val=0.0916, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0794, val=0.0913 (↓), lr=0.000031
   • Epoch   4/100: train=0.0792, val=0.0913, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0790, val=0.0913, patience=2/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0784, val=0.0918, patience=8/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 22 Summary - Client client_82
   Epochs: 18/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0357
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0127
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2505, R²: 0.0229

============================================================
🔄 Round 26 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0893 (↓), lr=0.000008
   • Epoch   2/100: train=0.0789, val=0.0893, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0789, val=0.0893, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0789, val=0.0893, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0789, val=0.0893, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0787, val=0.0893, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 26 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0395
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0177
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: 0.0146

============================================================
🔄 Round 31 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0906 (↓), lr=0.000002
   • Epoch   2/100: train=0.0798, val=0.0906, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0798, val=0.0906, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0798, val=0.0906, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0797, val=0.0906, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0797, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 31 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0245
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0175
============================================================


============================================================
🔄 Round 32 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 32 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0285
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0082
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2530, R²: 0.0073

============================================================
🔄 Round 33 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 33 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0254
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0124
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2530, R²: 0.0068

============================================================
🔄 Round 34 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 34 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0297
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0058
============================================================


============================================================
🔄 Round 35 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 35 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0212
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0232
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2531, R²: 0.0063

📊 Round 35 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2531, R²: 0.0063

📊 Round 35 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2531, R²: 0.0063

============================================================
🔄 Round 39 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 39 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0223
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0214
============================================================


============================================================
🔄 Round 41 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 41 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0223
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0221
============================================================


============================================================
🔄 Round 42 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 42 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0190
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0347
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2530, R²: 0.0070

============================================================
🔄 Round 45 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 45 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0285
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0329
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2530, R²: 0.0072

============================================================
🔄 Round 47 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 47 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0216
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0257
============================================================


============================================================
🔄 Round 48 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 48 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0288
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0047
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2529, R²: 0.0077

📊 Round 48 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2529, R²: 0.0077

============================================================
🔄 Round 52 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 52 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0239
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0124
============================================================


============================================================
🔄 Round 53 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 53 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0255
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0048
============================================================


============================================================
🔄 Round 55 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 55 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0205
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0205
============================================================


============================================================
🔄 Round 56 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 56 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0214
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0286
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2528, R²: 0.0085

📊 Round 56 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2528, R²: 0.0086

============================================================
🔄 Round 58 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 58 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0175
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0458
============================================================


============================================================
🔄 Round 59 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 59 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0269
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0032
============================================================


============================================================
🔄 Round 60 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 60 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0202
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0205
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: 0.0088

============================================================
🔄 Round 62 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 62 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0178
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0446
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2529, R²: 0.0083

============================================================
🔄 Round 68 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 68 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0219
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0238
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2528, R²: 0.0086

============================================================
🔄 Round 71 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 71 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0115
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0589
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0093

============================================================
🔄 Round 74 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 74 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0158
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0354
============================================================


============================================================
🔄 Round 75 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 75 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0277
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0059
============================================================


============================================================
🔄 Round 77 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 77 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0255
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0116
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

📊 Round 77 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

============================================================
🔄 Round 80 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 80 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0234
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0193
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: 0.0089

📊 Round 80 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: 0.0088

============================================================
🔄 Round 83 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 83 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0186
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0311
============================================================


============================================================
🔄 Round 84 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 84 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0214
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0332
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2528, R²: 0.0087

============================================================
🔄 Round 85 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 85 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0231
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0116
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2528, R²: 0.0087

📊 Round 85 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: 0.0089

📊 Round 85 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: 0.0091

============================================================
🔄 Round 88 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 88 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0241
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0143
============================================================


============================================================
🔄 Round 89 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 89 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0172
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0422
============================================================


============================================================
🔄 Round 90 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 90 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0171
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0412
============================================================


============================================================
🔄 Round 91 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 91 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0233
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0144
============================================================


============================================================
🔄 Round 92 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 92 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0217
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0255
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2526, R²: 0.0101

============================================================
🔄 Round 95 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 95 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0228
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0224
============================================================


============================================================
🔄 Round 96 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 96 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0227
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0228
============================================================


============================================================
🔄 Round 97 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 97 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0258
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0020
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0103

============================================================
🔄 Round 99 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 99 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0181
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0288
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0103

============================================================
🔄 Round 102 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 102 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0223
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0071
============================================================


============================================================
🔄 Round 105 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 105 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0175
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0334
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0103

============================================================
🔄 Round 106 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 106 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0233
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0193
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0104

📊 Round 106 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0104

📊 Round 106 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0105

============================================================
🔄 Round 109 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 109 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0301
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0199
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0106

📊 Round 109 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0105

📊 Round 109 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2526, R²: 0.0101

============================================================
🔄 Round 117 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 117 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0221
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0224
============================================================


============================================================
🔄 Round 119 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 119 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0267
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0055
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2527, R²: 0.0097

============================================================
🔄 Round 120 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 120 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0203
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0273
============================================================


============================================================
🔄 Round 121 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 121 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0165
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0429
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0095

📊 Round 121 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0093

📊 Round 121 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0092

============================================================
🔄 Round 125 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 125 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0267
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0013
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0092

📊 Round 125 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0092

============================================================
🔄 Round 127 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 127 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0181
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0030
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0093

============================================================
🔄 Round 128 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 128 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0216
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0046
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0093

📊 Round 128 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

============================================================
🔄 Round 130 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 130 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0215
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0164
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2527, R²: 0.0095

============================================================
🔄 Round 132 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 132 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0157
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0388
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0092

============================================================
🔄 Round 135 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 135 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0214
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0191
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0091

📊 Round 135 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0091

============================================================
🔄 Round 137 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 137 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0214
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0059
============================================================


============================================================
🔄 Round 138 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 138 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0199
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0186
============================================================


============================================================
🔄 Round 139 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 139 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0228
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0112
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: 0.0090

============================================================
🔄 Round 143 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 143 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0237
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0096
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0092

============================================================
🔄 Round 145 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 145 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0190
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0194
============================================================


============================================================
🔄 Round 146 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 146 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0241
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0068
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2527, R²: 0.0096

============================================================
🔄 Round 148 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 148 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0256
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0027
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

============================================================
🔄 Round 152 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 152 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0274
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0189
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

============================================================
🔄 Round 154 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 154 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0287
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0154
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0095

============================================================
🔄 Round 156 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 156 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0174
   Val:   Loss=0.0768, RMSE=0.2770, R²=0.0137
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2527, R²: 0.0095

============================================================
🔄 Round 157 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 157 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0148
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0350
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

============================================================
🔄 Round 159 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 159 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0229
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0128
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

============================================================
🔄 Round 160 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 160 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0219
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0100
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

📊 Round 160 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0093

📊 Round 160 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0093

📊 Round 160 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0093

============================================================
🔄 Round 167 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 167 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0227
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0106
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2527, R²: 0.0094

📊 Round 167 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2527, R²: 0.0095

📊 Round 167 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2527, R²: 0.0097

📊 Round 167 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: 0.0098

============================================================
🔄 Round 173 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 173 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0221
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0077
============================================================


============================================================
🔄 Round 174 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 174 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0133
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0416
============================================================


============================================================
🔄 Round 176 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 176 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0212
   Val:   Loss=0.0940, RMSE=0.3065, R²=0.0172
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0102

============================================================
🔄 Round 177 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 177 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0189
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0109
============================================================


============================================================
🔄 Round 178 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 178 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0222
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0053
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0106

============================================================
🔄 Round 184 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 184 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0225
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0055
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0106

📊 Round 184 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: 0.0107

============================================================
🔄 Round 186 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 186 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0247
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0104
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: 0.0108

📊 Round 186 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: 0.0108

============================================================
🔄 Round 189 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 189 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0179
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0258
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2525, R²: 0.0109

============================================================
🔄 Round 191 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 191 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0256
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0002
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: 0.0111

============================================================
🔄 Round 195 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 195 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0259
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0021
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: 0.0111

============================================================
🔄 Round 197 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 197 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0266
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0055
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: 0.0113

============================================================
🔄 Round 200 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 200 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0228
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0074
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2525, R²: 0.0109

============================================================
🔄 Round 202 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 202 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0219
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0123
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: 0.0108

============================================================
🔄 Round 204 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 204 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0197
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0026
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: 0.0108

📊 Round 204 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: 0.0108

📊 Round 204 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: 0.0108

============================================================
🔄 Round 208 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 208 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0220
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0139
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: 0.0108

============================================================
🔄 Round 209 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 209 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0174
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0283
============================================================


============================================================
🔄 Round 210 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 210 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0214
   Val:   Loss=0.0727, RMSE=0.2695, R²=0.0151
============================================================


============================================================
🔄 Round 211 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 211 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0256
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0002
============================================================


❌ Client client_82 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
