[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b786b0e7-71b0-4559-97ed-e70d0933b91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4279894-8e2d-4de4-b35e-ad9525490ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6740c47b-8b7d-421a-a511-b8eed39c28b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571e2c71-9516-4c63-b17d-20794351bdfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d30c983-7aca-4708-9fb5-06e7cc747fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785fc9b8-186b-437f-a04c-572573082750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe31ad6-a096-4c47-adf8-a37db717af69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e6f3173-4a24-4c4d-a749-22faf3776cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200092c3-5b60-4272-84de-9bca5604bcee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41dbd7cf-541d-4f38-8f58-a5cede23d76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1369e3d-1728-4f19-8726-d0492a3bc447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42fc6499-d3d6-4484-a001-9f9596ff66a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4d4d0c-34e9-46e9-850e-45b6c1d58f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfff5dc4-eb15-4b1b-bcee-01541452175f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b39612e-e7d4-4abf-915f-b71c0794d28b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ead3047-e586-44a9-b0b5-248b3535b38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f93ed01-93bf-47ee-b02b-59c60b0df02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67196f3-7362-4e46-9fda-0fd3f71de467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15142e20-5d08-4113-8165-35c6b782303a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8617cbdb-75ef-4db5-ba83-0174acbda6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a82a19dd-88fc-422c-9740-e00b649c1b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aedd87e3-406e-4308-8dca-362d0aac76f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30de0677-8722-4ca7-b19b-903769cf2527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd4a077-0764-4204-9fe0-54935b2752a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc51d6e0-1bae-40d0-8134-00534297d08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b42b8cb-825d-46e0-b6c4-17e41d73c940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0442c6bc-9569-48bc-b342-7bc93df02769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef311820-100c-48c2-94ea-05969ed21137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20cf7f2-7519-4f4a-b60d-01bd300a1537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c807be5-b78c-4e21-93e2-45f96dc4c91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e51289-5692-4a14-8976-db9901cba25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1df8e5e-8a39-4d97-bf91-b76fa13d1fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38985e76-f703-42a3-9beb-21e52fa26f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664e1071-5558-482c-a2df-003e081aa34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7d2ab9c-a6e6-4af8-af82-484aec029dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b12154ff-9359-4257-b40a-4ab7385bf31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f421bce8-aa10-4a3b-8970-ed55e5463096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce51f12-2046-4477-8747-f70ad98d8405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 296fc839-11d2-40ed-a965-963ade204158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f0ff87-b01b-4bb5-9cd4-a5c71a1c9d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b0029c-beca-4329-941c-ae4e6fd6d463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90347106-b735-443d-b732-8203596d922d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c39bdf1-656c-4718-abe6-3f1aeca283b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2119492-b15a-4a7b-9171-7fe9944a5276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57de5ce-ddc3-415e-9577-e14c6ff3d136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56ad845b-f4fe-4e24-99ef-5611c34a2e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c194aa3-ce10-43b8-98c5-e1935d829fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 804e0c12-9e79-453c-9669-ccd2c5bda92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c337aa8c-f4ea-4a0b-83ce-f4abb4315f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df29930-0224-41a2-b3ff-d47a1f62f2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e8757e3-30ff-4869-8590-e1b5a7192382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3a913f-13f4-4ca4-8e60-d200944b5e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b6288f0-abee-40c3-b255-4f254609fdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88105d5-a620-482f-9429-650e575d9edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd0faea-914e-4c6b-bf05-b7206bbbd924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 416992e3-2bb0-4916-a316-1adeac1772e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e573abcf-5706-4960-8d12-fdf85b9c9972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9078bb48-f68c-4e90-827f-3b7411c62eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0078b1d-b8b2-4959-a127-bd9b7e426311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e25af2-bf08-4d8f-a187-81daa198ebee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae71dc5e-994b-4d14-a54b-17b5e395c607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 958973de-afd8-4454-9a66-c743f22dbacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6767ea27-d65f-4eb3-a18b-ed621969e3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7b293a-a5f5-4c48-9392-ccf2780541f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66988ab-c784-42ab-8ef9-b0e1fa40c646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30af465c-b77a-461f-b4a2-a8179ad18d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1c0f6e-ce8e-4260-be52-795c92f71689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d506c851-88d3-465c-b1dc-5268b22c77f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 441254d6-2ce8-4485-9b0f-6428d98d51aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f32b2695-325c-4700-92bd-1ed86642b4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8323a068-07a5-4259-b7df-6b33cfd0a1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe2721c2-5cf1-4cbc-92fa-3984b4f64086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd708d1-0c06-4b09-8771-569f2ce8773f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd74a845-a287-4445-9387-6bf418d0d554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4daa0732-3427-40f4-8c5b-957daddaee40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f88b9805-7f65-4dab-b86e-d5218428b20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa6d46d-f020-4f13-877b-1e53dd976a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e491f0-2e7a-43e5-96a1-3142d9fe28df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e4e71f7-7d92-42f6-8170-624711e60c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dade5d7-df91-40a2-91d7-d1802bbdec49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da5748f8-7c6f-4641-9e6d-649c40ffec71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7aeb4cb-82d5-4146-86c5-0bb1fb5c99ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13f2302-f6ae-4442-ba44-2554bd77373b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cbdad8e-c065-435c-9b56-ff4ba41f2eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c84394-9096-42e0-8f09-069a254e8a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d20321a-f3a6-4a76-a2fb-e0956f202dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1aa6f63-f0f9-4395-a39c-6e7f1f6dd2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fba6b6e-07f2-4ae6-9b85-da376c4e76c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8068fcce-82a9-4ac0-89a0-e0c8fcd0e6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd4fb2a-9b4c-4024-86df-a5f782056bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8bd2e11-b2cb-4818-9077-fd08e886baf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4432a598-6967-4775-b26f-065e7e36d91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14c231c-3489-4e2b-885a-75acd3a229a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57542aad-50a9-4f8f-865c-c29f434ee733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3a74eb-c5e1-4603-9470-97980f6139ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c6ea61-04d3-4d06-ba4a-b38288cc228b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb696de-7d80-4c68-b762-511f85772852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adf9914f-897d-43db-bbf7-76d64969e14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbbddb9-33de-48d5-bcf5-3c1d6a3fe5a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf471b9e-528c-4550-a896-e78fa3ded63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e134b8-79ed-4e0a-bfb6-5c042c48668b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40f6fa95-04af-4cea-a831-d6d1f370eedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362fd6d6-b874-43ae-a023-739d5f50cc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210f054c-a146-4417-a48a-1eff0e764bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49f20768-7b54-4cdf-87e2-8172cdd82c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95939374-4593-4ac9-bfdf-5d06ae6f6944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 229f0116-a256-4b2c-999c-5ce3dcf5d0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9822147-ec4a-43ec-befc-f1e435633f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c09473-4196-4fae-a80e-6c5d061d105a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3174b2-b37c-4b0f-81b2-aba3e00d31a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34911161-4a91-4121-a181-baff8d974246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3be1428-9f0e-49a0-afaa-c91f76197b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 268b1caa-e55d-4799-a7dc-db74efdc46ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71478c78-1af4-49c8-96a9-d2a483f81082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e9b518-b0da-48d9-8d05-b9b83e651df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d942801-3e97-4e0d-aa03-c0c91f567afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf0b5e0-9a38-4c00-9841-aa726f71c709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612fe84c-ca8f-4002-9a2f-e0c02ce85fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b603f52-c237-45ca-909a-3bbc7c86091c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77c2e7e-3138-4002-b285-0a7fff8992da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c91e29-4a99-426c-a736-6fc8d38e9a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37e59b1-268a-4d77-8862-dd3b612e7232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea5972ea-d47b-4270-b0d0-a7ee092a3056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 298c8edd-6043-4e71-afd9-8d8b4df84ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6f304b-84f1-4731-900f-b0d8223a3dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc854a57-f8f7-4097-adce-b55bb4733ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccbffd3-5cce-4be1-b64c-6c320c8113e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c2c666-388d-40d4-9582-5aa326c877e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012349cd-d9ae-48f2-9e88-bbe89b2860ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c5afbee-535b-40dc-afd2-a26f69df2f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3792a80f-a2db-45b1-b8b6-144cc9f07d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820e0d46-1d14-41ba-a140-0b877c461dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24d961c-84ed-4e01-b835-f65b452e3a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33715962-9a7f-46cb-a4a3-38dda5a5e7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message debbdc37-1ba5-4361-b3bb-2bffda64a023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082df77b-2a75-4f6e-b1bc-80146bc2c959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9348fba-a438-4370-b658-d2b58242c1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bcaa1f4-4d5b-4695-8f9f-8ce381f9eaa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed116853-ec94-46f0-a479-b24e54bd6669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db8a0cba-3681-460b-b420-949df95cd174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7caf69d1-3712-41d6-a00c-146dec3fb818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72a2aed-b9e9-4454-ab1a-cdaae1541e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37548dc9-711d-49b1-9312-88febe1927e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e45daff-1ce6-4a2f-9aa7-eef290ac6511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb9d5ff-db33-42d9-bb12-6935888430c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c8187b-7e41-40da-a161-8dc364572b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08050fb3-8e49-4f82-ac50-91a8c980d437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a8bdc5-0002-4b80-91b8-1f2e949eeb65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2f5bba-74af-4761-96e1-bade653c7a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d41307f-07cd-40ed-bad2-8caa1f962d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed35be2-cae4-4c51-bfc5-bdfdc8a00003
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_83
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_labels.txt

📊 Raw data loaded:
   Train: X=(559, 24), y=(559,)
   Test:  X=(140, 24), y=(140,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 550 samples, 5 features
   Test:  131 samples, 5 features
✅ Client client_83 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0973 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0773, val=0.0959 (↓), lr=0.001000
   • Epoch   3/100: train=0.0740, val=0.0956, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0725, val=0.0962, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0711, val=0.0965, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0648, val=0.0976, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 16 Summary - Client client_83
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0610
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0317
============================================================


============================================================
🔄 Round 17 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0863 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0847, val=0.0839 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0819, val=0.0828 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0806, val=0.0819 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0795, val=0.0813 (↓), lr=0.000250
   • Epoch  11/100: train=0.0761, val=0.0804, patience=3/15, lr=0.000250
   • Epoch  21/100: train=0.0721, val=0.0804, patience=6/15, lr=0.000250
   📉 Epoch 22: LR reduced 0.000250 → 0.000125
   📉 Epoch 30: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 17 Summary - Client client_83
   Epochs: 30/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0976
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0130
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0956, RMSE: 0.3092, MAE: 0.2568, R²: -0.0941

📊 Round 17 Test Metrics:
   Loss: 0.0970, RMSE: 0.3115, MAE: 0.2588, R²: -0.1108

📊 Round 17 Test Metrics:
   Loss: 0.1036, RMSE: 0.3218, MAE: 0.2690, R²: -0.1855

============================================================
🔄 Round 23 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0953, val=0.0785 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0914, val=0.0756 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0887, val=0.0739 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0870, val=0.0728 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0857, val=0.0720 (↓), lr=0.000063
   ✓ Epoch  11/100: train=0.0824, val=0.0694 (↓), lr=0.000063
   • Epoch  21/100: train=0.0797, val=0.0680, patience=5/15, lr=0.000063
   📉 Epoch 31: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0782, val=0.0681, patience=15/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 23 Summary - Client client_83
   Epochs: 31/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0585
   Val:   Loss=0.0682, RMSE=0.2612, R²=-0.0097
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.1038, RMSE: 0.3222, MAE: 0.2692, R²: -0.1883

============================================================
🔄 Round 24 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.1008 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0888, val=0.0985 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0872, val=0.0967 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0859, val=0.0954 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0849, val=0.0944 (↓), lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0815, val=0.0915, patience=1/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0799, val=0.0903, patience=5/15, lr=0.000008
   📉 Epoch 24: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0794, val=0.0900, patience=6/15, lr=0.000004
   📉 Epoch 32: LR reduced 0.000004 → 0.000002
   📉 Epoch 40: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 24 Summary - Client client_83
   Epochs: 40/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0126
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.1514
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.1025, RMSE: 0.3202, MAE: 0.2675, R²: -0.1738

============================================================
🔄 Round 26 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.1044 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.1043, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.1043, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.1042, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.1041, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0880, val=0.1038 (↓), lr=0.000001
   • Epoch  21/100: train=0.0875, val=0.1034, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0871, val=0.1030, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0868, val=0.1026, patience=5/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0865, val=0.1022 (↓), lr=0.000001
   • Epoch  61/100: train=0.0861, val=0.1019, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1022)

============================================================
📊 Round 26 Summary - Client client_83
   Epochs: 66/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.1073
   Val:   Loss=0.1022, RMSE=0.3198, R²=-0.0694
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.1010, RMSE: 0.3179, MAE: 0.2653, R²: -0.1568

============================================================
🔄 Round 27 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0924, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 27 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0931, RMSE=0.3051, R²=-0.1285
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0629
============================================================


============================================================
🔄 Round 28 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0974, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0883, val=0.0969, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0880, val=0.0965, patience=6/15, lr=0.000001
   • Epoch  41/100: train=0.0878, val=0.0961, patience=3/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0876, val=0.0957 (↓), lr=0.000001
   • Epoch  61/100: train=0.0874, val=0.0953, patience=10/15, lr=0.000001
   • Epoch  71/100: train=0.0872, val=0.0950, patience=7/15, lr=0.000001
   • Epoch  81/100: train=0.0870, val=0.0946, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0868, val=0.0942, patience=13/15, lr=0.000001

============================================================
📊 Round 28 Summary - Client client_83
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0703
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0958
============================================================


============================================================
🔄 Round 29 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0954, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0954, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0953, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0953, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0952, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0950, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 29 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0948, RMSE=0.3080, R²=-0.1286
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0050
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0999, RMSE: 0.3161, MAE: 0.2637, R²: -0.1438

============================================================
🔄 Round 30 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 30 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0806
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.1914
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0998, RMSE: 0.3159, MAE: 0.2636, R²: -0.1423

============================================================
🔄 Round 31 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 31 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=-0.1179
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0078
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0997, RMSE: 0.3157, MAE: 0.2635, R²: -0.1412

============================================================
🔄 Round 33 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 33 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=-0.1068
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0400
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0993, RMSE: 0.3151, MAE: 0.2631, R²: -0.1370

============================================================
🔄 Round 40 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 40 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.1055
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0253
============================================================


============================================================
🔄 Round 42 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 42 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.1048
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0443
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0994, RMSE: 0.3152, MAE: 0.2632, R²: -0.1377

============================================================
🔄 Round 45 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 45 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3039, R²=-0.1207
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0293
============================================================


============================================================
🔄 Round 47 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 47 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.1269
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0198
============================================================


============================================================
🔄 Round 48 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.1057 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.1056, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.1056, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.1056, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.1055, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.1054, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1057)

============================================================
📊 Round 48 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0728
   Val:   Loss=0.1057, RMSE=0.3250, R²=-0.1643
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0995, RMSE: 0.3154, MAE: 0.2634, R²: -0.1389

📊 Round 48 Test Metrics:
   Loss: 0.0995, RMSE: 0.3154, MAE: 0.2634, R²: -0.1388

📊 Round 48 Test Metrics:
   Loss: 0.0995, RMSE: 0.3155, MAE: 0.2635, R²: -0.1392

============================================================
🔄 Round 54 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0915, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0884, val=0.0912, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.0882, val=0.0909, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0880, val=0.0905, patience=11/15, lr=0.000001
   • Epoch  51/100: train=0.0878, val=0.0902, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 54 Summary - Client client_83
   Epochs: 60/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0392
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.2768
============================================================


============================================================
🔄 Round 55 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 55 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0889
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0990
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0996, RMSE: 0.3155, MAE: 0.2636, R²: -0.1398

📊 Round 55 Test Metrics:
   Loss: 0.0996, RMSE: 0.3156, MAE: 0.2637, R²: -0.1401

============================================================
🔄 Round 58 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 58 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0938
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0820
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0996, RMSE: 0.3156, MAE: 0.2637, R²: -0.1403

============================================================
🔄 Round 63 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 63 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3014, R²=-0.0919
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.1237
============================================================


============================================================
🔄 Round 64 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 64 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0887
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0938
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0994, RMSE: 0.3153, MAE: 0.2635, R²: -0.1384

📊 Round 64 Test Metrics:
   Loss: 0.0994, RMSE: 0.3153, MAE: 0.2634, R²: -0.1379

📊 Round 64 Test Metrics:
   Loss: 0.0994, RMSE: 0.3152, MAE: 0.2634, R²: -0.1377

📊 Round 64 Test Metrics:
   Loss: 0.0994, RMSE: 0.3153, MAE: 0.2635, R²: -0.1380

============================================================
🔄 Round 69 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 69 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0799
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.1390
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0995, RMSE: 0.3154, MAE: 0.2636, R²: -0.1386

============================================================
🔄 Round 72 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 72 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0714
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.1775
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0996, RMSE: 0.3155, MAE: 0.2637, R²: -0.1397

============================================================
🔄 Round 74 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 74 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0780
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.1497
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0996, RMSE: 0.3156, MAE: 0.2638, R²: -0.1399

============================================================
🔄 Round 76 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 76 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0812
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.1531
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0995, RMSE: 0.3155, MAE: 0.2637, R²: -0.1396

📊 Round 76 Test Metrics:
   Loss: 0.0995, RMSE: 0.3155, MAE: 0.2637, R²: -0.1392

============================================================
🔄 Round 79 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 79 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0872
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.1082
============================================================


============================================================
🔄 Round 80 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 80 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.1103
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0299
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0994, RMSE: 0.3153, MAE: 0.2636, R²: -0.1381

============================================================
🔄 Round 82 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 82 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3039, R²=-0.1055
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0170
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0993, RMSE: 0.3151, MAE: 0.2634, R²: -0.1368

============================================================
🔄 Round 84 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 84 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0866
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.1100
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0992, RMSE: 0.3150, MAE: 0.2633, R²: -0.1360

📊 Round 84 Test Metrics:
   Loss: 0.0992, RMSE: 0.3150, MAE: 0.2633, R²: -0.1360

📊 Round 84 Test Metrics:
   Loss: 0.0995, RMSE: 0.3155, MAE: 0.2638, R²: -0.1393

📊 Round 84 Test Metrics:
   Loss: 0.0996, RMSE: 0.3156, MAE: 0.2639, R²: -0.1401

📊 Round 84 Test Metrics:
   Loss: 0.0996, RMSE: 0.3157, MAE: 0.2640, R²: -0.1407

============================================================
🔄 Round 96 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 96 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.1078
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0453
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0996, RMSE: 0.3156, MAE: 0.2640, R²: -0.1402

============================================================
🔄 Round 99 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.1034 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.1034, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.1034, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1034, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1034, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.1032, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1034)

============================================================
📊 Round 99 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0917
   Val:   Loss=0.1034, RMSE=0.3216, R²=-0.0919
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0996, RMSE: 0.3156, MAE: 0.2639, R²: -0.1400

============================================================
🔄 Round 100 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 100 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.1044
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.1045
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0996, RMSE: 0.3155, MAE: 0.2639, R²: -0.1397

📊 Round 100 Test Metrics:
   Loss: 0.0995, RMSE: 0.3155, MAE: 0.2639, R²: -0.1396

📊 Round 100 Test Metrics:
   Loss: 0.0995, RMSE: 0.3155, MAE: 0.2639, R²: -0.1395

📊 Round 100 Test Metrics:
   Loss: 0.0996, RMSE: 0.3155, MAE: 0.2639, R²: -0.1397

============================================================
🔄 Round 106 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0933, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0932, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0932, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0932, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0930, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 106 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0934, RMSE=0.3057, R²=-0.1214
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0400
============================================================


============================================================
🔄 Round 109 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 109 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.1078
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0684
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0996, RMSE: 0.3157, MAE: 0.2641, R²: -0.1406

============================================================
🔄 Round 112 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 112 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0922
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0907
============================================================


============================================================
🔄 Round 115 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 115 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0729
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.1662
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0995, RMSE: 0.3155, MAE: 0.2639, R²: -0.1392

============================================================
🔄 Round 117 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 117 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0952
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0759
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0995, RMSE: 0.3154, MAE: 0.2639, R²: -0.1391

============================================================
🔄 Round 119 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 119 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0991
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0777
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0994, RMSE: 0.3152, MAE: 0.2637, R²: -0.1375

============================================================
🔄 Round 122 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.1041 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.1041, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.1040, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.1040, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.1040, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.1038, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1041)

============================================================
📊 Round 122 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0700
   Val:   Loss=0.1041, RMSE=0.3226, R²=-0.1601
============================================================


============================================================
🔄 Round 123 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 123 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.1070
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0231
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0993, RMSE: 0.3151, MAE: 0.2636, R²: -0.1367

============================================================
🔄 Round 124 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 124 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=-0.0948
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.1152
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0993, RMSE: 0.3150, MAE: 0.2636, R²: -0.1363

============================================================
🔄 Round 132 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 132 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3030, R²=-0.0982
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0491
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0992, RMSE: 0.3150, MAE: 0.2635, R²: -0.1357

📊 Round 132 Test Metrics:
   Loss: 0.0992, RMSE: 0.3149, MAE: 0.2635, R²: -0.1354

============================================================
🔄 Round 137 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 137 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0962
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0554
============================================================


============================================================
🔄 Round 139 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 139 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0972
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0597
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0991, RMSE: 0.3147, MAE: 0.2633, R²: -0.1340

📊 Round 139 Test Metrics:
   Loss: 0.0990, RMSE: 0.3147, MAE: 0.2633, R²: -0.1337

📊 Round 139 Test Metrics:
   Loss: 0.0991, RMSE: 0.3147, MAE: 0.2634, R²: -0.1340

============================================================
🔄 Round 145 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 145 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3029, R²=-0.1154
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0129
============================================================


============================================================
🔄 Round 146 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.1042 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.1042, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.1042, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.1042, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.1042, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.1042, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1042)

============================================================
📊 Round 146 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0885
   Val:   Loss=0.1042, RMSE=0.3227, R²=-0.1408
============================================================


============================================================
🔄 Round 147 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0927, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0926, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0926, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0924, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 147 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3045, R²=-0.0713
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.1753
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0990, RMSE: 0.3147, MAE: 0.2633, R²: -0.1338

📊 Round 147 Test Metrics:
   Loss: 0.0990, RMSE: 0.3146, MAE: 0.2633, R²: -0.1334

============================================================
🔄 Round 151 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0977, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0862, val=0.0974, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0860, val=0.0971, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 151 Summary - Client client_83
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0556
   Val:   Loss=0.0976, RMSE=0.3123, R²=-0.1887
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0990, RMSE: 0.3146, MAE: 0.2633, R²: -0.1332

📊 Round 151 Test Metrics:
   Loss: 0.0990, RMSE: 0.3146, MAE: 0.2633, R²: -0.1331

============================================================
🔄 Round 156 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0931, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0931, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0930, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0930, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0930, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0927, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 156 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0930, RMSE=0.3050, R²=-0.0982
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0301
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0990, RMSE: 0.3146, MAE: 0.2633, R²: -0.1329

============================================================
🔄 Round 158 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.1034 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.1034, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.1033, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.1033, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.1033, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.1031, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1034)

============================================================
📊 Round 158 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0488
   Val:   Loss=0.1034, RMSE=0.3215, R²=-0.2333
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0989, RMSE: 0.3145, MAE: 0.2632, R²: -0.1325

============================================================
🔄 Round 159 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 159 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0822
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.1009
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0989, RMSE: 0.3145, MAE: 0.2632, R²: -0.1321

============================================================
🔄 Round 162 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 162 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.1180
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0266
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0988, RMSE: 0.3143, MAE: 0.2631, R²: -0.1312

============================================================
🔄 Round 164 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 164 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=-0.1274
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0713
============================================================


============================================================
🔄 Round 165 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 165 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.1060
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0229
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0988, RMSE: 0.3144, MAE: 0.2631, R²: -0.1313

============================================================
🔄 Round 166 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 166 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0945
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0512
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0988, RMSE: 0.3144, MAE: 0.2631, R²: -0.1314

============================================================
🔄 Round 167 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 167 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0762
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.1225
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0989, RMSE: 0.3144, MAE: 0.2632, R²: -0.1317

============================================================
🔄 Round 169 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 169 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3039, R²=-0.1064
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0089
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0989, RMSE: 0.3145, MAE: 0.2632, R²: -0.1320

📊 Round 169 Test Metrics:
   Loss: 0.0989, RMSE: 0.3145, MAE: 0.2632, R²: -0.1323

============================================================
🔄 Round 171 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 171 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0796
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.1144
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0990, RMSE: 0.3146, MAE: 0.2633, R²: -0.1331

============================================================
🔄 Round 173 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 173 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=-0.0948
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0657
============================================================


============================================================
🔄 Round 175 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 175 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.1242
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0444
============================================================


============================================================
🔄 Round 176 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 176 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0564
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.2533
============================================================


============================================================
🔄 Round 177 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 177 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0693
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.1668
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0991, RMSE: 0.3148, MAE: 0.2635, R²: -0.1344

============================================================
🔄 Round 180 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 180 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0879
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.1139
============================================================


============================================================
🔄 Round 181 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0931, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0931, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0931, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0930, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0930, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 181 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3042, R²=-0.1133
   Val:   Loss=0.0750, RMSE=0.2740, R²=0.0241
============================================================


============================================================
🔄 Round 182 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 182 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=-0.0874
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.1089
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0992, RMSE: 0.3149, MAE: 0.2636, R²: -0.1351

📊 Round 182 Test Metrics:
   Loss: 0.0992, RMSE: 0.3149, MAE: 0.2637, R²: -0.1355

============================================================
🔄 Round 185 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.1027 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.1027, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1027, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1026, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.1026, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.1024, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1027)

============================================================
📊 Round 185 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0514
   Val:   Loss=0.1027, RMSE=0.3205, R²=-0.2932
============================================================


============================================================
🔄 Round 187 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0939, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0874, val=0.0936, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0872, val=0.0933, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 187 Summary - Client client_83
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0535
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.2129
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0992, RMSE: 0.3150, MAE: 0.2637, R²: -0.1356

📊 Round 187 Test Metrics:
   Loss: 0.0992, RMSE: 0.3150, MAE: 0.2637, R²: -0.1356

============================================================
🔄 Round 190 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 190 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.1152
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0103
============================================================


============================================================
🔄 Round 191 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 191 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.1181
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0203
============================================================


============================================================
🔄 Round 192 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 192 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.1096
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0090
============================================================


============================================================
🔄 Round 193 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 193 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0937
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0691
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0993, RMSE: 0.3151, MAE: 0.2639, R²: -0.1366

============================================================
🔄 Round 194 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.1052 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.1052, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.1051, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.1051, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.1051, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.1049, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1052)

============================================================
📊 Round 194 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0427
   Val:   Loss=0.1052, RMSE=0.3244, R²=-0.2708
============================================================


============================================================
🔄 Round 195 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0930, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0930, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0930, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0930, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0930, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0734, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0926, val=0.0730, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0924, val=0.0727, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 195 Summary - Client client_83
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3044, R²=-0.1058
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0125
============================================================


============================================================
🔄 Round 197 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 197 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.1208
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0188
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0994, RMSE: 0.3152, MAE: 0.2640, R²: -0.1375

============================================================
🔄 Round 200 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 200 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=-0.1140
   Val:   Loss=0.0796, RMSE=0.2820, R²=-0.0264
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0992, RMSE: 0.3150, MAE: 0.2637, R²: -0.1356

============================================================
🔄 Round 203 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 203 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0964
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0542
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0992, RMSE: 0.3149, MAE: 0.2637, R²: -0.1353

📊 Round 203 Test Metrics:
   Loss: 0.0991, RMSE: 0.3149, MAE: 0.2637, R²: -0.1350

📊 Round 203 Test Metrics:
   Loss: 0.0991, RMSE: 0.3148, MAE: 0.2636, R²: -0.1346

❌ Client client_83 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
