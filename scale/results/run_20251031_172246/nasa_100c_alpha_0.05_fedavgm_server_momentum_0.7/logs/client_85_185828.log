[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7ee9f63-42ff-445b-9bcf-97ef200bf5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6921760-ee7a-4891-9112-0e1908fbe829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95020895-883c-466d-a6a6-ca3024312dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ce4f5f-1f75-4986-8cff-ac7248667bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d654442-3202-4138-9c45-6a64607c7439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6be7987-418f-4a87-a001-9033a11736ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514c8055-18f1-435d-9f82-92bf2647c489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672d06c5-f99c-4e12-b3a1-2b00bc215135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c693fda8-63ff-4f9f-b02f-521e4ffafddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0be2c32-a493-4f87-9974-044872ee147a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0856f99a-0a98-4320-87fc-5cf608cc0d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53d2dec7-e5ad-483f-8042-cf782d943ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70512760-37ba-4d84-b2ea-a358b6fa28d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d7b32b7-348e-44f5-905b-18e0d41a0ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037d37ab-f318-4218-b4ca-8fb8541f3f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b032b34-1a84-484a-987f-954ae94de5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bfe107e-9bb8-4134-bea6-baa7fecea15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655a4b41-614f-44f8-aafc-a4f15956c145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 397e8685-d7db-46de-b624-4a4c3afda8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231023f9-0b2a-4ac7-ac8a-823c9146d5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b602d3f1-a842-45f7-ad36-e85e5a646a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5484b2a0-8c54-4606-9804-cea4fad29d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f328cb2-c47f-4dc9-bfb8-195742d7093e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33797145-fa30-4235-9963-4bf3cfd5f98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22acd24c-9175-45fa-8f5c-0b7e9ff99fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c34bbf-d849-4526-9a50-2741092d686b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e1c353-1b5f-48f1-8367-d084630c4867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf266bf-20d2-478d-b2c0-2949f23f3d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09894b9e-75d9-489e-be62-81a8994e7b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc51707-433d-4d14-a53a-4f125e6586a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87191c3-10de-4626-aff0-86c1fb4e79ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1a0fb7-80c8-4b49-ae92-88a25f5bb733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67c15f6d-29a4-4f5a-b5e8-a6bcab863995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff23b75-a964-4153-b436-8dfe284aee5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ecc496-2ddd-408b-9597-3e56015ad7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa8421e-6235-459b-a92c-9fba3cfef5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3469b6c-79f7-4dcc-b863-dfb6d20679ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eacfa452-b728-4f67-b6b5-8e61f76d1f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26e45345-48ce-441d-a076-d90ef53ceaf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3caced7-37fb-449c-a67c-fdaf3f63a96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79559b9-64e8-4725-9723-9465278b7458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b30bc68f-3341-4225-8ff8-5d665dc116a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e850914-8ce5-4ae4-a250-1590be633b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69bba7dd-3036-4b3d-840b-4b59e1cc7506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 153f08ae-1806-49a2-a36d-5d160b436936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e06dd4-79e7-45a1-8143-6bafbbcfad04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31df457b-b940-448b-97fa-39788b00d3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c21aa0-10cf-4b9d-be49-7b62a62df839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2db65b-9abd-40a7-bff4-6258c6c39f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c97b2df-a020-4e8f-ae02-5b4cce390d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a91b3ca-70df-4dd9-be2c-4cc3dcf8d81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8481d6ad-1ca7-412a-970c-e511d61e5fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a901ba-2575-4e7f-ae8c-dd09a328e6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bff341a-ef41-44d9-b4bd-33eff774160b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f6a2d8-6221-4de4-b606-dbb5f29178b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12938578-0dc5-4d1c-b3b2-99a084f8f947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b75685d6-59e8-47e1-b2d6-00961a83b7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b534208-3910-4aa3-abdf-b70b6d1ba9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa19e41d-672b-4689-95be-296570b75778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc6a76a-4993-44b6-8c1f-92045c71949d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ab44b4-21a5-42ca-8e1f-6115d039e5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b4e8b4-1137-4dbc-b5fe-fc52c9d41301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28d3cc89-52da-414a-9dcb-2376e8dace2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb312363-2f07-4b3c-9eab-812c71faaab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc2b385b-6eba-403a-84d8-dba45b07632e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0103eb-8887-47d0-bc38-f221e0404579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e8712b-b27a-4e85-8bc3-1d9c37080d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720ff77b-6d3c-47ba-9264-7e6c588da354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c5c5e72-dc0f-40b5-86a0-f2d25d065f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d68d6fd-5855-4136-80c4-1fdd677fad35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc0ecca-6f59-4923-8dbd-1ee9339d84f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c711c43a-ee42-46e2-9c4e-0ac74f6f4b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbeaf2f9-ab47-4768-8412-04bb11545601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c7338e0-5a57-4b14-a8bb-dfc09b8aab9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2aef006-34f7-425f-9543-6f18bb6af0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5bfef8e-5c72-4ec8-bc65-b736c6185859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063b4ff7-88ac-412e-8840-4fd23e58cd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c185077-1d8b-4a88-8a70-31641af02c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79cfdefc-0473-4a94-92be-3d66d687dd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e56b4d9-2944-44d0-a547-62fa3ffc0139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39a97b75-dba5-4c0a-a25a-032c326f1146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6dd8ded-4b61-4edb-a684-e000169314f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 809d6e03-e159-4b9a-a6bc-b2ca3fc4bf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448844e1-bf27-4638-bfe2-ea93bbf77030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6a92b37-7956-4cea-801d-0fde3119c353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea064db4-f364-4e59-a832-04fa54f4e851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e870ed2-eb5f-47da-9c6b-059f05acbf9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1c0f8f-9e08-4c31-b325-b463e04ea84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e180a8e1-c1e2-4497-a8ac-57c46ddf7435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 711d8450-85e8-4e0d-b68c-822b637fb591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3945d71-b9ae-4e34-a0b7-c24cfb451a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aaebe99-2f4e-479f-bb42-ae20a77d9ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad6d9fc-62ea-48a6-a55d-9974d47f797b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9052b79a-3c90-42c0-b424-bf03fd115a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631b7648-3b06-4b27-bc2a-3d37b5ad8ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af8ffd7-a79b-4e79-be0e-dab86720e114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8813bb26-f7ad-42b8-ab66-4eee4df1a39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a51904-8724-4878-8225-44126a3b891f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceed7023-1dd7-4b6e-a37a-3a2c812ce3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01c2aba-fdfb-4419-9cf9-3443d688064c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3093e332-f188-4775-9e78-a90796163e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e7ea5ed-6b96-49cb-9ace-7a7fad8da25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e81025a5-7a3f-47c3-960f-7f65317bcd24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f20dd0-d36d-4ba5-9847-b75215671c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0b82e9-e89a-42ee-9dba-fd0949b4c911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5977888-c424-4c9f-a98b-1958b601fc70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c59d04a3-2a78-4510-b4b2-75eb6f09e5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8192b8e-2196-4885-89a7-0d07574a870b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d54726f-0058-4b12-a1fd-fc2162bf83fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28429f94-780c-4041-aff3-c7bc27901ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37bf7ff3-32d5-4444-b62d-49f0a6ce7007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f24a146-8b0d-43ea-b40e-6441a3f55cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61540408-13aa-4fc4-9028-6a107a4cbb69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e1d84ee-46ca-4fa1-82dc-f6b73b886ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee075a5-1b91-4d22-9232-00490cfc6c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ddd1903-091e-4340-930f-e754416e788b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb987791-1695-42eb-9d16-85d8b515b1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42bcda7-9f9d-4e93-baa6-daa89a5872ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a0aaad-f5de-45e6-818f-f54e041b3ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40c9108-dc26-4113-9537-4dc87c2fb2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa80803f-5588-43db-8b76-0084bcc4ae17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba2d5cd5-bcc3-4db2-8ded-3face846a4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76af5d39-70e4-488b-b9f2-891d4686f629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d56bfa-697e-4d61-b043-f3b5e4b4285e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71369cce-c327-45fc-a156-03104a3a8e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2866f77-5ec6-40e1-b3f0-67a9ec0b45f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e65b795-27be-42d2-adca-efceaefae0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b4d93a-d455-4c27-af0f-28e9f654fcb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b45e6f21-9aa5-485b-8bec-8447fa228ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d91777-df5d-4af9-8679-9960f1a5eb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c30746-276f-4425-9fcc-4950fec634f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48429c88-4f54-422d-9041-29aa6306a1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15ea294-955d-4c40-b142-166954794bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b43d9a6-17fc-4916-8008-9edd39085b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de395c17-be01-47e8-af56-97338df87878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 190a43aa-c126-4b47-924a-1e0ced636ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c27c465-b1cf-4e98-8168-252a2d727f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a24b4d-b716-4a7c-a652-c2596e67d8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a410e3f7-be03-4701-a11e-45a30cf4a1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eba0821c-91a4-4e58-8fbd-135776c7f028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5ab8f4-6f61-44b7-80aa-0e2b597d5b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c7e49c-d98a-4e46-a5b4-1e66395feb03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1300026a-101a-4bf0-89e1-5081b353d622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd2a1def-4a81-4fb1-8848-3e8427f92dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7452e435-43e5-47f5-acc6-7f586ed4cc1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bdf70cc-1a83-411a-b451-648f1825795c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_85
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_labels.txt

📊 Raw data loaded:
   Train: X=(1160, 24), y=(1160,)
   Test:  X=(291, 24), y=(291,)

⚠️  Limiting training data: 1160 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  282 samples, 5 features
✅ Client client_85 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2429, R²: 0.0105

📊 Round 0 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2433, R²: 0.0062

============================================================
🔄 Round 19 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0708 (↓), lr=0.001000
   • Epoch   2/100: train=0.0744, val=0.0712, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0721, val=0.0710, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0706, val=0.0717, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0696, val=0.0720, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0638, val=0.0728, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 19 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.1048
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.1001
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2428, R²: 0.0115

============================================================
🔄 Round 20 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0754 (↓), lr=0.000250
   • Epoch   2/100: train=0.0761, val=0.0754, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0752, val=0.0744 (↓), lr=0.000250
   • Epoch   4/100: train=0.0743, val=0.0739, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0737, val=0.0737 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0710, val=0.0732, patience=2/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0686, val=0.0732, patience=12/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 20 Summary - Client client_85
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1284
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.1116
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2413, R²: 0.0268

============================================================
🔄 Round 22 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0836 (↓), lr=0.000031
   • Epoch   2/100: train=0.0738, val=0.0833, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0736, val=0.0830 (↓), lr=0.000031
   • Epoch   4/100: train=0.0735, val=0.0828, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0733, val=0.0825, patience=2/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0729, val=0.0818, patience=5/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0725, val=0.0812 (↓), lr=0.000008
   📉 Epoch 23: LR reduced 0.000008 → 0.000004
   📉 Epoch 31: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0723, val=0.0811, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 22 Summary - Client client_85
   Epochs: 36/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0724, RMSE=0.2692, R²=0.0877
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.1154
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2409, R²: 0.0302

============================================================
🔄 Round 28 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0708 (↓), lr=0.000002
   • Epoch   2/100: train=0.0791, val=0.0708, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0791, val=0.0708, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0791, val=0.0708, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0791, val=0.0708, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0790, val=0.0707, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 28 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0499
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0811
============================================================


============================================================
🔄 Round 30 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0788 (↓), lr=0.000002
   • Epoch   2/100: train=0.0772, val=0.0788, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0772, val=0.0788, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0772, val=0.0788, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0772, val=0.0788, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0771, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 30 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0522
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0573
============================================================


============================================================
🔄 Round 31 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 31 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0507
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0591
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2419, R²: 0.0243

📊 Round 31 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2419, R²: 0.0244

📊 Round 31 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2419, R²: 0.0244

📊 Round 31 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0245

============================================================
🔄 Round 36 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 36 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0509
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0433
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0246

📊 Round 36 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0246

============================================================
🔄 Round 39 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 39 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0509
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0484
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0247

📊 Round 39 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0248

============================================================
🔄 Round 41 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 41 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0465
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0661
============================================================


============================================================
🔄 Round 44 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 44 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0467
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0674
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0251

============================================================
🔄 Round 47 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 47 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0453
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0656
============================================================


============================================================
🔄 Round 48 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 48 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0460
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0757
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0252

============================================================
🔄 Round 52 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 52 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0536
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0299
============================================================


============================================================
🔄 Round 53 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 53 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0489
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0598
============================================================


============================================================
🔄 Round 54 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 54 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0461
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0645
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0253

📊 Round 54 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0254

📊 Round 54 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0255

📊 Round 54 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0255

============================================================
🔄 Round 61 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 61 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0471
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0678
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0254

============================================================
🔄 Round 63 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 63 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0545
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0282
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0253

============================================================
🔄 Round 65 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 65 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0437
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.0861
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2420, R²: 0.0252

============================================================
🔄 Round 67 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 67 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0483
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0602
============================================================


============================================================
🔄 Round 68 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 68 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0544
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0381
============================================================


============================================================
🔄 Round 69 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 69 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0480
   Val:   Loss=0.0672, RMSE=0.2591, R²=0.0649
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: 0.0252

📊 Round 69 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: 0.0252

📊 Round 69 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: 0.0253

============================================================
🔄 Round 74 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 74 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0453
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0721
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: 0.0254

============================================================
🔄 Round 75 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 75 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0515
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0214
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: 0.0254

📊 Round 75 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2421, R²: 0.0253

============================================================
🔄 Round 78 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 78 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0397
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0953
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: 0.0249

============================================================
🔄 Round 83 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 83 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0523
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0426
============================================================


============================================================
🔄 Round 84 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 84 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0439
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0767
============================================================


============================================================
🔄 Round 85 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 85 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0530
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0410
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: 0.0248

============================================================
🔄 Round 87 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 87 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0534
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0222
============================================================


============================================================
🔄 Round 88 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 88 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0536
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0165
============================================================


============================================================
🔄 Round 90 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 90 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0490
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0580
============================================================


============================================================
🔄 Round 92 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 92 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0537
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0373
============================================================


============================================================
🔄 Round 93 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 93 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0534
   Val:   Loss=0.0663, RMSE=0.2574, R²=0.0386
============================================================


============================================================
🔄 Round 94 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 94 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0524
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0436
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0250

============================================================
🔄 Round 103 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 103 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0544
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0352
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0250

============================================================
🔄 Round 105 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 105 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0512
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0403
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0250

============================================================
🔄 Round 109 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 109 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0446
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0555
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0250

📊 Round 109 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0249

============================================================
🔄 Round 114 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 114 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0556
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0286
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0248

📊 Round 114 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0248

============================================================
🔄 Round 116 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 116 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0515
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0444
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0248

============================================================
🔄 Round 117 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 117 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0506
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0486
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2422, R²: 0.0247

============================================================
🔄 Round 120 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 120 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0451
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0706
============================================================


============================================================
🔄 Round 122 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 122 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0500
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0512
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0243

============================================================
🔄 Round 125 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 125 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0474
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0521
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0243

📊 Round 125 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0243

📊 Round 125 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0243

============================================================
🔄 Round 129 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 129 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0489
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0528
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0243

📊 Round 129 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0242

============================================================
🔄 Round 134 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 134 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0445
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0650
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0242

============================================================
🔄 Round 136 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 136 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0503
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0492
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0241

============================================================
🔄 Round 138 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 138 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0522
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0310
============================================================


============================================================
🔄 Round 142 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 142 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0513
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0424
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0241

📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0242

📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0242

📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0242

📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0242

============================================================
🔄 Round 155 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 155 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0530
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0221
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: 0.0241

============================================================
🔄 Round 157 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 157 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0456
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0565
============================================================


============================================================
🔄 Round 158 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 158 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0547
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0264
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0241

============================================================
🔄 Round 159 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 159 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0436
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0673
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0241

============================================================
🔄 Round 160 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 160 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0511
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0426
============================================================


============================================================
🔄 Round 162 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 162 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0473
   Val:   Loss=0.0734, RMSE=0.2708, R²=0.0509
============================================================


============================================================
🔄 Round 164 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 164 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0482
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0514
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0240

📊 Round 164 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0241

============================================================
🔄 Round 170 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 170 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0542
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0255
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0241

============================================================
🔄 Round 171 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 171 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0557
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0222
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0242

============================================================
🔄 Round 175 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 175 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0495
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0396
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0242

============================================================
🔄 Round 178 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 178 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0512
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0246
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0242

📊 Round 178 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0242

📊 Round 178 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

============================================================
🔄 Round 183 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 183 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0535
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0216
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

============================================================
🔄 Round 184 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 184 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0473
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0503
============================================================


============================================================
🔄 Round 186 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 186 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0531
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0326
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

============================================================
🔄 Round 188 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 188 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0493
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0464
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

📊 Round 188 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

📊 Round 188 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

📊 Round 188 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0244

============================================================
🔄 Round 194 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 194 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0492
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0508
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

============================================================
🔄 Round 198 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 198 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0425
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0751
============================================================


============================================================
🔄 Round 199 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 199 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0472
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0548
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0244

📊 Round 199 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0243

============================================================
🔄 Round 201 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 201 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0505
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0453
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0242

============================================================
🔄 Round 204 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 204 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0416
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0809
============================================================


============================================================
🔄 Round 205 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 205 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0482
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0546
============================================================


============================================================
🔄 Round 206 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 206 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0453
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0495
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0241

📊 Round 206 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0241

📊 Round 206 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: 0.0241

============================================================
🔄 Round 210 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 210 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0521
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0360
============================================================


❌ Client client_85 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
