[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddccff6a-f380-42ce-9dee-f632a61c351c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1075e102-6a85-42ee-845b-6cd597c5f8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94e012a7-a9fd-41d2-83ea-70d8af5cc881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13a7c0cc-0086-47ff-9049-d3ff9fb72c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823c95f7-7d7c-4489-a605-f2836f650667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 909175e2-599e-4eca-bc8a-4cb8e66d1b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a17bcf36-8c90-4fab-81bc-0972648ba5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 242b8366-d6a1-4c75-b812-b0d42a100661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16ff340f-81d1-4f50-b2d2-f5b70dfdec80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6434e8fd-09a5-4266-81a3-6d321106a245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5c9563-b5e7-4eec-84bf-43684619a5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c379910-5a7b-44f8-887e-3dc1f2742b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7907ac54-88a5-4d27-bf79-aac26c330620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9128a1d3-6a25-4e1a-80ce-eb5b0657ebc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a544c9-8b82-446b-8b98-3bcdaf0d7aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36271e25-3b3a-428b-a6d6-0ef382a5a83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edec78db-b331-41b3-a1c6-c4a9d4fd8027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 639d3b2b-1752-4b5a-a2d6-d248580a1632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc0e094d-d1df-4256-943e-c23672b726b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb2081e-f3bb-4e89-b9a8-fbfb059816c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a572868-6302-45f7-b645-037d57e0eb80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06714db-b073-4266-87f8-6e069df01171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ba0be9-410a-406b-864e-afad78155a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b94d81b7-6e25-48bf-8f53-e792be9dd034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20bbb1d5-b547-4f28-bc06-f4e4cd91d367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99fe534d-4a8d-4849-bce7-5592b1e40228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2386b46-56da-4f88-b8c1-d4dbd1c9fad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd5f1c01-9308-433a-bd46-e2d772750246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd078fec-6c46-4802-987c-c97e3b443138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b9f070a-98a3-45a5-806d-2c154343ac31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f3419d-464d-4398-b064-b4ae25674110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b6141c-e1fa-434d-8123-3ea6d729d1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b232811f-b76a-4707-b431-cda9d99afae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25cd646a-97f7-4208-a65e-ba5ad3260ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbad5e04-fdf6-4ab5-898f-fe2dadf871c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e166af4f-dd96-4964-8a76-fa7dd18b0628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07de0049-bcaf-4268-a459-014fe16f6453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05746001-5d18-4ead-bec2-7c0ed98a5da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcfd4dff-d397-43c3-88f8-112601a07e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56326b89-2523-4252-accc-29ff67947df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b6f2f2-210f-47b7-b447-8eca5eefaa66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1682f0-bc1f-45f8-ae54-96dcce056f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b31531-52da-4e3e-8f96-13d5b0b4323b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6553f4f-8fbf-4965-8619-dca558af330b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94a526d2-3d87-483d-9487-36d30c608f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fcf8906-02ec-426f-a6de-e494a03754db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61cb63b0-96e0-478e-831f-54399050813c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b942e24-036c-4d41-9ece-ce8b04f49979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ca60c8-a2c7-47f7-98b2-f25d3887f986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c64d85-44af-4f27-bd34-d396f056fd47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a37681-529e-4baf-b582-6790c72931a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 366ff89e-b1c6-4c40-8d87-4d4450cf9a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72af9533-cd90-4c5f-bd58-9481ef7bf30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b722fe64-db08-4063-9a9c-0dd7270d4c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ace8797-9912-4875-bc82-3a755fc1fe48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50192fac-0212-43ee-a9f0-bed5f36229b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca91f39f-976c-4440-b23a-abe1555ece19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06baa9b1-b1c7-4d36-a73d-0de97850873b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad8506d-35a5-49a0-bf51-1e673f101738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c2aeaa-63b5-4e24-b34c-84f06522eac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a9f51b3-c0ee-4e96-8b7a-1d49f8038298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74305a5e-6ae8-43e8-ad94-598494b64460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b0fa38-2d38-4849-b27d-3e308102c7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6437fd-5e3d-41ca-abd0-a9a33a38ef5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce78be10-ea9c-4c89-b64d-aa75a5eab6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69076899-a850-48f7-8544-249a668ba84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63eb4b3f-ace0-4fd8-acb7-ecc8b2dfaf5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce03c5fb-ca65-4437-9188-e56c9d23cddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db450618-b73c-4371-9658-957e4d36ec57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df184bc-994f-44b2-a10e-b4f4b9dcc2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4cd7a3a-b6f1-40b3-a649-c4aa29fed2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e61b588-9720-49f4-b626-73d833d9a2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbebeeee-23b4-4837-b478-6496f8aa88e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f006b9b4-e5a3-49ed-8349-8db71d43173a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c515e4b1-592c-4723-9820-6ea9466611e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b5acc0-756a-481f-891e-50e9e6f44bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932fdfcf-0ad7-4efb-b9b1-87da7b2726a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2378e0db-dfa7-4973-9411-a10a0710f122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68741f60-f96e-42ef-ba6b-2c2157688da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f8cf5e-2ab1-4b43-8517-0b1ee4438ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37cd6038-ea90-4ca2-b3fb-7e8fc316c9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d93f67a-60e4-4803-8c8a-ecf52ee545f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e9a6de-0cab-442e-af29-f18b05459068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 419de6ba-70fb-4fb9-8748-85b34f53c03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d71d1d8f-bba2-4119-89eb-c46a5b62811a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843aafa1-9441-4a64-87fd-cd93f47e2568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d994da29-0d21-4964-88a0-832b935806d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 998b9564-7a43-48e4-b6cc-c73fd5448ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 929cfdf1-b35a-4c6f-89d6-e79f242bedd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b5ae551-27d7-47f5-8551-924b1e83abec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f28be646-9a27-4eb4-8829-52eced6dcaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90bf90b5-107c-42bf-920d-9f0b13b6dce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ad484c-3c97-4358-b4a8-9f01605ff3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cbd51c2-50dc-4634-bd1b-3d67011193e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb1187c-3274-4b5d-a5fd-8d2d753bb804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22d85bdf-f160-41cc-b17a-026b8abd82f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed034f95-1249-4830-a586-db3684b3decb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0512ec9-4566-460d-81bf-efa003a22a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c617403-48a5-47bd-8bea-41ef0d6c9279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9455d93e-37c9-4d4e-b619-625fb101a809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c82eec-42e1-4a3c-9da0-de90540ef8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15bdb942-6a2a-4e3d-a181-e17ec29912b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a4a3d8-f602-4de4-9873-f1bad9825c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ba3ff9-975f-4f55-b8f8-c49522b59198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8fca30e-be13-49dc-aab5-4fbccfd8329a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c19056-efdd-493f-9e8b-376d1e210af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57fbcb7a-34a0-4d98-9faf-68592015db40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a41bfd-1675-4dc0-b97a-1c12d39c27ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 072464dd-1b88-4c5b-8654-379722309674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad36bba-96db-4b89-80c3-e30ff4f545f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 181aafef-076f-4152-9c82-d3a1e9c5c994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d4ad6d-ce46-41a9-becf-b744d379f939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c83c132-1c79-41a5-adfe-e6584dcd8ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c720d2-47d3-4073-bfc1-71249bf9e417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d13f2ca6-8b55-4241-8527-a68062a32962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97cd1734-ffd3-4ad9-a134-43b44ad75d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf196ab8-e052-4f88-973e-279e027f9242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e5acedf-d2ef-45dc-a2d3-7eed55705ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bea7f2-d165-4c70-b85e-e08187e81760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed93005b-8b5c-442a-967c-156cd3a12e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75fbeec4-f084-428d-8ea8-943ac7d46168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772003e2-e67e-4fe3-9353-39c93cfb7713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4900734f-203f-4691-9559-b40d6daec684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c66743-13ac-4dfa-8d15-d5b583a5f929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950e98b0-218e-41ff-acae-751483accbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac3de6c-e092-4ab1-a949-62d501e3566c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb67e63c-5bf6-441f-bcaa-d19eca6788a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4266593-beb1-4cf5-9e98-6258de3f8000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3980b00e-6864-49c0-b5aa-78d411c5cdc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 833a9072-ab63-46d4-9364-5ef6bab92ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 390998d3-b1c4-408f-b019-3f0f3ff75164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb862c7-97da-4068-aaed-ac9d9b8f9a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94fa6c4-d607-4e42-b0e7-fe50ef2d4fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f4c8a6-f48f-499c-9557-293bffdd57be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c366c26-0c86-4444-accf-0100db8957d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccd86994-f45b-4020-8ca6-73d1f1f8cdff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c892e58-281a-485a-9189-5c1406eb8e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10382772-8811-4daf-96a9-16ffb6fe3d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cd6e39d-efce-4fdb-b5fe-525016d07428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064b7fc5-434b-4c28-9a10-b9cea60fda58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55655ef8-fb18-4506-b066-e2a21e5002bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10103927-92ba-4b64-8d72-a23ff53fe0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb94f02e-9b55-4423-ad13-6a65e4cffa68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4030cfb9-710b-4b9e-8554-387049ffaba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f537d8-0424-4237-b995-240b6b12fffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf6ea89-bfd0-4da8-b5c4-1a88d4074176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d7a30f-7f6f-4a8f-9415-a0cef932ec1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d730e2a-3176-4692-97f4-1d64d5b61498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a5c057-aea9-4017-9ffc-a3ba1da3d1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b26951-675d-4fdb-a327-3c08038d0ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ecf84d-98f7-4810-957b-5ce46f42b887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e948b8-2271-4d4b-bde9-30a1f5c22e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e990e4-dde2-4672-90f2-6dd17b0367f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e1bb92-c573-45e1-8aa1-063c30424715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa67695a-0671-45f9-9654-349dbbf09802
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_86
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_labels.txt

📊 Raw data loaded:
   Train: X=(698, 24), y=(698,)
   Test:  X=(175, 24), y=(175,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 689 samples, 5 features
   Test:  166 samples, 5 features
✅ Client client_86 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0030

📊 Round 0 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2541, R²: -0.0219

============================================================
🔄 Round 18 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0860 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0867, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0802, val=0.0870, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0795, val=0.0866, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0788, val=0.0865, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0725, val=0.0860, patience=10/15, lr=0.001000
   📉 Epoch 16: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 18 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0132
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0284
============================================================


============================================================
🔄 Round 19 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0713 (↓), lr=0.000500
   • Epoch   2/100: train=0.0859, val=0.0715, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0850, val=0.0714, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0845, val=0.0714, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0840, val=0.0715, patience=4/15, lr=0.000500
   📉 Epoch 8: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0815, val=0.0718, patience=10/15, lr=0.000250
   📉 Epoch 16: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 19 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0002
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0135
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2539, R²: -0.0197

============================================================
🔄 Round 21 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0883 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0818, val=0.0877 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0812, val=0.0871 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0806, val=0.0866 (↓), lr=0.000125
   • Epoch   5/100: train=0.0803, val=0.0862, patience=1/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0790, val=0.0850, patience=3/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0783, val=0.0844, patience=7/15, lr=0.000031
   📉 Epoch 24: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 21 Summary - Client client_86
   Epochs: 29/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0310
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0014
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2493, R²: 0.0120

============================================================
🔄 Round 24 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0837 (↓), lr=0.000016
   • Epoch   2/100: train=0.0833, val=0.0832, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   ✓ Epoch   3/100: train=0.0831, val=0.0829 (↓), lr=0.000008
   • Epoch   4/100: train=0.0829, val=0.0828, patience=1/15, lr=0.000008
   • Epoch   5/100: train=0.0828, val=0.0827, patience=2/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0824, val=0.0823, patience=2/15, lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0821, val=0.0821, patience=12/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 24 Summary - Client client_86
   Epochs: 24/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0032
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0645
============================================================


============================================================
🔄 Round 25 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0853 (↓), lr=0.000002
   • Epoch   2/100: train=0.0829, val=0.0853, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0829, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 25 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0218
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0003
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2521, R²: -0.0030

============================================================
🔄 Round 32 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 32 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0014
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0280
============================================================


============================================================
🔄 Round 33 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 33 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0135
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0215
============================================================


============================================================
🔄 Round 34 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 34 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0039
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0113
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0029

============================================================
🔄 Round 35 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 35 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0052
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0042
============================================================


============================================================
🔄 Round 36 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 36 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0017
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0173
============================================================


============================================================
🔄 Round 37 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 37 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0029
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0113
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2521, R²: -0.0027

📊 Round 37 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2521, R²: -0.0026

============================================================
🔄 Round 39 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 39 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0070
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0051
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2521, R²: -0.0025

============================================================
🔄 Round 40 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 40 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0006
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0346
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0024

============================================================
🔄 Round 42 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 42 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0127
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0094
============================================================


============================================================
🔄 Round 43 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 43 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0048
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0059
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0022

============================================================
🔄 Round 44 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 44 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0045
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0421
============================================================


============================================================
🔄 Round 46 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 46 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0003
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0246
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0020

============================================================
🔄 Round 48 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 48 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0010
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0170
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0019

📊 Round 48 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0019

============================================================
🔄 Round 50 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 50 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0048
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0240
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0019

📊 Round 50 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0018

📊 Round 50 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0018

📊 Round 50 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0017

📊 Round 50 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0017

============================================================
🔄 Round 57 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 57 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0018
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0847
============================================================


============================================================
🔄 Round 59 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 59 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0053
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0506
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0015

============================================================
🔄 Round 64 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 64 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0016
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0121
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0017

============================================================
🔄 Round 66 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 66 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0075
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0105
============================================================


============================================================
🔄 Round 68 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 68 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0129
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0316
============================================================


============================================================
🔄 Round 70 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 70 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0095
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0122
============================================================


============================================================
🔄 Round 71 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 71 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0040
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0037
============================================================


============================================================
🔄 Round 72 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 72 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0070
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0371
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0017

============================================================
🔄 Round 76 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 76 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0008
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0208
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0015

============================================================
🔄 Round 77 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 77 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0141
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0378
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0016

============================================================
🔄 Round 78 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 78 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0080
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0152
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0016

📊 Round 78 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0016

============================================================
🔄 Round 81 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 81 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0100
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0226
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0017

============================================================
🔄 Round 82 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 82 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0069
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0116
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0018

📊 Round 82 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0018

============================================================
🔄 Round 86 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 86 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0014
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0102
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0019

📊 Round 86 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0018

============================================================
🔄 Round 90 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 90 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0108
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0673
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0017

📊 Round 90 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2519, R²: -0.0017

📊 Round 90 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0016

📊 Round 90 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0016

📊 Round 90 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0015

============================================================
🔄 Round 99 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 99 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0075
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0144
============================================================


============================================================
🔄 Round 101 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 101 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0072
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0039
============================================================


============================================================
🔄 Round 103 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 103 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0098
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0203
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0015

📊 Round 103 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0016

============================================================
🔄 Round 106 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 106 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0109
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0270
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0015

📊 Round 106 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0015

============================================================
🔄 Round 108 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 108 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0100
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0205
============================================================


============================================================
🔄 Round 109 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 109 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0057
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0122
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0016

============================================================
🔄 Round 111 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 111 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0027
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0061
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0017

📊 Round 111 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0017

============================================================
🔄 Round 113 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 113 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0069
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0108
============================================================


============================================================
🔄 Round 114 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 114 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0051
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0378
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2519, R²: -0.0018

============================================================
🔄 Round 116 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 116 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0121
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0925
============================================================


============================================================
🔄 Round 117 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 117 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0066
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0216
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0020

============================================================
🔄 Round 121 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 121 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0061
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0129
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0023

📊 Round 121 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0024

============================================================
🔄 Round 125 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 125 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0098
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0510
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0025

============================================================
🔄 Round 127 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 127 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0054
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0089
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0025

============================================================
🔄 Round 130 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 130 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0024
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0190
============================================================


============================================================
🔄 Round 132 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 132 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0068
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0420
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0024

============================================================
🔄 Round 136 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 136 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0058
   Val:   Loss=0.0964, RMSE=0.3106, R²=-0.0621
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0025

============================================================
🔄 Round 140 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 140 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0096
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0288
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0025

============================================================
🔄 Round 142 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 142 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0025
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0013
============================================================


============================================================
🔄 Round 143 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 143 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0045
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0098
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2520, R²: -0.0023

📊 Round 143 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0023

============================================================
🔄 Round 146 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 146 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0070
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0192
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0022

============================================================
🔄 Round 150 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 150 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0093
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0248
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0022

============================================================
🔄 Round 151 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 151 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0005
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0155
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0022

📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0022

📊 Round 151 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0021

============================================================
🔄 Round 157 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 157 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0078
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0188
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0021

============================================================
🔄 Round 159 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 159 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0026
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0021
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0020

📊 Round 159 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0020

📊 Round 159 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0021

============================================================
🔄 Round 164 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 164 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0036
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0082
============================================================


============================================================
🔄 Round 166 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 166 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0033
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0059
============================================================


============================================================
🔄 Round 167 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 167 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0087
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0284
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0020

============================================================
🔄 Round 168 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 168 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0048
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0230
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0020

============================================================
🔄 Round 172 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 172 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0107
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0324
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

============================================================
🔄 Round 173 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 173 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0011
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0096
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

============================================================
🔄 Round 174 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 174 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0067
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0162
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

📊 Round 174 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

============================================================
🔄 Round 178 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.1001 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.1001, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.1001, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.1001, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.1001, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.1000, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1001)

============================================================
📊 Round 178 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0075
   Val:   Loss=0.1001, RMSE=0.3164, R²=-0.0310
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

============================================================
🔄 Round 180 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 180 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0040
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0248
============================================================


============================================================
🔄 Round 181 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 181 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0053
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0410
============================================================


============================================================
🔄 Round 184 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 184 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0086
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0073
============================================================


============================================================
🔄 Round 185 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 185 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0051
   Val:   Loss=0.0715, RMSE=0.2675, R²=-0.0086
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0018

============================================================
🔄 Round 189 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 189 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0069
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0210
============================================================


============================================================
🔄 Round 191 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 191 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0107
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0583
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0018

============================================================
🔄 Round 198 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 198 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0090
   Val:   Loss=0.0974, RMSE=0.3120, R²=0.0165
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0017

============================================================
🔄 Round 200 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 200 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0073
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0119
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

============================================================
🔄 Round 205 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 205 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0038
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0157
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2518, R²: -0.0020

============================================================
🔄 Round 207 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 207 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0017
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0052
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

📊 Round 207 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2518, R²: -0.0019

============================================================
🔄 Round 211 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 211 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0003
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0138
============================================================


❌ Client client_86 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
