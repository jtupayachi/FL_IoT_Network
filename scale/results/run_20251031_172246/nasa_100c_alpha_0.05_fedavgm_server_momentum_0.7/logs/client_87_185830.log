[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d316cb76-9815-4fe1-a4a7-c6ade77a4c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120eec87-6e58-41cd-8386-97ec02e6e209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 194737b0-35b6-4502-8384-b369a3335765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b214f88f-ff2a-4dcf-97e8-99fe3cc1699b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84fe9b10-6003-46cd-8365-648de0cfe4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffcdf4f-efa6-4eca-aeaf-30a95d19e564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c404ede-2e65-450c-9600-6db676f81979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 709fc148-4604-4835-849e-9ca8fbc93c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5668f93e-845e-433c-b32b-ad557da088e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f70601bd-158f-4520-b22d-7321880894bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e3e76f-6e3a-40b8-8641-95af153936a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9edbc21c-82ff-42dc-ac2e-3f755498357b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dca6806-6da9-4e42-9d1d-bfda4bbd748c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bffbe36-76ed-427e-9c01-fd15248f7622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6cbb6ce-9750-406a-8e41-2b55664677d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96a1a04-ca41-49fb-b2a4-50303ec28c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 481ab50f-1774-4193-ad18-41fd4eb79cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e904605a-ef02-489d-87b6-7d67b4a560e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc3c7b2-624a-400a-8359-7ba75b7c8034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65844cd1-8a3b-4ba4-9396-046b4184ac15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f5f9ec7-43d2-448c-b6b5-462d4910ab97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46807ec8-b652-4f3b-b566-62694bd4fe40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29429182-c326-4eff-91f0-c6cff1a33dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81fb921f-3e86-4c60-914b-ff1fff1f2ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a82de6-ba37-4938-a103-0656525290a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 030bb4aa-d6b2-42d1-979c-e03d5fe9351c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474a84fe-f597-4301-abd9-b5b2e2ab905a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cebcb29-039a-4263-a0a1-c42437d69a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4b823f-e6e6-437c-991c-2b4c15b6b87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8711a42-e953-4d72-a43e-02cde9fe0829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8571888-b7c1-4c66-a60d-e8fdec2d8493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383d73f6-015a-45a5-99be-74ac5283450f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf84f80-aadc-423d-81cd-dc5fd116f40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5402fc53-2649-4363-b414-80c69346b5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697da664-fe5d-48c7-8294-c9424916e196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea83d2b-833b-4e54-b022-0a065fe0c365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8358e70a-b46f-48f9-9b60-43ce3b5902c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f472860-3170-4305-9890-ff8d5f68d587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c863e46-6fee-4810-b8d5-7a9acb24cdc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4202649-1343-4dbb-9483-64bebb35d8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c9fbfb-2426-4689-8c3e-bf3e31615492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5f367b-b1f5-46bc-99fe-a89fe73c8195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a846ef8-4692-441b-9e31-18ba8b461ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e56496-7644-4039-bac4-1c9cbb83ece3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 129765b6-f453-412f-b8ca-738368316ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943eb3c6-4811-4c4d-8112-03365d0867b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29a6d953-c4ca-4010-a15b-145458b2993a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d678887-a70e-4d71-9a22-572e85914f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d33f154-835d-45d8-86f3-9a9db374de1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8f3e3d-ff21-470b-96c6-cc869105f89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eb63fb9-8a56-471b-97da-d6eb8d6dd512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dadbf758-5934-4525-9e2d-219c90404abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff270fb-d1b6-429a-b47c-8207a9baacbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c946f26-fef4-4c0d-bd9e-ebb321e262a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5487f8b5-ee5c-458e-9525-9849025876f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5102db7-b528-44d5-bc74-6108ded809f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 230d9333-dc1e-4b8a-bfa3-12e2df0d63df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20c70a72-3cc6-460b-a44b-3f3c27eae7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab3ad79-a43d-4006-809e-9bf999a07193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178adbbb-f039-48d1-b3b0-8e35603ff007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a34992-568a-45ae-baac-b560663e1a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56bb0b33-7346-4942-a68f-f2a0cf4ed32c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d5731b-73b5-4626-8846-bd5ced0f3227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8600e55d-edde-460c-8c38-fc91693029d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2222b2d-b8aa-422f-817b-59765008c773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a70798-a79f-4d51-8815-a96a903595b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31e27d47-2ea0-4dd2-9402-f527f2bacd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f5f7167-f32a-4c67-b007-153d4bff1f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42916c58-e8a5-4d90-82fd-483982102dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37fb4b28-0958-4779-b6a4-66adc569552b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b49851ad-9001-4b6a-85a4-28b7761fd2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd3dd37-5cd4-43ca-a107-a9a0f0a5eff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77dab6fe-b449-48eb-b89c-77cfe6021ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2315f8-53ab-4c2e-a670-0a7861f456af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4d6f4ad-7665-4696-ab7e-efd680662ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba424964-2fee-4885-b74a-01f98574a98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec35c3d-69c4-4779-ab7d-03711017c482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b048ca-4818-4c9d-9faa-596672fce74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1e0300-eca5-4cc2-a52b-958466deb60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4cba56-df75-486a-82e7-b7ee8248adc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbcea980-7a6c-42a6-aea0-f1f1e83be05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf28cb25-4f09-4d43-a37f-dd3ad94ab2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cefd13-7ba1-42c3-9706-e9804dd36d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0366425-4376-409b-af19-bf9171405ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c8addc0-c6a4-4c73-857f-601f5af7f299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c787f602-704a-4b78-9bdf-a0a3aaaf95d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c099eb-d68f-4dae-ab67-6abdbafa3bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1500e242-6b08-4da5-a29b-a06ffbc671b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3baea4a2-89e5-4a29-b5d0-478a136ade39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947de5c7-fa8a-44cf-9c34-f22689e5255a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0710ec8a-c23e-4b61-b78c-8bb8fa188f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 125aedf4-b721-495c-9110-e0236b5b2319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a8a433-15a0-4425-9c59-606a65bfd37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89fdc2e1-8414-4d69-b0d6-0f60a84431b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c34e6f78-0b28-4921-9a70-fec6a79c6e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13dc159b-d6a1-47d8-9875-bb147546dda0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7d09c9-e971-4a86-be23-95880dfe3dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e386ca0d-8c18-4db8-9b82-da7f655e7e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca02950-dfd8-441c-ac8f-5b4b684017f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f98b637-e94e-4b29-9e3c-d9be7251c806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 623d10ea-297b-44d9-aa4a-a121d4cfdd24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c462da15-a7dd-4f83-ba3f-89c8b171c68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748abc01-8351-44b5-a3bb-ca87e2c044da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1df2183a-e1e5-4a26-b37f-d5e4c04a9206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aea0fdb-08ec-4d0a-9c63-1c91ada03209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52dff706-389c-4976-9152-b096d8604a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b512bccd-2f51-4dd9-87db-419a038c4079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eae27af-a71d-4614-9454-75801d53e27c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80fee3a4-ee40-481e-b083-c2fd2d9d38c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 130c8534-ce92-487c-b5dd-709c7ba54230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151bc2dc-1a2c-4a71-8d8d-99da0cec0f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2bab5a5-9c95-410c-bb92-86b902ea3df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 405ca0b7-a675-4b01-a68c-f6bc71bd64ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a5b7af-9892-418b-97e1-681863e82898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8dba8f-128b-4321-87bb-68b16fa96567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f10a97-9c1c-4c82-8b0c-03e972eeb1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68796bd-5505-49cb-bd4b-7254189ed830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4625cb06-b1ed-4593-8d25-d3e1bccf3652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a2b3fa-eda9-44a0-ba13-755f31fd21e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46527c95-57cb-40b0-b932-5cc663451562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1211bc3c-f47b-4ff9-abc7-b0b64c5de7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d49e174-932d-4502-b826-7aacb7891d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfdddad-8dfa-4390-a5bb-4da47bcbdd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a326fb12-ca51-443e-909a-dfecece65328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d74b1e-962d-4af6-93e9-c141c4b9a5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab39f88-cc59-4589-a480-ae58adccd12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb92d69-08fe-422a-a9ac-fba73d518204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 203b3d13-0534-4fca-a28e-a75c25cac8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e270acea-9574-4c76-b51a-5cfd86a0ce25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fbb4e0b-14df-4f60-8a90-60afb5865190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f3c727-8ded-47eb-bc8a-88433973a1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9ae8803-f530-4e6e-aa45-57b44845cadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfbb0e5d-a3ca-4fc0-8b1d-5392a6de74a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1838e483-f267-4828-8432-1012c4a14a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26bc5cc-c7ce-4b54-a2b6-40ed07d87be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46927c24-9bef-42ae-bb2e-46a185645aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e46f6144-56ce-4d00-8ba9-edc89ab95a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 622555b1-5b9e-4dd6-a90e-1ddc160a6397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fec326b-03b7-4ffa-ad89-ce358db90ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da06885-f5f6-46ca-bb68-a9cba79b6c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2409391-5587-4725-b3f2-94ba07051da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc2f1d58-0468-421a-97ff-0bd9adffff9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a96028c6-0121-4b7a-bf84-3f04198922ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e89fad39-2338-448a-a08a-b47ba9b98db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d75f8a51-4f89-44e3-91c4-dd044f2fc85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdbc4b01-dfbd-4894-bff1-6dd485c47dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3ed358-0e64-4211-8835-f962ca9e8468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db93af98-7e3e-4f2a-9998-b34c086b5f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6985799f-4089-42e4-bdc3-d2a80a97b1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e450b7d-086e-4909-b8fe-8e35b75dba20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4501b55-1135-414f-b256-efd55c32be9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc3e51b-5b60-4ac7-b612-91ec6051ac18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3b75c5-a709-4083-bfaf-333fac5cab55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c98392-515a-48c6-b359-7ae3f07a8328
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_87
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_labels.txt

📊 Raw data loaded:
   Train: X=(1701, 24), y=(1701,)
   Test:  X=(426, 24), y=(426,)

⚠️  Limiting training data: 1701 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  417 samples, 5 features
✅ Client client_87 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2458, R²: 0.0189

============================================================
🔄 Round 16 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0826, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0792, val=0.0834, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0782, val=0.0846, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0716, val=0.0891, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 16 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0192
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0288
============================================================


============================================================
🔄 Round 19 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0733 (↓), lr=0.000250
   • Epoch   2/100: train=0.0830, val=0.0743, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0825, val=0.0747, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0753, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0815, val=0.0757, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0800, val=0.0767, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 19 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0001
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0172
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2463, R²: 0.0203

============================================================
🔄 Round 21 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0882 (↓), lr=0.000063
   • Epoch   2/100: train=0.0800, val=0.0877, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0797, val=0.0875 (↓), lr=0.000063
   • Epoch   4/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0794, val=0.0873, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0789, val=0.0873, patience=8/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 21 Summary - Client client_87
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0122
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0121
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2450, R²: 0.0284

📊 Round 21 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2447, R²: 0.0294

📊 Round 21 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2460, R²: 0.0233

============================================================
🔄 Round 28 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0786 (↓), lr=0.000016
   • Epoch   2/100: train=0.0819, val=0.0787, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0812, val=0.0791, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 28 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0014
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0014
============================================================


============================================================
🔄 Round 36 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0753 (↓), lr=0.000004
   • Epoch   2/100: train=0.0834, val=0.0753, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0833, val=0.0753, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0832, val=0.0753, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0831, val=0.0753, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0829, val=0.0754, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 36 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0104
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0181
============================================================


============================================================
🔄 Round 37 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 37 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0061
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0893
============================================================


============================================================
🔄 Round 38 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 38 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0045
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0000
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2484, R²: 0.0075

📊 Round 38 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2484, R²: 0.0078

============================================================
🔄 Round 44 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 44 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0104
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0062
============================================================


============================================================
🔄 Round 46 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 46 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0057
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0083
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2484, R²: 0.0081

============================================================
🔄 Round 50 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 50 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0042
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0044
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2484, R²: 0.0083

============================================================
🔄 Round 51 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 51 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0092
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0148
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2484, R²: 0.0084

📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0085

============================================================
🔄 Round 54 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 54 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0000
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0256
============================================================


============================================================
🔄 Round 55 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 55 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0053
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0081
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2483, R²: 0.0088

============================================================
🔄 Round 57 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 57 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0019
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0186
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2483, R²: 0.0089

============================================================
🔄 Round 61 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 61 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0059
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0141
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2483, R²: 0.0090

============================================================
🔄 Round 62 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 62 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0016
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0233
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0087

📊 Round 62 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0087

============================================================
🔄 Round 67 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 67 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0027
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0030
============================================================


============================================================
🔄 Round 68 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 68 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0086
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0160
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2483, R²: 0.0089

============================================================
🔄 Round 73 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 73 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0020
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0006
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0092

📊 Round 73 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

============================================================
🔄 Round 75 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 75 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0033
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0072
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

============================================================
🔄 Round 78 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 78 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0044
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0292
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

📊 Round 78 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2483, R²: 0.0089

============================================================
🔄 Round 82 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 82 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0041
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0225
============================================================


============================================================
🔄 Round 83 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 83 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0082
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0199
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0087

📊 Round 83 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0087

============================================================
🔄 Round 86 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 86 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0061
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0150
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0089

📊 Round 86 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2483, R²: 0.0090

============================================================
🔄 Round 88 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 88 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0034
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0057
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

📊 Round 88 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0094

📊 Round 88 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0097

============================================================
🔄 Round 94 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 94 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0003
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0035
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0099

============================================================
🔄 Round 97 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 97 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0016
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0138
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0098

============================================================
🔄 Round 100 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 100 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0073
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0024
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0098

============================================================
🔄 Round 101 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 101 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0058
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0090
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0098

============================================================
🔄 Round 102 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 102 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0019
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0192
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0098

============================================================
🔄 Round 108 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 108 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0011
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0094
============================================================


============================================================
🔄 Round 109 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 109 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0033
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0271
============================================================


============================================================
🔄 Round 110 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 110 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0022
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0055
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0100

📊 Round 110 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0100

📊 Round 110 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0100

============================================================
🔄 Round 113 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 113 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0032
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0176
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0099

============================================================
🔄 Round 114 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 114 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0030
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0180
============================================================


============================================================
🔄 Round 115 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 115 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0036
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0079
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0098

📊 Round 115 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0098

📊 Round 115 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0098

📊 Round 115 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0096

📊 Round 115 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0095

============================================================
🔄 Round 121 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 121 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0020
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0173
============================================================


============================================================
🔄 Round 122 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 122 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0030
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0272
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

📊 Round 122 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

============================================================
🔄 Round 125 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 125 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0024
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0163
============================================================


============================================================
🔄 Round 126 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 126 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0005
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0056
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

📊 Round 126 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0093

📊 Round 126 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0094

📊 Round 126 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0095

============================================================
🔄 Round 132 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 132 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0059
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0155
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2483, R²: 0.0094

============================================================
🔄 Round 134 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 134 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0004
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0100
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0092

📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0092

============================================================
🔄 Round 137 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 137 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0003
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0074
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0091

============================================================
🔄 Round 139 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 139 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0017
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0021
============================================================


============================================================
🔄 Round 140 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 140 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0036
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0061
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0090

============================================================
🔄 Round 142 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 142 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0020
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0162
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0091

============================================================
🔄 Round 143 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 143 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0052
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0437
============================================================


============================================================
🔄 Round 145 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 145 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0022
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0189
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0093

📊 Round 145 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0094

============================================================
🔄 Round 148 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 148 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0072
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0440
============================================================


============================================================
🔄 Round 149 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 149 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0006
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0156
============================================================


============================================================
🔄 Round 150 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 150 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0026
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0213
============================================================


============================================================
🔄 Round 151 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 151 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0025
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0104
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0092

============================================================
🔄 Round 153 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 153 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0037
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0038
============================================================


============================================================
🔄 Round 155 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 155 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0073
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0016
============================================================


============================================================
🔄 Round 156 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 156 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0048
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0095
============================================================


============================================================
🔄 Round 157 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 157 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0017
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0105
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0092

============================================================
🔄 Round 159 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 159 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0047
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0105
============================================================


============================================================
🔄 Round 160 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 160 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0016
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0096
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0091

📊 Round 160 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0091

📊 Round 160 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2484, R²: 0.0090

============================================================
🔄 Round 164 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 164 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0104
============================================================


============================================================
🔄 Round 168 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 168 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0081
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0229
============================================================


============================================================
🔄 Round 169 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 169 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0067
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0164
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0093

============================================================
🔄 Round 171 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 171 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0042
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0063
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2484, R²: 0.0095

============================================================
🔄 Round 173 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 173 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0027
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0020
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0096

📊 Round 173 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0096

============================================================
🔄 Round 175 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 175 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0032
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0013
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0097

📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2483, R²: 0.0098

📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0098

📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0099

📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0099

============================================================
🔄 Round 183 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 183 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0079
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0509
============================================================


============================================================
🔄 Round 184 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 184 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0055
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0023
============================================================


============================================================
🔄 Round 185 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 185 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0035
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0409
============================================================


============================================================
🔄 Round 186 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 186 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0041
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0030
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0101

📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0101

📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0101

============================================================
🔄 Round 189 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 189 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0057
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0087
============================================================


============================================================
🔄 Round 194 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 194 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0116
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0250
============================================================


============================================================
🔄 Round 195 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 195 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0031
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0039
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0104

============================================================
🔄 Round 198 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 198 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0055
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0118
============================================================


============================================================
🔄 Round 201 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 201 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0019
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0109
============================================================


============================================================
🔄 Round 203 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 203 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0004
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0050
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0103

============================================================
🔄 Round 206 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 206 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0026
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0150
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0102

============================================================
🔄 Round 209 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 209 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0084
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0289
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2483, R²: 0.0101

❌ Client client_87 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
