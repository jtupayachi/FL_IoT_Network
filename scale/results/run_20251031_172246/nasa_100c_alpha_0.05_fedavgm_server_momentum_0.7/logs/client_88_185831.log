[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09cd3d8f-467e-4d63-9d11-5d2503418982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b56374-dacf-474d-9338-7360fb96de89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f330574f-620f-4c17-b8b6-9c408b1b40d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18237532-e500-4a31-975e-fe30901eea25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beefeabd-7ee7-43be-9fee-0f381415bd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588448bf-66eb-4951-b9a9-1f551cac505e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb004e3-da4e-4f4f-8729-ef08db18e585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da4ff117-9c5a-44c6-82e7-72872b6ca50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baac0571-df44-4ba5-8495-0bd8efb6eacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca88a457-c022-4d98-980c-6f0f71096727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d711887-abf2-469a-a871-769c7cfb9198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01e284c-596d-40e7-94cd-4726784fa071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816235ce-fa55-46c2-beb0-4672570edf64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be3d94a8-195b-43ef-bf2c-8db8de38583c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e9a30c-33b0-49e2-834a-b55eb8a6c441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52ca5cc-90df-4e0d-b665-10c3e264d1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d830cc0a-e359-4bef-a664-98c48025021e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3416e317-e20a-4041-96d3-1ad2a66d02fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0836c5d-bcad-4255-9f5b-fa71909d0c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c2b945-5e9b-47fe-8e00-8ecc6c0178d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74769bce-0a45-4170-abd8-001115c3896d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fa5ef7-a72a-45ff-8e27-81f1d07048c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a982dd2e-231a-4263-80d7-c6c3deaf9d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed68a14-b482-43f9-be07-e58917d0d14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a42ffe5-1509-46ca-a5e1-8d371adc9797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9239e0-d8d8-4774-891d-8d95efa64816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f04702c-a82b-4927-9f65-373cc55a598b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6322eaf7-a8fa-433b-ab1c-200e7d8bf71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205b3673-3a63-4246-bec3-ff2c933274d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36699e4e-716b-454a-9580-1a50b910bc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e49988a-d75a-4ae1-88b2-5f442c8f53ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66ef8b8-982f-48ce-9200-eddceda2bdfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c57dc9c-5d49-49dc-855c-20655a9db49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b426d025-5e9c-4a55-b521-8a746b69021a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe9b693-6c57-4e28-a3f2-090759857a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e480a440-6aaf-4b95-a7d2-35e6bdab634d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93065d89-35c8-44f6-8a73-63c5b8bfd1c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c7df1ed-14d0-4326-a9b9-db50a0bc62bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ec782d4-806d-4eae-bb9d-a1546672d661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db610d7-6001-4cc7-8bb3-432bd7632188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef789fe8-a5dd-4e33-aace-967b8f4a6004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe5b438-012e-4d7f-be93-a6efd36a8d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da8ea02-4809-4a3f-9bb9-d083a1a60da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e617644-0181-4ea6-bdcf-e36c965055ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aafc416-44cb-4f37-a359-03f3d37464a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209d03f3-a443-4709-acb4-fe197403dd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9030094-f04a-4fe9-a463-9bae4b84283e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1899a6c-6b5c-4284-b97b-ad2d1ef90ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943f1d15-a43d-4d60-9b5f-8551a74f9154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19c59433-d522-4429-a83d-7a7df6d71437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03e591c-f449-4899-a354-6de0153ed90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9739a631-8f22-40e3-b67c-b71cf2f5f260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8042dfe4-2b81-42f5-ac11-7da424e9bc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a77945b-75f2-44bf-8003-1734a21e496c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffae519e-9646-4d7f-bf76-27f5208ffc61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba5234f-c9c9-468a-b08f-0d39f800b9bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae6e54b-dab2-43c2-ab82-59bd4fbf1d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3276cb02-6976-4e6f-910b-80985a780050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db2894d-e8b5-4004-931c-62a628868333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c3cabc9-7c0e-474a-a575-b0e6f0a36dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d0ad5c-82c3-419c-98c3-ed0ed18782c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 275cb29d-dc1e-49a3-95c8-408a7eec608a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95435a58-92f6-4a90-9157-62d650a61fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43d7f9f-a0ee-4e12-8aa3-99a6c1056457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b4f6e91-1cf0-40a1-a22a-0cebd1029288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b44ae5b8-992a-47c6-9afc-118f0e9aab1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9451266e-cb7f-4156-9647-4e81d2863b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f4a824-6483-46fe-b9c4-e34ab9822c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fada6f61-d7b5-4fe9-9566-884c8a892c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6c7cdd-80dc-4a54-ab82-9239f0f6e825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a30fa9ed-fa03-4b12-ab7a-c116adc04e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dde143c-9116-4e62-959c-6bec9d9191f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a83ec5d-b442-441e-a357-a13b365667ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90f73787-e8a9-4523-bf8e-e6e7102bc9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a75f3f-22e6-41bc-aa74-879f647ba004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4336d4-3cf6-4912-afad-b96cef79adb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb32de35-41f0-4a32-8dd4-e5077b8bd1b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de6b17c-da36-41e2-82db-a77073e230ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19daed52-64b9-4407-92ef-a2c451156b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761efff8-39b5-4c52-96d1-ab9ad2fc3677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a364100-e54e-409a-9537-ffe68843d020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4b90fa-80a1-42cb-a429-6c4b16ee6bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f3a576-2e73-4f43-8796-498a97277b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58cba26-2e41-4dd1-bf33-1f1e48eb22f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29b6b0fe-7d0f-4132-a200-3a67392a2f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a6e6fd-65ef-487b-835e-386b779799ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a204bc9b-448c-4581-88fb-cd1e9ef2d677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a911f2c3-84d5-4880-948d-206ad94e4391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cadc5f5-5512-4c87-849e-12027116d1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8cd656-9174-4841-bfdd-21a062c0e0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d2829e5-11ba-46e6-bdae-f6f2b1dfe0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ca39a1-cf9e-41b5-98b4-3c65aa76df5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7cfa9e-e65e-423b-afbf-145527f4747d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be13f63-8789-4ee6-8e14-9d91a33ae146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3188a455-9bcf-4f86-a341-ffdadbc969a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde32e9a-6613-4896-a647-2ebc34b987ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c70ad2c-19ab-4f48-9b4d-5be0ef466568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a8d923-97da-4e33-855f-e0a0de206de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843f6286-1bff-4cfb-80d3-869d3dbc2b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73167ba8-5d9d-4673-b7dd-2b31931651ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72809285-22fa-4e66-92a8-fb6a6656625d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92b48cb-258d-4595-bfc0-9f7bfc79260b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69ddadcc-280f-448e-8df9-040dea5596d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05288146-222b-45c6-9566-d98af70f9596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9f6ade-5970-43a4-ba0a-0a9fc88c4c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d14932-9b94-4fa0-b737-e9e002e3b9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c03559-f233-4f15-8001-9a1016e6a18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c91dbd8-7b5c-408d-914b-fb2acb9921d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e14ad60-d95d-4e91-a1fe-be2badb5b364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d97090-3d7f-43d5-8b36-ca3f99f86a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d25a7a1-9931-4787-b4a5-c798c45907b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b40157e-3db0-4dd5-a282-2908068288e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f3c25e4-99fc-4a2f-8523-9cb9196a45c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4c0451-d3ba-4c79-8ab6-793b804b8ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff9b86b-78fd-4960-a84b-b61bf1f0216c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf17580-c913-4884-b7f3-c24d139c6738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5bfb59-3c46-44fd-b4e9-43c13a1efc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d905a4cf-1d01-4546-994c-bc0e3dc3a92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47daab30-2a66-4198-bfa8-1fbd0685f3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4d025a-4fad-4b77-afda-85f829c254e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c58085-5cc0-430c-b4ca-cd089ef6554c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655f0807-c769-41a2-9845-ca8ac31d97a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56f99b9-dde7-4f1d-b9c2-33a450cfeec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34568685-9cfc-41a2-bc53-c0d8d4bdc20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8b3172-8015-4aff-91f5-3d10ee6efa7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 646eae28-978c-4e33-9111-fb505ccbb05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db79bcd3-6d58-48db-af47-c8fef0f001d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ba5a29-5225-4b7f-b8f7-7f131f9e932f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f7b28a-bbd7-44ca-8256-2018dfd4e651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98bc73be-0443-426f-873c-f5cbc1f4db33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2230a4c0-8057-4060-8b84-1e1ab65d9e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65ec9dd7-8bd4-467c-9281-7e4f052cd359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8bae205-b08b-4e69-98b3-9a4a51ab154c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883fa9a2-f3cb-4d16-9764-0385b615e6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd5d7ce4-0bfb-4f00-a58d-18faf0350443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448eb3eb-3b89-471d-8074-c0038ff02161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f146474-f1dd-4910-a280-4572a498bd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5fd5670-d019-4398-b3bd-09c0333a2544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964a3fdb-29e0-4a0d-81c9-c7c76842c372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52426bf6-a8a4-4586-af1a-cd7acd017aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e35d10-d3c2-4379-ab17-d08233472061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4e3cb4-fb8d-4c74-bcc8-e2a1e0c3f399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06cff41c-08ca-435e-a613-64f65150bb32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abe38835-7cce-4b6f-94e5-984349c98bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe67b6f3-ba28-4481-9fb5-fa2a346529a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81879b35-fbd5-472f-a8cf-2b8fee07e82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cc8f314-35a5-41fa-a463-186b5b788d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd6d4b97-7611-4b97-9329-b5b454c90c44
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_88
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/test_labels.txt

📊 Raw data loaded:
   Train: X=(1537, 24), y=(1537,)
   Test:  X=(385, 24), y=(385,)

⚠️  Limiting training data: 1537 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  376 samples, 5 features
✅ Client client_88 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 17 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.001000
   • Epoch   2/100: train=0.0817, val=0.0833, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0800, val=0.0824, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0789, val=0.0821 (↓), lr=0.001000
   • Epoch   5/100: train=0.0783, val=0.0819, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0715, val=0.0852, patience=5/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0602, val=0.0943, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 17 Summary - Client client_88
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0579
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0078
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2637, R²: -0.0631

📊 Round 17 Test Metrics:
   Loss: 0.0928, RMSE: 0.3047, MAE: 0.2628, R²: -0.0580

📊 Round 17 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2590, R²: -0.0391

============================================================
🔄 Round 23 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0827 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0808, val=0.0814 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0796, val=0.0807 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0789, val=0.0801 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0784, val=0.0795 (↓), lr=0.000250
   • Epoch  11/100: train=0.0760, val=0.0771, patience=1/15, lr=0.000250
   • Epoch  21/100: train=0.0730, val=0.0768, patience=7/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 23 Summary - Client client_88
   Epochs: 29/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0827
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0637
============================================================


============================================================
🔄 Round 27 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0847 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.0815, val=0.0837 (↓), lr=0.000063
   • Epoch   3/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0800, val=0.0830 (↓), lr=0.000063
   • Epoch   5/100: train=0.0795, val=0.0828, patience=1/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0774, val=0.0820, patience=4/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0762, val=0.0816, patience=8/15, lr=0.000016
   📉 Epoch 26: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 27 Summary - Client client_88
   Epochs: 28/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0544
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0188
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2592, R²: -0.0344

============================================================
🔄 Round 28 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0751 (↓), lr=0.000008
   • Epoch   2/100: train=0.0848, val=0.0750, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0847, val=0.0750, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0846, val=0.0749, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0846, val=0.0749, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0841, val=0.0746, patience=10/15, lr=0.000008
   • Epoch  21/100: train=0.0835, val=0.0742, patience=9/15, lr=0.000008
   • Epoch  31/100: train=0.0829, val=0.0737, patience=7/15, lr=0.000008
   • Epoch  41/100: train=0.0822, val=0.0732, patience=6/15, lr=0.000008
   • Epoch  51/100: train=0.0816, val=0.0727, patience=7/15, lr=0.000008
   • Epoch  61/100: train=0.0811, val=0.0721, patience=7/15, lr=0.000008
   • Epoch  71/100: train=0.0807, val=0.0716, patience=7/15, lr=0.000008
   • Epoch  81/100: train=0.0803, val=0.0712, patience=6/15, lr=0.000008
   • Epoch  91/100: train=0.0799, val=0.0708, patience=3/15, lr=0.000008

============================================================
📊 Round 28 Summary - Client client_88
   Epochs: 100/100
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0511
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0268
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2592, R²: -0.0338

============================================================
🔄 Round 29 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0835 (↓), lr=0.000008
   • Epoch   2/100: train=0.0826, val=0.0835, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0825, val=0.0834, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0825, val=0.0833, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0824, val=0.0833, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0821, val=0.0831, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0819, val=0.0829, patience=7/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 29 Summary - Client client_88
   Epochs: 29/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0008
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0400
============================================================


============================================================
🔄 Round 30 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 30 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0151
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0066
============================================================


============================================================
🔄 Round 32 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 32 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0108
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0177
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2591, R²: -0.0320

📊 Round 32 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2591, R²: -0.0319

============================================================
🔄 Round 36 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 36 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0139
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0027
============================================================


============================================================
🔄 Round 37 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 37 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0095
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0409
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2590, R²: -0.0316

📊 Round 37 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2590, R²: -0.0314

============================================================
🔄 Round 39 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 39 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0144
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0031
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2589, R²: -0.0310

============================================================
🔄 Round 41 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 41 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0048
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0327
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2589, R²: -0.0307

📊 Round 41 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2589, R²: -0.0306

============================================================
🔄 Round 43 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 43 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0057
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0313
============================================================


============================================================
🔄 Round 44 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 44 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0100
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0231
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2587, R²: -0.0296

📊 Round 44 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2587, R²: -0.0295

============================================================
🔄 Round 51 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 51 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0046
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0318
============================================================


============================================================
🔄 Round 53 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 53 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0111
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0067
============================================================


============================================================
🔄 Round 56 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 56 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0101
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0381
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2586, R²: -0.0287

📊 Round 56 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2586, R²: -0.0286

============================================================
🔄 Round 59 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 59 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0027
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0356
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2585, R²: -0.0283

============================================================
🔄 Round 60 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 60 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0093
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0111
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2585, R²: -0.0283

📊 Round 60 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2585, R²: -0.0286

============================================================
🔄 Round 63 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 63 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0128
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0048
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2585, R²: -0.0286

📊 Round 63 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2585, R²: -0.0284

============================================================
🔄 Round 69 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 69 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0042
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0332
============================================================


============================================================
🔄 Round 71 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 71 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0112
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0048
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2584, R²: -0.0279

📊 Round 71 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2584, R²: -0.0277

📊 Round 71 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2584, R²: -0.0275

============================================================
🔄 Round 75 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 75 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0096
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0146
============================================================


============================================================
🔄 Round 76 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 76 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0088
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0330
============================================================


============================================================
🔄 Round 77 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 77 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0119
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0002
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2583, R²: -0.0273

📊 Round 77 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2584, R²: -0.0276

============================================================
🔄 Round 81 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 81 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0051
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0292
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2585, R²: -0.0281

📊 Round 81 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2584, R²: -0.0278

============================================================
🔄 Round 87 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 87 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0077
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0187
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2584, R²: -0.0276

============================================================
🔄 Round 88 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 88 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0114
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0030
============================================================


============================================================
🔄 Round 92 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 92 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0091
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0124
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2582, R²: -0.0264

📊 Round 92 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2582, R²: -0.0262

📊 Round 92 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2581, R²: -0.0261

📊 Round 92 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2581, R²: -0.0261

============================================================
🔄 Round 98 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 98 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0113
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0012
============================================================


============================================================
🔄 Round 101 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 101 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0082
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0172
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2581, R²: -0.0261

============================================================
🔄 Round 102 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 102 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0107
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0043
============================================================


============================================================
🔄 Round 103 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 103 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0073
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0170
============================================================


============================================================
🔄 Round 105 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 105 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0113
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0009
============================================================


============================================================
🔄 Round 106 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 106 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0159
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0188
============================================================


============================================================
🔄 Round 107 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 107 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0117
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0059
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2581, R²: -0.0258

============================================================
🔄 Round 112 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 112 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0074
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0164
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2581, R²: -0.0260

📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2582, R²: -0.0262

📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2582, R²: -0.0261

============================================================
🔄 Round 117 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 117 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0109
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0018
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2582, R²: -0.0262

============================================================
🔄 Round 118 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 118 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0136
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0057
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0266

============================================================
🔄 Round 121 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 121 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0073
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0241
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2583, R²: -0.0270

============================================================
🔄 Round 123 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 123 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0100
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0217
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2583, R²: -0.0271

============================================================
🔄 Round 125 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 125 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0156
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0125
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2583, R²: -0.0271

============================================================
🔄 Round 127 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 127 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0060
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0240
============================================================


============================================================
🔄 Round 128 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 128 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0100
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0077
============================================================


============================================================
🔄 Round 130 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 130 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0111
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0200
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2583, R²: -0.0267

📊 Round 130 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0266

============================================================
🔄 Round 132 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 132 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0010
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0472
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2583, R²: -0.0269

============================================================
🔄 Round 134 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 134 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0106
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0055
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2583, R²: -0.0270

============================================================
🔄 Round 135 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 135 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0125
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0159
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2583, R²: -0.0270

============================================================
🔄 Round 137 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 137 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0081
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0401
============================================================


============================================================
🔄 Round 138 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 138 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0047
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0339
============================================================


============================================================
🔄 Round 139 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 139 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0097
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0098
============================================================


============================================================
🔄 Round 140 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 140 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0015
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0470
============================================================


============================================================
🔄 Round 141 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 141 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0130
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0004
============================================================


============================================================
🔄 Round 142 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 142 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0013
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0659
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2583, R²: -0.0271

============================================================
🔄 Round 146 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 146 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0043
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0307
============================================================


============================================================
🔄 Round 150 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 150 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0059
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0319
============================================================


============================================================
🔄 Round 151 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 151 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0169
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0216
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0267

============================================================
🔄 Round 152 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 152 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0079
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0188
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0266

============================================================
🔄 Round 154 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 154 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0014
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0495
============================================================


============================================================
🔄 Round 156 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 156 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0067
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0215
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0265

============================================================
🔄 Round 158 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 158 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0094
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0756
============================================================


============================================================
🔄 Round 162 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 162 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0162
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0076
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0267

============================================================
🔄 Round 164 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 164 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0020
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0404
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0267

============================================================
🔄 Round 165 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 165 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0092
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0111
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2582, R²: -0.0267

============================================================
🔄 Round 168 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 168 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0112
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0045
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2581, R²: -0.0261

============================================================
🔄 Round 171 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 171 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0157
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0073
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2580, R²: -0.0256

============================================================
🔄 Round 179 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 179 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0112
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0039
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2580, R²: -0.0251

📊 Round 179 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2579, R²: -0.0250

============================================================
🔄 Round 183 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 183 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0116
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0013
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0248

============================================================
🔄 Round 184 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 184 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0069
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0170
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0246

============================================================
🔄 Round 187 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 187 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0098
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0062
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0246

📊 Round 187 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0245

📊 Round 187 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0245

============================================================
🔄 Round 193 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 193 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0129
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0971
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2578, R²: -0.0242

============================================================
🔄 Round 197 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 197 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0052
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0260
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0243

============================================================
🔄 Round 202 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 202 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0070
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0163
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0244

============================================================
🔄 Round 203 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 203 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0094
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0222
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0244

📊 Round 203 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0244

============================================================
🔄 Round 205 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 205 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0085
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0117
============================================================


============================================================
🔄 Round 207 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 207 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0100
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0288
============================================================


============================================================
🔄 Round 208 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 208 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0073
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0147
============================================================


============================================================
🔄 Round 209 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 209 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0062
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0203
============================================================


============================================================
🔄 Round 210 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 210 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0090
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0285
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2579, R²: -0.0246

❌ Client client_88 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
