[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340664bb-a60e-45af-b7f3-c20fcc2f4982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3bf9d65-c567-4daa-8850-1de95deddf22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06af5090-2856-438e-bd5f-20cd5dd47f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9850fe23-8b06-422d-9a39-4059362c9e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca62293c-9e56-46b6-8363-9b64457685dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eee4836-d70e-4f1c-9230-e9e297b4a9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057c5015-654e-4215-a416-3e9ba867a320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df791e2-b600-444a-9a10-30d93e680e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff353e19-1f4d-4286-88ed-c26a0e84f3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30906d1b-f740-4ebf-b185-c3f5632d25d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8fbc84e-2db7-4e25-8b8e-d6de53f8627e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868a6bb7-f88f-4565-aeba-2716691b6e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6caf7f39-7bca-4baf-85a0-74c75dd62bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa78f82-e611-44d0-96d7-24862e6647cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a32431-a5bd-46c9-b6e8-62bfae60aebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ac1b1b3-cd60-46b5-a627-b22ba00be2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 483a2daa-d607-4450-875d-11bb851f48fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d89ca62-b2c6-4729-8c7f-830544d32cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efac83f1-c6cd-4f14-a66c-4a50f24d148e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a017296-1513-489a-87ce-75db315c7988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b033f3-6278-4177-b435-2b58e46d44e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3665500b-5349-4cdb-94b0-0b46d20001bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73987e08-4647-4a68-a220-ec16c63bd473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46fe797b-1cf0-47d6-890f-365853c0eceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77fe3236-6782-4eda-87b8-403ba782522d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da6bbbc-f711-440e-b70d-b30a07f64c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0810643d-f272-46ba-823e-94fe10967756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afcbe2c-a6e3-412c-8dba-2c323286c8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6a8f28f-1eac-4a57-bbef-939602eb8d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2416c2a2-27e8-4648-be4a-9366d7d24f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b862c57a-4400-4157-9b08-6d50ad3adf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a247ff-5e10-4813-b90f-2f84e94fd44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e85412e-ecc9-4ab6-93bb-8e3ac2b2a61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7195ccee-c372-4310-a497-021af93829a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34d61f6-edc6-401f-ab45-38c49cccddda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164f6f8a-68be-4b7f-9f96-243e7467b8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9cfcbdf-caac-4a0b-93f9-c249f31ae466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6531267-c1e8-45c0-b540-23bcf6e12664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c186fa05-2a89-4839-9f6e-b50a1c8c61ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf64f3a-8d8a-48b9-ab45-01c3d0f4a15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9871383-6a74-4c5a-b0c1-3b6dfaa28fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 369c6de4-634c-431a-807d-32d69a514a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e09dcbe8-58b3-4a4c-ac6e-fc4699b3ff70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2695630-f4e2-4b08-a72f-ba52bf73a51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d51e16-57f4-4344-9dd9-93c4926fec2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e3b5b9-8ac1-46d9-a5da-95827a659c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d789d698-1ea1-45b9-ad57-a0da7dd2c0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1bd67b-1d1e-420a-9ad2-3a630588d238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a9dd37-2e2a-412d-993f-8c5a395f7d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52fdd690-be21-4ca3-9733-33344c291748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a7c3ad-c80f-4075-a1af-2d2cdb8dc59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d9650b-ec25-4daa-93f8-46c0b2e1d841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35cf9cb5-671b-43b2-b9d5-75b35395c770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04c24fa-50b7-47c6-a788-18dc0f181a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65063898-f942-4e25-a317-ce734b50d81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5894a0-5ec7-4f92-8d4e-b8f9d1ac768d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 917c6638-97c0-440d-8117-96cbd7447a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 159f1517-4634-45be-9bc9-e8f8a61c7aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3bad0dd-6c8f-43a5-ae65-91965b4a7388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 455c432f-b83f-4454-91ce-52e699ab3250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba708e9-3c26-45d5-8dbd-5f813b1b3377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44880b2d-2703-4a97-81b3-b12a02d50676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d81dad-6796-4906-a113-4da85dd79a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6ce5b4-e2b4-4ea3-b8cd-6bf590d0c2af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc010da-0de9-44fd-9098-8eb3c73091ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf71e5d4-5968-4e39-ae88-1baa54885af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d43d98-c161-46fa-a5d7-b52c39bb96a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26950dfa-1303-4b60-9b8b-15242d34d52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f263a20c-7dfa-404f-844f-1a1aee338656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e484e1b-5207-4468-9d7f-caee2de5c3f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166b9f6e-2c96-492d-be78-86f9e28f7201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ede302-9976-4686-98bc-1dd7eb1fcb4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d9ce85-3f8b-4837-aa7c-4e7bcdd963f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251fd8de-6569-4f5f-99be-4d1ce6ebc8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac915635-45af-4f88-abd2-72049323c4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 671f4ea4-aab3-4511-ba13-b565e09dc797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40260f53-a210-447a-bd47-bd6b12259701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efbecf06-d41c-4a82-bfde-66ee7fb711de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d03990f-1bde-4399-9d2d-8d166a901ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7700636-636b-4cd6-b7fd-9af0594f7fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd5a88a-056c-4a00-bc98-86a8a3ec070f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3151508b-2635-4fb3-b0df-e1a9cbaa4f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1ad67a9-bf8c-4369-99c9-4d2ddabbceb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9021cea3-e258-4763-9260-a898c6e65a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974c9ca1-67c4-4da9-999b-e0ae6bbb6652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e64c3337-f226-4d9b-8da5-c64e2f6177a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805545a5-74a7-4858-a7ed-40b1665fe5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da6c2ab-9f15-4464-82cf-0688ce211e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2be04b-cb9e-4e58-a94c-50daf020263e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbc68e3d-884f-460c-8dfd-e40885406180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dca7ef1-c517-44f7-a940-fe3394561f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd82ce4d-c8ea-4a1c-81cd-adb3142ce691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8236827a-e5ba-4329-900f-35559efda2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ec659b-718b-4a9d-88a5-5b974ce36ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52c6715-0c06-46dd-9913-5c3d026b8c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aad3bd9-27ba-4914-af89-2cd57b0592a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47428018-c9e9-4ba9-9ed2-9118bd629252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818a2b9a-7047-4eab-a4d3-6d0a1173ce2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60684610-b54f-44af-bcd4-8fe4ea10df06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce2dba3-b3c8-44a2-aa60-8b6bd55b8c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbea52f-aee2-431b-8a16-f45ee1940359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d4a2eba-af6f-4565-97a5-fe3f246a17f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab924c9-660c-41a4-bd78-3777a478a54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9c3f5b-a4cc-45f0-9de0-dec1037542d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b61ba60-62cf-4981-8a83-a9f8a554226e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da95a4b6-dace-48ef-83bc-098320ff8528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d160720f-17d9-4129-b4bd-d1400d7fe399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f768d81a-1074-44e9-aa69-f1157abbaa8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7949d324-3c84-4a75-9c70-1a835f1778a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746955a9-c12a-4965-a44a-4e31a684b380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24abbd56-4296-441b-9cfa-9876171496bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0b3df0-86e7-40bd-96f8-027969367f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cab255e-da6b-4bd2-9567-c5b819aff4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36610d6f-6e96-451d-9f60-b84dd837f417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aed2838-038c-42a8-bcb1-2c4306087b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9366e5b-5a8d-4202-acb7-cfac3702ed56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d2a0dd-12a1-4cd1-aee3-0b609063f4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1c6711-31e8-4756-b79c-8998a57e87de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2a75de-f349-4c7c-bee7-65fc1cec340b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcaf752b-38fe-41f0-b048-97972cf11dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea979ca-30eb-45b4-aee2-cc21ced314ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 632d1cd5-8970-4001-ac2c-91e832296615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8e506c-874b-497f-a30c-0a5a68991ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4989e7-b9bb-4238-a8eb-f58b3be81bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44cc6c6d-8db3-4b70-8a38-b52981661372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53c2b00-d3fc-48ef-894e-e50f6582560a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0046f1b6-4e56-4c51-a3ec-1dd60efcddec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5114b01a-5ac3-443c-8cb7-d19964d9081b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb85120-3a53-422a-9200-cb3368166eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791af930-68b4-443a-acb5-40b935d7ab50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448de9d4-9602-4587-bd07-12f87132f553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd4f90e-115b-4842-b7b1-ab761a4fc662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2924c4b6-1a69-49ff-9f54-d08e92e80319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e51fff-af5e-4dd5-b1e2-d114e63f2f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace3e5f7-928d-40ed-8642-b5c2289c832b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba38a2c6-d038-4564-a2c4-9f3d344ba756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d06532-6030-4599-a01c-1d2d9359f7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f215d4-82c6-432c-98b9-ebcc0454e5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9093c7-7538-4c15-bf07-445fe60c0830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1d04f21-ebc6-4817-8d97-f20b5ae7a0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0226da-9fab-4f22-a11e-f0ff0322d646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1f75ab-70fa-45a5-89c5-af75be176315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e27dc4-42bb-4f07-b2ec-df152b149da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c46d2d1-2fdb-4479-a4bc-29628be054f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66098485-97f0-4254-99a0-6a27dc91d70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d7cb3f-ab93-474f-a6e7-a5ca13e5bbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880577ef-9178-45c9-ae5a-db843dfa1034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146db108-3364-42a0-bd51-d734ed20bb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43628ac-c4c0-4174-96a4-7d0a5667f610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 753d388c-504d-4fe0-808e-e5d1763cf4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c5925a-a42a-415f-abcc-31aca58027c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceac129d-8c97-4b8c-b81a-42f1fd3a1fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aeb2a5e-c955-47d3-bfed-f0dd7130e07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a83460-b921-4668-adf7-e24fd32d033b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec403eb6-701e-4dcf-8b25-ce2e8f29c70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a50fe8-ac8c-438f-8b47-8ff4407b90a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0250865-9e42-4abf-8857-3083cf576325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a474d801-d568-4013-98be-7bfaaae2ff80
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_89
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_labels.txt

📊 Raw data loaded:
   Train: X=(1393, 24), y=(1393,)
   Test:  X=(349, 24), y=(349,)

⚠️  Limiting training data: 1393 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  340 samples, 5 features
✅ Client client_89 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0918 (↓), lr=0.001000
   • Epoch   2/100: train=0.0805, val=0.0918, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0798, val=0.0919, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0789, val=0.0916, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0782, val=0.0919, patience=4/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0713, val=0.0947, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 16 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0065
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0344
============================================================


============================================================
🔄 Round 17 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0925 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0810, val=0.0915 (↓), lr=0.000500
   • Epoch   3/100: train=0.0797, val=0.0912, patience=1/15, lr=0.000500
   ✓ Epoch   4/100: train=0.0790, val=0.0907 (↓), lr=0.000500
   • Epoch   5/100: train=0.0784, val=0.0904, patience=1/15, lr=0.000500
   • Epoch  11/100: train=0.0753, val=0.0893, patience=2/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0692, val=0.0915, patience=12/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 17 Summary - Client client_89
   Epochs: 24/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0622
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0280
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0909, RMSE: 0.3015, MAE: 0.2625, R²: -0.0656

📊 Round 17 Test Metrics:
   Loss: 0.0909, RMSE: 0.3014, MAE: 0.2623, R²: -0.0649

============================================================
🔄 Round 19 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000250 → 0.000125
   ✓ Epoch   1/100: train=0.0830, val=0.0950 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0814, val=0.0941 (↓), lr=0.000125
   • Epoch   3/100: train=0.0810, val=0.0941, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0807, val=0.0944, patience=2/15, lr=0.000125
   • Epoch   5/100: train=0.0803, val=0.0945, patience=3/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0790, val=0.0946, patience=9/15, lr=0.000063
   📉 Epoch 17: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 19 Summary - Client client_89
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0148
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0503
============================================================


============================================================
🔄 Round 20 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0853 (↓), lr=0.000031
   • Epoch   2/100: train=0.0848, val=0.0856, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0843, val=0.0859, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0840, val=0.0861, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0837, val=0.0863, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 20 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0364
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0695
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2614, R²: -0.0560

📊 Round 20 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2611, R²: -0.0552

============================================================
🔄 Round 22 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0785 (↓), lr=0.000008
   • Epoch   2/100: train=0.0863, val=0.0786, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0861, val=0.0786, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0860, val=0.0787, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0859, val=0.0787, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0855, val=0.0789, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 22 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0255
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.1057
============================================================


============================================================
🔄 Round 24 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0808 (↓), lr=0.000002
   • Epoch   2/100: train=0.0859, val=0.0807, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0859, val=0.0807, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0859, val=0.0807, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0858, val=0.0807, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0857, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 24 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0354
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0280
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2612, R²: -0.0514

============================================================
🔄 Round 26 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 26 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0390
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0573
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0896, RMSE: 0.2993, MAE: 0.2614, R²: -0.0501

📊 Round 26 Test Metrics:
   Loss: 0.0893, RMSE: 0.2989, MAE: 0.2613, R²: -0.0470

📊 Round 26 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2608, R²: -0.0407

📊 Round 26 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2605, R²: -0.0369

============================================================
🔄 Round 32 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 32 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0275
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0155
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2604, R²: -0.0356

============================================================
🔄 Round 34 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 34 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0257
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0192
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2602, R²: -0.0335

============================================================
🔄 Round 36 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 36 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0224
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0249
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2601, R²: -0.0332

📊 Round 36 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2601, R²: -0.0330

📊 Round 36 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2601, R²: -0.0328

============================================================
🔄 Round 40 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 40 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0252
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0102
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2601, R²: -0.0327

📊 Round 40 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2601, R²: -0.0326

============================================================
🔄 Round 45 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 45 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0256
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0087
============================================================


============================================================
🔄 Round 46 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 46 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0228
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0281
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0327

============================================================
🔄 Round 50 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 50 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0221
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0260
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0326

============================================================
🔄 Round 52 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 52 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0225
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0198
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0327

📊 Round 52 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0327

============================================================
🔄 Round 54 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 54 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0211
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0266
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0327

📊 Round 54 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2602, R²: -0.0329

============================================================
🔄 Round 59 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 59 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0238
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0149
============================================================


============================================================
🔄 Round 62 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 62 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0256
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0083
============================================================


============================================================
🔄 Round 64 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 64 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0167
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0412
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0323

============================================================
🔄 Round 65 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 65 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0234
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0180
============================================================


============================================================
🔄 Round 66 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 66 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0250
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0061
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2602, R²: -0.0320

============================================================
🔄 Round 68 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 68 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0167
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0653
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2602, R²: -0.0320

============================================================
🔄 Round 70 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 70 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0179
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0530
============================================================


============================================================
🔄 Round 71 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 71 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0137
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0485
============================================================


============================================================
🔄 Round 72 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 72 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0262
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0016
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0322

📊 Round 72 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0322

📊 Round 72 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2602, R²: -0.0322

📊 Round 72 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2602, R²: -0.0321

============================================================
🔄 Round 80 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 80 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0182
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0332
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2602, R²: -0.0316

============================================================
🔄 Round 83 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 83 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0242
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0188
============================================================


============================================================
🔄 Round 85 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 85 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0178
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0353
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2601, R²: -0.0309

📊 Round 85 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2601, R²: -0.0310

============================================================
🔄 Round 87 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 87 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0197
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0413
============================================================


============================================================
🔄 Round 88 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 88 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0158
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0418
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2601, R²: -0.0311

============================================================
🔄 Round 89 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 89 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0238
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0059
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0313

============================================================
🔄 Round 91 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 91 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0246
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0047
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0314

============================================================
🔄 Round 97 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 97 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0212
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0182
============================================================


============================================================
🔄 Round 98 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 98 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0235
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0089
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0312

📊 Round 98 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0310

📊 Round 98 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0310

📊 Round 98 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0310

============================================================
🔄 Round 105 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 105 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0115
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0613
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0311

📊 Round 105 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0311

============================================================
🔄 Round 109 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 109 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0220
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0874
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2602, R²: -0.0311

============================================================
🔄 Round 111 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 111 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0180
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0378
============================================================


============================================================
🔄 Round 115 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 115 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0267
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0057
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0307

📊 Round 115 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0307

📊 Round 115 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0306

📊 Round 115 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0305

📊 Round 115 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2601, R²: -0.0304

============================================================
🔄 Round 123 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 123 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0239
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0147
============================================================


============================================================
🔄 Round 124 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 124 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0181
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0287
============================================================


============================================================
🔄 Round 125 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 125 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0185
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0268
============================================================


============================================================
🔄 Round 126 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 126 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0225
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0092
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2600, R²: -0.0299

============================================================
🔄 Round 128 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 128 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0219
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0118
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2600, R²: -0.0299

📊 Round 128 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2600, R²: -0.0300

📊 Round 128 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2601, R²: -0.0299

📊 Round 128 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2600, R²: -0.0298

============================================================
🔄 Round 136 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 136 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0180
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0260
============================================================


============================================================
🔄 Round 137 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 137 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0214
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0133
============================================================


============================================================
🔄 Round 139 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 139 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0221
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0090
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2600, R²: -0.0291

============================================================
🔄 Round 140 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 140 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0267
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0246
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2599, R²: -0.0290

============================================================
🔄 Round 143 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 143 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0225
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0188
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2600, R²: -0.0290

============================================================
🔄 Round 145 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 145 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0147
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0504
============================================================


============================================================
🔄 Round 148 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 148 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0202
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0300
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2600, R²: -0.0289

============================================================
🔄 Round 149 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 149 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0194
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0196
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2600, R²: -0.0288

============================================================
🔄 Round 150 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 150 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0210
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0111
============================================================


============================================================
🔄 Round 151 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 151 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0164
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0352
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2599, R²: -0.0286

📊 Round 151 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2599, R²: -0.0286

============================================================
🔄 Round 153 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 153 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0178
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0236
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2599, R²: -0.0286

============================================================
🔄 Round 155 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 155 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0186
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0195
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2599, R²: -0.0285

============================================================
🔄 Round 156 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 156 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0242
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0137
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2599, R²: -0.0285

📊 Round 156 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2599, R²: -0.0284

============================================================
🔄 Round 159 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 159 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0136
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0387
============================================================


============================================================
🔄 Round 160 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 160 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0213
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0198
============================================================


============================================================
🔄 Round 162 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 162 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0189
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0177
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0279

📊 Round 162 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0279

📊 Round 162 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0279

============================================================
🔄 Round 167 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 167 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0211
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0082
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0279

📊 Round 167 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0279

📊 Round 167 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0280

============================================================
🔄 Round 172 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 172 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0196
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0297
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2599, R²: -0.0280

📊 Round 172 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2599, R²: -0.0280

============================================================
🔄 Round 175 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 175 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0182
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0243
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2599, R²: -0.0280

📊 Round 175 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2599, R²: -0.0280

============================================================
🔄 Round 181 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 181 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0176
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0212
============================================================


============================================================
🔄 Round 185 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 185 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0179
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0220
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2600, R²: -0.0281

============================================================
🔄 Round 187 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 187 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0184
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0188
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2600, R²: -0.0281

📊 Round 187 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2600, R²: -0.0280

============================================================
🔄 Round 190 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 190 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0162
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0323
============================================================


============================================================
🔄 Round 191 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 191 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0187
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0173
============================================================


============================================================
🔄 Round 192 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 192 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0167
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0375
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2600, R²: -0.0281

============================================================
🔄 Round 194 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 194 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0229
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0009
============================================================


============================================================
🔄 Round 196 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 196 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0239
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0094
============================================================


============================================================
🔄 Round 197 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 197 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0168
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0317
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2600, R²: -0.0281

============================================================
🔄 Round 198 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 198 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0176
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0306
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2600, R²: -0.0282

============================================================
🔄 Round 200 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 200 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0104
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0516
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0278

============================================================
🔄 Round 204 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 204 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0204
   Val:   Loss=0.0712, RMSE=0.2668, R²=-0.0075
============================================================


============================================================
🔄 Round 205 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 205 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0173
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0322
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2599, R²: -0.0277

============================================================
🔄 Round 207 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 207 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0186
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0160
============================================================


============================================================
🔄 Round 210 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 210 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0160
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0315
============================================================


❌ Client client_89 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
