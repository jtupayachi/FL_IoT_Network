[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b028d6e-ebe3-40ab-bc62-b99f9c2e69e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a3155a-ed4b-4a5b-9b38-922723d19724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3468e6ba-6ea4-484b-8668-3d69f61f3d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df90e36a-5977-4f8e-9417-d43a5678119d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1cb5e0-55f1-400b-af0b-97bcb156ada5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78bfe404-f2fb-4879-a58c-8b2953af9852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3578c7b9-1b38-4c7a-9be4-8fe5ca819565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f44143-a8d8-4a70-a959-8cf97f7e6852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c810510a-3938-4394-bac4-2f7f6c5cf844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622919e2-cdfa-486c-970d-5b869527f188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af722dc9-c0c2-4633-89bb-2d167e4479c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f78bb02-feef-4a8b-b5e2-4dea5b9eb098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1772443a-b910-40e3-b50c-68ca6064dd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a870af60-d3e2-4e4c-939d-9ca6d8eda050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ca5224-f1e7-4a7d-9f0a-70d02b4fcede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f93da4e-83f8-4a86-98e2-98859dbf3c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116aa7ab-5961-4c47-b8f5-139b43b5260c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44f12fd-d88e-4992-905d-a502020d3ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1503c9f3-d7e6-4814-a879-e7815da1841c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df5e2f8-ca99-4a6d-911a-67f1f2efb740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200b0d2d-33ab-434f-95e6-4c858f3e022f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c5cae95-edc0-4e2a-b13f-587f64c342da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980e6688-337b-425b-b801-1d93bc8a4819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4956dbe8-c23b-4a4e-a5a8-f0ca1a6960de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1632a9-cad5-48e3-8f1c-58da4832c62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b971322b-79d2-40e3-a3c7-30cc79d2435d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f595d52a-5891-4d18-a427-72e8a219cd74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7e8809-62b6-4f81-9863-97c02284a0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0bbfe1-fbf4-4fdd-8364-0504ff3d45db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9ee4ac3-9c88-4452-8b6a-42bb4e1cd532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 245d51c2-3ea6-47d4-8c9e-72b47c2fe709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe1cc16-4895-4aad-8d6b-d40bfd7c4ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a74e9d-382c-4dde-b32c-38bc2c35026b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b0a2217-a8dc-497c-8e97-75cc4b0e87cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 633db192-90cf-4d4d-8a2d-96551b78a4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5e63c3-556b-4ccb-acc5-3d2c9a1e2312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2afc6f-e7c8-42ca-87a4-9e82275506cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed8f9f6-74a7-49e7-bd15-25df32b4cd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b970bf7-86b6-4a20-90f6-ae0b1c09a3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91bc374-f9c6-4fdb-b36d-26afaa4116ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d114c39a-79fd-461c-b42a-e463fc288c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 722e97c6-6fda-471a-83df-35b0607711f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a28e112c-865d-48ec-8263-945f23f9ec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33aeab1-58c9-449a-bb5a-ef2eb02cbd0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21159d6c-727d-430b-8934-1a884e96a254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e30d33a-b034-43da-9e37-26f1a4618991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdad009f-b390-4a66-948c-c8587d8b86ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474602ed-9da7-4f91-82d9-3453e55566c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8856f2e-f926-446d-bb50-1e315639cc1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d6d53d-f771-43c9-8cfa-a62203826e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c83ef77-38ef-4eee-a60a-f895da766419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a63edb3b-d156-4ed3-b3bd-693e5b333d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b1488a-b277-4e82-84a5-9e1a8ab015df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d134308-6d82-4ac2-a126-044c00693cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 278b80ea-4772-4f0a-ae45-b7eef6b0415c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ca4d98-522d-44ba-84e3-70738f6dac7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82af4a82-7076-4f80-93af-0470f013bc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c18576-8b29-4280-b036-2cfe1e60f40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d823e3a7-3994-4ce0-8f6e-74e361ac3f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0370f838-cd3f-4734-bf9e-932ce3fc8411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468b6262-f26f-46dc-8a93-ef199baa53e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46140194-ce0c-445e-a603-b35c1d3f9f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a3e517-75df-4e14-b627-d7b8ce7d8d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5445ff-3b84-4df6-98a8-4563b1984e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f36690-6178-428f-bb0f-6e92de92a8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56196ed4-f61d-450f-9b2b-6a5e59b0fab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe15794-b86c-4cec-991a-69474e80061c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0dfd32-42ed-44c4-b85d-1417d2d49673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619492a8-7986-4959-a7ac-8e2af5121cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66037587-24f6-4ca1-b1e6-54fc10a3c830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63fd0db5-ace0-4e48-8175-0d0a4594d283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efeccae8-e81d-4a80-8bb0-7dd664383875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a12ce040-ef37-4b10-9474-11a1ef129921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6352fb92-6e45-40e9-b23b-2744c6ce35c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea258c5-3a97-4d7b-ba2d-967c760f9289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e36aa42-770e-4542-8c0c-ac58e03304ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a857f7-1a08-4ec8-84df-14ffcbdde299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b06077-4fff-4a73-97af-b7f8c6e94cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a41cb432-99d4-437a-b65f-21c42a5c5fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54bb3f23-5d06-4633-81a7-3a39f2bc6d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4694165-a9d0-4e48-b7c5-b70d9a2c8e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c26cd520-fe77-42eb-be8c-ad704a0625bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ea5eb9-af60-4a7e-8ac2-da5b89fe8897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3419d4a6-f5c8-4f5d-9d84-7b4903bfbbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c1abdcd-27e9-4be2-84ba-049713ffa9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41db20b4-49d6-4dbf-9f89-dd8966652cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2414c14c-358f-4c95-8643-1a67c8b74e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f93e2f6-1b8e-4d97-af84-279d953593c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e408964-b6d0-47fd-a55d-df125a626ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e73185d2-8ef6-4b05-9d86-5dd95b5104fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 379c0b36-af55-4527-b6ac-8bc9ea593e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e97d12-13e7-444e-9e9f-81db6d4deeff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9d5ac4-a67d-4f50-baf3-454e7ba5fe33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2ad25c-23bb-426e-9e01-999b1de2c19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867ab191-5242-4550-86d2-15c4a27e3c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b50ca413-4b1a-4e89-8f49-db0943e45b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d17fb005-9507-4b8c-ade7-0fabec8cb04f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b555c319-2247-444f-9704-557ece46602a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd9af12a-ad6d-46dd-bd2e-d4e91720ae87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21656df8-b7d9-4964-b2c3-706984f2ea04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1040444b-8d8b-41ae-a251-c42d49d7abd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a4f789-546d-48a6-bb91-b12ca034bb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f5d634-1c8e-47b9-90bb-f738e9a6f7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d5959f-c935-41ba-af00-457ff6636f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b64213-62af-4a96-aef0-4f6f5ca728e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe83c4e0-11ae-4aac-be00-80dd952893fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48cb4673-ddbb-40fb-8962-b20b48d040ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2dd0510-fe84-49fc-bad1-74be1a400d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58edd26-27ec-4808-a980-766fa6a1b01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040459eb-70f2-4556-8590-a5d5b6d5da39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 435b3908-1337-4ed4-b4d3-6d95d21a09d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35684591-1e0e-455d-a7de-ede45b0bd37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af7ed3be-b3f9-4ef7-bae5-0e8910876246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15938c38-d7f3-41db-aaef-a19ce8eec0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c08d738-5394-4c9b-971d-2fbe0cb0ae61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62e745d-8318-479e-906c-dd8b63e2252f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680b8fbe-6044-412b-a86d-d77d90b760e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09778da3-d82a-4fd4-8c74-6acdfdfb4386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d64bf4-0570-4541-abb4-443ecac830d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3fc25d-d387-469a-a790-6b3895d5c870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a05c46f-d535-4d1e-b927-8a7b5413966d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141a982b-dc5c-40ce-b01c-25bb8a75b920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb49988-cb4a-4b18-abf3-1954169c153b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec0265c-aa8f-4797-a9d0-23be59b89e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d75a3a5-3ede-486d-ae2b-22f077e801b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 741fe36f-c029-417d-b221-7a4307e641eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d020c0d-edac-49f4-9e77-9311388d185e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 621ca8e3-ef0c-425e-9c9f-0a5a4a7b2423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ee63c0c-a02c-49c3-835f-df535a64dfbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb11294-5719-449b-86a7-7eb3908e1b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101b3ea2-eeb5-4664-bec1-72a7d3183563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b15cd164-ea02-4826-a7de-3835ee892b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5888c03-5064-4ca3-81f3-b57e2055ba89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0364d1f-7566-4da3-ae8a-fc861ef8d100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2b7266-88af-4b7f-9663-2ed25dd337cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a713fc-4c45-4602-8b81-999775a779e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9cf2fdb-7970-4475-9bfc-1f11b7cff4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 215d2798-1f66-418f-a872-1cbaaf191e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0262d5a-1f92-460c-864b-55e78636016b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab17bef4-6c60-4520-8676-1724a3ce32c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eff7199-ae7e-4e92-b6d1-7335296b6cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6d5e17-779a-4b85-89a3-9939950c2727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f361dde-a652-446f-bc26-1b327eb595de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 995099b8-2ac4-43eb-a762-bef340bb3758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025e7b06-e538-493c-85ca-3cdc96c768e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 305fe83c-9a1c-4c25-bd97-b02b0502af75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2649d70d-72e1-4888-be8f-875f1813c4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795ff480-d513-4cbd-8445-ff95d6d8140b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec85fd70-33e0-4ef1-9ba9-108daacb3d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e954fe9-f507-4427-b311-302337edb5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c6c640-67bf-48ba-8389-c7b518493a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d3bef5-d7e8-4413-872b-c4d0325ae57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be3fc93-2e08-474f-a48b-c5cb4e5ab2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8fe2151-83d1-43fc-8701-4f6f41ad83ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9f8f15-c32f-426b-a324-9fc48a9fda69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9a6916-ef25-440a-9578-1c610375c414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f21163b-9fba-41d1-a6e1-df5d500d3a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55fbc1bc-ca76-4518-b9bc-5395e5da3db4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(1156, 24), y=(1156,)
   Test:  X=(290, 24), y=(290,)

⚠️  Limiting training data: 1156 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  281 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1480, val=0.0884 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0808, val=0.0800 (↓), lr=0.001000
   • Epoch   3/100: train=0.0820, val=0.0801, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0809, val=0.0800, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0811, val=0.0802, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0800, val=0.0814, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 3 Summary - Client client_8
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0051
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0070
============================================================


============================================================
🔄 Round 10 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0857 (↓), lr=0.000250
   • Epoch   2/100: train=0.0793, val=0.0856, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0788, val=0.0861, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0785, val=0.0862, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0783, val=0.0864, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0775, val=0.0867, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 10 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0036
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0070
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2550, R²: 0.0108

============================================================
🔄 Round 12 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0791 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0820, val=0.0780 (↓), lr=0.000063
   • Epoch   3/100: train=0.0815, val=0.0776, patience=1/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0812, val=0.0774 (↓), lr=0.000063
   • Epoch   5/100: train=0.0810, val=0.0774, patience=1/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0804, val=0.0777, patience=7/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 12 Summary - Client client_8
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0069
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0047
============================================================


============================================================
🔄 Round 13 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0770 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0833, val=0.0762 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0830, val=0.0756 (↓), lr=0.000016
   • Epoch   4/100: train=0.0827, val=0.0751, patience=1/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0824, val=0.0747 (↓), lr=0.000016
   • Epoch  11/100: train=0.0817, val=0.0734, patience=1/15, lr=0.000016
   • Epoch  21/100: train=0.0813, val=0.0728, patience=6/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 13 Summary - Client client_8
   Epochs: 30/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0124
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0016
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2521, R²: 0.0255

============================================================
🔄 Round 14 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000016
   • Epoch   2/100: train=0.0790, val=0.0862, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0788, val=0.0861, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0787, val=0.0860, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0786, val=0.0859 (↓), lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0783, val=0.0857, patience=6/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 14 Summary - Client client_8
   Epochs: 20/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0105
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0226
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2535, R²: 0.0257

============================================================
🔄 Round 19 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0797 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0803, val=0.0796, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0802, val=0.0796, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0802, val=0.0796, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0801, val=0.0795, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0799, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 19 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0103
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0020
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0518

📊 Round 19 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2477, R²: 0.0592

============================================================
🔄 Round 21 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 21 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0183
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0298
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2478, R²: 0.0592

============================================================
🔄 Round 26 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 26 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0119
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0160
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2495, R²: 0.0458

📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2499, R²: 0.0430

📊 Round 26 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2500, R²: 0.0422

============================================================
🔄 Round 33 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 33 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0145
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0221
============================================================


============================================================
🔄 Round 34 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 34 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0162
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0116
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: 0.0409

============================================================
🔄 Round 36 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 36 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0168
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0015
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2502, R²: 0.0403

📊 Round 36 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2502, R²: 0.0403

📊 Round 36 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2503, R²: 0.0403

============================================================
🔄 Round 43 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 43 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0073
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0392
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2503, R²: 0.0403

📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2503, R²: 0.0402

📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2503, R²: 0.0403

============================================================
🔄 Round 48 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 48 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0117
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0332
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0403

============================================================
🔄 Round 51 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 51 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0193
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0038
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2503, R²: 0.0403

📊 Round 51 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0404

============================================================
🔄 Round 54 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 54 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0158
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0183
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0404

============================================================
🔄 Round 55 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 55 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0120
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0048
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0404

============================================================
🔄 Round 56 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 56 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0159
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0169
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0405

📊 Round 56 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0405

============================================================
🔄 Round 59 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 59 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0182
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0007
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0405

📊 Round 59 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2503, R²: 0.0404

============================================================
🔄 Round 62 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 62 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0118
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0355
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2503, R²: 0.0402

📊 Round 62 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2503, R²: 0.0401

============================================================
🔄 Round 65 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 65 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0161
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0138
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0398

📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0398

📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0398

============================================================
🔄 Round 69 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 69 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0174
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0051
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0398

============================================================
🔄 Round 71 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 71 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0143
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0229
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0399

============================================================
🔄 Round 72 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 72 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0168
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0073
============================================================


============================================================
🔄 Round 73 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 73 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0204
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0157
============================================================


============================================================
🔄 Round 76 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 76 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0168
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0132
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0398

📊 Round 76 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0397

📊 Round 76 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2504, R²: 0.0397

============================================================
🔄 Round 79 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 79 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0179
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0110
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2504, R²: 0.0394

============================================================
🔄 Round 82 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 82 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0176
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0106
============================================================


============================================================
🔄 Round 84 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 84 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0110
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0342
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2505, R²: 0.0389

📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0391

📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0392

============================================================
🔄 Round 91 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 91 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0151
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0206
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0392

📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0393

📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0392

📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0392

============================================================
🔄 Round 98 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 98 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0151
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0242
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0391

📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2505, R²: 0.0390

📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2506, R²: 0.0390

📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2506, R²: 0.0389

============================================================
🔄 Round 107 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 107 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0164
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0114
============================================================


============================================================
🔄 Round 108 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 108 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0164
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0140
============================================================


============================================================
🔄 Round 112 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 112 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0119
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0218
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2506, R²: 0.0389

📊 Round 112 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2506, R²: 0.0388

============================================================
🔄 Round 114 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 114 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0160
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0194
============================================================


============================================================
🔄 Round 115 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 115 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0113
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0301
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2506, R²: 0.0387

📊 Round 115 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2506, R²: 0.0387

📊 Round 115 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2506, R²: 0.0386

============================================================
🔄 Round 119 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 119 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0150
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0215
============================================================


============================================================
🔄 Round 124 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 124 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0163
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0034
============================================================


============================================================
🔄 Round 125 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 125 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0159
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0077
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2507, R²: 0.0381

============================================================
🔄 Round 128 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 128 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0190
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0028
============================================================


============================================================
🔄 Round 131 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 131 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0187
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0043
============================================================


============================================================
🔄 Round 133 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 133 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0158
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0155
============================================================


============================================================
🔄 Round 134 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 134 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0124
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0258
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2507, R²: 0.0379

📊 Round 134 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2507, R²: 0.0378

📊 Round 134 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2507, R²: 0.0377

📊 Round 134 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2507, R²: 0.0375

📊 Round 134 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2507, R²: 0.0375

============================================================
🔄 Round 141 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 141 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0198
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0053
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2508, R²: 0.0375

📊 Round 141 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2508, R²: 0.0375

============================================================
🔄 Round 144 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 144 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0135
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0181
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2508, R²: 0.0375

============================================================
🔄 Round 146 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 146 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0162
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0112
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2508, R²: 0.0375

============================================================
🔄 Round 148 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 148 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0124
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0293
============================================================


============================================================
🔄 Round 149 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 149 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0157
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0047
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2508, R²: 0.0374

📊 Round 149 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2508, R²: 0.0373

============================================================
🔄 Round 151 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 151 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0074
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0489
============================================================


============================================================
🔄 Round 152 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 152 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0221
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0186
============================================================


============================================================
🔄 Round 153 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 153 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0140
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0209
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2508, R²: 0.0372

============================================================
🔄 Round 155 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 155 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0167
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0092
============================================================


============================================================
🔄 Round 158 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 158 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0109
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0202
============================================================


============================================================
🔄 Round 159 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 159 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0087
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0455
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0369

============================================================
🔄 Round 161 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 161 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0124
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0168
============================================================


============================================================
🔄 Round 162 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 162 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0187
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0013
============================================================


============================================================
🔄 Round 163 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 163 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0174
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0056
============================================================


============================================================
🔄 Round 164 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 164 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0113
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0293
============================================================


============================================================
🔄 Round 165 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 165 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0142
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0197
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0367

============================================================
🔄 Round 167 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 167 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0149
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0083
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0367

============================================================
🔄 Round 169 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 169 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0152
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0115
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0367

============================================================
🔄 Round 170 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 170 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0174
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0071
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0368

📊 Round 170 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0368

📊 Round 170 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0369

============================================================
🔄 Round 174 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 174 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0129
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0259
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2509, R²: 0.0369

============================================================
🔄 Round 176 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 176 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0148
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0136
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2509, R²: 0.0370

📊 Round 176 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2509, R²: 0.0370

📊 Round 176 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2509, R²: 0.0370

============================================================
🔄 Round 184 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 184 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0206
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0081
============================================================


============================================================
🔄 Round 186 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 186 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0153
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0147
============================================================


============================================================
🔄 Round 187 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 187 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0169
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0111
============================================================


============================================================
🔄 Round 188 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 188 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0168
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0008
============================================================


============================================================
🔄 Round 190 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 190 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0128
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0045
============================================================


============================================================
🔄 Round 191 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 191 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0198
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0002
============================================================


============================================================
🔄 Round 192 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 192 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0136
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0204
============================================================


============================================================
🔄 Round 194 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 194 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0122
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0302
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2510, R²: 0.0371

============================================================
🔄 Round 195 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 195 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0156
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0144
============================================================


============================================================
🔄 Round 196 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 196 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0131
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0191
============================================================


============================================================
🔄 Round 197 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 197 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0131
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0185
============================================================


============================================================
🔄 Round 199 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 199 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0142
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0252
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2510, R²: 0.0369

============================================================
🔄 Round 202 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 202 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0176
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0089
============================================================


============================================================
🔄 Round 203 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 203 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0126
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0042
============================================================


============================================================
🔄 Round 205 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 205 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0125
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0288
============================================================


============================================================
🔄 Round 210 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 210 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0215
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0102
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2510, R²: 0.0367

❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
