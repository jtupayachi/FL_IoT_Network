[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869990ef-18dc-4297-a9d0-b806c3070b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b882e4e-ee10-4c63-85ae-23815249a137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4754aa6b-30eb-497d-b4b7-8b23004d3244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43edebf2-68d5-466e-9f7d-d3668e49b5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcf6d007-fbe3-43cd-b5ef-f00beee7e377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d934f042-c72f-4dc8-88fa-adfdfd0f13e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dc9d3eb-37de-4d7c-95e5-7fe662211268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d8abdad-e605-4ba1-9f50-4828226ec18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d937fad6-41c6-4236-a274-e60f3a20c2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7134858-d5fe-4adf-9b0a-4c6280e2a6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc438bff-6051-4fdb-9bc5-cd5f6966754a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c67bac1-adec-4503-9dc3-a2fe4448e25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5535dd88-564d-428a-b664-cd10d9a4dc8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791e537a-b724-42b1-acc1-78b698fe4699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ca96cc-6d25-41c5-b16a-e2b6e8bdee18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a5e02ac-8414-426f-b158-9574c9214d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504cbe71-4a3d-4874-8805-7d2945ecb6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3cce971-7ab3-49aa-8131-8afd359fb110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b0dc9a-cd11-47ec-b738-8fc7b7694fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 532ba41b-4e6b-4f4f-9593-fad246ea42ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdfab698-d185-4b09-aa12-d4e90f108a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2202e38c-e92a-4d36-a365-0a6344a80439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe10efc6-3d26-44dd-9570-ae4c85350972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34672a6c-4730-4464-8775-7d87d4b5eeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0371729-86e0-4a0f-b2fe-45e9eb912e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e05e2bc-59e8-4d5e-bffd-f4cca0e0c324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f105d353-6ce0-4a19-bcdd-e13140c6c313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371700de-fab1-4c23-96fe-5b843c9a201d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d779258-621e-4fee-9418-67c5e490bb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81e35172-3535-47e6-975e-7812d946e198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600b1843-ba86-4688-b8df-e859f8526778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b59fe8-cd39-4dfd-9581-0f77f1f20be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58530c44-fdd0-4c21-adce-84b6583d8485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48800103-9707-41c6-8912-1c9241dd299d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13484a6-e4d6-4ed7-9889-280fe5357523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24774d94-9ea7-4211-8567-220b14b0a9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0db660c-623c-4422-a76c-0a731c159f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c630ad0-5536-4708-9aea-e90f6354d24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fa31a08-1336-49cd-9487-13d954549fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c337bef5-6025-4cd9-b4e2-ae1c053c33c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3fbfc4-2569-4174-9d5e-be981b3980f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba920b0-6e38-47cb-bb7c-56cd95075d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e15c6c-0c5d-47cf-8b8f-33f970f9e0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d91af7-8b37-4aec-bfa2-a42d85d37452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23401a11-fa78-467e-a46e-805063c9bd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ad91cf5-49f6-4faa-968f-af6cc3f6a3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7a6dc4a-4b9e-44b0-bb4b-d7761894b36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1a9dfd-4624-42c3-a2a7-c84dd828fdca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8253fc6-b3ea-4388-96e0-5d8548bb5e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e03f7dd-e4dd-4538-a33a-fd74a4722693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43cac6a4-18e3-4265-ab83-f9b08311b0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2cb108-8b23-4cf0-bc8a-49857754378f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919420e9-7aeb-470c-9006-16761ce0b528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b49a81-c7bc-4983-b73e-b420f9e34777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362a75b7-63c9-43f7-a2a9-1559da264f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64223269-cf2e-4623-bb91-572f1b252615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c5ec8dc-d9a8-4dc7-8379-01db0a02451d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2adf37a2-4733-48c4-a06b-83e5166f3ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc24016e-3692-489f-9285-62af2eae9dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cebe8ea-9702-4655-b373-71030205ef0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669508bc-e9a5-4a0f-bdac-5f708438593d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 903c2023-c816-400b-9f65-9024cdbb904d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7705bf0-c573-4b1f-bb8d-65eeb0f75a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41b410c-6d84-42e7-b7a6-5b66488096c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918987be-460b-4e41-a699-c0c704ec8f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76e4af8-6173-4052-a0d3-477a270d480a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aecb3c0-870d-4a52-ba47-b57678fbc2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63d31eb8-bd65-4d2c-acb4-e7174e62ad76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd335c7-7b9d-4c36-8cf1-5972126334fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eac5586-e7fd-43e6-870b-4c78133e3faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c3a6ad-8e40-4ba3-ba96-a29a49473da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 459a2715-b22e-4f95-bf04-fe5bc4f4713f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6cbde33-d864-4ad6-bfe0-fd665f467d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5544b3d4-270d-414f-80ca-b486acfd6c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea1ff37-7f0b-48f7-8fc4-5ded9cca4317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2385c643-3e38-4c19-aec7-039ce056c8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6239b77-3448-4de4-9971-7b2e43dc2bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf049c3-0ac4-4ca8-8e01-994549c3c2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a707ce-17e8-4ebf-ad65-013981cf9c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f85c03a-2d97-4989-a5ed-8fd50ce6acc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab3cea7-953a-4b19-af62-85dbb3664158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17d843f-bbc3-4ae5-b520-d8d725adddd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d80acd-02be-44c3-9db5-068a3b192f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cba41f3-2492-48d0-af8b-084b14db2bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a397cfb2-14a6-473a-879c-bf52789da9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 981a9207-8e98-456a-a292-f40a3e1d726f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66437b1-0596-4bc8-94fd-780a8ff59324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e47167d-cd39-4203-a296-d512477b111d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1247d0a-f564-4127-93be-b29891916c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a16f363-68e7-4e46-b537-5e25000d562a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02b9b73-5305-47cb-88bb-a79a48fbe964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b59b93-9f89-467b-b844-67487b59c73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2080be8b-d54c-447a-bc2d-9d11a5a72158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74513cda-eb19-4e40-96a2-13e1fa534931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc07d62-38fb-46b7-8598-551838354192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732d98d7-0959-43ee-93d2-4e717b773b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0536080-1c32-4f8f-8c6a-5d8d8811f9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a64eddb-4186-4a3e-a4e9-cfd3898d02b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2fc98a4-520b-4957-82f5-eba9d72d1a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ecc47ca-85b9-4321-9557-3dbece1b9e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a86bc1d-2912-45b1-8272-3e2c0e556c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8850930-56da-406e-adb9-983fa7a594d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31043757-cc6b-4692-8528-441900ebe71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0ce30d-b180-43d4-a031-e0770324bce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2c00db-8c6c-4e1f-a4e4-9b15c98d8d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc2ec52-762f-4683-8658-140e84249743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530f9dff-5bc0-4592-b3e5-94bddee1aa68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17141ec-dd45-4183-b803-42985b3ad189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b346d8-be14-4627-b163-22d5262cbda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbc77717-6c94-4546-b481-97c4fe511b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 300c138c-ebee-4ff8-a911-f7e0e47811ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfdaba6d-1f32-4682-8121-45978cd21995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94bcc475-7517-4e01-b047-1c597e019d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f033c779-11d9-44dd-8607-95c25e6422ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbabfd2c-2ced-46ba-a73a-e75709d99d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33cfd93-8611-4b97-97f6-d0098e4d0cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83cc99c-4af1-4249-8734-1cd1e7960a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495b1d3f-2bc3-4eef-9ad1-8fb5ad956521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71bcf6b4-3fa6-43b9-a575-1d4a53be40f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192a9b73-6479-4597-8dcd-c06cb50e2cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d2a840-c282-4541-969a-7f63c3be5e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d2a368a-353d-4294-ac26-3c76b3a007cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa7d680-e84c-4059-9356-3e7df8313a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60812ea3-1bf0-43d4-9156-344f35a9b5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad0c35c-3b3f-46e2-9c32-da32cdacdd98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e6acbc-12ee-402c-9496-a7090b576f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75075530-0324-4dc8-8407-5d5cadda2a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608d3225-9bdc-4f9d-8583-f9e45b187ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78b71d2-48cf-4634-86d0-5ab0354c1327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b768253-5e82-4364-b36e-13596068188d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 756d8599-78d4-46f7-af14-34eb4637e3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef5192b8-efa1-43cf-b54d-97f0943c9c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc764b04-1783-4de4-b3f8-1ddb21895975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae37caa1-8764-4841-9b40-585e9c751e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cd818a6-5f72-497c-8575-3df629631cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e015a30-8465-45d8-9aaa-f879b2263219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed88cff-d737-4bb2-bd73-4c77620f8644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0af011c-ff06-4d84-92c8-f3ccf8e67876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec9cac8-1128-4f9e-82df-98b2be4bb382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9310bfc-b3b0-426b-9dae-e771e3bc663e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3844b32d-12e4-491b-b8cb-361b3f39385c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89fef53c-f59a-4b43-ab5a-f60e84ae5430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e35397cd-f892-4f19-9011-2d4e8d823a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c44320-878d-47ac-ba64-cbefc66c9fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9c1c678-7bf0-4f47-aecf-27c84c1bd75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4111991-9cc2-45a8-9ebb-5b1afb4eb599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78139217-50fc-4cb5-9f2c-dd1b510af71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233563ba-0fe8-4a9d-8428-b38781485387
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_91
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_labels.txt

📊 Raw data loaded:
   Train: X=(563, 24), y=(563,)
   Test:  X=(141, 24), y=(141,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 554 samples, 5 features
   Test:  132 samples, 5 features
✅ Client client_91 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 25 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0747 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0805, val=0.0740 (↓), lr=0.001000
   • Epoch   3/100: train=0.0777, val=0.0754, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0768, val=0.0749, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0748, val=0.0757, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0676, val=0.0778, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 25 Summary - Client client_91
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0987
   Val:   Loss=0.0740, RMSE=0.2719, R²=0.0661
============================================================


============================================================
🔄 Round 27 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0823 (↓), lr=0.000250
   • Epoch   2/100: train=0.0821, val=0.0821, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0799, val=0.0823, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0764, val=0.0827, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 27 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0372
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0047
============================================================


============================================================
🔄 Round 28 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0858 (↓), lr=0.000063
   • Epoch   2/100: train=0.0818, val=0.0859, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0816, val=0.0860, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0813, val=0.0860, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0811, val=0.0861, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0803, val=0.0865, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 28 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0161
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0373
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0216

============================================================
🔄 Round 30 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0937 (↓), lr=0.000016
   • Epoch   2/100: train=0.0801, val=0.0936, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0800, val=0.0936, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0800, val=0.0936, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0799, val=0.0936, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0797, val=0.0935, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 30 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0293
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0124
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0214

============================================================
🔄 Round 33 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0967 (↓), lr=0.000004
   • Epoch   2/100: train=0.0792, val=0.0967, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0792, val=0.0966, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0792, val=0.0966, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0792, val=0.0966, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0792, val=0.0966, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 33 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0210
   Val:   Loss=0.0967, RMSE=0.3109, R²=0.0362
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2397, R²: 0.0208

============================================================
🔄 Round 35 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 35 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0234
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0266
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2397, R²: 0.0206

📊 Round 35 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2397, R²: 0.0207

============================================================
🔄 Round 39 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 39 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0179
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0344
============================================================


============================================================
🔄 Round 40 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 40 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0235
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0288
============================================================


============================================================
🔄 Round 42 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 42 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0247
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0246
============================================================


============================================================
🔄 Round 43 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 43 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0226
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0018
============================================================


============================================================
🔄 Round 46 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 46 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0289
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0023
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0212

📊 Round 46 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0213

📊 Round 46 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0214

📊 Round 46 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0214

============================================================
🔄 Round 51 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 51 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0292
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0165
============================================================


============================================================
🔄 Round 56 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 56 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0249
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0190
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

📊 Round 56 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

============================================================
🔄 Round 59 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 59 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0264
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0184
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0219

============================================================
🔄 Round 61 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 61 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0210
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0166
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0217

📊 Round 61 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2396, R²: 0.0216

📊 Round 61 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0213

============================================================
🔄 Round 68 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 68 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0296
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0147
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0212

============================================================
🔄 Round 70 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 70 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0248
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0231
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0214

============================================================
🔄 Round 72 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 72 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0268
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0015
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0214

📊 Round 72 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0215

============================================================
🔄 Round 74 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 74 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0222
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0270
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0216

📊 Round 74 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2396, R²: 0.0216

📊 Round 74 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0214

📊 Round 74 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0214

============================================================
🔄 Round 80 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 80 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0238
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0247
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0209

============================================================
🔄 Round 83 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 83 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0187
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0136
============================================================


============================================================
🔄 Round 85 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 85 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0243
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0168
============================================================


============================================================
🔄 Round 86 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 86 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0212
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0007
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2398, R²: 0.0208

📊 Round 86 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2398, R²: 0.0208

📊 Round 86 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2398, R²: 0.0209

📊 Round 86 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0211

📊 Round 86 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0211

📊 Round 86 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2397, R²: 0.0211

============================================================
🔄 Round 99 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 99 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0255
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0156
============================================================


============================================================
🔄 Round 100 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 100 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0219
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0184
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2398, R²: 0.0211

📊 Round 100 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2398, R²: 0.0210

============================================================
🔄 Round 104 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 104 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0180
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0422
============================================================


============================================================
🔄 Round 106 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 106 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0245
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0198
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2398, R²: 0.0210

============================================================
🔄 Round 107 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 107 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0270
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0114
============================================================


============================================================
🔄 Round 108 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 108 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0164
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0452
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2398, R²: 0.0209

📊 Round 108 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2398, R²: 0.0210

📊 Round 108 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2398, R²: 0.0208

📊 Round 108 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2398, R²: 0.0207

============================================================
🔄 Round 115 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 115 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0240
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0114
============================================================


============================================================
🔄 Round 118 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 118 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0230
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0227
============================================================


============================================================
🔄 Round 121 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 121 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0219
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0227
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0200

📊 Round 121 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0198

📊 Round 121 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0197

============================================================
🔄 Round 126 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 126 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0204
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0336
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0196

============================================================
🔄 Round 127 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 127 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0177
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0172
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0196

============================================================
🔄 Round 128 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 128 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0199
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0364
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0196

📊 Round 128 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0196

📊 Round 128 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2399, R²: 0.0197

============================================================
🔄 Round 131 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 131 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0199
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0275
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2400, R²: 0.0195

📊 Round 131 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2400, R²: 0.0195

============================================================
🔄 Round 136 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 136 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0171
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0371
============================================================


============================================================
🔄 Round 137 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 137 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0183
   Val:   Loss=0.0949, RMSE=0.3080, R²=0.0346
============================================================


============================================================
🔄 Round 140 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 140 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0278
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0017
============================================================


============================================================
🔄 Round 141 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 141 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0221
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0133
============================================================


============================================================
🔄 Round 142 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 142 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0153
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0139
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

============================================================
🔄 Round 144 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 144 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0230
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0198
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0193

============================================================
🔄 Round 145 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 145 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0259
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0040
============================================================


============================================================
🔄 Round 151 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 151 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0239
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0155
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

📊 Round 151 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

============================================================
🔄 Round 154 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 154 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0258
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0020
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

📊 Round 154 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

📊 Round 154 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

============================================================
🔄 Round 157 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 157 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0198
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0707
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

📊 Round 157 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

============================================================
🔄 Round 160 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 160 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0160
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0439
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

============================================================
🔄 Round 161 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 161 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0196
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0274
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

📊 Round 161 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0190

📊 Round 161 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0190

============================================================
🔄 Round 164 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 164 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0275
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0179
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0190

📊 Round 164 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0190

📊 Round 164 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

============================================================
🔄 Round 170 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 170 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0212
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0241
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0191

============================================================
🔄 Round 172 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 172 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0230
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0138
============================================================


============================================================
🔄 Round 173 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 173 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0137
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0537
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

============================================================
🔄 Round 174 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 174 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0295
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0644
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

📊 Round 174 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

============================================================
🔄 Round 180 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 180 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0226
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0151
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

📊 Round 180 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

============================================================
🔄 Round 182 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 182 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0184
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0199
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

📊 Round 182 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0193

============================================================
🔄 Round 186 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 186 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0207
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0241
============================================================


============================================================
🔄 Round 187 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 187 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0191
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0115
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

📊 Round 187 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

============================================================
🔄 Round 190 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 190 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0261
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0122
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0192

============================================================
🔄 Round 191 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 191 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0209
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0270
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0190

============================================================
🔄 Round 195 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 195 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0218
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0220
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0190

============================================================
🔄 Round 197 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 197 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0274
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0011
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0189

📊 Round 197 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2400, R²: 0.0189

============================================================
🔄 Round 201 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 201 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0248
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0122
============================================================


============================================================
🔄 Round 203 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0638 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0638, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0638, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0638, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0638, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0638, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0638)

============================================================
📊 Round 203 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0171
   Val:   Loss=0.0638, RMSE=0.2525, R²=0.0211
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2401, R²: 0.0187

📊 Round 203 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2401, R²: 0.0186

============================================================
🔄 Round 207 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 207 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0221
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0079
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2401, R²: 0.0186

============================================================
🔄 Round 210 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 210 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0272
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0030
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2401, R²: 0.0185

============================================================
🔄 Round 211 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 211 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0208
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0080
============================================================


❌ Client client_91 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
