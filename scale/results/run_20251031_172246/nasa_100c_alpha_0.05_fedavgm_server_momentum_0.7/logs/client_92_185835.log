[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa92bf5-b804-4d70-909e-7d91db11930f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9355d49-0996-4a0b-9c9b-49833604bfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2643ce57-776a-4c7c-bffb-08f4f5832d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2ee7ff-9751-4cf4-bc45-dd577264ef13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b9ec8d6-d1b8-4597-81e9-82fabc4054dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8360b0c-3d0e-490f-8ff6-5e1f54de67ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0fca058-f7ab-4e5c-be13-168468e13b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95cd48c5-28f0-467a-ab2d-d2461b8d99e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e8eb5b-82eb-4cdb-a7e3-5c751a5deca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456f7edf-9daf-47a5-b323-dc70b1157f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 391c78fa-9c37-442c-aece-282c02557937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c8b9ab-cd98-48a6-8f2e-6031a633c38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 920c444a-e59c-4686-89b8-3f15dca7198b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bec81d-ecb1-48fa-b1ca-552bf90bb68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f5f1b1-29ed-41ab-beb1-b8115b9773fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c259aa14-57c6-4e20-b8bb-3b0d64eadde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33eb7752-7565-4dc7-98c6-b0fb078e9733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4399b03-af10-46a7-a26f-1b61d924de41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4498cabc-07c3-454f-93b8-f58bfb2b00f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c67c52-f27f-429c-9830-d64fa2a22704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5320823-357c-4337-91e3-d9dd57061838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686f83df-452c-413c-a383-5d5c9a16f8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58681051-bfef-4f55-b99e-a057c0fea27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c10a8ba-a504-4fa8-a350-dbe013c56764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c2a18c-f076-44c8-95ed-7576f724aab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e76417-a8af-4fee-9c76-95f0cfcc345f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d21b275-1c66-443f-ad98-f2dced615c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90cf2ec6-7a14-4824-b2f3-f75391948160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b40a9164-0d26-4a0e-8fc8-7979ec4b0cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a19f20-5967-4c10-87e7-0ac82c5b88b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469f74ba-33f4-4453-9278-94f321a75b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b812ebd5-8ea0-4a52-b599-31bd01fce575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c39625-715a-441f-8d5b-feec9d962092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5dfec81-b8c9-4b81-b712-0908bae0354a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f91dfeb-671c-4e22-b886-e9e04402a0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e1089d-8def-4a6f-9402-53b2bc791a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 001a3171-f5de-42ff-ad99-afb697205e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1c11ce-093d-491c-9074-07c7e2786188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909d05b7-4c9a-4dbc-93bd-ab8d61a08b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46a57144-f781-4652-b4e8-2968f347e5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7c64c1-fdb0-4068-8bb5-446738db3705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d80089b-18f0-4bfd-a55c-24909ed0781f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c83df12-7f22-45a0-aff7-3fb6c9a459df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d175fa0-ecef-42e5-a3f5-adbe9486ed88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f90e04-745e-4f16-af69-b979633d154b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 817a0ff8-3ae9-45e1-b740-d3d00fa122e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715f567e-a31f-435c-a651-2e6b056f776d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dafe84f7-a218-4d59-b37a-206a296fce5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6186e970-9083-4623-80a1-b4bbcaaa0461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9686b50-c302-4ec8-a02c-790a1f55517e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39780920-8ff0-4b6e-a3b7-d9c990b201bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8819d0d9-7074-4751-a57f-e0e1342ab6af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76daf69c-f194-4a3d-aa55-b1f5c5c50bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3927f13a-0592-487b-80f9-9eead8cb3807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd563622-13c2-4cba-a843-0e47ccc739ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f74393-b38d-408f-ab8c-65ea17127ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa59a78f-c393-48e5-9b6d-b50d8225674e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88a68fd1-59e8-4cc8-b3e4-03b96991b187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a0cedb-b853-42c1-997c-f245b787b705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b7ae9f-0d82-446b-9f3c-e570422e3978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 202f9588-8c19-40b4-958e-1883aa4a63fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c41a5915-a9f0-4050-9cfc-7f331a3e0696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5328ef75-c3a9-4712-9276-0c9d83b214af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c736fad0-47b9-4071-9e06-ff98194d34dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0c9aeb1-d300-452b-a5cb-b2c54831d2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9036a9-dc85-4b62-94e5-eb8e03c4e00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e16a73-09d0-47ff-b481-9aee12aaf987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba744c2-1b55-401b-8371-80b5ae7e9d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e4a2ee-5376-49c7-9c1e-f8374fc6274b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcf94f2-eea7-4561-a670-08561fb69c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ed1f53-d463-4ee5-afe7-d2c1fbfceb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f43dfde-5250-4424-a6c6-867a3d7515a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db74338-8dc6-4b68-b5ab-d69b139cdb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14951c3-f717-4fb6-a6ab-94dbfd533e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ade76ae-b5ff-420c-918a-315317656307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b1c2e5-ffa0-46f0-a266-acd8f335c04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c16012a-a4d6-475e-bd4c-9fe8954480b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85340df5-e80f-47b9-b657-648efaf2110d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ca63a4-4f3d-49d4-a14f-722f8499cf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bda2774-4986-44a2-bbae-5fd2c770ebe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76fc2a4f-5944-4a3f-9422-d2856f551aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5a4881-8caf-45ff-8593-90024f85be5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c19a8ee-606a-4a5e-86f1-2f790ffd8e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c1162a-b93a-4057-b43e-f2af05b43b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c67fd4-b58a-4083-a114-7a39c0bbfe0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d93000a-d4b8-49fc-a183-83bbb14bb09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d36a9bbe-37ef-412f-b479-5af3cb6fd615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66b5124c-43d4-4a6e-876f-eb88504a206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67b08e0a-e1cf-47ce-bb0b-c59b7c7fbacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e379b2ba-91d5-40cf-a981-336c682d580e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 360c1b20-195a-4d59-82ca-d750ea83c577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f305b8b-a73e-4e23-a49a-525f338ab651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb593a0-a459-485e-aa0b-9438f8d0a31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ada02c-5116-4136-b78d-4f0dfcd5ace7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e63b788-1061-41fb-82df-881478aedf3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c3ad57a-3468-429f-8bc1-d8c45ad80143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 069ab631-9427-4653-977d-767581a6fc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb60dfaf-9190-4ea8-aed4-30dfa316f6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90618531-a456-40a4-b6fb-604f1e9fcea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562b04a3-2ab2-4bff-847e-197ca089dea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30fe8422-0dce-465b-a59a-b66f8dcd71e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8420f89-4087-4bf7-b520-c940dc9af6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b6eef3-95cd-48db-bd7a-d2d672740513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8794eb5-6f17-41ee-9d52-49fb0d48a1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d0edc0-4808-4d9e-8703-7ea6c273e362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edca293e-b4fd-40af-84aa-b00c0658ac85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e4e8a1-6111-424a-8965-efd1196b35d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4211e93-26eb-4241-8344-3f4bf0266ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752f4b5c-ba24-4ec5-9ea1-6fddd67538fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67eede7d-aabc-4f54-bc32-ee8bf49148bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb18e2a1-211b-4c93-920d-12c9ac981f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b287b5b0-f7e7-49a4-8504-6f8e976925f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8331d9bf-1f0a-434f-ba95-5fe947783b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8eb923c-b56b-4df2-9747-ead64a8f8fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e786cf8-ff1d-46c1-939e-3bb37ab51792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff6fb395-8a3f-4493-bb41-344b67789d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10dbae8-4b9a-4136-9fc0-1b0c08edb3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b79555b-9b52-463d-adaf-187cbe4c456a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13caabb7-3ef3-46b5-9d34-ed21a4100a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 418fa463-f108-409a-8ed3-3a9e44f5a55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460a5809-cff9-4ec7-885b-2d42bd292903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6faeda1f-a405-4a35-b914-0058e69cc839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a05227d-d0cf-4f6b-b119-12fa2368429d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acdb5aee-2d40-4c09-8d06-7c9ee2e17469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7991cedf-d82c-4786-b14d-ad55a401315d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3120afdc-0db2-4e79-88ad-8fb35dd4f7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a7580c-5cdb-4d63-a671-e382bba8b9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774a6947-a5e0-445a-b7a5-fa74b0cc1f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee62d4be-5402-4536-af80-5fe937a9ea1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0296e2d9-c63a-4915-b4a8-1fbac7ae6c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e06998c-3f60-46ee-9bab-62b0e7eb64c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0b0831-bded-48a8-b64c-0ad83fa3f08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c87d2a-bd5a-4a27-b8a0-d0d95657d0b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f40384e-29d2-4829-9d42-4ffce50d74fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb007f9b-9d7c-4ab6-8b2a-dea90cdb3767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb238b0-86de-4c78-a1ba-e8ddfec5cdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6aeadbf-f1f4-49cf-a47e-ca7a2e26f689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eaa8299-34e5-4dbc-9d9d-732c238badab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d423487-890b-4888-9451-c4b7af4dbd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7747cb8-2980-450a-9348-98c8ce915031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13b307c9-b8c7-4f15-a792-b4ed444df5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d92f350-6b7e-46a9-82d5-c03ee7d007e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e0e0540-af4f-47ef-9c35-2a62085a1011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a544c83-9f24-4df6-a2f9-4ed41704e4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162b8d78-0fd6-4021-95d1-ae0ce70e9dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c850f797-4cd1-460c-9f7c-dde56eac561a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a673d0-8454-439e-9645-ff369331a807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721a9d8a-b0b3-4e82-bcbe-65f743b9720c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6ebf90-8879-4570-97ae-192cbc1ca0b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e064d46d-ebe4-451a-a968-6653766b7c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158e41a7-2c6b-47e0-9d3a-843021ba5bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e86429-cd5a-4bb5-9e4c-38ffc0ea4d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1576513-e757-417d-832a-e859f136aa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33775aa-0489-428b-9944-19d99353e6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dd415a-a666-48a6-9bd3-6d40a4945314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfea866d-3dd0-40e7-b3ef-677ab4314383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac5b4fb-61e3-4753-9045-46c6ae71718f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ec30c7-2ca8-4cf1-8ae8-a17cb8303fa7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_92
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_labels.txt

📊 Raw data loaded:
   Train: X=(1170, 24), y=(1170,)
   Test:  X=(293, 24), y=(293,)

⚠️  Limiting training data: 1170 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  284 samples, 5 features
✅ Client client_92 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2420, R²: 0.0005

============================================================
🔄 Round 16 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0890 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0782, val=0.0870 (↓), lr=0.001000
   • Epoch   3/100: train=0.0758, val=0.0885, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0751, val=0.0893, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0743, val=0.0898, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0676, val=0.0908, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 16 Summary - Client client_92
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0883
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0288
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2414, R²: 0.0082

============================================================
🔄 Round 17 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0921 (↓), lr=0.000250
   • Epoch   2/100: train=0.0767, val=0.0916, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0756, val=0.0914 (↓), lr=0.000250
   • Epoch   4/100: train=0.0749, val=0.0914, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0745, val=0.0912, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0730, val=0.0912, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 17 Summary - Client client_92
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0565
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0343
============================================================


============================================================
🔄 Round 18 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0868 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0805, val=0.0860 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0797, val=0.0854 (↓), lr=0.000063
   • Epoch   4/100: train=0.0792, val=0.0850, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0788, val=0.0847 (↓), lr=0.000063
   • Epoch  11/100: train=0.0769, val=0.0833, patience=1/15, lr=0.000063
   • Epoch  21/100: train=0.0758, val=0.0826, patience=5/15, lr=0.000063
   • Epoch  31/100: train=0.0749, val=0.0821, patience=6/15, lr=0.000063
   • Epoch  41/100: train=0.0741, val=0.0817, patience=4/15, lr=0.000063
   • Epoch  51/100: train=0.0734, val=0.0814, patience=14/15, lr=0.000063
   • Epoch  61/100: train=0.0726, val=0.0810, patience=9/15, lr=0.000063
   • Epoch  71/100: train=0.0717, val=0.0806, patience=6/15, lr=0.000063
   • Epoch  81/100: train=0.0708, val=0.0803, patience=1/15, lr=0.000063
   • Epoch  91/100: train=0.0698, val=0.0801, patience=11/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 18 Summary - Client client_92
   Epochs: 95/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0707, RMSE=0.2659, R²=0.1362
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0914
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2420, R²: 0.0044

============================================================
🔄 Round 19 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0958 (↓), lr=0.000063
   • Epoch   2/100: train=0.0785, val=0.0962, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0777, val=0.0964, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0769, val=0.0963, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0762, val=0.0961, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0739, val=0.0954, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 19 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0121
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0049
============================================================


============================================================
🔄 Round 20 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0839 (↓), lr=0.000016
   • Epoch   2/100: train=0.0816, val=0.0839, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0813, val=0.0839, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0810, val=0.0838, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0807, val=0.0838, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0797, val=0.0834 (↓), lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0789, val=0.0830, patience=10/15, lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 20 Summary - Client client_92
   Epochs: 26/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0374
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0135
============================================================


============================================================
🔄 Round 22 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0910 (↓), lr=0.000002
   • Epoch   2/100: train=0.0788, val=0.0910, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0788, val=0.0909, patience=2/15, lr=0.000002
   📉 Epoch 4: LR reduced 0.000002 → 0.000001
   • Epoch   4/100: train=0.0788, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 22 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0371
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0215
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2393, R²: 0.0304

============================================================
🔄 Round 25 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 25 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0367
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0041
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2399, R²: 0.0267

📊 Round 25 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2405, R²: 0.0219

📊 Round 25 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2409, R²: 0.0191

📊 Round 25 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2411, R²: 0.0182

============================================================
🔄 Round 29 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 29 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0139
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0214
============================================================


============================================================
🔄 Round 30 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 30 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0200
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0027
============================================================


============================================================
🔄 Round 31 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 31 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0168
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0103
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2413, R²: 0.0175

============================================================
🔄 Round 32 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 32 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0192
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0006
============================================================


============================================================
🔄 Round 33 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 33 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0162
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0139
============================================================


============================================================
🔄 Round 34 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 34 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0083
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0387
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2414, R²: 0.0171

============================================================
🔄 Round 36 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 36 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0110
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0292
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2414, R²: 0.0170

============================================================
🔄 Round 37 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 37 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0190
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0001
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2414, R²: 0.0171

============================================================
🔄 Round 39 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 39 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0191
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0146
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2414, R²: 0.0171

============================================================
🔄 Round 42 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 42 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0125
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0167
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2414, R²: 0.0173

============================================================
🔄 Round 43 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 43 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0189
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0077
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2414, R²: 0.0175

============================================================
🔄 Round 49 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 49 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0101
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0216
============================================================


============================================================
🔄 Round 51 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 51 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0121
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0269
============================================================


============================================================
🔄 Round 52 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 52 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0136
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0243
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2414, R²: 0.0178

============================================================
🔄 Round 53 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 53 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0093
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0395
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2414, R²: 0.0179

============================================================
🔄 Round 54 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 54 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0180
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0043
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2414, R²: 0.0179

============================================================
🔄 Round 56 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 56 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0166
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0138
============================================================


============================================================
🔄 Round 57 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 57 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0179
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0066
============================================================


============================================================
🔄 Round 58 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 58 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0154
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0209
============================================================


============================================================
🔄 Round 61 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 61 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0116
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0121
============================================================


============================================================
🔄 Round 63 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 63 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0147
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0219
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2414, R²: 0.0179

============================================================
🔄 Round 65 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 65 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0176
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0095
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2414, R²: 0.0178

============================================================
🔄 Round 67 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 67 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0193
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0010
============================================================


============================================================
🔄 Round 68 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 68 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0156
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0117
============================================================


============================================================
🔄 Round 70 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 70 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0183
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0158
============================================================


============================================================
🔄 Round 71 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 71 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0118
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0284
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0183

📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2413, R²: 0.0184

📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2413, R²: 0.0185

============================================================
🔄 Round 75 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 75 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0192
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0050
============================================================


============================================================
🔄 Round 76 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 76 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0199
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0103
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2413, R²: 0.0184

============================================================
🔄 Round 78 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 78 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0178
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0113
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2413, R²: 0.0184

============================================================
🔄 Round 80 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 80 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0132
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0280
============================================================


============================================================
🔄 Round 84 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 84 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0199
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0056
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2414, R²: 0.0179

============================================================
🔄 Round 89 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 89 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0145
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0247
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2413, R²: 0.0185

============================================================
🔄 Round 90 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 90 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0124
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0140
============================================================


============================================================
🔄 Round 92 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 92 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0149
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0054
============================================================


============================================================
🔄 Round 93 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 93 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0161
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0225
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0189

============================================================
🔄 Round 95 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 95 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0183
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0018
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0190

============================================================
🔄 Round 99 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 99 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0197
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0021
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0189

📊 Round 99 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0189

============================================================
🔄 Round 103 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 103 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0216
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0018
============================================================


============================================================
🔄 Round 104 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 104 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0161
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0201
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0189

📊 Round 104 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0190

📊 Round 104 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0191

============================================================
🔄 Round 110 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 110 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0114
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0400
============================================================


============================================================
🔄 Round 111 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 111 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0223
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0080
============================================================


============================================================
🔄 Round 113 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 113 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0159
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0052
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0190

============================================================
🔄 Round 114 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 114 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0196
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0094
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0190

============================================================
🔄 Round 116 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 116 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0160
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0228
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0190

📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0189

============================================================
🔄 Round 121 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 121 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0158
   Val:   Loss=0.0937, RMSE=0.3062, R²=0.0158
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0187

📊 Round 121 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0186

============================================================
🔄 Round 126 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 126 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0178
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0120
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0186

============================================================
🔄 Round 127 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 127 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0179
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0000
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0186

============================================================
🔄 Round 128 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 128 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0190
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0077
============================================================


============================================================
🔄 Round 131 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 131 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0153
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0224
============================================================


============================================================
🔄 Round 132 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 132 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0148
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0244
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0187

============================================================
🔄 Round 137 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 137 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0181
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0099
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0184

============================================================
🔄 Round 138 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 138 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0248
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0211
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0183

📊 Round 138 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0183

============================================================
🔄 Round 147 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 147 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0165
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0024
============================================================


============================================================
🔄 Round 148 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 148 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0165
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0164
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0185

============================================================
🔄 Round 152 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 152 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0166
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0028
============================================================


============================================================
🔄 Round 153 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 153 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0152
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0024
============================================================


============================================================
🔄 Round 154 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 154 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0094
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0318
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0184

📊 Round 154 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0184

📊 Round 154 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0184

📊 Round 154 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0183

📊 Round 154 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0183

============================================================
🔄 Round 160 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 160 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0174
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0071
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0183

📊 Round 160 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2414, R²: 0.0182

============================================================
🔄 Round 163 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 163 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0099
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0351
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2414, R²: 0.0181

============================================================
🔄 Round 164 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 164 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0162
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0127
============================================================


============================================================
🔄 Round 165 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 165 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0144
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0115
============================================================


============================================================
🔄 Round 168 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 168 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0187
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0037
============================================================


============================================================
🔄 Round 170 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 170 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0150
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0196
============================================================


============================================================
🔄 Round 173 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 173 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0171
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0127
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0186

============================================================
🔄 Round 175 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 175 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0254
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0195
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0187

============================================================
🔄 Round 176 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 176 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0137
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0017
============================================================


============================================================
🔄 Round 177 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 177 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0200
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0017
============================================================


============================================================
🔄 Round 178 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 178 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0126
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0241
============================================================


============================================================
🔄 Round 182 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 182 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0170
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0014
============================================================


============================================================
🔄 Round 183 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 183 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0209
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0057
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0190

============================================================
🔄 Round 187 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 187 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0111
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0268
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2414, R²: 0.0191

============================================================
🔄 Round 190 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 190 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0205
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0158
============================================================


============================================================
🔄 Round 192 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 192 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0158
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0234
============================================================


============================================================
🔄 Round 193 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 193 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0181
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0158
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2413, R²: 0.0193

============================================================
🔄 Round 196 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 196 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0138
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0305
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2413, R²: 0.0194

============================================================
🔄 Round 197 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 197 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0140
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0365
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2413, R²: 0.0195

📊 Round 197 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2413, R²: 0.0194

📊 Round 197 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2413, R²: 0.0193

============================================================
🔄 Round 201 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 201 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0181
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0170
============================================================


============================================================
🔄 Round 202 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 202 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0185
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0116
============================================================


============================================================
🔄 Round 204 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 204 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0194
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0101
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2413, R²: 0.0193

============================================================
🔄 Round 206 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 206 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0186
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0148
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2413, R²: 0.0192

============================================================
🔄 Round 207 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 207 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0175
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0162
============================================================


============================================================
🔄 Round 208 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 208 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0172
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0056
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0192

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0192

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2413, R²: 0.0192

❌ Client client_92 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
