[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7509003-d2af-4861-8aeb-de588392d78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451a7b98-9896-47f2-bd76-7d5013a3304c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78927c3-5012-4d8f-b53a-606e020a4c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20568e41-759d-49ec-beb6-b356305b21e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3470ca0f-dcc9-4596-b029-ae86bc669cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e2374a-72ad-4cb5-9661-ec4e4a4a48b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda27fe9-d493-4008-8bd9-d9342ac84ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb3641f-5ed8-4821-bb3b-41c113825b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41190858-8325-4134-891e-9978fa357324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 193e407c-68ba-48da-aa9a-4eeab9097dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc5d3ad6-8242-4200-9aac-fcbae1fa51bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8da103-bd2c-445e-8f11-74d2cd9f85a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93bc9a40-ff22-46ed-ab12-ccd5b4772742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f34447-7c67-4d6d-b9fe-0ff16cb9df3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ba76183-ca67-48d8-a0b9-2814198b8b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baef9f90-86f9-4ff0-b2d5-2d96dfa30d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d530475-4035-469b-b1b2-ce19be26299b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd1582d-1855-4580-9a03-a4ce75369ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b267bc7f-4e69-4ea3-8ef1-e239972df67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cdad8ac-0cf9-4cd6-a7be-a59364a8dfb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3143a359-ba0f-4b6b-a7ac-554d72d8fbf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6931710c-fec0-42d9-ab59-aa59113d2dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d71f5d2-14aa-4b6c-8d41-9fa228bcff85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 731c849f-eae6-4f29-a699-8059424572e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de4cab8-db4d-48de-8863-e97f52bc1fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb2bede4-280a-4d87-b975-12d02ad5e2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 940648c8-de3f-4015-a051-fbbf243f29fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2859b562-eccc-49b7-9317-fdc3ac7b1a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2950771-13a4-484f-95dd-dd82143ef88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0f5dc2-3007-412b-89fb-279f0a67938e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23626d0e-0d6f-429f-aa6f-6cd87e2b42a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2aec11-db41-408f-9ff4-dd926b79b352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94482db-2486-42f7-ac81-eeda00fa7e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0279a1f-e3eb-4aa0-8097-8d99957daba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4480659f-feb9-409a-8464-2c753ef095ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf9f3d0-6bd8-42c5-8357-82162354261b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88589c3d-d56b-4d16-980a-351869700c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d63ecad-cfc1-404e-8415-60bcd9378573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f46dffb-efb7-46e8-828a-f83bfe8dac6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd70b2c6-2ed7-44e6-bf62-2b8e2bdbab54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff13aa14-abfb-487d-8fcc-26870f24f783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c86714b-f589-4f9b-8c3c-bf540afa45e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c85fc40a-48f0-4f07-9576-c95a348548f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38bde03a-2b23-4ebb-a998-55b92cb1b82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adbd8e62-5222-4027-80de-b2e075fb5d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c60ad1-0ad1-4159-b21b-202ca4d166b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3aa8b36-0db6-4788-9622-440cf4c17451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8cd029-f9a5-432e-b8ca-7a95b6a0980e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637a8404-53e0-4286-a85b-f1e1dc9cab17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0dadce6-9580-4b83-91ec-c90f9930cace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36353fe0-b03c-4cf4-87f2-5879dcf5ebae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e75e8c30-e8f7-45b6-9d00-21a162bd873a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0fb1eab-1b7e-45c4-bb67-ceae426661a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81e4b92-67d6-4df9-8d47-3f49236d3bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ebf2a4-8666-4c1a-a0b9-ef3c01174dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e024ee-7e9a-40f4-8e33-b18f2f5ad421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789142e7-32fd-41cc-9537-fed2a3e0ed6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a0917f-6468-4cdd-af1b-e9722af716b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef69443f-8da7-4482-9ef0-a443c8d3c0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d765f77-15f7-451d-82d8-d5acbc51d301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21275c47-0100-49bb-af68-03789928c246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f89de9c-4aed-4671-9960-fc607ddf6da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bba48be-0a81-4465-ad02-54e2ed99d693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51960a61-8354-4f9a-b7f8-ad1eda195853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993fe369-0030-4581-9d3d-266e6a3e652a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f508ef79-18e7-4768-b79d-bd4edfb59da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca943b61-c925-4ca9-b2b9-2bbe2eb41775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85edff6d-5187-483a-9023-5c63c7e4dfc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1d4b4e5-e7aa-4411-913c-f0599e8b203b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eff4470-a7ea-43df-8898-48e4d8947c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48eeeb03-4402-4ad4-badb-ac810bc1dce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13ec45a-9e5b-49ac-a794-239c6c9c0626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b0350c-d3ff-4377-9bff-3a301b122850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d744948-511d-4f83-a84c-05988c7264c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271b58fb-abb3-405d-8da6-12780d2ac38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd76736a-eed3-4989-9df1-af0f417904ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c60bd192-afd9-41ed-b9cb-243ea048ab9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8c7937-5bfa-486b-a45e-40d8e2f0cdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff1b9308-cfe6-4159-87ab-0de707a9a9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81daae9-0733-4e60-a5d4-8141a931735f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b15d9971-5f50-4e6b-a82d-51f26cafa507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5dfd7b-6457-4776-bd03-b3eea78e7cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75fd1090-49ae-476d-975e-4214c66b4a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ddf2df7-43da-435b-ab1c-9f99252c6341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6fe0cfa-51a9-4467-a6c8-674aa0246e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08c3502-43f8-4473-bc34-8c53e852eb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a89fc3a-e270-4232-8c25-22b387fe3b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b94762-9321-4063-9f19-4ee104c7bec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 079c88b6-de26-4d0d-bcce-577ea938475e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a62d28-e522-47aa-acd9-0818c24161df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61ba5b9-1402-46c6-a0db-249cc22566ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de1c1bf-1f87-47fe-8307-e215a9014845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fd65d9-3463-4241-a9f4-72034ed52258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0605bd0c-dfbb-486f-96ee-ac5430434d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5802d76c-0326-40f0-8973-563c5819617d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50cc14d6-8b9d-4c11-89aa-26874f992dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 873f7690-1a1b-431f-85c2-34eba367f63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c7946a8-990d-4675-b82e-24e89ebe2662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c85d1c8-0987-4aa5-936e-6641312bf925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5b9ffe-e006-4b02-a392-39d7212ae46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b699e5-fa16-433a-af97-c8df4bdcc08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d36354-5beb-436e-97a7-51c5d828cfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2fbd61-6026-4f65-b832-1dfe97f2a0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710a13b2-e923-47af-b224-668ed719347e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a86870c-38db-4078-8546-c02df0d5e598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5255241-a2a1-4650-8f57-3b34e316a2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3528118-f941-4858-aff5-fc11504ca90a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569ede1f-435a-4702-8cd6-6a036166ee12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6337eabe-eb29-48a5-b915-ba6beda092fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d69a8e-330f-4538-9ff0-b9b6f59f9309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77aa5e1f-26ac-4e7c-a06b-a5139cb33be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b67e156-8fab-4fe4-a9d1-8f09383b013d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fae9d63-0fbf-477a-948a-b7bce3c84d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cb9f90-e579-4731-a9bd-97a6d718f22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aa08b46-9ef3-4b4a-b186-b44ee3586f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cefbff9-dd42-4499-98fc-55b056c40f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6771196a-05f6-4c14-bd7b-6f48445d049d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 962e0004-43e3-481d-92a6-b71f0abb49fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157ec2d7-24a3-4d80-8947-2bdd85a44d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee1604f-7555-4269-be24-6953431efde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220a9b65-3f8d-4bca-bcb4-5603f35d2644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af284fa5-090b-498c-8eb4-177a9ce68475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a6bd72-478e-4c46-9f1d-23a573ef0f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4232e2-c1cf-42a9-b67a-b047ded74abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2522bf62-37f7-4766-b963-736088119bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a4b534a-6561-4b20-9b73-e4aead5b4e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0049e355-8538-4b98-95af-14bfc9274f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ee9019-edb2-4e39-8bf0-33df184d1eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0dd055-2525-4951-a64a-2d5d430b1567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deccc611-ec88-44cc-869d-651bcf47522d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74372cb-88e8-435c-88ce-aa3d2cee74c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1230d5-92cd-4031-90d1-971772e0d650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aca0377-8bb6-4c14-bfff-99256393d2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f29d6707-8907-4796-98ed-61baefca0370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd05c766-e77c-47e6-af92-3cfb17673d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a90414-aceb-48e4-aa4d-a2b03f9fd134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06eac26-c0fb-46e4-9754-a8addf64c146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84cd989d-86e9-4fd8-bff5-398a9e7c09c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15c7fe98-38bd-4715-8e06-d112f342618f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc0d8f4f-e06e-4c30-80f9-b57eeececdc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faedef1c-6b1b-4011-9800-906b5d224336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f62791c-0017-4fbb-9c89-a5e284bba2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ca4a70-4aa7-4fbd-9b53-a9947ef99b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d404aaff-a19d-49a8-b71e-84778549fc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090beea3-b404-4a01-8b83-0500f62833dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3630807a-daf3-4367-a2c5-c4ac8c521b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db812e6d-6d1c-4039-8a87-af6cfa991356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0a2b26-fe5c-4e6c-bfb5-c2264cee5bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b114f3a9-6310-4614-8efd-d25abbc46a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54dae110-3336-4d3f-aaac-9ec96e950c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad629dca-7455-4d00-a3eb-b24167caed6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c260f7f-9ac1-43d6-89ed-a7f304eb0c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8545de6-de20-4f72-a798-9e550f0ae8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 723b2c3c-d887-4b43-a050-573c8787dcee
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_93
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_labels.txt

📊 Raw data loaded:
   Train: X=(815, 24), y=(815,)
   Test:  X=(204, 24), y=(204,)

⚠️  Limiting training data: 815 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  195 samples, 5 features
✅ Client client_93 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2549, R²: -0.1097

📊 Round 0 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2536, R²: -0.0930

📊 Round 0 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2517, R²: -0.0758

📊 Round 0 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2512, R²: -0.0712

📊 Round 0 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2533, R²: -0.0837

📊 Round 0 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2554, R²: -0.0992

============================================================
🔄 Round 24 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0900 (↓), lr=0.001000
   • Epoch   2/100: train=0.0847, val=0.0896, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0838, val=0.0901, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0831, val=0.0901, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0823, val=0.0905, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0745, val=0.0934, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 24 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0119
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0534
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2543, R²: -0.0830

============================================================
🔄 Round 26 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0745 (↓), lr=0.000250
   • Epoch   2/100: train=0.0895, val=0.0747, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0890, val=0.0750, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0886, val=0.0752, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0882, val=0.0754, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0870, val=0.0762, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 26 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0245
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0362
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0649

============================================================
🔄 Round 27 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0836 (↓), lr=0.000063
   • Epoch   2/100: train=0.0880, val=0.0834, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0873, val=0.0836, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0871, val=0.0837, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0869, val=0.0838, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0864, val=0.0839, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 27 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0386
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0416
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2508, R²: -0.0438

📊 Round 27 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0419

============================================================
🔄 Round 33 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0853 (↓), lr=0.000016
   • Epoch   2/100: train=0.0877, val=0.0852, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0875, val=0.0851, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0873, val=0.0851, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0872, val=0.0851, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0868, val=0.0851, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 33 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0319
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0394
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2502, R²: -0.0392

============================================================
🔄 Round 34 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0992 (↓), lr=0.000004
   • Epoch   2/100: train=0.0845, val=0.0992, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0844, val=0.0993, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0843, val=0.0994, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0842, val=0.0994, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0839, val=0.0997, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 34 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0443
   Val:   Loss=0.0992, RMSE=0.3150, R²=-0.0631
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2501, R²: -0.0382

📊 Round 34 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2500, R²: -0.0375

============================================================
🔄 Round 36 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 36 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0309
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0453
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2499, R²: -0.0370

📊 Round 36 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2499, R²: -0.0365

============================================================
🔄 Round 41 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 41 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0266
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0584
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2499, R²: -0.0364

============================================================
🔄 Round 44 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 44 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0268
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0577
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2499, R²: -0.0364

============================================================
🔄 Round 46 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 46 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0372
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0314
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2500, R²: -0.0366

============================================================
🔄 Round 47 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 47 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0334
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0298
============================================================


============================================================
🔄 Round 49 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 49 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0336
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0281
============================================================


============================================================
🔄 Round 51 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 51 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0329
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0356
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2500, R²: -0.0366

============================================================
🔄 Round 53 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 53 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0246
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0637
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2500, R²: -0.0368

📊 Round 53 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2500, R²: -0.0368

============================================================
🔄 Round 55 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 55 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0358
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0186
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2501, R²: -0.0370

📊 Round 55 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2501, R²: -0.0372

📊 Round 55 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2501, R²: -0.0371

📊 Round 55 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2500, R²: -0.0366

============================================================
🔄 Round 64 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 64 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0347
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0463
============================================================


============================================================
🔄 Round 67 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 67 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0330
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0279
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2499, R²: -0.0357

============================================================
🔄 Round 70 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 70 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0315
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0346
============================================================


============================================================
🔄 Round 72 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 72 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0298
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0400
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2501, R²: -0.0363

📊 Round 72 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2501, R²: -0.0366

📊 Round 72 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2501, R²: -0.0361

📊 Round 72 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2500, R²: -0.0361

============================================================
🔄 Round 80 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 80 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0306
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0458
============================================================


============================================================
🔄 Round 82 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 82 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0296
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0376
============================================================


============================================================
🔄 Round 85 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 85 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=-0.0345
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0134
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2499, R²: -0.0346

============================================================
🔄 Round 87 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 87 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0393
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0048
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2499, R²: -0.0352

📊 Round 87 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2500, R²: -0.0354

============================================================
🔄 Round 91 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 91 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0305
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0396
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2500, R²: -0.0358

============================================================
🔄 Round 92 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 92 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0219
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0762
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2501, R²: -0.0360

============================================================
🔄 Round 93 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 93 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0292
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0432
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2501, R²: -0.0363

📊 Round 93 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2501, R²: -0.0359

============================================================
🔄 Round 98 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 98 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0334
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0212
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2501, R²: -0.0358

============================================================
🔄 Round 99 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 99 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0353
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0164
============================================================


============================================================
🔄 Round 100 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 100 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0278
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0430
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2500, R²: -0.0357

============================================================
🔄 Round 101 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 101 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0278
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0479
============================================================


============================================================
🔄 Round 102 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 102 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0302
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.0448
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2500, R²: -0.0356

============================================================
🔄 Round 103 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 103 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0332
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0237
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2500, R²: -0.0357

📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2500, R²: -0.0357

============================================================
🔄 Round 107 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 107 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0312
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.1252
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2501, R²: -0.0359

============================================================
🔄 Round 109 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 109 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0268
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0495
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2501, R²: -0.0360

============================================================
🔄 Round 110 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 110 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0374
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0049
============================================================


============================================================
🔄 Round 114 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 114 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0332
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0374
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2500, R²: -0.0357

============================================================
🔄 Round 115 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 115 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0262
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0511
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2500, R²: -0.0357

📊 Round 115 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2500, R²: -0.0356

============================================================
🔄 Round 122 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 122 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0326
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0355
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2499, R²: -0.0349

📊 Round 122 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2499, R²: -0.0349

============================================================
🔄 Round 127 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 127 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0293
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0353
============================================================


============================================================
🔄 Round 128 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 128 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0303
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0300
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2499, R²: -0.0350

============================================================
🔄 Round 129 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 129 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0234
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0556
============================================================


============================================================
🔄 Round 130 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 130 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0297
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0350
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2499, R²: -0.0352

📊 Round 130 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2499, R²: -0.0351

============================================================
🔄 Round 132 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 132 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0317
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0229
============================================================


============================================================
🔄 Round 133 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 133 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0339
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0106
============================================================


============================================================
🔄 Round 134 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 134 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0316
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0244
============================================================


============================================================
🔄 Round 135 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 135 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0268
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0394
============================================================


============================================================
🔄 Round 144 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 144 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0302
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0234
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2498, R²: -0.0339

============================================================
🔄 Round 145 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 145 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0289
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0295
============================================================


============================================================
🔄 Round 146 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 146 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=-0.0333
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0087
============================================================


============================================================
🔄 Round 148 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 148 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0254
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0437
============================================================


============================================================
🔄 Round 153 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 153 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0266
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0362
============================================================


============================================================
🔄 Round 154 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 154 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0333
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0394
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2498, R²: -0.0334

============================================================
🔄 Round 156 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 156 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0267
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0357
============================================================


============================================================
🔄 Round 157 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 157 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0266
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0387
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2498, R²: -0.0331

📊 Round 157 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2498, R²: -0.0330

📊 Round 157 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2498, R²: -0.0330

============================================================
🔄 Round 161 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 161 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0221
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0684
============================================================


============================================================
🔄 Round 162 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 162 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0219
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0557
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2497, R²: -0.0327

📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2497, R²: -0.0327

============================================================
🔄 Round 166 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 166 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0324
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0276
============================================================


============================================================
🔄 Round 168 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 168 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0227
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0635
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2498, R²: -0.0329

============================================================
🔄 Round 174 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 174 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0269
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0391
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2499, R²: -0.0335

============================================================
🔄 Round 175 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 175 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0304
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0268
============================================================


============================================================
🔄 Round 176 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 176 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0303
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0180
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2499, R²: -0.0336

============================================================
🔄 Round 177 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 177 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0231
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0521
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2499, R²: -0.0337

============================================================
🔄 Round 179 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 179 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0284
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0263
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2499, R²: -0.0338

============================================================
🔄 Round 181 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 181 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0264
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0368
============================================================


============================================================
🔄 Round 182 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 182 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0323
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0155
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2499, R²: -0.0340

============================================================
🔄 Round 184 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 184 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0200
   Val:   Loss=0.0990, RMSE=0.3147, R²=-0.0670
============================================================


============================================================
🔄 Round 185 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 185 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0240
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0451
============================================================


============================================================
🔄 Round 186 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 186 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0307
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0168
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2499, R²: -0.0341

============================================================
🔄 Round 187 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 187 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0287
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0318
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2500, R²: -0.0341

============================================================
🔄 Round 188 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 188 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0284
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0306
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2500, R²: -0.0342

============================================================
🔄 Round 191 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 191 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0308
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0182
============================================================


============================================================
🔄 Round 192 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 192 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0277
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0296
============================================================


============================================================
🔄 Round 193 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 193 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0278
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0451
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2500, R²: -0.0345

============================================================
🔄 Round 195 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 195 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0233
   Val:   Loss=0.0969, RMSE=0.3112, R²=-0.0573
============================================================


============================================================
🔄 Round 199 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 199 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0317
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0310
============================================================


============================================================
🔄 Round 200 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 200 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0281
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0284
============================================================


============================================================
🔄 Round 201 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 201 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0318
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0452
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2500, R²: -0.0342

============================================================
🔄 Round 204 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 204 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0208
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0582
============================================================


============================================================
🔄 Round 205 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 205 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0296
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0375
============================================================


============================================================
🔄 Round 207 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 207 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0262
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0467
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2499, R²: -0.0339

============================================================
🔄 Round 209 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 209 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0268
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0378
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2499, R²: -0.0339

============================================================
🔄 Round 210 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 210 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0316
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0154
============================================================


============================================================
🔄 Round 211 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 211 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0283
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0508
============================================================


❌ Client client_93 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
