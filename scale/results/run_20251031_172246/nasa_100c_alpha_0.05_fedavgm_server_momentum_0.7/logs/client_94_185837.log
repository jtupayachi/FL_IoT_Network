[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a46ce01-c5d6-4862-8c7a-cf6349cf3136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b49a0073-6da7-4cc4-80cf-fd6f8a113bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5fbe00b-7554-4f54-8c2d-3270613d37cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b112770a-3f77-47ad-8b26-a81fd69b9506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b124b28-112e-4c68-866a-09865ec90160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a890e2-5640-459d-ac30-1d2dd93e2cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e6d2af-eb5e-4676-b9da-0e33d4480e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48cd10bf-7dff-4a19-88c2-7bc6d42735b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edca6a58-fdcd-40be-bff4-e56c70141972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585818da-1899-4b69-a79a-beb230717a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c56facef-38d1-4733-bf8c-ed34dd1c70f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f646100-51e0-445f-8eb2-226e2021248b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544b0ac4-da88-4bea-8587-f43794d17d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd0c1e3-3af7-4cab-8c49-4c57db8f2997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28711cf2-2877-4f60-8c83-afe80c381c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5794796f-f8c5-431a-83e8-e509081ebf30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a25237-7ffc-4a92-b8ce-145630f8d4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea21e4d0-7d09-4beb-875d-39c4ba0f473a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db17af42-62db-4606-b3dd-40046e7d4851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da1878f5-5678-468d-bd58-f529d7842dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971cf300-84fa-44c2-883a-b758fec30638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67542f17-ba57-432d-b740-fb811a4cf314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66df18ba-f62b-42f9-92a5-c4b0d47df920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb8c6bb6-a8f0-441a-9ea9-f458555c63a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f88b8956-b120-4e89-8842-e8d04b59c225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b638380b-71e1-4f1a-b12f-f3ea506bbe85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c87a66fd-5ba4-4df2-a696-ccc71ad9dfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f638a2c-f0ec-4df4-a90d-2958d09d38c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae467bb3-0a31-41f3-9f54-fabc6cfe6b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb64fdd-d510-4ef3-a66a-9a7a0684ef71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d075af2-e074-470f-8481-ab052a5bc405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8f04c3-529f-4b49-a217-d8d01121416c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccd22447-139f-4ade-b315-117a7b34e994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8261d08-2e69-4453-a833-07c4b4ef7b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ab74f7-c2e3-4b7a-86c2-435865c27d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e95582c6-7c7c-4909-bdf7-59673725763d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc3aace-1a4b-42cc-81a2-5fcf42f4e61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae3f498-ad64-44ae-9b29-f6ebd465798c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7456dc8a-e4dd-4304-bb33-7ee24412bb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35ab68f-875a-49e4-a608-4ee60a2a93ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e08190-8e41-442d-bf4c-28510d4d6993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e7d6d63-f813-444f-b03f-ff4360d635d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63841d5c-915a-4cad-9229-8fa1a9d128b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b8ea18a-498e-4b54-bef3-f1b45e589609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba78f7a-9aa4-429a-a79b-713e3d468d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f5c11c-7653-46dc-8c91-4378bf6b649d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ce1ea8f-5adc-453b-b007-d7116f8277fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fe1713-1cf3-4214-9961-18eafdf3b52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fbe216b-a6a1-4853-a0b6-2e3a8be44e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a7735c-c759-4b29-9e84-41d4de608cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6e490b2-d19b-4097-b93f-c6dea0daa6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be615131-2e1a-424f-a22a-ad3cb4fe1baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5035034a-07cb-4075-94ec-5570e6c8e1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 160b3cba-4ecb-4a78-8666-6d295c24eba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6815030d-e16e-4a41-aa4b-4bb1c8951464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9888055-63c1-42c1-a9ea-f0c925967a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57e98be-0ed5-401f-b5dc-603840717b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46e16443-2ced-40d1-a28f-68287e8190e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0784099b-3b33-4fbb-a2bc-f0f278c2bd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d3a7c1-4aa9-4a6a-a535-b778a23101c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e2ad705-8a81-44d7-8084-85c4222ade8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f61954-b005-4fbf-b1b5-92161dcabee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8678a0ba-621f-4542-b8a3-4431d80e59fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4acae38-8bc0-4e10-8838-49e5d46c3148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522cf307-eeb7-4388-b0a7-f4a2686a52cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2c60cc2-afaf-4f16-ab54-9566288c5a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8728f977-8926-4ed0-862b-da989f0b56ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3181fe81-1812-40d3-991e-67c44e9ae789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239e25e9-50d3-4c1e-a421-2e158aea6a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5330c623-33d5-444d-a53b-a583e4817149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 290786c3-7859-4a91-a31f-e7afb25c3824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c3b633-ec23-450e-9f1b-8690b1e073e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c927f3a-ba8a-4a24-a568-8be9d9136c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257c924b-4143-4763-913b-4075e951905e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7fe976-8844-4bd7-bf65-f778c251c925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba2e118-3e02-47ae-b329-f1c6aa361dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecdbb293-bd38-4ce8-bec9-8b872b1f106e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd9fba49-4be1-4a36-a5be-cfddeca8f356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 740b070f-d129-4309-bbb1-2d2c8d430a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6555c59-71d8-461e-b133-1379a385fe0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55012729-b71c-444d-a603-91f6fe652bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b977d27-67b7-439a-a78c-420696bc3a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8513ea10-d5e4-4653-ace4-cc9d8451b826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d314b0d4-99e2-4488-a194-a0d9722de485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c27573-0f02-418d-8316-34fd7f84f7d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6bfdca2-59f9-48be-bb81-b42f731a25cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a56148c-bc42-4128-8bfc-39a1e4ef15db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 369f6d73-1bd3-45f5-a9b9-6a75f37b9963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb5606f6-92f8-45cf-9344-eaaace1e0ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1541582e-0ef9-4cf7-8762-73230ce73efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea5558c-dda5-42c9-b955-47eb94cbc083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb017bc1-de57-4245-9a28-42a2705d9273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2714ca1c-7340-4eba-b175-2871d03d867f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2589414e-42ba-4d23-98d1-452dfedc23a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988f2d92-6521-404a-8ebd-f498734a4038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41fdb122-be0c-409a-aec1-c8c5aaa46b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c4f698-95fd-4628-89e5-e5a1666f3bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 871e9b60-5f31-4940-af78-d59db0da549f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47153640-0690-4518-9118-408dd49eec38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6e8420-52f2-4c1c-83d2-b87a489973f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 439155df-7c01-4d0f-b946-9efbe1314d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04d9833-9102-4e6e-90c6-92f591d5f5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7419baed-97a2-4792-a557-5df2231c273d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeabee69-ea26-40b5-a5a7-3b855302672b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51d3fe4-a837-485f-a48b-85d077b15ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3455872f-758d-4c2c-b526-64d68b727295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb2394c-1e4d-4b20-9a57-b6a24d3a8d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c8533b3-898e-4399-8a99-13f9fcd63be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6510cbde-6194-48eb-9278-db45dffbf7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc888d53-9e65-4728-afe7-7757224c97bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b4d946-8a77-4a01-86ad-c30269cef41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acb42b0-3c8d-49da-a61f-104520c15adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d18d1b5-d634-4360-ac53-fd8161c8c403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9ca03c-43bd-4aa1-b7f6-971d98b236de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40f87e9-f195-4cd8-8177-ce1aa46e31e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68fdd1a-7a86-479b-a9a8-88566321c939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ded6aff-a4b8-4d0c-a89f-59100f84e438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05019edb-7725-4c1d-a14d-dfadaaea4a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f80ac5-ad44-45ba-9041-d267f9311348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4e45e3-7e76-4feb-a46d-bad17c17fd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a96abc2d-684b-462b-80b7-3ee69502f055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 970e5abc-f699-46b6-88a3-afec7e0193b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265e8333-ea1b-4687-93b4-6d20fd1553d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84405685-beaf-499a-bfa1-5e1881de29e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20298a0d-e4d2-4e68-92ea-0ff713f0c6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb43e130-298d-4833-a730-46b5eef6768f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d13d1f1-301e-4ef1-afad-7c51c16d6239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1194e3d-27b6-420e-8c80-b18fb6a7e004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 022f5de8-706d-428b-a333-fdc342d5d1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfa4a07-bbaf-498f-accb-a5e775c37cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2122a2d6-4fbc-4cde-9bf3-4eec59819352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80868a9c-7bf4-43eb-958b-c441f3a55ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc20c17b-a4de-469e-a15b-1cd16b1b0556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab2bd13-82b6-4ede-86ae-0bf5408c6976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6619a5dd-d0a8-4da0-86e0-254f1a91774e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a04d7aac-076f-4f65-84dc-cb19d1991a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4226b3f-f31f-43f5-893c-bb60fe0acafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ab687f-d098-4a19-8a31-5421d0a155e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a78bfe-6e6b-47a5-9856-629a1a15383f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 517cccc1-42a8-4b30-8e82-af33abe4e8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1be243-45ab-47f1-bca6-471441ccf924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d137dc5-7f83-4fe3-b2b6-9acd9bdba4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf4c536-08cf-4ffb-9d8f-f25fe550ec83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17cb242-36d0-4858-b1ec-7e917f29c71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbe350f-6c44-4ed6-8532-c5bfa8ff5053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291e6450-cf91-4fb6-a037-9e1ae5213cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ce9b3d-150a-4aa3-91c3-62a99cc89b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f305ac2-5904-4e12-8035-a837c4d731af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118cd3aa-b62a-4669-a3dc-6c14131dc13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d21870ae-c901-4600-b7b0-b955292832a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489e2510-fd30-40cf-83d7-2176d38e989c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_94
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_labels.txt

📊 Raw data loaded:
   Train: X=(860, 24), y=(860,)
   Test:  X=(215, 24), y=(215,)

⚠️  Limiting training data: 860 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  206 samples, 5 features
✅ Client client_94 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0812 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0842, val=0.0801 (↓), lr=0.001000
   • Epoch   3/100: train=0.0831, val=0.0799, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0821, val=0.0795 (↓), lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0794, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0748, val=0.0835, patience=7/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 16 Summary - Client client_94
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0641
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0073
============================================================


============================================================
🔄 Round 17 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0844, val=0.0867 (↓), lr=0.000250
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0825, val=0.0860 (↓), lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0862, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0818, val=0.0862, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0803, val=0.0869, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 17 Summary - Client client_94
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0231
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0036
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2433, R²: -0.0327

============================================================
🔄 Round 20 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0874 (↓), lr=0.000063
   • Epoch   2/100: train=0.0833, val=0.0873, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0829, val=0.0874, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0824, val=0.0874, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0815, val=0.0875, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 20 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0113
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0100
============================================================


============================================================
🔄 Round 21 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0830 (↓), lr=0.000016
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0838, val=0.0826, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0834, val=0.0823, patience=4/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0832, val=0.0821, patience=14/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 21 Summary - Client client_94
   Epochs: 22/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0105
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0300
============================================================


============================================================
🔄 Round 23 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0820, val=0.0928 (↓), lr=0.000002
   • Epoch   2/100: train=0.0820, val=0.0928, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0819, val=0.0927, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0819, val=0.0927, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0818, val=0.0926, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0816, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 23 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0093
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0036
============================================================


============================================================
🔄 Round 24 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 24 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0149
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0099
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2424, R²: -0.0257

📊 Round 24 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2420, R²: -0.0239

============================================================
🔄 Round 28 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 28 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0093
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0132
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2421, R²: -0.0244

============================================================
🔄 Round 29 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 29 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0025
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0356
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2422, R²: -0.0246

============================================================
🔄 Round 30 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 30 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0021
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0355
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2423, R²: -0.0249

============================================================
🔄 Round 33 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 33 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0025
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0102
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2424, R²: -0.0252

============================================================
🔄 Round 37 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 37 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0063
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0103
============================================================


============================================================
🔄 Round 38 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 38 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0117
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0148
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2424, R²: -0.0252

============================================================
🔄 Round 39 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 39 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0077
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0048
============================================================


============================================================
🔄 Round 40 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 40 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0044
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0186
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2425, R²: -0.0251

============================================================
🔄 Round 45 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 45 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0116
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0186
============================================================


============================================================
🔄 Round 48 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 48 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0105
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0230
============================================================


============================================================
🔄 Round 49 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 49 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0042
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0216
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2425, R²: -0.0250

============================================================
🔄 Round 53 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0977 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 53 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0055
   Val:   Loss=0.0977, RMSE=0.3126, R²=0.0135
============================================================


============================================================
🔄 Round 54 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 54 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0083
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0040
============================================================


============================================================
🔄 Round 55 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 55 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0132
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0115
============================================================


============================================================
🔄 Round 57 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 57 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0111
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0188
============================================================


============================================================
🔄 Round 59 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 59 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0133
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0139
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0246

============================================================
🔄 Round 60 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 60 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0006
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0404
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0246

============================================================
🔄 Round 62 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 62 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0138
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0154
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0246

============================================================
🔄 Round 63 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 63 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0109
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0465
============================================================


============================================================
🔄 Round 64 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 64 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0075
   Val:   Loss=0.0981, RMSE=0.3133, R²=-0.0136
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0247

============================================================
🔄 Round 68 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 68 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0068
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0011
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0246

============================================================
🔄 Round 69 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 69 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0099
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0028
============================================================


============================================================
🔄 Round 70 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 70 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0116
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0141
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0245

============================================================
🔄 Round 75 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 75 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0057
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0179
============================================================


============================================================
🔄 Round 77 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 77 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0122
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0114
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0244

============================================================
🔄 Round 78 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 78 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0126
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0199
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0244

============================================================
🔄 Round 79 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 79 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0064
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0053
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0244

📊 Round 79 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0245

============================================================
🔄 Round 81 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 81 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0084
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0055
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0245

📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0246

============================================================
🔄 Round 84 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 84 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0114
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0251
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2426, R²: -0.0246

============================================================
🔄 Round 86 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 86 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0036
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0241
============================================================


============================================================
🔄 Round 88 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 88 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0022
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0309
============================================================


============================================================
🔄 Round 89 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 89 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0090
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0078
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0243

============================================================
🔄 Round 91 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 91 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0025
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0271
============================================================


============================================================
🔄 Round 92 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 92 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0154
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0243
============================================================


============================================================
🔄 Round 93 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 93 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0053
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0190
============================================================


============================================================
🔄 Round 94 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 94 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0042
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0248
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2425, R²: -0.0240

============================================================
🔄 Round 95 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 95 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0049
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0117
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0241

============================================================
🔄 Round 98 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 98 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0028
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0258
============================================================


============================================================
🔄 Round 99 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 99 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0067
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0141
============================================================


============================================================
🔄 Round 100 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 100 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0323
============================================================


============================================================
🔄 Round 101 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 101 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0086
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0050
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2425, R²: -0.0241

============================================================
🔄 Round 104 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 104 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0008
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0080
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2425, R²: -0.0240

============================================================
🔄 Round 108 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 108 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0068
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0059
============================================================


============================================================
🔄 Round 111 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 111 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0110
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0026
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0239

📊 Round 111 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0239

============================================================
🔄 Round 116 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 116 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0010
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0349
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0239

============================================================
🔄 Round 120 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 120 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0065
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0095
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 121 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 121 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0047
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0210
============================================================


============================================================
🔄 Round 123 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 123 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0023
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0286
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 125 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 125 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0094
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0036
============================================================


============================================================
🔄 Round 126 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 126 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0101
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0037
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 131 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 131 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0006
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0279
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0237

📊 Round 131 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0237

📊 Round 131 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0237

📊 Round 131 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

📊 Round 131 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

📊 Round 131 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 140 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 140 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0069
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0023
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 142 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 142 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0020
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0272
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 143 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 143 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0068
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0034
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 148 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 148 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0043
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0188
============================================================


============================================================
🔄 Round 149 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 149 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0116
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0133
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2425, R²: -0.0238

============================================================
🔄 Round 150 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 150 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0099
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0021
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0238

============================================================
🔄 Round 151 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 151 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0090
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0007
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0238

📊 Round 151 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0237

============================================================
🔄 Round 154 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 154 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0373
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0237

📊 Round 154 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0237

============================================================
🔄 Round 157 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 157 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0068
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0048
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0237

📊 Round 157 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0237

============================================================
🔄 Round 162 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 162 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0026
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0225
============================================================


============================================================
🔄 Round 163 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 163 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0113
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0117
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0236

📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0236

📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0236

📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0236

============================================================
🔄 Round 167 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 167 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0019
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0292
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0236

📊 Round 167 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0235

============================================================
🔄 Round 172 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 172 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0032
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0258
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0235

============================================================
🔄 Round 177 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 177 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0046
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0212
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0235

============================================================
🔄 Round 181 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 181 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0067
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0057
============================================================


============================================================
🔄 Round 185 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 185 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0060
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0107
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0234

📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2426, R²: -0.0234

📊 Round 185 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2426, R²: -0.0233

============================================================
🔄 Round 191 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 191 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0055
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0169
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2426, R²: -0.0233

============================================================
🔄 Round 192 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 192 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0101
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0064
============================================================


============================================================
🔄 Round 194 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 194 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0079
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0022
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2426, R²: -0.0232

📊 Round 194 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2426, R²: -0.0232

📊 Round 194 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2426, R²: -0.0232

📊 Round 194 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2426, R²: -0.0232

============================================================
🔄 Round 199 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 199 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0046
   Val:   Loss=0.0938, RMSE=0.3062, R²=0.0167
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2426, R²: -0.0232

============================================================
🔄 Round 203 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 203 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0095
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0040
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2425, R²: -0.0231

📊 Round 203 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2425, R²: -0.0231

📊 Round 203 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2425, R²: -0.0231

============================================================
🔄 Round 210 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 210 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0154
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0255
============================================================


❌ Client client_94 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
