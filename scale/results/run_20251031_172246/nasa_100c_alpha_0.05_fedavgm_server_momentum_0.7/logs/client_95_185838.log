[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa3c1e98-a64e-474b-a543-f070815a1432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21933c9a-44fb-48de-8f22-c6c201d88eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814fab14-165f-439b-8680-ef4544b09436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 935102f1-4b5e-42b2-a536-4a3ba1057111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04321bbc-6c46-4a9b-b167-2e822bb2575b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b743872e-eecd-4558-9afb-78f4799e04d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19e9fdd-f9c2-4d68-b04f-16b51e1ced7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e11667a-2951-4924-aefd-25626ad24e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97f3f460-8206-44a7-9259-52b5bbab55ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14100d17-62da-4ecf-882c-3bf64db97174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 978f8005-b5f3-49b4-9d32-69081823b7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa1f518c-fb6c-4853-8569-5747bc4fd99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82929d07-2e3b-4a8e-87fb-cb940e4cc2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c397393-30cc-4d11-9038-b3c83ccfdcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6481e75f-5d37-4df3-9301-a25d9576e3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36227b22-4305-40f4-b652-1a28409bb24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 430d0ccc-fb8d-4b96-89bf-7506c97a426c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88b69e3-2878-426b-b03f-7e6a272a645d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 487158e8-f1b5-458e-900e-ff3e891effec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10aaee0d-65a6-44ed-848c-f894ec4cf92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ff14527-1eb5-46e7-bdbf-8f014cb39e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa4b238-7f78-46d1-912f-315f4e14b305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb892a56-6b52-4953-8f61-71e5a9617136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e6c240-4135-4c26-bae5-a25254a19019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76329464-c0b7-496f-aec7-d130cf968537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74edb21a-d865-4ace-b9c2-b6d77d58bf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177d4668-2dd7-4fa6-b7bd-a05df67ba86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ae55685-0273-45c6-b9a1-d7214f69bf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccd9de41-1135-48f4-906e-ba3cba9f7461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223ea6ac-1220-499f-a329-1422a291b55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090ecb61-ed23-4689-ad10-7b0505a08abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e01f7004-2974-4b71-a198-2f9c7932459e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ec4822-726e-47b4-bfc9-de0bc3681ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6393af7c-9848-47e7-9957-f282ac9b03d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3186b0d6-eae3-4277-8385-817e3532a002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b8e3f6-ca4e-4617-b093-b13d9cd2e079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76454cc7-b744-4b89-966d-269185ba429d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f674bf9-b988-4ae3-aa91-c0f197333a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35d8689-57cd-43ff-88b8-c244b4abfa58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dcf9e9b-5714-4a1b-a61a-8b67af5fc288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0190414a-d105-431a-8c22-d80684e4958f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c72853b1-3545-43e2-82a5-ebc23c9a1417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231cab38-9b4e-41ff-8e89-70a94a2f2e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe3af88-6ec0-4e8a-8ba2-ea0fe5ad3100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14fc88b-b1cf-4f9a-8b27-064345f1fb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105a8442-8d33-43eb-9279-d1dcae35f9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79d65da-d72f-4a99-9af7-c71256bdd545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bda9c94-030d-474c-8c7d-f882f256b7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5890982f-2126-4327-b1d1-58460338208f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e14c9c-cd55-4a5d-96c7-0c7fbfac4a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11497763-0603-44b8-9915-11717caeadbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 286d8b74-aa54-4647-bb33-b326a860422a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e17b855c-9728-4184-8c89-0f49fe9f3fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a65fe73e-3ecd-4441-bb03-85a5ffea617a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692609ef-a181-436a-ae35-5ab3486e6c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48dd810c-d635-46b9-8e39-55d12e202a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a35da69-c8f6-4a4d-8a1a-8d319bbfca5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7287ad2e-b8c5-4f37-a329-531f28c059f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8fed683-ac22-4ac5-9a53-17cdc73b1bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b8e7620-0d2b-44ec-bc0b-b8c28ff13fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8b6599-55ee-4b56-a5c9-ede123c80d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4614545-2792-46ec-8d39-d2c60b144217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f26d9c04-e7ee-4ec3-bd56-bfabf1bb6b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e32aa33-880a-44d9-ad3e-522befe06631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55379a6-4fb9-4195-8d03-2327234b16f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7de220-b861-4e15-9094-37fb01435bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53dcaa4b-2b33-4590-8246-dac4c5610855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a16f9bc-9c83-4a60-b7c8-3485e4398be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4100302-4754-47ef-95f2-24569d28fbbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d4d8db-bdeb-462b-9922-187f02d67f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77879678-555e-47f0-96b0-f53bb0d11f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4611b5-8bf9-430a-be68-b27b95ef2999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae9ac6e-1e6e-41ca-8b93-e9c28c3d077b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2122816-d0ee-42a2-8087-9849b3904de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33970163-0bf3-4999-a1f5-a36b5eddd35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e3b322-71a8-4069-aba4-ad4b134300eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34b5de80-696d-4e9c-a338-fc597525aefb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc61cbc4-1055-48f5-8c8e-78fc16b8c49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 508b37fc-adce-47f4-b99f-2e003bf039ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b7094d-b88f-4bf0-8a6f-2e4739e07e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6710e3-93e6-49e8-b648-7cc1e415827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c62261-e073-4837-a401-9330d99653b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c9b37e-fe7e-4ad2-8d8f-7b91915b5d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6043cdf9-4474-4b1c-87ea-bb581420fb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6616034e-96a7-4b3d-b1f6-d5f3ad529a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6241a6e-30e7-4fe0-9568-b6d9f59fd0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11787ce3-9aa6-42d7-a4e2-7f8cd771e9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647cb6a9-5b3d-4aa6-bdb5-eb323d0e2b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbf848b-7f34-4b6a-8d0a-22200ae15913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd79108-5f49-471f-abe0-dfd036fb4387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236fffa4-5b91-45fe-a46d-c22ed67526b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c3eb16-8401-42a5-89d0-aaaab1c04290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096be800-0847-4453-924b-a7c77390999f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14db94a-3e5b-48ae-bbff-32c57f7da1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68ff73b-0989-40eb-a033-ed8d33d6152c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a47be3ab-031c-4a7a-8dfe-40f1530c0d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc71ae5e-db29-45a6-bfa1-b54136c19382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38e8fbd-d53f-462a-a6a6-80373ae6ccd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8a232d-fa40-4915-91e4-c223a3fec450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 675c3b38-06eb-47c2-b0cf-fac1d7f62cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5883fd9-0ab3-4080-b57f-91b1a523683e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d5e5e4-9c1c-4e8e-b6c4-265d9a724fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e289a476-8e78-4516-9e72-20ca6516b5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4debc4-4b4e-4abe-adb4-446f05a0da04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57ba7bda-177d-4af8-a483-5692d582b886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e4c308-d0f1-4898-b827-7bc2e5003aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f89c14-e08d-4834-bf5b-03270a990853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae896771-7fe6-4e2c-9776-77f3f7ebf5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77e3432c-433f-4f01-a1ce-7645f7562167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be55fd88-d861-46fc-8af0-d42b61459ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 576f0040-b1f9-4c63-b987-b5aca8b1968a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34e72a85-264e-4c86-96d5-cec604b50a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87884a5-d77f-4911-9623-aa05c7a5e07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce4fe6f1-ebc8-48aa-a026-c8b95922b061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5df15a01-f694-4a29-b874-284e2a1ee144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4bf782e-b972-4cc9-b60e-4e11b4b28502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a56e0b01-b08a-458d-b6da-382b5bd936a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d84dd05-315e-407b-a5be-98f8379eb693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f28dc6-bc01-461e-b7c8-90b8dc6e88d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9203c16e-952d-4be0-b153-667dc613690a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c952fc86-3863-4ad2-893a-310a2b37db0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f95a1f7-c351-4b68-93fa-76b263711781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c8b7854-47af-48f6-8770-d64a6e3c84bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d3bc113-d0ad-4b38-986c-825dddb6ba00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e9c382-597d-40f3-83cd-d67d3b42f05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c87714-eae8-4be3-a7b1-27a4c921d71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a3d90a-2b32-4a29-bdfd-9eb374db31c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0665bcef-47a4-4d1b-863e-c0445a67e0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f760ac1-3bc4-47fc-a0e9-5f0ac0747ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34815ff1-9833-4de7-b966-ed06f6970427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb37b8a-d745-4f96-bf7d-40f50fd9414a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29fee312-184e-4657-bb2e-db564892b3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 014767ad-dc97-43af-b59e-0cccd673a67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17597f56-1310-489f-af49-6f74997e5d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80492e44-d41f-4be1-a1ca-bf9842608a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98bb8f17-d08b-4612-a763-78e5efddf753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55674d74-0d9c-4b2b-b09a-7ee9d7e0d01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a78eddc-f2a0-4a8c-9551-81094a466514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b18986-b8e4-4c2f-ab69-7372cb5d49c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9612b8-8e38-489d-8ae5-14d48d844350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeea53b6-3a3c-462e-904f-0a47b3abe43a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e254c171-e6b6-4359-99b2-09f65e75ee46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c152e8-a219-4bca-afe9-db832cb6000f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d75013-b700-4179-94a3-b1fbd5aae0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8593d30-766b-4bff-9a81-71c0b5aee326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90762674-3dbd-4475-9f11-ca73ecdfe34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06c9cdd-4f8d-4084-931c-05b284accfb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a5e791-f04f-47ab-bc33-c3674c1ff766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452c5011-6088-4fd1-96b5-047921974463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d0c619-6650-4f60-87a3-d0aef856fe9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90574356-2ba9-4661-811e-bc1e84dd54d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48d10a43-d7be-4710-81e8-bdcf95103e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51bda6e5-e796-46b4-abea-7b119b36ce8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea5a5656-f126-44a6-84b1-9e1533b260ec
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_95
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_labels.txt

📊 Raw data loaded:
   Train: X=(1176, 24), y=(1176,)
   Test:  X=(295, 24), y=(295,)

⚠️  Limiting training data: 1176 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  286 samples, 5 features
✅ Client client_95 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2625, R²: -0.0695

============================================================
🔄 Round 17 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0843 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0843, val=0.0837 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0822, val=0.0828 (↓), lr=0.001000
   • Epoch   4/100: train=0.0818, val=0.0827, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0813, val=0.0827, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0780, val=0.0851, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 17 Summary - Client client_95
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0123
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0274
============================================================


============================================================
🔄 Round 18 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0835 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0850, val=0.0825 (↓), lr=0.000250
   • Epoch   3/100: train=0.0844, val=0.0822, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0839, val=0.0820 (↓), lr=0.000250
   • Epoch   5/100: train=0.0836, val=0.0819, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0823, val=0.0813, patience=2/15, lr=0.000250
   • Epoch  21/100: train=0.0812, val=0.0808, patience=5/15, lr=0.000250
   • Epoch  31/100: train=0.0801, val=0.0803, patience=2/15, lr=0.000250
   • Epoch  41/100: train=0.0785, val=0.0797, patience=3/15, lr=0.000250
   • Epoch  51/100: train=0.0757, val=0.0802, patience=2/15, lr=0.000250
   📉 Epoch 55: LR reduced 0.000250 → 0.000125
   • Epoch  61/100: train=0.0713, val=0.0815, patience=12/15, lr=0.000125
   📉 Epoch 63: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 18 Summary - Client client_95
   Epochs: 64/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0721
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0659
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2609, R²: -0.0618

============================================================
🔄 Round 20 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0803 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0866, val=0.0790 (↓), lr=0.000063
   • Epoch   3/100: train=0.0857, val=0.0786, patience=1/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0854, val=0.0784 (↓), lr=0.000063
   • Epoch   5/100: train=0.0853, val=0.0783, patience=1/15, lr=0.000063
   ✓ Epoch  11/100: train=0.0847, val=0.0779 (↓), lr=0.000063
   • Epoch  21/100: train=0.0840, val=0.0775, patience=10/15, lr=0.000063
   • Epoch  31/100: train=0.0834, val=0.0772, patience=7/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 20 Summary - Client client_95
   Epochs: 39/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0226
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0294
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2614, R²: -0.0629

============================================================
🔄 Round 22 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0937 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0834, val=0.0923 (↓), lr=0.000063
   • Epoch   3/100: train=0.0822, val=0.0918, patience=1/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0819, val=0.0917 (↓), lr=0.000063
   • Epoch   5/100: train=0.0817, val=0.0916, patience=1/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0813, val=0.0916, patience=7/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 22 Summary - Client client_95
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0366
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0487
============================================================


============================================================
🔄 Round 25 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0902 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0857, val=0.0892 (↓), lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   ✓ Epoch   3/100: train=0.0852, val=0.0883 (↓), lr=0.000008
   • Epoch   4/100: train=0.0849, val=0.0879, patience=1/15, lr=0.000008
   ✓ Epoch   5/100: train=0.0847, val=0.0876 (↓), lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0838, val=0.0861, patience=1/15, lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0834, val=0.0856, patience=6/15, lr=0.000002
   📉 Epoch 27: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 25 Summary - Client client_95
   Epochs: 30/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0346
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.1218
============================================================


============================================================
🔄 Round 28 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 28 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0536
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.1072
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2577, R²: -0.0356

📊 Round 28 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2574, R²: -0.0336

📊 Round 28 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2572, R²: -0.0321

============================================================
🔄 Round 33 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 33 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0441
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0555
============================================================


============================================================
🔄 Round 34 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 34 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0443
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0538
============================================================


============================================================
🔄 Round 35 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 35 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0476
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0318
============================================================


============================================================
🔄 Round 37 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 37 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0407
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0506
============================================================


============================================================
🔄 Round 38 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 38 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0419
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0503
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2566, R²: -0.0278

============================================================
🔄 Round 43 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 43 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0505
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0094
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2566, R²: -0.0277

📊 Round 43 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2566, R²: -0.0277

📊 Round 43 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2566, R²: -0.0277

============================================================
🔄 Round 48 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 48 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0387
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0586
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2567, R²: -0.0278

============================================================
🔄 Round 49 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 49 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0395
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0577
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2566, R²: -0.0277

============================================================
🔄 Round 51 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 51 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0378
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0623
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2566, R²: -0.0277

============================================================
🔄 Round 52 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 52 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0407
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0525
============================================================


============================================================
🔄 Round 53 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 53 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0398
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0559
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2567, R²: -0.0278

============================================================
🔄 Round 54 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 54 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0429
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0505
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2567, R²: -0.0278

============================================================
🔄 Round 55 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 55 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0374
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0659
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2567, R²: -0.0279

============================================================
🔄 Round 63 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 63 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0456
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0316
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2566, R²: -0.0274

============================================================
🔄 Round 66 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 66 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0440
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0333
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: -0.0269

============================================================
🔄 Round 67 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 67 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0347
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0725
============================================================


============================================================
🔄 Round 73 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 73 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0426
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0403
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2567, R²: -0.0276

============================================================
🔄 Round 74 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 74 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0424
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0554
============================================================


============================================================
🔄 Round 75 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 75 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0485
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0225
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2567, R²: -0.0274

============================================================
🔄 Round 79 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 79 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0463
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0223
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2566, R²: -0.0271

📊 Round 79 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: -0.0263

============================================================
🔄 Round 84 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 84 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0400
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0434
============================================================


============================================================
🔄 Round 85 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 85 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0318
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0813
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: -0.0260

📊 Round 85 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2566, R²: -0.0266

============================================================
🔄 Round 90 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 90 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0420
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0523
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2566, R²: -0.0269

📊 Round 90 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2566, R²: -0.0270

============================================================
🔄 Round 93 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 93 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0428
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0410
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2566, R²: -0.0270

============================================================
🔄 Round 94 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 94 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0407
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0461
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2567, R²: -0.0271

============================================================
🔄 Round 95 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 95 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0429
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0383
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2567, R²: -0.0272

============================================================
🔄 Round 96 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 96 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0382
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0577
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2566, R²: -0.0269

📊 Round 96 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2566, R²: -0.0268

============================================================
🔄 Round 100 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 100 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0343
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0810
============================================================


============================================================
🔄 Round 101 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 101 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0395
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0503
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2566, R²: -0.0266

============================================================
🔄 Round 102 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 102 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0393
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0513
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2566, R²: -0.0265

============================================================
🔄 Round 105 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 105 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0457
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0596
============================================================


============================================================
🔄 Round 107 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 107 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0396
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0913
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2566, R²: -0.0265

============================================================
🔄 Round 109 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 109 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0421
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0393
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2566, R²: -0.0266

============================================================
🔄 Round 112 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 112 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0407
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0644
============================================================


============================================================
🔄 Round 113 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 113 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0387
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0561
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: -0.0263

📊 Round 113 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: -0.0262

📊 Round 113 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: -0.0261

📊 Round 113 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: -0.0261

📊 Round 113 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2564, R²: -0.0254

============================================================
🔄 Round 124 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 124 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0293
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0812
============================================================


============================================================
🔄 Round 125 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 125 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0422
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0301
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2563, R²: -0.0251

============================================================
🔄 Round 128 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 128 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0415
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0353
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2563, R²: -0.0250

============================================================
🔄 Round 129 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 129 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0325
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.1041
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2564, R²: -0.0251

============================================================
🔄 Round 131 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 131 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0409
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0398
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2563, R²: -0.0251

============================================================
🔄 Round 132 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 132 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0376
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0512
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0866, RMSE: 0.2944, MAE: 0.2563, R²: -0.0249

============================================================
🔄 Round 133 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 133 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0389
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0556
============================================================


============================================================
🔄 Round 135 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 135 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0400
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0362
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2562, R²: -0.0243

============================================================
🔄 Round 140 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 140 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0382
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0429
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2562, R²: -0.0240

============================================================
🔄 Round 142 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 142 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0384
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0481
============================================================


============================================================
🔄 Round 145 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 145 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0268
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0801
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2562, R²: -0.0241

============================================================
🔄 Round 148 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 148 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0424
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0264
============================================================


============================================================
🔄 Round 150 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 150 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0428
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0192
============================================================


============================================================
🔄 Round 151 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 151 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0378
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0427
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2561, R²: -0.0236

============================================================
🔄 Round 152 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 152 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0427
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0212
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2561, R²: -0.0236

============================================================
🔄 Round 154 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 154 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0467
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0382
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2561, R²: -0.0236

============================================================
🔄 Round 156 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 156 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0346
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0523
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2561, R²: -0.0235

============================================================
🔄 Round 158 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 158 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0449
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0120
============================================================


============================================================
🔄 Round 159 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 159 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0359
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0491
============================================================


============================================================
🔄 Round 160 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 160 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0407
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0280
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0232

============================================================
🔄 Round 163 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 163 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0347
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0600
============================================================


============================================================
🔄 Round 165 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 165 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0424
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0389
============================================================


============================================================
🔄 Round 166 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 166 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0380
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0375
============================================================


============================================================
🔄 Round 168 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 168 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0356
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0454
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2560, R²: -0.0230

============================================================
🔄 Round 170 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 170 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0382
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0480
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0231

============================================================
🔄 Round 171 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 171 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0375
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0379
============================================================


============================================================
🔄 Round 172 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 172 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0347
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0618
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0232

📊 Round 172 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0232

============================================================
🔄 Round 175 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 175 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0354
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0459
============================================================


============================================================
🔄 Round 176 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 176 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0399
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0304
============================================================


============================================================
🔄 Round 177 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 177 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0382
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0372
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0233

============================================================
🔄 Round 179 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 179 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0402
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0300
============================================================


============================================================
🔄 Round 183 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 183 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0415
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0757
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2562, R²: -0.0236

============================================================
🔄 Round 188 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 188 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0404
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0335
============================================================


============================================================
🔄 Round 189 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 189 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0430
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0194
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2562, R²: -0.0236

📊 Round 189 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2562, R²: -0.0237

============================================================
🔄 Round 193 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 193 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0383
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0393
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2562, R²: -0.0237

============================================================
🔄 Round 194 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 194 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0418
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0273
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2562, R²: -0.0237

📊 Round 194 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2562, R²: -0.0237

============================================================
🔄 Round 196 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 196 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0400
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0381
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2563, R²: -0.0238

============================================================
🔄 Round 199 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 199 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0397
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0357
============================================================


============================================================
🔄 Round 203 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 203 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0334
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0594
============================================================


============================================================
🔄 Round 204 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 204 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0474
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0032
============================================================


============================================================
🔄 Round 205 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 205 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0341
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0620
============================================================


============================================================
🔄 Round 206 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 206 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0393
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0357
============================================================


============================================================
🔄 Round 208 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 208 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0382
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0426
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0233

📊 Round 208 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0232

============================================================
🔄 Round 210 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 210 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0391
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0318
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2561, R²: -0.0232

============================================================
🔄 Round 211 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 211 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0368
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0408
============================================================


❌ Client client_95 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
