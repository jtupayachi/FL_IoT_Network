[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d87e011-94a5-4c13-bb02-ba26145e0e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95589ecb-73c6-440f-89f1-22dd83bb6996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915c0159-bfd5-4561-a6fa-0d8ade191eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a898d246-a69f-4b5d-bb15-1fe96479f3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a22caef-7348-448b-b265-ce8cdd076ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d188175-4420-4dc0-9731-b54c3c153f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c39287ab-9ab1-40e9-9590-653b97b67e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b9c65f-0c74-4ff4-9932-bdd7eed1f6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca9a9ebc-c9dd-4f49-99c0-ed62c7342711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b139ee9-1491-4430-8a8c-6dba7f06cd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4905ec3-02bc-403f-b672-c114c24d5345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119e82ea-130b-4675-9558-710cbc8590f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd9d0073-53ca-4270-a73c-9ff88c360697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43abba0f-ff51-4fe4-8cc7-89ab078dd113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f2311f-4f08-4056-a4f0-adf8e528a3b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adc9c0e7-1e0c-4492-b095-42f94fc01f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a298a19-f943-4ccd-86e7-4854b23f238b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2735b1-4501-4569-b973-0dfc2dcd44f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b520da3-3352-408a-8656-51dc151005ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818d3385-ddd8-46ff-a33c-191497d26e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bc0608-2812-4121-b71d-2a766d80a71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfaeebe7-f7c4-4bcb-8020-9c0fdb0740d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cffef9c8-362a-42db-82de-d94257ad9f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f666c9d0-4284-4abb-a26b-f0798d2fc132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df10def-d5bd-4b8a-b461-34d3683dde0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7fbb7b9-6b69-4ecb-ae76-4895b28c1770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1105b424-985c-421e-a5b8-b028d50eb82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4338b253-46a9-46e8-8e69-7fe85fc75704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2e66be-aa74-4880-92a6-85f6aa183bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8f4ec1-6166-4403-b9f7-dc6f461da0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa1a208-6f3b-49b7-b533-6b8552bd3de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1afcaf8-5834-4a80-a09c-b81ec65aba63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9618af5-6a24-40a1-aaa2-c6a08198d6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dec06b2-0c45-48cb-8fcd-9c38ec962c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd84eecd-6914-4db4-959c-a3d70c0a1b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a814b8a-f19c-4fe5-9d9c-ea4e0005cf44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c88e17ab-d86f-475e-a6f8-ee8c4dca37b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe3858c-befe-49a4-a2f7-fb0da38171fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5000b003-a566-46a0-b35c-a42feaf88134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812abf9d-b773-4379-ac7b-3da449910ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68165b45-aa88-4863-be80-4bce98f3a656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3571a5cf-741e-456d-a0d0-0d9519190d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6780831-c16b-43c9-af6c-db526746dcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04d6271-4dd3-4a70-a283-cab3ac75ae2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a9a48c-2508-4685-95a6-aee2e5989d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c25d587-23d1-466e-bb14-25bc8e0d01b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bcfc010-3f30-4571-9b3a-d9e498220ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e984918-0cac-4765-b3fe-869e4c945882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1339ee19-1796-44df-b792-8afd631913a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d1671d-5ef8-4bba-b452-a1e7b8f6becf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433a1732-2800-46d4-82f4-1a3ce823f9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b72ff5-4675-49c7-9249-38cdb06f9c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc56aea-0353-47e9-a10b-dc1fdf20c8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b49a556-5333-4920-ad94-1b616244f173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb4f8fb5-3909-42c1-8071-7e25489fa24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b232860-bd14-40e0-902d-42ae9ab7c427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340bd1e4-b5e4-4447-8bdd-2588c96e3841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc085da2-899a-47f7-a19e-69b7a3922b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0993dfbf-9bec-4c9e-a89f-4c7f8d024fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29086e1d-7f0d-4688-ad52-a69e5c53d16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 259ea945-d8ec-4491-a773-809230afbb61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65be93f4-e237-48f3-a737-39a953c516d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4044197-caef-487f-bdbe-7c1c1ae257b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a85a5691-c501-4c9f-8877-fc9bae50f860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e7533fa-615a-423f-9e21-1d378a1e4d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63666243-b708-4c59-b1aa-ffe5c1b4c10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1ce0eb-12a7-4c6f-9925-e98cb96e0301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c10d7f8-2678-43ef-96dd-3ed7060e046b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6264338c-427e-47db-a9f2-a8a36df01c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d1d83e8-3b62-49e8-996d-962cd20edabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4bb9b50-f5b0-4c6f-b91b-2203294670b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d513b6-bf55-41ab-8ac7-447f89feab91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a581415a-7a2f-462c-9407-cb3b5672e1ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c4e725-cbb3-4c41-9416-1edb5347dc5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a41be8-efbe-432a-85da-d3438e587fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce1b717-b7f7-4158-a2eb-1a1f924d655e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aadfdcec-6032-41f3-beea-e04191be8b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9ceb96-37e5-4ba9-b2c6-eb6e8504cd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d95f42d-2bf3-4f7f-a069-539b8ceb1361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d246f3ff-4123-410d-92b0-db0e02057d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fb9fa0-e745-4776-8ffa-258d0797e69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4adaa10-9129-48f5-a5a1-1ccddae16f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a937c73-9e9f-43fb-8ddc-8dc8e88fa755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e4fe30d-f265-4f82-afad-ed8b5537a2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a0eb7d-0708-4b1d-b134-bc6121e4727e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a0fe32-20bf-4483-bedb-69ca9ccf3714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79d9809-547b-4efc-b318-13d763515a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2379da5f-694b-4b1c-8d6c-71f0969f31d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9c66d7-6325-47e5-83ce-1bf495cdaa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e86ab4-7009-4701-bb8b-7e913c160926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf63c2a-49a8-4465-91b1-9512e9967b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa05636c-0512-4f99-afea-d4ec2ac05fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa264a59-3d9a-4b03-98a6-aa06285cbb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1260067a-45f7-41c8-ab2f-09545cf37495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb363811-5085-4b0e-8b96-f6a3862b1bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ad0671-e988-4160-8307-8d0ea6a897f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6e9c58-9279-43d5-a1ad-25a8814776aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3931a182-d6c3-46c2-8806-017c9dbfdfd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d255146-7bf5-484c-ae3f-3b0d6fe27e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3939db8-afe0-49dd-b7a5-e70fd2ed0182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d3e1fac-57a3-4ed0-8215-73b69c9327fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd3b5cca-50f4-4dbb-9b63-f048def7137c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25132b96-f812-4f0d-831d-7c3425080388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42327420-720e-4251-8f22-34167e3154c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f0a057-8c6c-4702-af9b-18fcd3b22b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4852c88-0fc6-471c-a746-255dbf1cd1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e867024f-4eac-462b-bf92-3ffd9e9c22e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f59cd95-3b6f-4eb8-8974-ade7b94ba41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f39aec57-95b6-49c4-9266-24ebbbead477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02aa2ae9-2c5a-402d-ac67-09d907ebe5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 009a7cca-8445-47be-8ad7-9afa3976706c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71deae0-62c0-47fb-a8f0-6e0ea8620d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b62a23-a130-463b-9484-3670a04bc828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a11cb0a-a1f2-4c75-a81a-ae2493c2a1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594a23fc-5cef-42e7-b46b-71f207de0fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebc8842b-054a-4629-ae3f-0150bdc24a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa43589-ace7-4c6e-9592-62abf1de12a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce51bf3-a822-4ee5-a970-a89be5f81cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39944b02-acb4-4798-b974-c0dff14abb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e07f51c-3f34-44dc-9cf9-b88f3c7f552b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f0e7f4-1a21-4297-9a20-ae57b777b953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 656e5f41-f8b8-4cbf-996e-8943880b3ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c45b44a4-db3e-4d71-a34e-374f7d7f27cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b496297-9c8b-4e16-8527-314a914ae7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac1f019a-b71f-4c80-ade9-5d64b9b15a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7981495e-5f25-4ae1-a751-8cb2e2303bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41bbe327-82f6-4685-8c42-a77b91bba0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fb08ff-b4b9-484d-bd7e-3950e025ec84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd637b13-e32a-478b-8bef-54230d2947b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57946adf-8211-4a14-ae31-597c2f3c2432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2fda84b-ef24-4db1-a0f0-f898565736b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c0710e-5039-4c38-9247-c8ed05e2fe88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc8e8b18-28e9-479b-841b-d719a137a418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce82087-421e-41ea-b5f1-f830b8f22daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b21918-cd1f-4ba0-b401-c3825d1bbef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b65a4a-1f21-42fa-a2d1-7336ab980728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0f1599-6488-4ad1-913e-22c0bf3d6fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a57bd1-6397-450b-af3d-993c4fddcacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a59bdd-8c5b-4ea7-a241-52aa4e5e89a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a050bbe5-f77e-400e-9e43-8292ff7cb818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99303e6a-e036-4a83-bce1-617098fbc868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2e3690b-b08f-4703-973e-4b9170b00081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad3425f-2b0f-458e-87ab-600a7b09fa0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0564e470-cd0d-4d1b-9052-a2f7e3797f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d4aa41-37c1-4118-a45e-2de0fbe28e3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66552049-d560-4816-b795-2f2006f75e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6305eb-b659-48db-a654-c451b7f106a3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_96
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_labels.txt

📊 Raw data loaded:
   Train: X=(1516, 24), y=(1516,)
   Test:  X=(379, 24), y=(379,)

⚠️  Limiting training data: 1516 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  370 samples, 5 features
✅ Client client_96 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2485, R²: -0.0270

============================================================
🔄 Round 19 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0783 (↓), lr=0.001000
   • Epoch   2/100: train=0.0788, val=0.0778, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0760, val=0.0769 (↓), lr=0.001000
   • Epoch   4/100: train=0.0742, val=0.0765, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0728, val=0.0772, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0645, val=0.0808, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 19 Summary - Client client_96
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.1210
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0863
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2483, R²: -0.0207

============================================================
🔄 Round 21 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0781 (↓), lr=0.000250
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0808, val=0.0770 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0799, val=0.0765 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0791, val=0.0759 (↓), lr=0.000250
   • Epoch  11/100: train=0.0748, val=0.0741, patience=2/15, lr=0.000250
   📉 Epoch 20: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0695, val=0.0739, patience=8/15, lr=0.000125
   📉 Epoch 28: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 21 Summary - Client client_96
   Epochs: 28/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1473
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0370
============================================================


============================================================
🔄 Round 22 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000063
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0808, val=0.0803, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0806, val=0.0802 (↓), lr=0.000063
   • Epoch   5/100: train=0.0803, val=0.0800, patience=1/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0791, val=0.0795, patience=3/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0781, val=0.0793, patience=13/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 22 Summary - Client client_96
   Epochs: 23/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0556
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0329
============================================================


============================================================
🔄 Round 23 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0816, val=0.0810 (↓), lr=0.000008
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0814, val=0.0811, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 23 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0457
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0285
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2481, R²: -0.0166

============================================================
🔄 Round 27 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0680 (↓), lr=0.000004
   • Epoch   2/100: train=0.0850, val=0.0680, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0849, val=0.0681, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0849, val=0.0682, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0848, val=0.0682, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0846, val=0.0684, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 27 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0248
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.0009
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2480, R²: -0.0155

📊 Round 27 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2478, R²: -0.0138

============================================================
🔄 Round 31 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 31 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0252
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0299
============================================================


============================================================
🔄 Round 32 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 32 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0223
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0219
============================================================


============================================================
🔄 Round 34 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 34 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0231
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0022
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2479, R²: -0.0131

============================================================
🔄 Round 35 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 35 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0255
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0222
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2479, R²: -0.0129

============================================================
🔄 Round 40 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 40 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0170
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0537
============================================================


============================================================
🔄 Round 41 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 41 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0273
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0149
============================================================


============================================================
🔄 Round 44 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 44 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0247
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0248
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2478, R²: -0.0119

============================================================
🔄 Round 45 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 45 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0264
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0129
============================================================


============================================================
🔄 Round 46 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 46 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0263
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0182
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2478, R²: -0.0116

============================================================
🔄 Round 49 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 49 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0273
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0063
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2478, R²: -0.0112

📊 Round 49 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2477, R²: -0.0110

📊 Round 49 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2477, R²: -0.0109

============================================================
🔄 Round 56 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 56 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0216
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0189
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2477, R²: -0.0106

📊 Round 56 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2477, R²: -0.0105

============================================================
🔄 Round 59 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 59 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0293
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0116
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2477, R²: -0.0103

============================================================
🔄 Round 63 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 63 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0256
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0151
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2477, R²: -0.0105

============================================================
🔄 Round 64 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 64 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0286
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0100
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2477, R²: -0.0105

============================================================
🔄 Round 68 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 68 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0248
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0216
============================================================


============================================================
🔄 Round 69 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 69 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0236
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0316
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2477, R²: -0.0104

============================================================
🔄 Round 70 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 70 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0254
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0252
============================================================


============================================================
🔄 Round 71 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 71 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0283
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0101
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2477, R²: -0.0102

============================================================
🔄 Round 72 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 72 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0310
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0037
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2477, R²: -0.0101

============================================================
🔄 Round 74 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 74 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0263
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0215
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2477, R²: -0.0099

============================================================
🔄 Round 77 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 77 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0257
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0250
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2477, R²: -0.0099

============================================================
🔄 Round 81 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 81 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0224
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0365
============================================================


============================================================
🔄 Round 83 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 83 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0268
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0108
============================================================


============================================================
🔄 Round 86 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 86 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0269
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0161
============================================================


============================================================
🔄 Round 88 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 88 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0268
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0172
============================================================


============================================================
🔄 Round 91 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 91 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0302
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0095
============================================================


============================================================
🔄 Round 94 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 94 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0220
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0293
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0092

📊 Round 94 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0092

📊 Round 94 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0092

============================================================
🔄 Round 98 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 98 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0227
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0223
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0091

============================================================
🔄 Round 99 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 99 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0301
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0055
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0091

📊 Round 99 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0091

============================================================
🔄 Round 104 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 104 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0287
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0123
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0091

📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0090

📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0090

📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0090

📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0089

============================================================
🔄 Round 109 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 109 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0240
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0289
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0089

============================================================
🔄 Round 110 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 110 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0255
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0250
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0090

📊 Round 110 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0091

============================================================
🔄 Round 115 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 115 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0243
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0245
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0092

============================================================
🔄 Round 116 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 116 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0284
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0040
============================================================


============================================================
🔄 Round 118 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 118 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0269
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0167
============================================================


============================================================
🔄 Round 122 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 122 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0192
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0368
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0098

============================================================
🔄 Round 126 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 126 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0263
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0149
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0097

📊 Round 126 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0096

============================================================
🔄 Round 130 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 130 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0252
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0238
============================================================


============================================================
🔄 Round 132 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 132 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0257
   Val:   Loss=0.0664, RMSE=0.2577, R²=0.0198
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0095

📊 Round 132 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0096

📊 Round 132 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0096

📊 Round 132 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0097

============================================================
🔄 Round 139 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 139 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0266
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0143
============================================================


============================================================
🔄 Round 143 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 143 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0260
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0113
============================================================


============================================================
🔄 Round 145 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 145 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0242
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0260
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2477, R²: -0.0092

============================================================
🔄 Round 148 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 148 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0271
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0100
============================================================


============================================================
🔄 Round 149 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 149 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0282
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0087
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0091

📊 Round 149 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0091

============================================================
🔄 Round 151 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 151 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0283
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0052
============================================================


============================================================
🔄 Round 153 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 153 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0283
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0082
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0090

============================================================
🔄 Round 155 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 155 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0229
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0295
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0089

📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0088

============================================================
🔄 Round 159 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 159 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0223
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0297
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0088

============================================================
🔄 Round 160 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 160 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0230
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0303
============================================================


============================================================
🔄 Round 162 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 162 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0287
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0002
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0089

============================================================
🔄 Round 165 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 165 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0182
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0489
============================================================


============================================================
🔄 Round 166 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 166 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0194
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0451
============================================================


============================================================
🔄 Round 169 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 169 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0205
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0251
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2476, R²: -0.0085

============================================================
🔄 Round 171 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 171 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0303
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0178
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2476, R²: -0.0084

============================================================
🔄 Round 172 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 172 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0256
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0123
============================================================


============================================================
🔄 Round 173 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 173 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0194
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0445
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2476, R²: -0.0082

============================================================
🔄 Round 176 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 176 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0191
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0386
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2476, R²: -0.0081

📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2476, R²: -0.0080

📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2476, R²: -0.0080

============================================================
🔄 Round 180 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 180 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0228
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0314
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2475, R²: -0.0079

============================================================
🔄 Round 183 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 183 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0290
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0037
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2475, R²: -0.0078

============================================================
🔄 Round 187 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 187 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0184
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0351
============================================================


============================================================
🔄 Round 190 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 190 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0277
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0057
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2475, R²: -0.0076

============================================================
🔄 Round 192 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 192 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0189
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0411
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2475, R²: -0.0075

============================================================
🔄 Round 193 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 193 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0294
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0058
============================================================


============================================================
🔄 Round 194 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 194 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0189
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0507
============================================================


============================================================
🔄 Round 195 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 195 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0217
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0376
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2475, R²: -0.0074

============================================================
🔄 Round 196 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 196 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0273
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0160
============================================================


============================================================
🔄 Round 197 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 197 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0278
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0122
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2475, R²: -0.0072

============================================================
🔄 Round 199 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 199 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0239
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0284
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2475, R²: -0.0075

📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2475, R²: -0.0076

============================================================
🔄 Round 205 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 205 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0235
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0314
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2475, R²: -0.0076

============================================================
🔄 Round 207 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 207 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0205
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0401
============================================================


============================================================
🔄 Round 208 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 208 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0248
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0088
============================================================


============================================================
🔄 Round 209 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 209 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0242
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0210
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2475, R²: -0.0076

============================================================
🔄 Round 210 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 210 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0266
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0118
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2475, R²: -0.0076

❌ Client client_96 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
