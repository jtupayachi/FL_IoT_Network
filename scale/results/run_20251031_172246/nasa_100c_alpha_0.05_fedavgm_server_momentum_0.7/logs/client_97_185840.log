[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497bc9e8-c483-4e9f-8b49-2ea7274b2c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70182e5e-b6a2-4e8a-8443-1eda92e54a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe7208a-d008-41ea-93c2-ca2e6f6be5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e9d1ef-76a0-49f7-bf52-11874031ac73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cde349e5-ccba-4eda-8ccd-05b2bd63ee05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086f3ad8-57a9-41b7-85fe-ef9595646de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c84df8-855b-4125-a836-3b80b06f027f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50604fc8-4cab-4bed-9b1c-82b300f01a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce714a9-dd65-4253-98a1-f1c86335f343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df3a3b1a-5fe1-43c1-a67d-fbb4908f5ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb631221-8c48-4d9d-83bc-90717e007d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f32c7297-7ae4-4034-a69f-1acd912dcde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd41f16-da1d-4792-ad60-c8171da8b789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1c3a9f-4a1f-477b-9c03-2dabdef618e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab159e3e-861c-47b0-94e1-33d5f74bf2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 882cb959-d5c5-4027-915f-0399a720b8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc790c8-e769-4829-b655-969ecb2aa022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fb8f53-605c-4530-84c8-57a4af091a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb00df30-b0f7-4211-b330-82d2e8937956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eebba9eb-6f12-4959-855f-398c0a798d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0050e83-4d38-4b29-be14-a92995bc6211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef868cd8-5792-481a-8e2d-ef8ad23bacba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f0617a-250a-489d-b4bd-c751f6178b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aae52d15-d2df-4cc5-bd09-ce70396117d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efdda214-e087-4607-9bb8-f0a20332d87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 044fe832-0db9-463c-b42b-324494a2d93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ccbedbe-0fae-423f-8f19-92894088e956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfdf345d-9cc2-4715-a183-b801db685a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c52afe7a-2dd5-4334-a785-6741729a3916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5966ff57-1f9d-4c09-9bf4-a082d644c5a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65b39a69-ec6c-48ec-8395-5e4a37f286db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f3b209-47c0-4e64-9d12-b76cb54d02e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65b335e4-8f2e-41b4-94d2-d5d276ccc16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf50be85-cda4-4468-bde9-0b2c9e7965f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df1e5dc-e965-4ece-88e3-dc8e61b96d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4463301-cdb8-4ce0-bcbf-51b1b5a336fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4926cc8-ec9a-4cac-939c-41e2d2a6f830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2820b2e6-b7f8-413d-8351-a19f249980f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3da2ed47-9d15-4fbe-a778-6ab75f85a989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea70ec7e-d865-4763-a05b-0008fd7cd5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68831b9f-3004-426c-b264-1ef8b7523b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18355bd-6e93-4f82-9948-bd5925306bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a9b7368-e8a7-483f-9904-aed6ace652ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f68511c-1349-4e4d-9de1-61e5448dcc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78e5020-7907-4764-8026-806135e161fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9915f1a3-6184-4c51-ba89-ef1b13c5d959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbc4894a-0b1f-4f0b-802f-2d9129f0734f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fedb6904-a8f8-4132-99c4-d3f9ee848d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d8f83b-140f-46ac-84fb-039bf54d4019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c74e16-69fa-484b-acc1-4f8fc57c3ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e7c3fc1-b8a6-4778-aba8-0aae35fc8e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dad513a-c24d-4c3b-b91b-007a5ffa50e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7be5e26-9b0b-429a-a05b-a85476da75ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601de61d-b948-4884-8c6d-d8d7849d6a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6599f289-2e23-4561-90df-b47db8874fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a7dd0d-81db-4120-9100-c076706ee2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df91fc36-c77d-49fd-814e-b1db6e3d0b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63660d5c-86fd-4237-bf37-59d02b4798a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d451a77-b8d6-404e-b2c5-f08c67ebffbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0818fc4f-d060-4311-8af4-474343f354f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b59867-372c-4bd1-82d6-a03a8a80dab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d45b562-f2ec-41b3-b1c0-9462f1506ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b92292-11b1-4e35-81c2-db31dbee6970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 518a984c-d458-42bb-877a-23909601275b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522216ac-f8a0-4bd1-bc8c-969a068aaf27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b99f9df7-133b-4bb4-9ea3-39124c44c776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac27eff-547a-4787-bd7d-bba7f32d7375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bbaab4-f3cc-47af-8e4f-9f933857b300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13520641-7386-4e4f-927f-d5e794159e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506e2a75-27ae-4965-875c-df8af0a9a336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbc0a508-5d9d-4bd5-87c2-09c41a4c1afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed4ad73-07ec-4712-bbab-444780f95f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a75ae4-f25e-40f2-b42d-bf50e30f282e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a023852a-1612-47e9-8eeb-fea898a52438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c00116a6-7456-45b3-b9dd-3363e0625637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08537874-7155-4412-94da-ce9a779ad356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d849d7a-70c7-40d3-a546-5f8fac1fbd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cb70e36-b2ae-4864-b08a-c740186a8da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45e36e0-cad0-4a70-9b0f-1a4f92c83c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95cd3b6-18c9-42ab-8b29-75f9a28f6d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b21564f-178c-47b7-a9e8-beda21d202a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9782690-3ef3-4efc-9066-f5fb03abf49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961df129-a0cb-4174-8a8a-7f8723a18442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b71e8fbf-fe75-4181-bee1-f333ff3db63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3f80e34-602d-4653-ae82-f07ac1b195a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02668567-7a52-4a3c-98b7-1ca64c8bea1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51dc087-f497-4213-b086-f5d2dafbad2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef641070-5568-4909-8246-66c1cd193a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15946e40-7a2f-491b-9523-f8ce866ca78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28281d3-e947-43da-b0b8-632b0aca06ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f33155-166d-4442-bf23-37deffb78b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91be0739-94ca-4e83-83b1-11b82dba3d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87f488d3-b617-4935-ae36-0d4a55c596ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f83166f-9d3d-48f7-9b9d-3fa7728065c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fdc830-b32d-4196-bc27-991359abfdd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af36558e-ead7-4e8e-9847-a678a9ff7d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae9baea-af93-48c9-9453-da456985664d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522df76f-63c4-49a5-9ced-d7e32240e9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95576071-5ae9-4b89-8ea9-8fda9a51ce42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd87362-1395-4927-835e-346d529c26ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4152a3-68b3-42d4-b208-9d1758c514a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4404e693-ed64-48bd-9383-84e10cf733a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718f2320-bbeb-4977-86cd-cc14652795dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356d8827-529b-48a8-b49a-7e2843acd4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba9375d5-ea38-40a8-94b1-df0a0a8c1bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 429ee2d7-2817-47a7-90b2-e04b8df66890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693f2141-e56f-4b7f-86b4-409691c7d6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a218e458-e96a-43a9-97e8-9790a464c24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1e6e2b-a780-4c36-b105-040fdb765a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2c1f19-ec7f-451f-aa9a-23238af15dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f2d45fb-2722-4b2c-9717-1dc5095bafcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f14d2de-f9b1-4c60-8f4a-01fa9517689d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1b2c7b-8088-45df-bdca-643454e1bbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b80bc1-04e0-4f7f-a87b-91f9642e2487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180bd172-1ddf-4b67-bba9-3dbf129dcd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b3dc59b-835a-4d16-b91b-cd6a42024cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f07aca28-010a-4932-a643-4b87d165f7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 805107fc-ff99-4290-bacb-db6d26cef0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a1bcbe2-b431-40f1-8a47-8dcfe3685bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b47932c-84ea-478b-a723-07ca45d25d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0078c587-56bc-4914-92fd-d15e0c72e8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6112743-0394-4175-bfc5-f635decbcec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0554f8c2-518b-4a91-9ec1-624937388341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72bb1e54-b4c3-4fc3-aaed-c30189572175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46528fe-e63c-47b5-ac86-55ae7b7210ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48e5041-8080-43bc-8dcd-022e25310b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c682332-9dec-4c40-9c50-1ba6a244260a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14fca6fe-692f-4ff8-8675-b4c6eb7cc350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b2a29a-ba22-41fa-9d59-ddf23dc57da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707bd5a0-bb47-4f71-b238-213a685cc118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acdc9221-5836-4ffd-b872-f49563732ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d1173a-b972-4b83-a04e-c6b4ce228264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805c918e-d0b2-42e9-96ed-b98aa6ccd773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b89955-8a3e-4dd5-b833-f184592fbe72
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_97
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/test_labels.txt

📊 Raw data loaded:
   Train: X=(1124, 24), y=(1124,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1124 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_97 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2485, R²: 0.0033

📊 Round 0 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2485, R²: -0.0002

============================================================
🔄 Round 19 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0824 (↓), lr=0.001000
   • Epoch   2/100: train=0.0791, val=0.0825, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0780, val=0.0843, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0769, val=0.0848, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0761, val=0.0863, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0710, val=0.0912, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 19 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0510
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0401
============================================================


============================================================
🔄 Round 21 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0831 (↓), lr=0.000250
   • Epoch   2/100: train=0.0790, val=0.0828, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0787, val=0.0829, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0783, val=0.0828, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0780, val=0.0829, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0769, val=0.0831, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 21 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0360
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0311
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2490, R²: -0.0033

============================================================
🔄 Round 23 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0908 (↓), lr=0.000063
   • Epoch   2/100: train=0.0772, val=0.0909, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0769, val=0.0910, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0768, val=0.0911, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0766, val=0.0911, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0761, val=0.0915, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 23 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0424
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0033
============================================================


============================================================
🔄 Round 24 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0770 (↓), lr=0.000016
   • Epoch   2/100: train=0.0803, val=0.0770, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0802, val=0.0770, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0801, val=0.0771, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0801, val=0.0771, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0799, val=0.0771, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 24 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0384
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0090
============================================================


============================================================
🔄 Round 25 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0806 (↓), lr=0.000004
   • Epoch   2/100: train=0.0798, val=0.0806, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0798, val=0.0806, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0797, val=0.0806, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0797, val=0.0806, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 25 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0324
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0391
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2483, R²: 0.0061

📊 Round 25 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2486, R²: 0.0059

============================================================
🔄 Round 29 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 29 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0354
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0249
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2488, R²: 0.0057

============================================================
🔄 Round 30 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 30 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0172
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0430
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2489, R²: 0.0053

============================================================
🔄 Round 34 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 34 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0213
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0057
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2490, R²: 0.0050

============================================================
🔄 Round 36 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 36 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0166
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0147
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2490, R²: 0.0049

============================================================
🔄 Round 41 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 41 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0069
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0551
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0051

📊 Round 41 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0051

============================================================
🔄 Round 45 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 45 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0249
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0040
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0052

============================================================
🔄 Round 46 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 46 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0263
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0265
============================================================


============================================================
🔄 Round 47 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 47 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0286
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0146
============================================================


============================================================
🔄 Round 48 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 48 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0141
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0410
============================================================


============================================================
🔄 Round 49 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 49 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0157
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0300
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0053

============================================================
🔄 Round 52 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 52 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0171
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0282
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0053

📊 Round 52 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0054

============================================================
🔄 Round 59 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 59 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0274
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0063
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2490, R²: 0.0055

📊 Round 59 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0054

============================================================
🔄 Round 64 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 64 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0217
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0127
============================================================


============================================================
🔄 Round 66 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 66 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0185
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0185
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0052

📊 Round 66 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0053

============================================================
🔄 Round 69 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 69 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0154
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0281
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0053

============================================================
🔄 Round 70 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 70 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0187
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0111
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0054

============================================================
🔄 Round 73 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 73 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0168
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0219
============================================================


============================================================
🔄 Round 75 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 75 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0193
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0248
============================================================


============================================================
🔄 Round 76 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 76 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0226
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0046
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2491, R²: 0.0055

============================================================
🔄 Round 78 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 78 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0215
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0083
============================================================


============================================================
🔄 Round 80 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 80 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0212
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0141
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0053

============================================================
🔄 Round 82 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 82 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0204
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0160
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

============================================================
🔄 Round 85 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 85 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0281
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0130
============================================================


============================================================
🔄 Round 86 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 86 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0207
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0007
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0053

📊 Round 86 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0054

============================================================
🔄 Round 89 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 89 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0211
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0151
============================================================


============================================================
🔄 Round 91 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 91 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0190
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0234
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2491, R²: 0.0056

📊 Round 91 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2491, R²: 0.0056

============================================================
🔄 Round 96 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 96 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0143
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0339
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2491, R²: 0.0055

============================================================
🔄 Round 101 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 101 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0162
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0326
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2491, R²: 0.0055

============================================================
🔄 Round 102 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 102 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0251
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0079
============================================================


============================================================
🔄 Round 103 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 103 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0178
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0090
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2491, R²: 0.0055

============================================================
🔄 Round 108 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 108 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0175
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0312
============================================================


============================================================
🔄 Round 109 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 109 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0172
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0104
============================================================


============================================================
🔄 Round 110 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 110 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0185
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0214
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2491, R²: 0.0055

📊 Round 110 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2491, R²: 0.0054

============================================================
🔄 Round 117 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 117 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0222
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0104
============================================================


============================================================
🔄 Round 118 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 118 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0243
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0043
============================================================


============================================================
🔄 Round 119 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 119 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0190
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0113
============================================================


============================================================
🔄 Round 123 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 123 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0213
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0105
============================================================


============================================================
🔄 Round 126 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 126 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0146
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0351
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

============================================================
🔄 Round 130 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 130 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0193
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0181
============================================================


============================================================
🔄 Round 132 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 132 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0208
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0120
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0051

============================================================
🔄 Round 138 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 138 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0183
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0153
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0051

📊 Round 138 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0051

============================================================
🔄 Round 142 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 142 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0107
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0403
============================================================


============================================================
🔄 Round 144 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 144 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0197
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0061
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

============================================================
🔄 Round 146 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 146 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0269
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0096
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

============================================================
🔄 Round 147 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 147 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0263
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0139
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

============================================================
🔄 Round 149 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 149 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0205
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0098
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

📊 Round 149 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

============================================================
🔄 Round 151 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 151 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0112
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0349
============================================================


============================================================
🔄 Round 153 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 153 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0164
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0248
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0053

📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0053

📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0053

📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0053

📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0052

📊 Round 153 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0053

============================================================
🔄 Round 167 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 167 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0150
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0314
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0053

============================================================
🔄 Round 169 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 169 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0083
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0534
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0053

============================================================
🔄 Round 173 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 173 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0133
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0375
============================================================


============================================================
🔄 Round 174 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 174 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0124
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0416
============================================================


============================================================
🔄 Round 176 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 176 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0205
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0090
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0054

📊 Round 176 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0054

============================================================
🔄 Round 180 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 180 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0187
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0179
============================================================


============================================================
🔄 Round 181 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 181 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0164
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0280
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2492, R²: 0.0054

📊 Round 181 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2492, R²: 0.0055

============================================================
🔄 Round 185 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 185 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0153
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0125
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2492, R²: 0.0055

============================================================
🔄 Round 186 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 186 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0104
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0504
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2492, R²: 0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2492, R²: 0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2492, R²: 0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2492, R²: 0.0055

============================================================
🔄 Round 190 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 190 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0237
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0077
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2492, R²: 0.0055

============================================================
🔄 Round 192 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 192 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0154
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0326
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2492, R²: 0.0056

============================================================
🔄 Round 194 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 194 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0203
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0012
============================================================


============================================================
🔄 Round 195 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 195 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0213
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0074
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2492, R²: 0.0056

📊 Round 195 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2492, R²: 0.0056

============================================================
🔄 Round 207 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 207 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0233
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0031
============================================================


============================================================
🔄 Round 210 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 210 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0231
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0120
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2492, R²: 0.0055

❌ Client client_97 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
