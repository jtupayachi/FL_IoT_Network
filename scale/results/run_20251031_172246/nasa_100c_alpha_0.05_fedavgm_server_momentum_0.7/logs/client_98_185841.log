[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e58c2099-3b3c-41f1-a711-69c01ad740c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b876b1-bd11-46eb-a9ab-a45ebb8e4ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7d4555-40ad-4a14-a7cd-c90901c7ae19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ce1c11-1baa-4c3d-a4f6-67d41f01b64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef1c4d38-f5eb-46f2-bf38-244a543740e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c729786-7c7f-4b8f-b087-c1eafb651bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9dd50b-250a-4773-8e6f-ac33cf27995c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28ce2af-b627-4f98-bab2-c41f45a153af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f067b0-c115-4283-b21a-b82bf17260bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15558f05-542f-47ca-a04a-bfd51dc39dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08371469-c0dc-4305-b057-7d600e31e3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f59b8a2-3de7-4009-8ed1-8b20c23ae17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f2c3be0-1d29-443b-8792-c43ba306695c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2eb95de-d5de-46fa-a615-f000b1bb4882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66bd85d4-bfe3-4577-bbac-584a20e614b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd97016-1d80-416d-a596-ff3a69f04819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d37adaef-7322-40c5-b25d-48d8b6df22b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fd3cfa-303e-4173-ba32-884fd77928a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4355cad-eb03-41e8-ae45-20af2ae4fd99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22d078f8-a831-4cd1-9c5d-5588297e8241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e9109f-6a53-4454-8950-e7b9d6dc9f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194bfdd0-d795-4599-ba76-e4cf4404d1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a332be-0d40-4a1a-a242-142593a20a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8e075a0-0f95-4d4f-88d1-a1d4d36f40e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de620f9-907a-4d1c-a038-4e9047867421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69806394-3d22-402e-82e9-86771015f10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987a3637-da26-4393-91bd-898d161a74ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14534397-e4c8-4c7b-bbfa-29d423d465a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67be4cfa-62f7-45cb-bf0e-13e9dfd22a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa78197a-e80e-4b65-82b4-8a3760ac7846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd113c0-fde9-422a-b8f3-e5152bffdf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1e5043-648b-44f8-bd04-0784690e1ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 685bee87-efdb-4a0f-9e62-d44dcb92fc72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 670ea3c1-6c92-43b7-8df1-16aafcb6b794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8fb11e-762f-4724-b37e-2bb2f97dd542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03386626-a75f-407a-ac6f-5771f459eebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 968a5824-c72c-4f20-9932-5042e9516336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58944867-0793-4842-89ee-710d0405f465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3336f605-080a-40ea-9adb-e953e076a011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4faa52e4-591e-44a9-adcf-87b774f01262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7774db-c0d2-4fd8-8f3c-d197517dace3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e16ce993-554a-4d9e-9185-98647e1ab2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cfb4cd8-5915-4529-9ed0-e39d1dd2e5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a54b80c-a65a-4588-8260-8b6e8dfc9c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a2031a3-69b9-4d3e-8ab6-a4d2d1808ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0192210-eb56-42d6-9115-85ba513a13e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ac6748-5057-42db-8770-13bc412e0d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f078a9b-8a75-41eb-b77e-a16c8df38080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2b1d68-c489-4179-bbb0-e294a59c9bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 725a9069-8183-4b5c-8b18-413c7bd1275c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571f7d0d-8f82-4651-8170-2dd2620ff710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1354b5c9-9420-4a3e-8373-6c1eff07563c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72c541f-2795-4ce0-939d-6bb44624c2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef064f2-9fc1-40e4-bd20-aa114b1b68b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561e7f04-8a57-436e-9109-5542186bc645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d152fea8-cfe1-4529-a345-d2f2dedf3d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ad53bd-27e8-4dd2-91b9-6153e91e6613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 856407a7-781b-4f03-8fa9-a78dac43bf97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b1db00d-4c08-4b0d-b508-1bf4c2ec23ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed947c4-3d77-46bb-b7ff-3f34e48d63be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610f933e-3ef8-495c-b7ba-4a94fd2f8fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8db0e7b-aec8-46a3-92c5-d54067aac2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b23f58-e230-4ef1-9e2c-c0dfc96f06a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7020efb-ca8f-4b97-bedf-a46949038973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7092c38-4586-4fc5-ba57-caf66ae341cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e64e31d-4344-498f-b5af-b1cca6d16c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e5bfb1-bc09-406e-9cef-600e39a5dac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f1cd0f-ab26-454e-831b-332e0f295947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f8b544-74e3-4c60-adba-7971b598801b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b7aac3-ff0a-44cb-812b-ae1716c217ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a634668c-ed29-4b21-b9ba-ae452c553a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df99676b-4b26-45bd-9619-22c575874039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2330e5-e8f0-41b8-9d1d-60c184565178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccdab27d-2cc2-4fb4-805b-b7d63e608ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0882910c-5866-4949-a000-645174a49f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144fd59d-c9f7-4187-8c2e-af067f7bcb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fedaca1-821e-4f4a-9ae9-00a1c0f50689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d342b0d1-157a-4d4e-8334-c92d79837b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed928f15-f06b-4392-b1f5-bc80aa00699f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 301ff39d-3f1e-4204-b350-cdc46452fdbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97b1811-9ad5-48ea-a5f8-28e61a0b2b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c44c4b-9702-4c03-a6af-148bce3c6cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a406ce4-1c56-43bf-8580-6dfe754f3d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2477a87e-b2fa-4a5b-b7a8-7886561d9597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15f4ea2-af39-4392-8d5e-44f8c6a36b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0077123e-d62a-4299-9d87-a06cdb06617e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6398afa2-4c1b-46fd-88a7-bd27f8b3d68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a1f7a6-0d1a-4237-b05f-18b0cb2ffcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fac59d8-20cc-4c25-9823-ee5e202172ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98980f33-5949-451b-b264-fd5967eebca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd1f567-765d-4711-8e88-59bc4a17edd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67b6470-e23f-4a27-baa1-b8fec42a0453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a7e480-e6f9-4763-84e3-51db047a4cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aa61afc-e0f1-4f96-8586-14f3d0f5ebb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0c09d33-34d0-4621-a65e-d25cd1966cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d76c9f7-2d38-4733-96ef-5721bab2f541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309ea161-a2e4-4a01-9201-edfc4ffa6a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c54d66d7-ad28-4a5f-87ea-cfcc8438fce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d359325-35a9-4389-b7f1-2e23291cdc27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da817174-b7be-436a-a78a-f0fd19b32f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b8ad7cd-8c7c-4da0-8b67-be472c5d31b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc72bc3-9cce-413d-adfa-80833d629b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea5f7dc-3788-4fd1-ab3a-a2ed8f0cdfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78ddf23-4157-4f0e-8912-85c4fb9339dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60b5a53-be05-44d3-8028-cf1eca9f419b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 873248d3-a85d-4254-a28c-0cc85b783a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecdf0f14-afa7-4d3c-a272-93d5764eb514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cfb38e3-5dbd-49d3-88a1-fcbe93ddd483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3388e4b8-e3dd-496a-8db1-507f87352aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe6968aa-21d8-4a82-b384-614baefd7084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e429891-17a6-4b57-b8fa-b67c8cb1fff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c818291-ecf7-4015-8cc4-eb2a1dc6b988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b7759e-2df4-44ed-b4fc-4cf116bb7192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615e96b4-6330-4a75-bf3a-f297f87bffe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f69fc3-c4d9-4f35-b1f5-3033d5cf03ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ab4eed-b160-43c4-915f-d9950d0a1227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f43b2e0-3a73-486e-83fa-4ae50a214932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a0b69c-e7f6-4885-ab22-b9da2f78f920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 837a48bc-1de1-472e-b8ff-bbf9a081143f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1522ac87-5b66-427f-a831-99a5373accbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a1c894-c61f-4acd-bfeb-d49a0159b7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a1decd-f630-4771-bc6f-5d04e929f3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e94d07-f063-4933-bcf0-eaa8118bba56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68130a75-993e-4dbd-b513-5a80d9bf3637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1da2310-fff7-4c0b-b1c9-2b6dc336e74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244e76ce-91a7-4aae-8ddc-8d0fcd33c727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1031ea-2ceb-4b70-bc07-ffde12b235ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b05b83e-6abc-42ba-89ad-56b73d30bc1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 245f533c-9b56-4d46-b948-dfab3f6fc748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54f8b31-dff3-4d52-af70-1c57fad6b68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48b533c-1109-4060-962c-befc1422441b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31dc0b81-5934-4a12-a44e-3850366d6a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 621aaa0c-ed77-4bf8-8dc1-188697bf1e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ec7904-2f00-4fd0-9cc6-4a60db699cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abcd1da-fe46-491c-84ab-0997f1a63f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eedd77d-90cd-4b4f-82af-3f10fa2d1471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acaa890b-41a0-46de-9d29-2cf6755e88f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e4b360-ac5c-44d6-a276-d86e713d16de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68ea35d-0395-4791-9439-dd70ae6745b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a892083-9c42-4223-ad37-6d7fbc84e208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700ee6a6-4af0-4d44-b78b-c4b669747b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff5838e5-31c3-462c-88e0-fc24a45de4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6b5f4a-3cfa-4a7c-bf97-e00ee34e16fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc039456-a123-49cf-9cbc-6632907975b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 872ece67-c928-4b17-b15c-92ec4a08c9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c3ee78-c1d3-4b5f-9b33-1570d22fb652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e43ecb-0b68-43cb-80e3-30bcfe6f03d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f401c249-3925-4b67-90b0-16141fef8789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5225479-90c0-44a3-a4b9-5c6324b9b058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae231bb3-078e-4647-8252-3ccd94c4167b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020ad7a5-8439-4256-b286-3e80d1b4292c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6d8644-8bed-4c17-8643-3e4cac28068c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa370b22-25b8-4801-942e-bcdebcfe2406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915bb43e-f8aa-4e82-bd6d-3f313a2dfcdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1a791a-b16b-48c7-9cc2-796c87fe6dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe6c675-9e02-4fcf-ad0d-f0bdb6709873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a99466b-3b22-4856-90fa-ffe0484da453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fb5a33-58a8-41ec-b8ed-c364da66fefe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa6c6b0-fd71-49db-a3c5-d279f10d21fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f46f4fed-a188-4bc3-ad83-881537b1dc34
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_98
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/test_labels.txt

📊 Raw data loaded:
   Train: X=(1000, 24), y=(1000,)
   Test:  X=(251, 24), y=(251,)

⚠️  Limiting training data: 1000 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  242 samples, 5 features
✅ Client client_98 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0815 (↓), lr=0.001000
   • Epoch   2/100: train=0.0733, val=0.0856, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0714, val=0.0841, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0701, val=0.0836, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0691, val=0.0837, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0641, val=0.0853, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 16 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0720, RMSE=0.2684, R²=0.1407
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0330
============================================================


============================================================
🔄 Round 17 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0752 (↓), lr=0.000250
   • Epoch   2/100: train=0.0758, val=0.0748, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0750, val=0.0746 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0742, val=0.0740 (↓), lr=0.000250
   • Epoch   5/100: train=0.0736, val=0.0735, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0713, val=0.0728, patience=5/15, lr=0.000250
   📉 Epoch 17: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0685, val=0.0738, patience=15/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 17 Summary - Client client_98
   Epochs: 21/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1522
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0836
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0685, RMSE: 0.2618, MAE: 0.2210, R²: 0.0934

============================================================
🔄 Round 22 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0774 (↓), lr=0.000125
   • Epoch   2/100: train=0.0754, val=0.0777, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0746, val=0.0777, patience=2/15, lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   • Epoch   4/100: train=0.0737, val=0.0774, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0728, val=0.0775, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0710, val=0.0786, patience=10/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 22 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.1166
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0586
============================================================


============================================================
🔄 Round 23 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0849 (↓), lr=0.000031
   • Epoch   2/100: train=0.0744, val=0.0847, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0743, val=0.0846, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   • Epoch   4/100: train=0.0741, val=0.0845, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0740, val=0.0844 (↓), lr=0.000016
   • Epoch  11/100: train=0.0737, val=0.0841, patience=6/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008
   📉 Epoch 20: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 23 Summary - Client client_98
   Epochs: 20/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1092
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0867
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0695, RMSE: 0.2637, MAE: 0.2227, R²: 0.0804

📊 Round 23 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2233, R²: 0.0762

============================================================
🔄 Round 29 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0818 (↓), lr=0.000004
   • Epoch   2/100: train=0.0759, val=0.0818, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0759, val=0.0818, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0759, val=0.0818, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0759, val=0.0818, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0758, val=0.0817, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 29 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0887
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0867
============================================================


============================================================
🔄 Round 30 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 30 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0786
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.1139
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2251, R²: 0.0659

============================================================
🔄 Round 31 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 31 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0825
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.1028
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2253, R²: 0.0646

============================================================
🔄 Round 33 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0608 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0608, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0608, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0608, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0608, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0608, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0608)

============================================================
📊 Round 33 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0758
   Val:   Loss=0.0608, RMSE=0.2466, R²=0.1352
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0707, RMSE: 0.2660, MAE: 0.2254, R²: 0.0644

============================================================
🔄 Round 34 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 34 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0918
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0623
============================================================


============================================================
🔄 Round 35 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 35 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0782
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.1146
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0641

============================================================
🔄 Round 36 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 36 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0903
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0670
============================================================


============================================================
🔄 Round 38 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 38 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0838
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0699
============================================================


============================================================
🔄 Round 41 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 41 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0873
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0712
============================================================


============================================================
🔄 Round 43 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 43 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0868
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0757
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0707, RMSE: 0.2660, MAE: 0.2255, R²: 0.0644

============================================================
🔄 Round 46 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 46 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0850
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0847
============================================================


============================================================
🔄 Round 48 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 48 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0872
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0685
============================================================


============================================================
🔄 Round 49 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 49 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0850
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0835
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2255, R²: 0.0647

============================================================
🔄 Round 51 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 51 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0895
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0651
============================================================


============================================================
🔄 Round 54 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 54 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0780
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.1014
============================================================


============================================================
🔄 Round 56 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 56 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0864
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0729
============================================================


============================================================
🔄 Round 58 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 58 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0892
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0624
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0652

============================================================
🔄 Round 60 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 60 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0833
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0789
============================================================


============================================================
🔄 Round 62 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 62 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0919
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0569
============================================================


============================================================
🔄 Round 63 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 63 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0866
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0703
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2255, R²: 0.0653

============================================================
🔄 Round 64 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 64 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0879
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0494
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2255, R²: 0.0654

============================================================
🔄 Round 66 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 66 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0832
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0883
============================================================


============================================================
🔄 Round 67 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 67 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0871
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0718
============================================================


============================================================
🔄 Round 68 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 68 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0742
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.1222
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2255, R²: 0.0655

📊 Round 68 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2255, R²: 0.0656

============================================================
🔄 Round 72 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 72 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0849
   Val:   Loss=0.0674, RMSE=0.2595, R²=0.0651
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0659

============================================================
🔄 Round 77 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 77 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0783
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0828
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2254, R²: 0.0660

📊 Round 77 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2255, R²: 0.0659

📊 Round 77 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2255, R²: 0.0659

============================================================
🔄 Round 84 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 84 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0808
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0939
============================================================


============================================================
🔄 Round 85 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 85 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0761
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.1153
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2255, R²: 0.0659

📊 Round 85 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2255, R²: 0.0661

============================================================
🔄 Round 88 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 88 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0888
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0566
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2255, R²: 0.0662

📊 Round 88 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2255, R²: 0.0663

============================================================
🔄 Round 91 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 91 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0821
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0844
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2254, R²: 0.0664

============================================================
🔄 Round 95 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 95 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0795
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1021
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0706, RMSE: 0.2656, MAE: 0.2254, R²: 0.0667

📊 Round 95 Test Metrics:
   Loss: 0.0706, RMSE: 0.2656, MAE: 0.2254, R²: 0.0667

============================================================
🔄 Round 98 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 98 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0865
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0747
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0706, RMSE: 0.2656, MAE: 0.2254, R²: 0.0667

============================================================
🔄 Round 101 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 101 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0787
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.1010
============================================================


============================================================
🔄 Round 102 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 102 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0741
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.1237
============================================================


============================================================
🔄 Round 103 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 103 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0963
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0289
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0706, RMSE: 0.2656, MAE: 0.2254, R²: 0.0668

📊 Round 103 Test Metrics:
   Loss: 0.0706, RMSE: 0.2656, MAE: 0.2254, R²: 0.0668

============================================================
🔄 Round 106 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 106 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0913
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0521
============================================================


============================================================
🔄 Round 108 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 108 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0886
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0651
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2254, R²: 0.0670

============================================================
🔄 Round 113 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 113 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0873
   Val:   Loss=0.0776, RMSE=0.2787, R²=0.0629
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2254, R²: 0.0670

📊 Round 113 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2254, R²: 0.0670

============================================================
🔄 Round 115 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 115 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0969
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0391
============================================================


============================================================
🔄 Round 116 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 116 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0926
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0498
============================================================


============================================================
🔄 Round 118 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 118 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0812
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0759
============================================================


============================================================
🔄 Round 119 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 119 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0811
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0955
============================================================


============================================================
🔄 Round 120 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 120 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0747
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.1010
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2254, R²: 0.0669

📊 Round 120 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0669

============================================================
🔄 Round 122 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 122 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0899
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0542
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0706, RMSE: 0.2656, MAE: 0.2255, R²: 0.0669

📊 Round 122 Test Metrics:
   Loss: 0.0706, RMSE: 0.2656, MAE: 0.2255, R²: 0.0669

============================================================
🔄 Round 126 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 126 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0882
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0636
============================================================


============================================================
🔄 Round 127 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 127 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0928
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0493
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0669

📊 Round 127 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0670

============================================================
🔄 Round 129 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 129 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0900
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0511
============================================================


============================================================
🔄 Round 130 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 130 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0809
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0810
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0671

============================================================
🔄 Round 132 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 132 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0836
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0861
============================================================


============================================================
🔄 Round 133 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 133 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0871
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0704
============================================================


============================================================
🔄 Round 134 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 134 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0865
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0454
============================================================


============================================================
🔄 Round 135 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 135 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0845
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0786
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0670

============================================================
🔄 Round 138 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 138 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0851
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0692
============================================================


============================================================
🔄 Round 139 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 139 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0798
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0970
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0670

📊 Round 139 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0671

📊 Round 139 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0671

============================================================
🔄 Round 143 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 143 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0689
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.1444
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0671

============================================================
🔄 Round 145 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 145 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0873
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0687
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0672

📊 Round 145 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0673

📊 Round 145 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2255, R²: 0.0673

============================================================
🔄 Round 153 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 153 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0808
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0924
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0705, RMSE: 0.2656, MAE: 0.2256, R²: 0.0673

============================================================
🔄 Round 154 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 154 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0784
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0936
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0673

============================================================
🔄 Round 155 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 155 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0897
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0552
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0674

============================================================
🔄 Round 159 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 159 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0714
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.1240
============================================================


============================================================
🔄 Round 160 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 160 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0850
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0756
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0673

============================================================
🔄 Round 162 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 162 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0876
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0615
============================================================


============================================================
🔄 Round 164 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 164 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0864
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0656
============================================================


============================================================
🔄 Round 165 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 165 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0823
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0853
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0674

============================================================
🔄 Round 166 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 166 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0749
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.1141
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0674

============================================================
🔄 Round 167 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 167 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0842
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0748
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0675

============================================================
🔄 Round 168 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 168 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0838
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0785
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0676

📊 Round 168 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2256, R²: 0.0676

============================================================
🔄 Round 172 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 172 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0851
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0659
============================================================


============================================================
🔄 Round 176 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 176 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0867
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0693
============================================================


============================================================
🔄 Round 177 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 177 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0734
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.1154
============================================================


============================================================
🔄 Round 178 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 178 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0832
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0819
============================================================


============================================================
🔄 Round 179 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 179 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0853
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0745
============================================================


============================================================
🔄 Round 180 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 180 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0828
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0773
============================================================


============================================================
🔄 Round 181 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 181 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0751
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.1087
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2255, R²: 0.0679

============================================================
🔄 Round 182 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 182 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0802
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0914
============================================================


============================================================
🔄 Round 183 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 183 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0815
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.0879
============================================================


============================================================
🔄 Round 184 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 184 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0908
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0378
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2255, R²: 0.0680

============================================================
🔄 Round 185 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 185 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0747
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.1134
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2255, R²: 0.0681

============================================================
🔄 Round 186 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 186 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0831
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0822
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2255, R²: 0.0681

📊 Round 186 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2255, R²: 0.0681

============================================================
🔄 Round 188 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 188 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0862
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0657
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2255, R²: 0.0682

📊 Round 188 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2255, R²: 0.0682

============================================================
🔄 Round 190 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 190 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0852
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0697
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2255, R²: 0.0682

============================================================
🔄 Round 192 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 192 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0822
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0836
============================================================


============================================================
🔄 Round 193 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 193 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0908
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0528
============================================================


============================================================
🔄 Round 195 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 195 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0870
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0682
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0704, RMSE: 0.2654, MAE: 0.2254, R²: 0.0684

📊 Round 195 Test Metrics:
   Loss: 0.0704, RMSE: 0.2654, MAE: 0.2254, R²: 0.0685

📊 Round 195 Test Metrics:
   Loss: 0.0704, RMSE: 0.2654, MAE: 0.2255, R²: 0.0684

============================================================
🔄 Round 202 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 202 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0707
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.1340
============================================================


============================================================
🔄 Round 203 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 203 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0897
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0583
============================================================


============================================================
🔄 Round 206 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 206 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0895
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0563
============================================================


============================================================
🔄 Round 209 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 209 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0877
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0521
============================================================


============================================================
🔄 Round 210 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 210 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0687
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.1022
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0704, RMSE: 0.2654, MAE: 0.2255, R²: 0.0684

❌ Client client_98 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
