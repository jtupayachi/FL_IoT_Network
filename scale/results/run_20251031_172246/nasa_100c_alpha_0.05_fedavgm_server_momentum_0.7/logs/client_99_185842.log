[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ecfb97-4931-4820-b5a5-0434e697ec22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c9fd47f-9340-4c6e-a838-e0b740cdff19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d3e284d-6995-486a-98b1-ef9b62a1096c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46af87ac-fb8f-447a-afe2-e7708e7d5d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20495d2d-f692-48f8-87f3-d7b34a74d857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056bea38-d2e7-4ff0-a1b7-a2ec5ddcd676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11024276-ae12-4e2a-9d3e-8754d34963ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 269590ca-7952-4a8e-b843-641e94e4609c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 251650c8-e2bf-45a5-831e-fe432cec1465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed32d2b-59b5-47a5-9722-8e5ff56c3dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f52f823-8e9e-4057-ac0a-7b641ad545cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f824fa13-399d-4146-a508-5961ad1b42fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1500e087-aff3-4af3-97aa-591864a03a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8064a01c-f8ae-4f1e-8b27-da650382386a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc5cc737-4a74-424d-a394-696f63a32333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c1f1a5a-89ea-409f-a555-30aef6be9498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 060c8510-1b4d-4ce2-ac5d-bf2ca867ae4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0bec9d-1884-4bef-9e2a-3f03c7da76b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6737168d-7472-45e7-a3c3-e8a25b13cde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5a8996-6a93-45a0-8a11-5bb5bbcf3a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2214dcef-b1ec-4fc5-8e14-b23091ab2903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2801472-0501-4330-96ea-a95bd1bc5a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a743cbe5-ce83-4e87-ae22-0dfaf09111fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71508996-f95e-4de5-a779-d105033cbcaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f66987-7346-44da-8b4e-5d3ef279d903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136beee6-17ea-4d39-88f8-fcfbf204d682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6647a104-341d-4bad-8bb4-eaf19e52ce87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a6f9052-7c1a-4fc6-94a7-add64ba4ee69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d15c27-8fc0-4edc-a78b-b8da7a00c58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0125d2e4-016a-4eb8-a10c-70c418588346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f477e99-d915-4fcc-9454-1c178268b728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01973bbb-57c4-4fe9-b358-813677dd025c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9272e661-1c38-4807-8bf2-9b7d35e418e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6250ee62-45e7-481b-b2ba-eb2456ebb2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2e14ed9-4127-481e-990e-6ca8ebf2467a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9a4e87-f9d7-4747-9870-8b4685bdb5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f12d14-e317-4efd-9ac8-a084d48284a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f390e36-8d8c-4e27-b784-239b02a95ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fcb30fb-2600-4da6-8d24-dbf225deb01b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9533be7e-fe8b-4d20-bec0-c571cf8abf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be80c536-1001-4ba7-a993-2c764d88acf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb4abcc-55a5-4244-b9af-0ceaaa9e22e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91586ab6-33c6-4113-b8cc-bd6f4dbdebb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcef4f10-66df-4635-bbca-cbbdb0979122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86ec0fc-e373-49f0-a21c-9a629758a3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a9c5f49-6a4b-4a2c-a231-491b660d8546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c61e480b-16cd-4555-99db-b17c354f6b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be4e1e0c-55fc-4c15-9302-e4e906e197df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2f801c-6244-44dc-9374-40a1b144207e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e561006-aaaa-4561-9c88-31956fe4a066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 589578a1-ba03-45d9-99c4-59d9ec5f4f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1401736-8490-4d21-b5e6-068f6cc85c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1defba54-3fd6-4458-87f3-3fcd663bc420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b010926-4895-456b-9744-1b5a6343694d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d822480-2b32-478d-b393-7fbc4c519fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c83041b-6e27-48b7-80d1-d31c9ce215bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7000f91-3833-4dc7-b88a-ce6ec8e6b8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de350ca-1ddf-4c73-b731-5e6dd5f42f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc20bfa1-b818-4ba9-a017-bb984c2b7fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f37c3d-e676-462f-9f95-44c56ad5ccfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9686e2ab-e63a-442d-96c9-52888c38dbd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d510be2-368f-4c9e-9b8f-9c606e432a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a3f0e9c-bca8-48f6-b140-d6e36e4ce103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 780b6a38-9100-4338-a55b-6f306b93e1ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e7958d-b598-4eb4-847e-23f5659a268f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 007e623c-eb1e-441c-9b3b-45cee829e625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e34d195-c282-442e-aebc-9c46a1584dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5eb21a-9ce8-4056-9a00-4552c5e6ceb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03081f8e-18aa-43b8-8e26-5ad4e04d2107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee85340b-460a-4d4a-8638-6672416ec25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b0320c3-a178-4855-85fb-c75c2104f56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361fba43-8ef7-400c-9db9-8de6aaef7ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2c7609e-99fd-4d3b-b1be-ec0200499640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb9a1b2-f0fa-4174-a33f-6704e9dd2b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f129a81f-47f2-4b8c-b48c-c19e3cc8719e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8e1ecc-a376-4903-9705-85cc555e514d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff072ef-1edd-4068-a10b-44233698f9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f3648e0-74a3-4cad-93ec-aa96851acaab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc859bbf-bc19-40fe-a6a4-8b3297707b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72d4585-242c-48e4-86bc-451d2dd76387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77747cb-229b-438e-9e7b-b7891bb33b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e06889c-ae1e-4bfc-b610-d43d560aaaaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd1b247-d523-469e-a82d-d59b9b28ba08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c7b554-413d-4f2f-af80-cfa6777f2ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4efbbb57-3a3c-4d6c-abeb-dd33ef79d792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eea5ae04-d2a6-460f-8bc1-590e301fdeff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fbd3a13-b17d-4d2b-8046-45dfb5160fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d51646-f991-43de-8803-b097c63b08ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4d4397-2247-4cdf-9036-1eeaefacf4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a84fcd-2dea-4dea-8121-97ef04ccdbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305d93c2-dede-41d5-bc7a-d2de7554f85b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8a4784-35c8-437b-81e8-a7a3f2fbae42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9987c8-45c0-4e39-ab12-b78552df125c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4969d516-ab9b-44ef-b1a6-89c899085ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52545770-db12-449d-be68-93976b04f7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a13e2dc-6d0c-4dfe-8160-b963d3480de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276ca1fa-b153-4f35-b59a-0c7639e19405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbdc8b79-2d22-4b39-901d-6d867343902c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00b035f2-8e5e-408c-969e-0cf9991472f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199ec45d-0bf2-4912-b1b5-8d56804c85bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de26e4d1-b226-441b-b4d6-719d1e748420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57fe9e52-ca96-4f35-9344-b6aab2d67306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1b5b34-4b68-4193-9e6f-950f07273597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4972463d-1ebc-4b28-8c87-4c787b7ee84e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad97946d-29af-4c43-8c2f-dc57c96217d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bdf0939-9bef-44f8-bd3a-de338aa817f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ad535c-e00e-4c2c-b738-47a49eaff343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad2aa2c-ae80-47c7-88af-bfedb031bb7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cf2e29-1d8b-4e4a-ba0d-ff5c97323b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d70815-77f8-4ef5-9cf1-adf72152f00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb92f9d-6c40-4e47-8fbd-c9be3fd8afb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2716be2-4dd7-491a-82fb-41162d53caa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0161164c-fffb-4bd4-a152-e689540c6c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d6a6b3-f50b-4d82-bcbb-73354e0a14bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb3b987-6363-42ac-aef1-929ec3053978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47268e56-19bd-4a33-97ff-5664340421b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22ca83c2-a24d-449a-8113-008cc77db283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab07f9f5-246b-4b76-9073-12f8568859ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b22dbaa-1894-4ff3-b9cd-85863e571297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d27c037-fc7a-4565-ad55-a075ea77b259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c42699-c364-4089-b54b-1ea42c942d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897eb68b-0b4c-4362-b3da-b0c72450bc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d249762f-d5a5-4ed5-9da7-51e23a814c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82867111-b016-4263-a433-009809166616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d6d4497-00d7-4a87-9755-615d34d7538b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e8a91b-d30c-4579-a6c1-634caa2bb616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09bd2be2-5d66-410c-9fb4-a2de31f7256c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb20cdf0-a96b-43f5-97be-72f374f854ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5f79fe-be37-4943-ab2b-a367cc41ad94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcabfb45-ca36-48ee-b3d5-a74c018ae73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf846620-7bb4-4117-8d58-a9f6208f9e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b9d398-5650-455f-a9b2-54073b1a542b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13ab2b8f-c54e-4087-9052-27ac7e0db178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585477ce-cf92-4d22-9990-abf0fae0eb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f316e5c7-f5e9-4d2a-9100-e3602f0b4333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcae2028-7f41-4344-8e65-1deb66c48645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78049bc-7356-418d-962b-d6f4df037627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f87002-19aa-4c29-8f6d-452676b9a0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f11607-0527-4190-bd98-55d12ea0f384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb9813a-0d44-4184-80a0-0af78696c28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db5d406-c951-4549-8c35-cb829d96c24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ac53bf-4272-4d05-a305-89535d461522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f7f4ff-eb07-4d3d-8e1f-dd970a39d464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7ebaf3-144e-4a1e-9305-3dd225a74a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56836734-c988-4bfc-87c0-57e166ec9f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d11de96-c9cb-467a-a3d0-0205727ae225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5c14b4f-c557-4c11-829d-bae025fcb114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a26b94b-5227-4872-a108-72863837fccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d68750d-af87-40ea-8a54-067b9ba860ce
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_99
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/test_labels.txt

📊 Raw data loaded:
   Train: X=(339, 24), y=(339,)
   Test:  X=(85, 24), y=(85,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 330 samples, 5 features
   Test:  76 samples, 5 features
✅ Client client_99 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0831 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0822, val=0.0819 (↓), lr=0.001000
   • Epoch   3/100: train=0.0807, val=0.0816, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0797, val=0.0816, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0790, val=0.0818, patience=3/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0728, val=0.0843, patience=9/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 16 Summary - Client client_99
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0233
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0795
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1099, RMSE: 0.3315, MAE: 0.2910, R²: -0.2738

============================================================
🔄 Round 17 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0843, val=0.1075 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0808, val=0.1059 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0793, val=0.1045 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0784, val=0.1038 (↓), lr=0.000250
   • Epoch   5/100: train=0.0778, val=0.1036, patience=1/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0754, val=0.1038, patience=7/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1038)

============================================================
📊 Round 17 Summary - Client client_99
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0011
   Val:   Loss=0.1038, RMSE=0.3221, R²=-0.0438
============================================================


============================================================
🔄 Round 18 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0703 (↓), lr=0.000063
   • Epoch   2/100: train=0.0894, val=0.0701, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0885, val=0.0698, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0877, val=0.0696 (↓), lr=0.000063
   • Epoch   5/100: train=0.0870, val=0.0693, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0848, val=0.0686, patience=4/15, lr=0.000063
   • Epoch  21/100: train=0.0831, val=0.0681, patience=8/15, lr=0.000063
   • Epoch  31/100: train=0.0819, val=0.0678, patience=8/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 18 Summary - Client client_99
   Epochs: 38/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0029
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0419
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.1014, RMSE: 0.3185, MAE: 0.2795, R²: -0.1758

📊 Round 18 Test Metrics:
   Loss: 0.1046, RMSE: 0.3235, MAE: 0.2848, R²: -0.2129

📊 Round 18 Test Metrics:
   Loss: 0.1106, RMSE: 0.3325, MAE: 0.2926, R²: -0.2820

============================================================
🔄 Round 25 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0841 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0851, val=0.0829 (↓), lr=0.000063
   • Epoch   3/100: train=0.0829, val=0.0827, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0816, val=0.0827, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0793, val=0.0818, patience=4/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0786, val=0.0813, patience=9/15, lr=0.000016
   📉 Epoch 22: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 25 Summary - Client client_99
   Epochs: 27/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0094
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0238
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.1062, RMSE: 0.3259, MAE: 0.2883, R²: -0.2310

📊 Round 25 Test Metrics:
   Loss: 0.1020, RMSE: 0.3194, MAE: 0.2833, R²: -0.1825

============================================================
🔄 Round 28 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0708 (↓), lr=0.000008
   • Epoch   2/100: train=0.0905, val=0.0707, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0903, val=0.0707, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0900, val=0.0706, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0899, val=0.0706, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0892, val=0.0706, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 28 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0524
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0208
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.1007, RMSE: 0.3173, MAE: 0.2815, R²: -0.1669

============================================================
🔄 Round 29 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0782 (↓), lr=0.000002
   • Epoch   2/100: train=0.0868, val=0.0781, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0867, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 29 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0372
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0334
============================================================


============================================================
🔄 Round 30 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 30 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0268
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.1093
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0990, RMSE: 0.3147, MAE: 0.2795, R²: -0.1482

============================================================
🔄 Round 31 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 31 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=-0.0320
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0322
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0986, RMSE: 0.3139, MAE: 0.2789, R²: -0.1427

📊 Round 31 Test Metrics:
   Loss: 0.0979, RMSE: 0.3128, MAE: 0.2781, R²: -0.1345

============================================================
🔄 Round 36 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.1089 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.1089, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.1088, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.1088, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.1088, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.1087, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1089)

============================================================
📊 Round 36 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0100
   Val:   Loss=0.1089, RMSE=0.3300, R²=-0.0668
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0973, RMSE: 0.3120, MAE: 0.2774, R²: -0.1284

============================================================
🔄 Round 37 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 37 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0132
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0632
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0973, RMSE: 0.3119, MAE: 0.2773, R²: -0.1276

============================================================
🔄 Round 39 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 39 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0497
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0446
============================================================


============================================================
🔄 Round 41 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 41 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0182
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0660
============================================================


============================================================
🔄 Round 43 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 43 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0078
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0918
============================================================


============================================================
🔄 Round 44 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 44 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0347
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0372
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0974, RMSE: 0.3122, MAE: 0.2776, R²: -0.1298

📊 Round 44 Test Metrics:
   Loss: 0.0975, RMSE: 0.3122, MAE: 0.2777, R²: -0.1303

📊 Round 44 Test Metrics:
   Loss: 0.0975, RMSE: 0.3123, MAE: 0.2778, R²: -0.1309

📊 Round 44 Test Metrics:
   Loss: 0.0976, RMSE: 0.3124, MAE: 0.2778, R²: -0.1315

📊 Round 44 Test Metrics:
   Loss: 0.0976, RMSE: 0.3124, MAE: 0.2778, R²: -0.1313

📊 Round 44 Test Metrics:
   Loss: 0.0976, RMSE: 0.3124, MAE: 0.2778, R²: -0.1314

============================================================
🔄 Round 52 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 52 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0282
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0053
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0977, RMSE: 0.3125, MAE: 0.2779, R²: -0.1324

============================================================
🔄 Round 53 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 53 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0184
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0474
============================================================


============================================================
🔄 Round 55 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 55 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0331
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0029
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0978, RMSE: 0.3127, MAE: 0.2781, R²: -0.1339

============================================================
🔄 Round 56 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0942, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0942, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0942, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0941, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0941, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0938, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 56 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0316
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0141
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0979, RMSE: 0.3128, MAE: 0.2782, R²: -0.1347

============================================================
🔄 Round 59 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 59 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0318
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0858
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0980, RMSE: 0.3131, MAE: 0.2784, R²: -0.1364

📊 Round 59 Test Metrics:
   Loss: 0.0980, RMSE: 0.3131, MAE: 0.2784, R²: -0.1365

📊 Round 59 Test Metrics:
   Loss: 0.0980, RMSE: 0.3130, MAE: 0.2783, R²: -0.1357

============================================================
🔄 Round 62 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 62 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0157
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0712
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0977, RMSE: 0.3125, MAE: 0.2779, R²: -0.1323

📊 Round 62 Test Metrics:
   Loss: 0.0976, RMSE: 0.3124, MAE: 0.2778, R²: -0.1315

============================================================
🔄 Round 67 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 67 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0163
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0490
============================================================


============================================================
🔄 Round 69 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 69 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0252
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0151
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0977, RMSE: 0.3126, MAE: 0.2780, R²: -0.1327

============================================================
🔄 Round 71 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 71 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0219
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0314
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0978, RMSE: 0.3128, MAE: 0.2781, R²: -0.1342

============================================================
🔄 Round 74 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 74 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0210
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0589
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0980, RMSE: 0.3131, MAE: 0.2784, R²: -0.1366

📊 Round 74 Test Metrics:
   Loss: 0.0980, RMSE: 0.3130, MAE: 0.2783, R²: -0.1358

📊 Round 74 Test Metrics:
   Loss: 0.0977, RMSE: 0.3126, MAE: 0.2780, R²: -0.1329

============================================================
🔄 Round 81 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 81 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0427
   Val:   Loss=0.0724, RMSE=0.2692, R²=0.0416
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0976, RMSE: 0.3123, MAE: 0.2778, R²: -0.1310

📊 Round 81 Test Metrics:
   Loss: 0.0974, RMSE: 0.3120, MAE: 0.2775, R²: -0.1288

============================================================
🔄 Round 84 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 84 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0228
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0197
============================================================


============================================================
🔄 Round 85 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 85 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0133
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0686
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0975, RMSE: 0.3122, MAE: 0.2777, R²: -0.1299

============================================================
🔄 Round 88 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 88 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0289
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0071
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0978, RMSE: 0.3128, MAE: 0.2781, R²: -0.1340

============================================================
🔄 Round 93 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0924, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0924, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 93 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0215
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0729
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0980, RMSE: 0.3131, MAE: 0.2784, R²: -0.1366

📊 Round 93 Test Metrics:
   Loss: 0.0981, RMSE: 0.3132, MAE: 0.2784, R²: -0.1372

============================================================
🔄 Round 97 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 97 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0303
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0025
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0980, RMSE: 0.3130, MAE: 0.2783, R²: -0.1360

============================================================
🔄 Round 98 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 98 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0234
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0253
============================================================


============================================================
🔄 Round 100 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 100 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0313
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0047
============================================================


============================================================
🔄 Round 101 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 101 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0144
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0653
============================================================


============================================================
🔄 Round 102 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 102 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0466
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0463
============================================================


============================================================
🔄 Round 104 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 104 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0235
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0308
============================================================


============================================================
🔄 Round 105 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 105 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0196
   Val:   Loss=0.0989, RMSE=0.3144, R²=-0.0415
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0979, RMSE: 0.3129, MAE: 0.2783, R²: -0.1353

============================================================
🔄 Round 107 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 107 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0331
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0151
============================================================


============================================================
🔄 Round 110 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 110 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0173
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.1834
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0980, RMSE: 0.3131, MAE: 0.2784, R²: -0.1365

📊 Round 110 Test Metrics:
   Loss: 0.0978, RMSE: 0.3127, MAE: 0.2780, R²: -0.1337

============================================================
🔄 Round 116 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 116 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0123
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0803
============================================================


============================================================
🔄 Round 117 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 117 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0293
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0057
============================================================


============================================================
🔄 Round 119 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 119 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0236
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0204
============================================================


============================================================
🔄 Round 121 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 121 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0053
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.1347
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0974, RMSE: 0.3122, MAE: 0.2776, R²: -0.1297

============================================================
🔄 Round 123 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 123 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0247
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0660
============================================================


============================================================
🔄 Round 124 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 124 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0161
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0668
============================================================


============================================================
🔄 Round 127 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 127 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0271
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0035
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0973, RMSE: 0.3119, MAE: 0.2774, R²: -0.1282

📊 Round 127 Test Metrics:
   Loss: 0.0974, RMSE: 0.3120, MAE: 0.2775, R²: -0.1287

📊 Round 127 Test Metrics:
   Loss: 0.0973, RMSE: 0.3120, MAE: 0.2775, R²: -0.1285

📊 Round 127 Test Metrics:
   Loss: 0.0972, RMSE: 0.3118, MAE: 0.2774, R²: -0.1274

📊 Round 127 Test Metrics:
   Loss: 0.0972, RMSE: 0.3117, MAE: 0.2773, R²: -0.1264

============================================================
🔄 Round 134 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 134 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0103
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.1457
============================================================


============================================================
🔄 Round 135 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 135 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0199
   Val:   Loss=0.0997, RMSE=0.3158, R²=-0.0543
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0970, RMSE: 0.3115, MAE: 0.2771, R²: -0.1251

============================================================
🔄 Round 136 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 136 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0133
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0561
============================================================


============================================================
🔄 Round 139 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 139 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0143
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0393
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0968, RMSE: 0.3111, MAE: 0.2768, R²: -0.1222

============================================================
🔄 Round 141 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 141 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0089
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0865
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0967, RMSE: 0.3110, MAE: 0.2768, R²: -0.1216

============================================================
🔄 Round 143 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 143 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0190
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0457
============================================================


============================================================
🔄 Round 144 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 144 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0292
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0187
============================================================


============================================================
🔄 Round 146 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 146 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0294
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0226
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0969, RMSE: 0.3113, MAE: 0.2770, R²: -0.1237

📊 Round 146 Test Metrics:
   Loss: 0.0968, RMSE: 0.3112, MAE: 0.2769, R²: -0.1226

============================================================
🔄 Round 149 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 149 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0257
   Val:   Loss=0.0937, RMSE=0.3062, R²=0.0048
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0968, RMSE: 0.3111, MAE: 0.2768, R²: -0.1219

📊 Round 149 Test Metrics:
   Loss: 0.0967, RMSE: 0.3109, MAE: 0.2767, R²: -0.1209

📊 Round 149 Test Metrics:
   Loss: 0.0967, RMSE: 0.3110, MAE: 0.2768, R²: -0.1211

📊 Round 149 Test Metrics:
   Loss: 0.0967, RMSE: 0.3109, MAE: 0.2767, R²: -0.1209

============================================================
🔄 Round 156 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 156 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0115
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0943
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0965, RMSE: 0.3107, MAE: 0.2765, R²: -0.1191

============================================================
🔄 Round 160 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 160 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0017
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0899
============================================================


============================================================
🔄 Round 161 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 161 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0166
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0239
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0964, RMSE: 0.3105, MAE: 0.2764, R²: -0.1179

📊 Round 161 Test Metrics:
   Loss: 0.0963, RMSE: 0.3104, MAE: 0.2763, R²: -0.1169

============================================================
🔄 Round 163 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 163 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0344
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0402
============================================================


============================================================
🔄 Round 166 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 166 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0228
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0095
============================================================


============================================================
🔄 Round 167 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 167 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0331
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0277
============================================================


============================================================
🔄 Round 169 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 169 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0261
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0178
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0964, RMSE: 0.3105, MAE: 0.2764, R²: -0.1178

📊 Round 169 Test Metrics:
   Loss: 0.0966, RMSE: 0.3108, MAE: 0.2767, R²: -0.1202

============================================================
🔄 Round 174 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 174 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0233
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0848
============================================================


============================================================
🔄 Round 177 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 177 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0330
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0388
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0967, RMSE: 0.3110, MAE: 0.2768, R²: -0.1216

============================================================
🔄 Round 179 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 179 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0014
   Val:   Loss=0.0999, RMSE=0.3161, R²=-0.1022
============================================================


============================================================
🔄 Round 181 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 181 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0252
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0041
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0968, RMSE: 0.3112, MAE: 0.2769, R²: -0.1226

============================================================
🔄 Round 182 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 182 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0165
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0494
============================================================


============================================================
🔄 Round 184 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 184 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0165
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0322
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0969, RMSE: 0.3113, MAE: 0.2771, R²: -0.1238

📊 Round 184 Test Metrics:
   Loss: 0.0970, RMSE: 0.3114, MAE: 0.2771, R²: -0.1240

============================================================
🔄 Round 187 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 187 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0258
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0191
============================================================


============================================================
🔄 Round 188 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 188 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0173
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0462
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0970, RMSE: 0.3115, MAE: 0.2772, R²: -0.1248

============================================================
🔄 Round 191 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 191 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0126
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.1042
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0971, RMSE: 0.3115, MAE: 0.2773, R²: -0.1252

📊 Round 191 Test Metrics:
   Loss: 0.0971, RMSE: 0.3117, MAE: 0.2774, R²: -0.1261

============================================================
🔄 Round 194 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 194 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0154
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0362
============================================================


============================================================
🔄 Round 195 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 195 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0040
   Val:   Loss=0.0956, RMSE=0.3093, R²=-0.0776
============================================================


============================================================
🔄 Round 196 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 196 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0359
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0324
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0972, RMSE: 0.3118, MAE: 0.2774, R²: -0.1268

📊 Round 196 Test Metrics:
   Loss: 0.0972, RMSE: 0.3118, MAE: 0.2775, R²: -0.1273

============================================================
🔄 Round 198 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.1092 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.1092, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.1092, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.1091, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.1091, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.1090, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1092)

============================================================
📊 Round 198 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0089
   Val:   Loss=0.1092, RMSE=0.3305, R²=-0.0865
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0970, RMSE: 0.3115, MAE: 0.2772, R²: -0.1247

============================================================
🔄 Round 204 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 204 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0097
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0596
============================================================


============================================================
🔄 Round 206 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 206 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0185
   Val:   Loss=0.0976, RMSE=0.3125, R²=-0.0217
============================================================


============================================================
🔄 Round 209 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 209 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0262
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0101
============================================================


============================================================
🔄 Round 211 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 211 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0033
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0867
============================================================


❌ Client client_99 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
