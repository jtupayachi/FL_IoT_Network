[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5da2718-8670-48f4-8a1a-812b25f758cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab0b8db-4421-4e00-b192-cb785ce878b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145e2c5c-d617-4239-98ac-7920863028a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ef843a-ba16-4bcb-bf2c-9deb14f08689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18b0bff0-86a8-4f59-b3e3-98eef5eaaed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e41fca32-8f8c-431d-945c-e30014d58469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebe09429-b40c-45a5-af3c-f6f51bb5f93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857f795d-6053-479f-bd4d-9372ab7210a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5c11b40-9101-490e-8f1c-e7e48ca86ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8347f5fe-43bd-4f49-9f2f-acd789e05ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c359c5c-3424-424d-8492-cb4f606aac8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43c0661-6110-4c9e-95c9-064558f8557a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b364cf39-80d5-4bb9-a800-5adca982a4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72dd4c8f-01b0-4087-ae52-9e364c5e1a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db9048a5-01ac-4303-9c7b-361e00cb8237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c3af90-8411-427d-8b28-9077b78cecbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2de61a90-f0d1-4b0e-81c3-3b792e49ce89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6d5f51-6244-4b57-831b-e636d56fde5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aee2b0d-7fb7-4611-bfaf-e6782423862c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c9ea3f-96bd-46a3-9b0d-6eb398945c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c847794e-6a40-43fa-92a7-ff1e5b2228c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25563bd-f418-4896-b6ec-c619af5cbf5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bb4a3d-a1f2-4653-9a93-8bb4758b3df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c703e8e-aef9-4366-9745-9c0c0c684711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3098572d-671f-42c7-9055-fe4f62ed3c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6bc0f3-5e2a-4930-bd4f-6d385ef85105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a83e4a9-206c-4430-9966-f4adf503ab53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e1e185-a725-442c-8034-ad7cae5d7be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b5a8b6d-8ac8-4971-8cbe-8b3ebebc56d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19af48b-9c58-48e2-87cf-9ce851323f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e58a1fd-2d3e-4332-97da-e2e0c2d1685d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da6a70d6-cd28-4c0c-98e0-51c32eeebc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad7fae29-a2d1-4d8c-8a65-39b355253f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ee2363b-c861-4988-bd32-8a4ef4106947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb26e988-dab0-4015-a69b-47907e836a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b5aee2-cd70-4eee-9d74-78f5450b59c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dee6f8e-9948-4623-9401-5200007d5ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7162fdc0-a670-4059-afad-745cf0c0658e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a542f4c3-1140-433a-aa77-7126b5614dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad0881c1-a4bc-45b3-ad19-5a4ed2e847f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c7b76b-e954-4e73-aca2-81c9bbe01981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2219904-04df-4b97-9cec-847711ad5678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42aafb7c-d13f-427d-ba87-63269f6a85fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 463b3f44-b385-4cb8-8beb-a8487eabeb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d2115d2-14d3-4eef-8e0d-bcabf55ea80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd854ca-7d8d-4f4e-91b5-84be48834a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ad56d1-309e-409a-8e5d-f564d4744e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364f3639-b251-4c4b-9d96-41dc0bbd8361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384b6c08-7878-4b86-9945-bb36ceedb34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2869c71-3db6-4618-9a01-8ddaa238547d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70aca34a-010f-4542-ad5a-aa104bc9159b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 639a8dba-744a-47cc-9bab-0ba899821673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1e1506-9962-4df1-9fc8-a4d51277734a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adadb650-9745-4677-8e1f-0bfd74380585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18aa90b4-3893-4208-852c-05bda1774696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d4dcc4-90de-4bfb-b231-77d247da33e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d978363d-1cad-40d4-91a7-3637440643eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa83e200-ab6f-4390-9834-3c493b226446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d9fe42-5cb2-4630-a9e7-96cf1078309f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a40cfbb6-c85e-4f46-ab72-4e8b2a7c972d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a81ace8-f7df-49e5-85a2-6ce40e9dcb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd997136-5eca-448c-92a0-0252c1902b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b153b642-33ed-4a04-b5f1-03a6eef666e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45aa258a-7373-4c47-9eb9-f12ad02ada75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b5c750-4003-4180-8d88-98bf6fb31965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2930275-ae26-4a15-adec-bae00da41a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d445632-117e-4b96-a3fd-2732ba39c47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb28679-22b5-4664-abd5-f7c46e70b244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6e2f2f-545a-4cb2-add0-664a4191e768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74bf1cb-02f9-4cb4-946a-2f2b2ab85592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae191ad6-1e2a-418e-a15b-4a91e02c90d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a5359dc-8d0a-4725-b022-2b9cf4a80bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8d0604-23da-487b-8ab3-2ca7d09a9dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 950dbc31-ef75-4a04-8184-d3c3ec04ad61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4058ab2-e429-474a-a958-575cf082a9ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0984fa8-78cb-4a58-a878-4685afb3028c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8733aec-ba1d-4c66-8e69-09d700536995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de9f0fa-85fa-4e07-aa60-c58aa3325945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a88f90e-1664-4a70-8375-174cc28f5b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f832a960-3678-4542-aaed-8424ed5deb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc51711-a696-4234-be1c-9ad8f206b771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b88140-48fe-4f13-8318-6c942032d3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b705015b-158f-4fe5-a481-d88844181639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef980b7-2570-4404-a297-c88700339dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00129c4c-0be1-47c2-95c9-826bab05cd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f1835d-19c2-43be-8179-1c2b1e14c976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c6b1c2d-3472-4b7d-9af9-19e2b7b7a974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 447e9cf6-2ec5-415a-92ee-58c099f4fcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529d6dbe-3662-4b11-89a0-00aac95a6a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24cfc4f9-3d43-4c11-a9f6-4b9a099c5c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c5a5aa2-4e20-45ee-a54e-7e0bb7c39b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 103abd19-090e-411a-a897-81f5b57c7df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46c7b1b-5fd7-43e9-ad54-eae22cd760b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 149d5463-2fab-4877-b4e5-e93bf83fb673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac456d7-d61a-432c-9912-dbd349f38a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608e2340-3e53-49c7-a120-ad0058741080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe596b6-2bcf-4e8d-a0dc-3161b646d2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588ce89b-faa5-4a88-8395-0a5784c9ab3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d3321ef-b87f-441e-b2a3-9ae6206b9b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b88dad0-a59c-4ea9-b509-d95bd1ac0f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6db6a685-bb64-45f7-a4c0-e33dca4ac9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50835c22-7570-4cc0-9450-e7a0b14af607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2342b7-8123-48dd-a502-3df49e57f5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302fc4fb-6d3e-4aee-a11c-c822caeb3c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b70799e0-fdfe-4b27-ad2a-2a3e2a4ae215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eace995-914c-40a1-b5bf-bc0cf42e32ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563a183b-a04f-4491-9e65-ea5fd35d416e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84225b2-c803-4ef0-893c-7df0a269ab30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85dbe958-74d4-4568-bfc4-d2e906207e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90458fb0-4ac4-468b-b74a-39480c159676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1a93e2d-d2f3-4544-9106-f591ee59375c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37a96df-0214-4b96-af0a-e973874cfb50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77fd9766-50c5-46c0-91e2-4da8262b3763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55eab359-aedb-437e-9bfb-cdcc669e83d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdb0f86-d625-401c-84bf-97238472cf6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bc00310-9c37-4535-98c1-b27871df8d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171f10be-d736-4b59-807f-2ba6ec1d471f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4549026c-c737-4aff-a432-639ba31b801a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42f22a7-cc88-432b-9967-d3ac2fe1fcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b4b18c-47aa-4579-bf1a-c241b0e2e50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7693c45-78af-483e-ae10-c5c8b2a80af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd110ccd-27eb-432b-8457-491d09d07d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 048208c3-98d2-440d-9e3e-8d1a997f0332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6fa340c-0ff7-4c60-9b68-67a2beab36c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c2de4a-ee26-4597-bed1-f49ac185b797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89841b00-d83c-454f-8226-508148907d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aaf0443-6cb0-490a-921b-727778fc95ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b150c95-9c97-48d5-bc0d-eb48e1e3a9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27af8316-f1cd-4435-b33f-f10c8804a330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9deb71f0-c3bd-4bf1-a1fb-91e0e476a936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfba6660-8a7f-4909-a3c9-5ffe83af1938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef182d96-98cc-4b33-9365-f04e226950a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db26c28-0c27-48b2-977b-da2b67bad398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40efb4e-c457-42b9-85af-c65f4746957a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca64eca-1807-4b12-8811-d2f5d57c07d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437bb532-86f7-4708-bbca-21754dbb2ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3579ca5f-2f83-4606-895c-ab905959b4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4139f4a-6cd0-44cf-86b9-05927c63cb4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83fa60be-d135-4bd5-a5db-a557f78bb657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd444b7-a0cf-44bd-8008-116eca00fff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a1a29d-17b0-46c5-aed0-dc3da3033cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a8b0bd-016b-4a58-b05d-24d85de909b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4671032e-0212-491b-b7c9-e29da551249a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54265e57-531d-4fe0-b60d-1b4246d0ad1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70cf72e-35ab-4759-94d0-18e5cd42a2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d3ecdf7-2b66-46a3-a9f6-9f5634d26a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e26a12fe-e2ed-46dd-a6f6-72a36e3a4a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 428795f7-92f4-46b1-971a-b421537724f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3986678d-478a-42be-b479-748121be3079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6bece94-3838-486e-b68e-5594139a10cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68825331-21fd-404f-9324-84a42acebf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320c4e08-685a-44c9-a2e8-97c92792b094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51253c2f-b821-439c-9c06-d1d4d91b7ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffb2bfa-fa67-4ed9-a9d6-fb3a1cf9c18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2b3cec-b623-4c21-978a-457e5a83cdcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa7f9cf-51ec-45e6-8ce0-24e022e03fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 093ba035-4796-406b-8a6b-15221116eedd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(755, 24), y=(755,)
   Test:  X=(189, 24), y=(189,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 746 samples, 5 features
   Test:  180 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2443, val=0.0910 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0928, val=0.0897 (↓), lr=0.001000
   • Epoch   3/100: train=0.0830, val=0.0899, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0833, val=0.0891 (↓), lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0888, patience=1/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0829, val=0.0900, patience=7/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 1 Summary - Client client_9
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0041
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0140
============================================================


============================================================
🔄 Round 3 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1871, val=0.0948 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0851, val=0.0873 (↓), lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0824, val=0.0876, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 3 Summary - Client client_9
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0211
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0023
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1278, RMSE: 0.3575, MAE: 0.2947, R²: -0.5654

📊 Round 3 Test Metrics:
   Loss: 0.0940, RMSE: 0.3066, MAE: 0.2579, R²: -0.1507

📊 Round 3 Test Metrics:
   Loss: 0.1157, RMSE: 0.3402, MAE: 0.2779, R²: -0.4169

============================================================
🔄 Round 6 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1108, val=0.1066 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0999, val=0.0964 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0930, val=0.0906 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0892, val=0.0872 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0871, val=0.0851 (↓), lr=0.000063
   • Epoch  11/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000063
   📉 Epoch 20: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0840, val=0.0819, patience=12/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 6 Summary - Client client_9
   Epochs: 24/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0003
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0016
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2572, R²: -0.0762

============================================================
🔄 Round 9 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0815 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0896, val=0.0806 (↓), lr=0.000031
   • Epoch   3/100: train=0.0879, val=0.0802, patience=1/15, lr=0.000031
   ✓ Epoch   4/100: train=0.0868, val=0.0800 (↓), lr=0.000031
   • Epoch   5/100: train=0.0860, val=0.0800, patience=1/15, lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0845, val=0.0806, patience=7/15, lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 9 Summary - Client client_9
   Epochs: 19/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0225
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0127
============================================================


============================================================
🔄 Round 10 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0889 (↓), lr=0.000008
   • Epoch   2/100: train=0.0874, val=0.0887, patience=1/15, lr=0.000008
   ✓ Epoch   3/100: train=0.0870, val=0.0884 (↓), lr=0.000008
   • Epoch   4/100: train=0.0866, val=0.0882, patience=1/15, lr=0.000008
   • Epoch   5/100: train=0.0863, val=0.0879, patience=2/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0851, val=0.0873, patience=5/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0845, val=0.0870, patience=9/15, lr=0.000002
   📉 Epoch 24: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 10 Summary - Client client_9
   Epochs: 27/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0221
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0020
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2490, R²: -0.0423

============================================================
🔄 Round 13 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 13 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0526
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0161
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2543, R²: -0.0716

============================================================
🔄 Round 15 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 15 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0559
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.0425
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2568, R²: -0.0913

============================================================
🔄 Round 17 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0893, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0885, val=0.0889, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 17 Summary - Client client_9
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0528
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.1192
============================================================


============================================================
🔄 Round 21 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0942, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0907, val=0.0938, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0904, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0901, val=0.0932, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 21 Summary - Client client_9
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0741
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.1006
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2547, R²: -0.1026

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0944, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0943, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0942, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0941, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0940, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0935, val=0.0901, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0929, val=0.0895, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0923, val=0.0890, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0919, val=0.0886, patience=3/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0914, val=0.0882 (↓), lr=0.000001
   • Epoch  61/100: train=0.0911, val=0.0878, patience=10/15, lr=0.000001
   • Epoch  71/100: train=0.0907, val=0.0875, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 80/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3021, R²=-0.0783
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0984
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2525, R²: -0.0822

============================================================
🔄 Round 27 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0924, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0904, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0917, val=0.0898, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0912, val=0.0893, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0908, val=0.0888, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0905, val=0.0884 (↓), lr=0.000001
   • Epoch  61/100: train=0.0902, val=0.0880, patience=10/15, lr=0.000001
   • Epoch  71/100: train=0.0899, val=0.0877, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 27 Summary - Client client_9
   Epochs: 80/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0639
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.1161
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2510, R²: -0.0672

============================================================
🔄 Round 29 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 29 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=-0.0899
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0970
============================================================


============================================================
🔄 Round 30 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 30 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0856
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0701
============================================================


============================================================
🔄 Round 31 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0833, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0913, val=0.0830, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.0909, val=0.0827, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0905, val=0.0824, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 31 Summary - Client client_9
   Epochs: 45/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=-0.0724
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0320
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2505, R²: -0.0584

============================================================
🔄 Round 32 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0880, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0902, val=0.0876, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0899, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0895, val=0.0870, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 32 Summary - Client client_9
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0630
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0701
============================================================


============================================================
🔄 Round 34 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 34 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=-0.0798
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0442
============================================================


============================================================
🔄 Round 35 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0926, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0924, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 35 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0928, RMSE=0.3046, R²=-0.0836
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0178
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2501, R²: -0.0509

📊 Round 35 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2501, R²: -0.0510

📊 Round 35 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2502, R²: -0.0512

📊 Round 35 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2502, R²: -0.0513

📊 Round 35 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2502, R²: -0.0513

📊 Round 35 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2502, R²: -0.0514

============================================================
🔄 Round 45 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 45 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0861
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0084
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2502, R²: -0.0516

📊 Round 45 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2502, R²: -0.0519

============================================================
🔄 Round 47 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.1000 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.1000, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.1000, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.1000, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1000)

============================================================
📊 Round 47 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0684
   Val:   Loss=0.1000, RMSE=0.3163, R²=-0.0873
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2503, R²: -0.0521

📊 Round 47 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2503, R²: -0.0524

============================================================
🔄 Round 50 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 50 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0700
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0746
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2503, R²: -0.0523

📊 Round 50 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2504, R²: -0.0533

📊 Round 50 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2505, R²: -0.0542

📊 Round 50 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2505, R²: -0.0546

============================================================
🔄 Round 60 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0919, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0889, val=0.0915, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.0884, val=0.0912, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0880, val=0.0909, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 60 Summary - Client client_9
   Epochs: 44/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0545
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0700
============================================================


============================================================
🔄 Round 61 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 61 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3044, R²=-0.0723
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0716
============================================================


============================================================
🔄 Round 62 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.1003 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.1001, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.1001, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.1000, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0997, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0863, val=0.0991, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0860, val=0.0986, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0857, val=0.0980, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0854, val=0.0975, patience=1/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0852, val=0.0971 (↓), lr=0.000001
   • Epoch  71/100: train=0.0849, val=0.0966, patience=10/15, lr=0.000001
   • Epoch  81/100: train=0.0847, val=0.0961, patience=9/15, lr=0.000001
   • Epoch  91/100: train=0.0845, val=0.0957, patience=7/15, lr=0.000001

============================================================
📊 Round 62 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0244
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0824
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2503, R²: -0.0515

============================================================
🔄 Round 64 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 64 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0771
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0383
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2503, R²: -0.0510

============================================================
🔄 Round 65 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0929, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0929, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0928, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0924, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 65 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0929, RMSE=0.3047, R²=-0.0793
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0297
============================================================


============================================================
🔄 Round 66 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.1000 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.1000, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.1000, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0996, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0859, val=0.0993, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0855, val=0.0989, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0851, val=0.0986, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 66 Summary - Client client_9
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0543
   Val:   Loss=0.0990, RMSE=0.3147, R²=-0.0582
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2502, R²: -0.0495

============================================================
🔄 Round 67 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0852, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0898, val=0.0848, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.0895, val=0.0845, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0891, val=0.0841, patience=13/15, lr=0.000001
   • Epoch  51/100: train=0.0887, val=0.0838, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 67 Summary - Client client_9
   Epochs: 58/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0456
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0565
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0858, RMSE: 0.2928, MAE: 0.2502, R²: -0.0501

📊 Round 67 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2503, R²: -0.0513

============================================================
🔄 Round 72 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 72 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0806
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0212
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2504, R²: -0.0517

============================================================
🔄 Round 73 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 73 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0709
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0898
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2504, R²: -0.0521

============================================================
🔄 Round 75 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0958, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0876, val=0.0954, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0873, val=0.0949, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0869, val=0.0945, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0866, val=0.0942, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0863, val=0.0938, patience=12/15, lr=0.000001
   • Epoch  71/100: train=0.0860, val=0.0935, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 75 Summary - Client client_9
   Epochs: 79/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0306
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0886
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2504, R²: -0.0518

============================================================
🔄 Round 77 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 77 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0889
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0086
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2503, R²: -0.0512

📊 Round 77 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2503, R²: -0.0510

📊 Round 77 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2503, R²: -0.0506

============================================================
🔄 Round 80 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0857, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0891, val=0.0853, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0887, val=0.0849, patience=5/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0884, val=0.0846 (↓), lr=0.000001
   • Epoch  51/100: train=0.0880, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 80 Summary - Client client_9
   Epochs: 56/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0475
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0541
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2500, R²: -0.0472

============================================================
🔄 Round 83 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0833, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0893, val=0.0829, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0889, val=0.0825, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0885, val=0.0822, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 83 Summary - Client client_9
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0510
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0580
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2499, R²: -0.0464

📊 Round 83 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2500, R²: -0.0470

============================================================
🔄 Round 90 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 90 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=-0.0761
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0290
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2502, R²: -0.0494

📊 Round 90 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2504, R²: -0.0511

============================================================
🔄 Round 96 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0856, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0896, val=0.0850, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0893, val=0.0845, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0890, val=0.0840, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0887, val=0.0835, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0884, val=0.0831, patience=11/15, lr=0.000001
   • Epoch  71/100: train=0.0882, val=0.0827, patience=9/15, lr=0.000001
   • Epoch  81/100: train=0.0879, val=0.0823, patience=6/15, lr=0.000001
   • Epoch  91/100: train=0.0877, val=0.0819, patience=2/15, lr=0.000001

============================================================
📊 Round 96 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0311
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0331
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2503, R²: -0.0506

📊 Round 96 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2503, R²: -0.0502

📊 Round 96 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2502, R²: -0.0491

============================================================
🔄 Round 102 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 102 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=-0.0756
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0264
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2502, R²: -0.0489

📊 Round 102 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2502, R²: -0.0494

============================================================
🔄 Round 112 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 112 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=-0.0733
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0397
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2502, R²: -0.0495

============================================================
🔄 Round 113 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0985, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0856, val=0.0981, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0852, val=0.0976, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0849, val=0.0972, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0846, val=0.0969, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0843, val=0.0965, patience=11/15, lr=0.000001
   • Epoch  71/100: train=0.0840, val=0.0962, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 113 Summary - Client client_9
   Epochs: 80/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0308
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0732
============================================================


============================================================
🔄 Round 114 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0843, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0893, val=0.0840, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0888, val=0.0837, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 114 Summary - Client client_9
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0563
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0688
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2501, R²: -0.0482

📊 Round 114 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2500, R²: -0.0476

📊 Round 114 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2499, R²: -0.0463

📊 Round 114 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2499, R²: -0.0458

📊 Round 114 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2497, R²: -0.0445

============================================================
🔄 Round 126 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 126 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=-0.0783
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0097
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2496, R²: -0.0432

============================================================
🔄 Round 130 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 130 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0735
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0261
============================================================


============================================================
🔄 Round 131 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0821, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0896, val=0.0817, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0892, val=0.0813, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0889, val=0.0810, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0886, val=0.0807, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 131 Summary - Client client_9
   Epochs: 53/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0434
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0614
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0852, RMSE: 0.2920, MAE: 0.2497, R²: -0.0437

============================================================
🔄 Round 132 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0891, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0885, val=0.0888 (↓), lr=0.000001
   • Epoch  21/100: train=0.0881, val=0.0883, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0877, val=0.0879, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0874, val=0.0875, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0871, val=0.0872, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0869, val=0.0869, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 132 Summary - Client client_9
   Epochs: 65/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0423
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0326
============================================================


============================================================
🔄 Round 133 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 133 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=-0.0716
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0433
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2495, R²: -0.0418

============================================================
🔄 Round 135 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0913, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0871, val=0.0910, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0867, val=0.0906, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0864, val=0.0903, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 135 Summary - Client client_9
   Epochs: 44/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0388
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0781
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2495, R²: -0.0413

============================================================
🔄 Round 136 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0934, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0869, val=0.0930, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0865, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0862, val=0.0924, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 136 Summary - Client client_9
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0482
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0564
============================================================


============================================================
🔄 Round 137 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0966, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0858, val=0.0962, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0854, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0851, val=0.0956, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 137 Summary - Client client_9
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0487
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0372
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2494, R²: -0.0400

============================================================
🔄 Round 139 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0883, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0883, val=0.0880 (↓), lr=0.000001
   • Epoch  21/100: train=0.0880, val=0.0875, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0877, val=0.0871, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0874, val=0.0868, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0871, val=0.0864, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0868, val=0.0861, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 139 Summary - Client client_9
   Epochs: 65/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0303
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0756
============================================================


============================================================
🔄 Round 140 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 140 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0658
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0331
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2493, R²: -0.0386

📊 Round 140 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2493, R²: -0.0384

📊 Round 140 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2493, R²: -0.0385

📊 Round 140 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2493, R²: -0.0387

📊 Round 140 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2494, R²: -0.0393

============================================================
🔄 Round 148 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0974, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0856, val=0.0971 (↓), lr=0.000001
   • Epoch  21/100: train=0.0853, val=0.0966, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0850, val=0.0961, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0848, val=0.0957, patience=7/15, lr=0.000001
   • Epoch  51/100: train=0.0846, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0844, val=0.0949, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0842, val=0.0946, patience=11/15, lr=0.000001
   • Epoch  81/100: train=0.0840, val=0.0942, patience=7/15, lr=0.000001
   • Epoch  91/100: train=0.0838, val=0.0939, patience=2/15, lr=0.000001

============================================================
📊 Round 148 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0149
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0621
============================================================


============================================================
🔄 Round 150 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0894, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0876, val=0.0890, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0872, val=0.0887, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0868, val=0.0884, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 150 Summary - Client client_9
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0372
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0645
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2492, R²: -0.0368

============================================================
🔄 Round 154 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0913, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0876, val=0.0909, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0872, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0869, val=0.0903, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 154 Summary - Client client_9
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0428
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0404
============================================================


============================================================
🔄 Round 156 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0944, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0866, val=0.0941 (↓), lr=0.000001
   • Epoch  21/100: train=0.0863, val=0.0936, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0860, val=0.0932, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0857, val=0.0928, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0855, val=0.0925, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0852, val=0.0922, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 156 Summary - Client client_9
   Epochs: 65/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0341
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0408
============================================================


============================================================
🔄 Round 158 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0891, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0870, val=0.0886, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0868, val=0.0881, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0866, val=0.0877, patience=11/15, lr=0.000001
   • Epoch  51/100: train=0.0863, val=0.0873, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0861, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0859, val=0.0866, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 158 Summary - Client client_9
   Epochs: 72/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0245
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0726
============================================================


============================================================
🔄 Round 162 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0960, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0862, val=0.0957 (↓), lr=0.000001
   • Epoch  21/100: train=0.0859, val=0.0953, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0856, val=0.0949, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0854, val=0.0945, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0851, val=0.0941, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0849, val=0.0937, patience=13/15, lr=0.000001
   • Epoch  71/100: train=0.0847, val=0.0934, patience=9/15, lr=0.000001
   • Epoch  81/100: train=0.0845, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0843, val=0.0928, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 162 Summary - Client client_9
   Epochs: 92/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0239
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0363
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2489, R²: -0.0333

📊 Round 162 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2489, R²: -0.0332

============================================================
🔄 Round 165 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 165 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0655
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0097
============================================================


============================================================
🔄 Round 166 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 166 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0633
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0058
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2489, R²: -0.0333

============================================================
🔄 Round 167 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 167 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0605
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0213
============================================================


============================================================
🔄 Round 171 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 171 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0578
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0336
============================================================


============================================================
🔄 Round 174 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0882, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0879, val=0.0879, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0875, val=0.0876, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 174 Summary - Client client_9
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0404
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0704
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2492, R²: -0.0360

============================================================
🔄 Round 176 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 176 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0606
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0408
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2492, R²: -0.0362

📊 Round 176 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2493, R²: -0.0365

============================================================
🔄 Round 178 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0809, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0895, val=0.0806, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0891, val=0.0803, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 178 Summary - Client client_9
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0474
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0468
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2493, R²: -0.0370

📊 Round 178 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2493, R²: -0.0375

============================================================
🔄 Round 184 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0769, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0903, val=0.0766, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0900, val=0.0763, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 184 Summary - Client client_9
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0495
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0383
============================================================


============================================================
🔄 Round 185 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0908, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0873, val=0.0904, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0870, val=0.0900, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0867, val=0.0897, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 185 Summary - Client client_9
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0398
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0635
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2494, R²: -0.0380

============================================================
🔄 Round 187 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 187 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0561
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0531
============================================================


============================================================
🔄 Round 190 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 190 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3045, R²=-0.0576
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0507
============================================================


============================================================
🔄 Round 191 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 191 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=-0.0538
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0622
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2495, R²: -0.0387

📊 Round 191 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2495, R²: -0.0390

============================================================
🔄 Round 194 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 194 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0594
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0422
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2495, R²: -0.0395

============================================================
🔄 Round 196 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 196 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0616
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0354
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2495, R²: -0.0397

============================================================
🔄 Round 197 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 197 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0527
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0778
============================================================


============================================================
🔄 Round 199 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0827, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0899, val=0.0824 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0896, val=0.0819 (↓), lr=0.000001
   • Epoch  31/100: train=0.0893, val=0.0814, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0891, val=0.0810, patience=9/15, lr=0.000001
   • Epoch  51/100: train=0.0889, val=0.0805, patience=7/15, lr=0.000001
   • Epoch  61/100: train=0.0887, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0885, val=0.0797, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0883, val=0.0793, patience=11/15, lr=0.000001
   • Epoch  91/100: train=0.0881, val=0.0790, patience=8/15, lr=0.000001

============================================================
📊 Round 199 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0089
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.1143
============================================================


============================================================
🔄 Round 200 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0802, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0894, val=0.0798, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0890, val=0.0795, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0887, val=0.0792, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 200 Summary - Client client_9
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0467
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0311
============================================================


============================================================
🔄 Round 201 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 201 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0622
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0313
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2494, R²: -0.0381

📊 Round 201 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2494, R²: -0.0377

📊 Round 201 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2494, R²: -0.0378

============================================================
🔄 Round 206 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0977, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0857, val=0.0974 (↓), lr=0.000001
   • Epoch  21/100: train=0.0854, val=0.0969, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0851, val=0.0964, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0849, val=0.0960, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0847, val=0.0955, patience=6/15, lr=0.000001
   • Epoch  61/100: train=0.0845, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0843, val=0.0947, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0841, val=0.0943, patience=11/15, lr=0.000001
   • Epoch  91/100: train=0.0839, val=0.0940, patience=8/15, lr=0.000001

============================================================
📊 Round 206 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0153
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0544
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2493, R²: -0.0366

📊 Round 206 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2493, R²: -0.0364

============================================================
🔄 Round 209 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0908, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0869, val=0.0905, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0865, val=0.0901, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0862, val=0.0898, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 209 Summary - Client client_9
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0340
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0899
============================================================


============================================================
🔄 Round 211 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0821, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0892, val=0.0818, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 211 Summary - Client client_9
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0437
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0708
============================================================


❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
