[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91912d62-a9e9-4c79-9bc2-f7256217b954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a03f24-6a25-443b-bee5-4319760af849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d9d5d6-42a6-4d24-9706-aed0eb97c973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b21ed21-5d26-4f27-982d-d661a2281fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc9ff33-7e6c-4be6-9e6d-a3b0c09e2fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33920b1f-a195-4a63-bb83-9b5fba892759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 739ad264-de5c-4bb0-bcb3-74cb78cbacf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d86cf2-b58b-48ec-9507-039f2396f52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b820507e-d391-4bce-a4d0-99a3ae764661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8297bbb2-cc20-4aaa-a3d9-ce2efefd1338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f977b336-3424-46fd-b8a2-a446c73912a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20b54d4d-ba10-4183-aa4c-d926f6dde137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec96327-9cd0-4e76-8391-db6b0ed2bb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b6d82e-4b07-4040-abe4-961fb623dbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cdad9be-7668-4c89-ba2b-4762b3aa98ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05656e39-1ff9-472b-a4c3-9238f1e1843a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789e52a2-fc3f-4980-b86e-6942ad42f6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 482bcb4a-1449-450d-bee0-25fc35ac6c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eaa219a-e66a-48d6-a7f8-940fdd54de2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed80c9c7-77de-4376-8733-e95e24bd15a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c66509b-68ed-4115-92cf-de1af833b7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffcdcb89-aac2-45a5-bf76-7f22ea7fc67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf34af0-4f52-478b-ab18-ec430ad08871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e327157f-37d8-4415-97b1-5c513dbfafbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee14494a-d1a3-445a-8bd4-1f50658542b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8a0a7e-bb2d-4b68-b63a-e44ba541d106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23365bc-4260-4d5e-ae6a-8a3232e4f34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c19975-6d65-4641-8d0c-00f0ca581d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efeb5f18-bad8-492a-adaf-8108ffd5bc0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4411e3b6-2151-4577-8c8d-fc02117123fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771ba93b-f987-4508-843b-87d7bee169d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e065ba11-a952-4b33-b2a5-09c2716a23e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544980fe-b779-48ce-8cec-eea9e855f69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4be0623-bee0-41c2-959c-f3697ae090b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597ec745-2030-4dd4-8e14-66adde033f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c61394ff-f1fd-4b38-aa51-15d09cd86f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a94a554-dfda-4813-98de-48a7dbffd58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad0dc30-46a7-49f7-a1fd-bbd1f25d9aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7702c78c-8ac3-4d92-92ad-40036a3533ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6929f9ff-83f1-4145-afbd-204b2ceda7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2085fa1e-e1b9-4316-8ace-19db5006df35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7b4a2b-e091-4347-9335-5ba1a2d6a926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b4124d-2cab-4f7a-9578-15978f2ff4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9adab031-1b57-4686-b1c2-57ac52300e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ebb7e2-e96c-4838-ab8f-269124bf9326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6e501c-1538-45ca-85d1-cbaf71f0d081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94dc89b0-c235-47e6-8ba0-4660bf5ad095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 771dbd4b-8463-48d7-91d2-58df857394a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3547c0d7-be6f-4d91-8a26-84d85621f627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af28ba23-c017-4072-9e9f-8a5756f7291a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30cf5264-90b8-414a-a9ee-0a37d75a4487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e789330-3a8e-4ddd-80a1-5d1ea7698b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d921d2d4-5e55-4a82-b3bc-befbebe97890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d1cc13-5e6b-4839-9374-06220329a491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79163b1-b88e-45e5-a0dd-f32074265ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1883997-ed87-4bec-9060-be59e9caa2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcaa652f-c1e4-4c45-8d78-bc1e5626150c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97995558-31c9-4e8d-a452-1e409013732b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a2bb47-1f50-444f-9c17-be5517a1c0c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5137eb2e-970e-4ddd-85cc-0e78f4253bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e28f6d5-4671-4e21-8f04-9a04e4f158af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e806d1-79e7-404a-b7c2-3818bb2c2928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1908f44-d508-4ee4-b13c-963083a2fdad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed8bf737-6890-4151-9071-71d30759eba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a407d2bb-d612-4166-bab2-7ff608da5514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81fa32fd-3730-4056-88ab-dd025af35a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933e8599-4b49-49a8-b227-7afd4a229045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2349c7da-16eb-4609-b84a-11c55491478c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c32065-098e-4c4f-b550-6c8f21c0776e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184b319b-caff-4087-9883-c450a8fb8641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec22a99-1624-48ea-8839-e514b22831b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a71e232-6b6e-4912-a8c2-a92b43e73d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a23f949-11be-4a21-b4c7-2157ae7a4c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8589995f-acfb-41af-a63e-37d44a8d97ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea39416-3cbd-448f-82fd-e03ded342a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0baf00-e76e-461e-8da1-4ac3cafc1fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb6e032f-1d8b-41f4-a447-7e53d5db1ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cfa4f4d-0fb8-4358-a1f2-abe5ba65347c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e33c8bb-9b65-46b1-8af4-2462f106ea35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeea829d-e880-4b54-a7fc-f9dc4d54d665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989d950f-4db7-4848-8608-0edffbdcf1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c62b30-53b0-4697-ad32-016e0298972f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1a4cf9-7b07-4bce-b0cb-cfa3b43df85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17dba22b-8c48-4a42-a42a-488e5745d7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bca9272-7b97-453c-934d-a03c8a5849ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07243fb8-5324-409a-b3b2-89ed9bfd66c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf3960f0-76c4-4b42-9950-c81b40f13c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 000cb657-ea33-4603-8b30-6de5bedb26c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e35711-0377-4da5-860d-e371e02fb322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e95c2d-fadb-49ad-a545-7f5e1ffbe041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59647af0-ac0b-4c8b-bf39-e4febc666e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7f799ba-8693-495c-9245-090dfd05c98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ebbdfa-3da8-41e5-b811-9cdeedd9defb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e38bc45-e2a0-485e-a732-7e6796eeb327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1256c2d-bf35-4d95-87e2-c7137028edb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995da02d-321a-4bbb-8447-fd6dddba2dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7140bb8a-a5ab-4781-b849-af7f2b164a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58ac7ec-7220-42f4-b962-cc2af5678569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ae22da-b1cf-4e22-947f-b17960371a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ccf962-ce29-4b9f-8387-4fb6bba814db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5db58519-2020-49a0-9ede-15c219b650b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7201ffe-8418-4343-aeff-2f023335e668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53937180-4646-4293-b298-c43e91747f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9772b9-ba1e-45d3-9d1e-49974d1c4fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ed5f77-1759-4597-8ba1-99e3bc1af927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dfdc585-4143-43dc-bf8f-8ef4f5c8e70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d911b95-367f-42fa-9212-9e71f5844fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab74845-adaf-4bf2-891a-c3256cd5fc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66be418b-6a61-4335-99a9-07cf5d91f028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b180569-3a33-4334-a701-4aed1067108b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91cd31db-6dac-49fb-98b4-f276c03100c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafbd88a-c6ef-4ae2-a0ab-3cfa4f705c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936c8c80-56bb-4431-b550-9030898de805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7b7613-00ca-4d77-ba98-d2c47edfa980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bdc0b6e-6a7b-46a1-b504-0149d37356a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001f3b97-f51e-4bae-aacb-1fbf0f4e7cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 149944f0-6a40-4a64-ab6f-8da9145d6654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f445d00-b8e3-4f48-8da0-7251b457e38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a60579-d54f-41ee-818b-a268c5c00625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be1c5738-bce6-4480-95ad-8336b5381020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c933eff-2557-457f-a957-c8ce34e2ef42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1992147-8be1-4e0d-b5e6-26030775d931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a7b252e-d34b-429c-a6f0-9df4d944f650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bddd1a5-8dcb-4f86-8849-33872dafe440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8249fe-1668-459f-9bcf-caf0872269a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efb91c69-a711-4661-90bb-c106b1676fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b89e687b-3e7b-40ac-a940-6417234cad02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8261a366-eb69-4ac5-9fb6-21cf8018dd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26605fc2-bf09-4154-b7a3-4cb549ecbc8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f1cf9fa-5fe1-4a4d-a44b-a1be4963da31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c28f60-8fc1-4bc5-91f0-5bffc49efa27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b79f276-bf90-467a-b4c0-15caac6c79ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e05b6c-83d4-401e-9000-17874d03f402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45561a06-5985-4d10-839c-5df29ade47d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdbccdad-67ac-47aa-a282-131643fce297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 963e0ede-3cc8-4ba5-8583-21742b3335f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a01d58c-acaa-4cfd-b517-52d6d29c43e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cae75c08-46c9-4766-a3ea-c517fa4fd6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4897799-1a9f-45bb-88eb-1b811e5a6a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 386feadd-52c1-43af-98a1-98b6ca6c9632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fe9eff-2d18-40cb-a141-7f5ee79004c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17955411-c5f1-4187-badc-bc94f5b5082d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db59b309-4997-41b0-a560-715f03bebe40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92473be-bfd6-4919-a486-55ab45948949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a122308-31f1-40ad-99d9-72890849be63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a10fd51-e65b-48fd-8632-d1b358b3fba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c11cbd-9693-464f-8d18-fb19e6ff749e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39badbd9-669b-49ed-8fab-e71e211a8098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7287895e-1d16-49b4-9fc8-adeda98a5fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ce5803-6172-4b89-bfb5-209c0e1c04f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd369e31-15ec-44e3-babf-daa19141bb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890e04f4-bfcd-4a78-bfbf-a3ac3ae75014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd8eadf-02a9-4b19-a182-56f1e7933c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f85a54b2-43c5-45e6-a905-f6ce28e0bae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa34436a-71ee-43b3-b318-ce632ca054fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dfd157b-9acc-45fe-8887-d4dd060f34ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeaeb463-38ab-4f36-b815-0f7484fc3ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52565a0f-784d-4fe4-aa2e-f86e604bac8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb01c76-686c-4029-899e-f93c2479dcfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9357a0-1c06-45dc-b89f-4eb8b3f1fefb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd2eab4-587f-4261-93fb-759715f70baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a300fc0-d395-4b39-a0bb-f778a42d561a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(424, 24), y=(424,)
   Test:  X=(106, 24), y=(106,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 415 samples, 5 features
   Test:  97 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2557, R²: 0.0084

============================================================
🔄 Round 3 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0915 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0790, val=0.0880 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0769, val=0.0874 (↓), lr=0.001000
   • Epoch   4/100: train=0.0766, val=0.0870, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0764, val=0.0870, patience=2/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0745, val=0.0880, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 3 Summary - Client client_10
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0225
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0012
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0145

============================================================
🔄 Round 4 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0755 (↓), lr=0.000500
   • Epoch   2/100: train=0.0808, val=0.0757, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0801, val=0.0759, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0796, val=0.0762, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0792, val=0.0764, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0779, val=0.0770, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 4 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0101
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0126
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2573, R²: -0.0137

📊 Round 4 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2572, R²: -0.0143

📊 Round 4 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2574, R²: -0.0164

============================================================
🔄 Round 7 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0832 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0795, val=0.0825 (↓), lr=0.000125
   • Epoch   3/100: train=0.0791, val=0.0822, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0791, val=0.0821, patience=2/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0790, val=0.0820 (↓), lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0783, val=0.0818, patience=6/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 7 Summary - Client client_10
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0071
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0136
============================================================


============================================================
🔄 Round 9 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000031
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0800, val=0.0836, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0800, val=0.0835, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0799, val=0.0835, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0798, val=0.0833, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 9 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0021
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0746
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2578, R²: -0.0236

============================================================
🔄 Round 10 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0760 (↓), lr=0.000008
   • Epoch   2/100: train=0.0814, val=0.0760, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0814, val=0.0759, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0813, val=0.0757, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 10 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0092
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0028
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2582, R²: -0.0263

📊 Round 10 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2583, R²: -0.0274

============================================================
🔄 Round 12 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000002
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 12 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0021
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0456
============================================================


============================================================
🔄 Round 13 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 13 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0063
   Val:   Loss=0.0999, RMSE=0.3160, R²=-0.0102
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0909, RMSE: 0.3015, MAE: 0.2584, R²: -0.0281

============================================================
🔄 Round 16 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 16 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0049
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0163
============================================================


============================================================
🔄 Round 17 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 17 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0111
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0088
============================================================


============================================================
🔄 Round 18 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 18 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0014
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0320
============================================================


============================================================
🔄 Round 22 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 22 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0077
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0067
============================================================


============================================================
🔄 Round 23 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 23 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0094
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0082
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

============================================================
🔄 Round 25 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 25 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0118
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0511
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

📊 Round 25 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

📊 Round 25 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

============================================================
🔄 Round 29 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 29 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0073
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0081
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

============================================================
🔄 Round 30 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 30 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0053
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0551
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

📊 Round 30 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

============================================================
🔄 Round 33 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 33 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0176
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0254
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

📊 Round 33 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

============================================================
🔄 Round 35 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 35 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0028
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0266
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0297

============================================================
🔄 Round 38 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 38 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0191
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0036
============================================================


============================================================
🔄 Round 39 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 39 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0173
   Val:   Loss=0.0697, RMSE=0.2639, R²=-0.0604
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0296

============================================================
🔄 Round 40 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 40 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0004
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0681
============================================================


============================================================
🔄 Round 41 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 41 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0054
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0174
============================================================


============================================================
🔄 Round 44 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 44 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0174
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0298
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0295

📊 Round 44 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0295

============================================================
🔄 Round 49 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 49 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0046
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0977
============================================================


============================================================
🔄 Round 50 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 50 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0066
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0645
============================================================


============================================================
🔄 Round 51 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 51 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0132
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0079
============================================================


============================================================
🔄 Round 53 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 53 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0107
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0045
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

============================================================
🔄 Round 54 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 54 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0033
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0260
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

============================================================
🔄 Round 57 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 57 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0034
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0598
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

============================================================
🔄 Round 58 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 58 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0104
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0176
============================================================


============================================================
🔄 Round 59 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 59 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0070
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0209
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 60 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 60 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0095
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0023
============================================================


============================================================
🔄 Round 61 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 61 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=-0.0071
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0407
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 61 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

📊 Round 61 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

============================================================
🔄 Round 65 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 65 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0071
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0099
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

============================================================
🔄 Round 66 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 66 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0075
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0153
============================================================


============================================================
🔄 Round 68 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 68 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0027
   Val:   Loss=0.0673, RMSE=0.2594, R²=-0.0418
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

📊 Round 68 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 68 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 72 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 72 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0096
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0021
============================================================


============================================================
🔄 Round 73 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 73 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0093
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0008
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 73 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0293

============================================================
🔄 Round 77 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 77 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0040
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0250
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0293

============================================================
🔄 Round 78 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 78 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0172
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0223
============================================================


============================================================
🔄 Round 79 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 79 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0021
   Val:   Loss=0.0654, RMSE=0.2558, R²=-0.0391
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0292

============================================================
🔄 Round 82 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 82 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0117
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0056
============================================================


============================================================
🔄 Round 84 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 84 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0010
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0605
============================================================


============================================================
🔄 Round 85 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 85 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0109
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0025
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

============================================================
🔄 Round 86 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 86 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0195
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0280
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0294

============================================================
🔄 Round 88 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 88 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0047
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0798
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 88 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 88 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0293

============================================================
🔄 Round 91 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 91 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0069
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0230
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 93 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 93 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0062
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0178
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 97 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 97 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0137
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0130
============================================================


============================================================
🔄 Round 98 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 98 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0030
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.1119
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 98 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 98 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0293

📊 Round 98 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0293

============================================================
🔄 Round 104 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 104 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0069
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0136
============================================================


============================================================
🔄 Round 105 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 105 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0191
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0412
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 105 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0292

============================================================
🔄 Round 110 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 110 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0017
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0337
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0292

============================================================
🔄 Round 111 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 111 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0119
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0047
============================================================


============================================================
🔄 Round 113 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 113 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0047
   Val:   Loss=0.0672, RMSE=0.2592, R²=-0.0265
============================================================


============================================================
🔄 Round 114 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 114 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0122
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0101
============================================================


============================================================
🔄 Round 115 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 115 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0119
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0363
============================================================


============================================================
🔄 Round 116 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 116 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0087
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0041
============================================================


============================================================
🔄 Round 117 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 117 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0149
   Val:   Loss=0.0686, RMSE=0.2619, R²=-0.0015
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0292

============================================================
🔄 Round 119 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 119 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0108
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0025
============================================================


============================================================
🔄 Round 121 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 121 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0029
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0765
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0292

============================================================
🔄 Round 123 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 123 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0117
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0115
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0292

============================================================
🔄 Round 124 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 124 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0120
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0095
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0292

============================================================
🔄 Round 126 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 126 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0129
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0083
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0291

============================================================
🔄 Round 127 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 127 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0139
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0017
============================================================


============================================================
🔄 Round 130 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 130 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0042
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0348
============================================================


============================================================
🔄 Round 131 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 131 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0131
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0026
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0291

📊 Round 131 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 136 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 136 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0054
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0197
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 136 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 142 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 142 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0033
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0265
============================================================


============================================================
🔄 Round 144 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 144 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0110
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0271
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 144 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 144 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

📊 Round 144 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 150 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 150 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0102
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.0034
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 152 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 152 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0151
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0122
============================================================


============================================================
🔄 Round 153 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 153 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0125
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0109
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0293

============================================================
🔄 Round 161 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 161 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0093
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0255
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0292

============================================================
🔄 Round 167 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 167 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0022
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0683
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0291

📊 Round 167 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2584, R²: -0.0291

============================================================
🔄 Round 169 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 169 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0021
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0416
============================================================


============================================================
🔄 Round 170 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 170 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0186
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0136
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0910, RMSE: 0.3016, MAE: 0.2584, R²: -0.0291

📊 Round 170 Test Metrics:
   Loss: 0.0910, RMSE: 0.3016, MAE: 0.2584, R²: -0.0291

📊 Round 170 Test Metrics:
   Loss: 0.0910, RMSE: 0.3016, MAE: 0.2584, R²: -0.0291

============================================================
🔄 Round 175 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 175 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0046
   Val:   Loss=0.0665, RMSE=0.2580, R²=-0.0633
============================================================


============================================================
🔄 Round 176 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 176 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0089
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0051
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0910, RMSE: 0.3016, MAE: 0.2584, R²: -0.0290

============================================================
🔄 Round 177 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 177 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0025
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0463
============================================================


============================================================
🔄 Round 178 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 178 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0144
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0316
============================================================


============================================================
🔄 Round 179 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 179 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0165
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0248
============================================================


============================================================
🔄 Round 180 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 180 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0137
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0198
============================================================


============================================================
🔄 Round 181 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 181 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0133
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0047
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2585, R²: -0.0292

============================================================
🔄 Round 182 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 182 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0030
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0499
============================================================


============================================================
🔄 Round 185 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 185 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0176
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0061
============================================================


============================================================
🔄 Round 186 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 186 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0046
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0305
============================================================


============================================================
🔄 Round 188 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 188 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0044
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0210
============================================================


============================================================
🔄 Round 190 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 190 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0117
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0054
============================================================


❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
