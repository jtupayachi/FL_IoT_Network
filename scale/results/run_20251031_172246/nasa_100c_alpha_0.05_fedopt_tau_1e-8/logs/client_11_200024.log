[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e352d8a-5b84-4fc1-af1a-b4095b69cb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f7ef085-4c5b-4e02-aa9b-9000760d7893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 793121dd-69d7-460c-8928-de3fb5c405dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55df8e7d-12e2-45e3-b86c-ac76bf60d7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afe0549-aa69-4356-b794-546b2eb56e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 429698bf-78f6-4490-a41c-26fcb63cc0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca950a31-4bf8-46ce-9526-a94f4fa78421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121fd9fe-29d4-448e-86ea-11bd9b9f714e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55012952-0f96-4d50-8257-46ed0b5d804c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c7df30c-f2de-4a89-b0b3-ad2528e177bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd84995-1f68-4354-a68f-47cfd3c3daca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa069d6-d2f4-4f92-a2f0-8f9c9de5ec35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be49799-608f-4d7d-bb75-8cda63cf9d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97af4714-64e5-4ca4-8ae1-1d583e66d58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb3f0659-b23f-4ec2-be46-85914d649dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f20caeb-29f8-452e-8861-90b92d3faa2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb4c8eb-d395-4541-b674-c8e58ef89a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083a3597-2871-4a80-ab85-afacb31cfe4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58767ab-f095-436c-8557-1f4768408d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1b11037-f519-4031-893e-3733473e41f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3f89b1-c36b-4ec0-a664-43d63d4b9708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdeb4cde-4841-4755-9aeb-f7dad47d7a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed294f76-67da-4d1d-aafc-00c77f39a569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e363a5aa-923d-4398-ac85-15670fe2f3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4220c0b5-5e55-4d36-b40e-23af61390104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d6a952-1946-4e67-b856-7cb5be23f598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6588d2ba-6771-4b5e-a74b-3afff29648ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40d4015-fccd-4760-bdbe-b7b684f73845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc4eea6-0fd7-4403-9423-598a8f6e98d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c03969d-8957-4641-b76d-47db069c1152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2acec8fa-6a2d-4ed8-bf9b-7f9bbe4db986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6cdb1d-ed4d-4b85-b635-b59d7a390310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4e73fd-c13b-440b-ae43-30a6ab5f208b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef23367-24a3-4774-8d56-d17b69c48235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a3a30d-ecdb-4c99-ac03-85a5a7e3722e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0866a98-f9d5-4751-bed8-3aa17e646473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b12e90-ac69-44ff-9ec2-829037f5f636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e20f37-7eaf-44c0-9883-bc1eacfa8608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c60b87-1fbe-4c76-9b48-ec4496c22f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6db4907-d4eb-4dc8-b47a-b03b41a3fd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee10739-a630-4022-9c75-c5dde768a3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029126f8-630a-4f5f-abeb-5697d59ffe66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 766d11c0-7369-485e-a0c6-b016a789a4e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f27ddba-b7b4-4d04-b751-8757c3ab1a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 235ce959-28b9-4666-b937-526e77cce8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536a90c5-d71f-4149-9ad1-776e0ec32f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccea6391-8a8a-4a94-b56a-665fe065d5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334056a8-28e8-4373-8df8-490b6d7b44d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b55826-c011-464f-b221-c5010f87a88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b22fc30-420f-40e1-9f56-8b18fa95671f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4690b0db-c934-4f29-904e-5ffce655599e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 314d7250-f468-4259-9e6c-02aa468c4177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e61105-107c-4f75-b323-dab13362303b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ea4daa-e99b-4043-86f4-967115404a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed469ba8-15f1-456b-98d7-9d6454f70011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5449d749-0683-41cc-84a2-ac785f5026a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a46e9fca-6b90-4036-9402-3cb9d5efb451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66852292-a413-42fa-98b6-3d6420f83624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4072a35f-cec1-4105-a04c-8caf774bba8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8eeaa6-afc3-42cd-86b3-d5860370d02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7282997-44eb-415a-82b9-dfe6c58678d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abb986e-13b1-42b0-b5d8-357ba532e67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3395424d-dd75-4f4b-9d8d-73cc2dc4547f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd21bed6-aed0-4e72-9d99-616932c53ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e61eee30-c26e-4aee-a1a6-465433c6932c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c9f676-920e-4610-ace5-9dd4ef88957e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 770ca1b6-09ce-4465-a2d5-48576979107c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a56e9339-b863-490e-9ed2-eddde5fcc82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b5d6dcc-b950-4cb4-a104-7671cc39871b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c63599-6612-4632-9547-5b3dd7a74bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2648a5f-972c-4138-a16d-fe02872458b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b3f715-801e-4893-9107-b05292dceda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca25dd05-cc89-4e22-935b-09b526679f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a364e10-aa26-420e-aa6d-b3c14c6121cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77fe6068-becd-4e55-97a2-e8247c6a45ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae45145-3e00-45bd-8908-38d7f5e2431c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a60362c-fd3c-4f03-958c-49f522d2a43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95379ddf-4d33-460c-8da5-4d544bf7fa08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34aa9742-ccae-41f9-aa4e-78ad926ab8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ac0532-e485-44fc-86e6-da834b4f0d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf4587d-398c-4b4c-b12e-96e6c82a9b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af05cc1-c9cc-4de0-a161-13a3eb20ef83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315c7da3-edd1-4de4-bf59-a32775ceb034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 847f045c-7d26-4125-8555-4151c1f51c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fdedbd4-6f31-4f2e-bea5-ee37d8dcc504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552797f6-c6bb-4e9b-8336-9b7fa761ab34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc7576a-e60b-4daa-8bba-55df4bbf7241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 181f8d3d-a2b9-48e1-b30d-53b732fb4851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3311a0f5-a173-42af-916c-9df791f52fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f6c9546-db88-4206-b569-bf71b69b5f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de542725-4831-48d7-88c4-b9ff25ac1262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b844a98e-1b96-47ad-93c5-4b2bb3301c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d9db15e-dd95-446a-8e2f-aceb553813e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a863c783-52df-425d-b703-d1f79013e0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd11084a-7b3c-4ab7-aeb4-f884d3484647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66816fb9-703d-42ab-b801-e4df29f1e2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b8866b-afaf-4135-9ebb-8aac468d83d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb4098e-4f99-45f4-a951-7bec666aabf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc78ca04-8b7a-480c-8c93-a5261800a226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10acc38a-0d87-40c2-9413-dcd070cc7247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ea4142-96cd-4e80-86bd-ec625fea956b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a40cb8-6f84-40d7-acce-e219b889535c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0135ac3e-acda-4031-abfe-95722e04cbf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fa4640-dedc-4eec-9768-ea499b7dfea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4847a567-ea8e-4918-83eb-222a217da052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 281594d4-3f07-4607-b179-60db4fc8b923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b1b0fd4-e7b0-4e4e-9510-6152480bba0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4b5aed-40d6-493e-a1cc-0ee08b30cc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efcfd422-bb4f-4a69-9884-5a266f03076e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353d4be3-4aa0-42db-9421-6ff5c642e283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc899e84-b070-4841-8339-e324d4c2d01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e77db49b-fef3-49c6-8514-3f1cab78de0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3a3ac5-7a55-493b-a6e6-80ded02e2aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e290009e-78c7-410d-aa39-514dba92e7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b7e8cd-478c-47c7-a6a9-9631658fe0f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713498f6-a768-4383-a287-a01cf3448cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14fd948-2995-4fdc-a098-9856ba46cca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c03d1c0-01c5-4e27-94da-68c31a768a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7002aa60-21e0-448f-a7ca-f4091f050002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb59227c-aa91-4b24-b161-16c46935110c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ffc0555-c515-48c4-af5e-305268b347e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7751a9a2-0885-454f-ae48-4bb48cd1c1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d208441-7290-4fc5-af90-6b4c4c2e66cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5462998-f89b-4a12-998c-801be2cb141b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b40de73-47f6-4d2a-b3f5-179e4217064f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57fd986-9e53-40d8-87a2-e109c2201d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055bcdb1-ef95-4224-bfb0-fc2230bca9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b78995-94f8-46be-b38a-7f376c3d861c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea64e21-865d-4970-b5f4-90f2e8bbb5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bc14e0-0b40-4c5a-9d35-7ecd9e5fb8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0c4aa82-b7b7-47e4-8a6f-e442e4a5adaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdea5f61-edce-4427-9e02-e0703ac021ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e3f58a1-0328-4a45-bfa0-c9925b429780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3772466-620b-408c-8841-4627ccbbab4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db60174-5e9f-499a-bae0-8e6ddcd61cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ffdbd9-4e2a-435f-878a-d78a433538e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ec0350-5a24-4b28-a11f-2bcfec77ea65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46dbe92-5489-4fcd-af4a-40c5a5f66306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27955f45-a201-41f0-b5cc-d6524748ee2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84b72f8e-ba60-416b-9eb8-42a2e941741e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f314b9-581a-46ff-9792-b3f6483822d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8254727-7c77-45da-a554-9312f058664b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92bbfc6-af36-4238-8c7d-61e2abd961be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f5225fa-0b2b-437a-98ae-2bb9915c56ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81054189-d2c0-47d0-8c17-0f2440289595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5bdc91-aad7-41ad-8e48-228abfe12f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc554a5a-d7d6-486c-a0f7-a3e6225bc865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c93b2c9-e984-48d4-bef6-c3d4d8b14839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59622f1f-2fec-497c-9b19-c6fd72f72495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e3cb8c3-54e1-4b9e-b20b-561637070553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 352ad9ef-b94b-4fd4-93dc-f76107d9aabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3243c8f-40e6-465d-af22-da54564a57da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dacc39d-ceb3-48fe-a693-a1de76450f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48e7fba-e1aa-4c64-afe0-358a1a11f340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470e5e3c-9261-49d5-b363-50c65a360994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8339a62e-d89c-4f71-97b8-0c4ae691b120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f3f833d-35c9-4d59-b2af-044bfd017c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27226459-bfd6-422f-8ce5-d97de9e14b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3bb2faf-3293-4438-9dc0-6dbb1427648b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9ec8d7-e489-4555-ad03-4af301df5bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c49f36b-a771-49bb-bed0-df95971414d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da6ee3ed-3657-4ebe-a15c-d1b58eec5ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e12604d-5ed4-4222-850f-0d991fcfbc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be6732da-b44f-4980-ab9e-881e379490e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfda78d0-142a-41ed-8982-420c9046b73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad38f215-fb7c-4a36-b40f-cc93b45cc2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f2a660-f6af-4a4a-9b36-3cb8929bde08
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(301, 24), y=(301,)
   Test:  X=(76, 24), y=(76,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 292 samples, 5 features
   Test:  67 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2530, R²: 0.0043

📊 Round 0 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2529, R²: 0.0045

============================================================
🔄 Round 6 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0822 (↓), lr=0.001000
   • Epoch   2/100: train=0.0882, val=0.0856, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0874, val=0.0841, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0864, val=0.0839, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0857, val=0.0844, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 6 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0051
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0728
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2529, R²: 0.0060

📊 Round 6 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2525, R²: 0.0087

============================================================
🔄 Round 10 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0782 (↓), lr=0.000250
   • Epoch   2/100: train=0.0905, val=0.0777, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0897, val=0.0772 (↓), lr=0.000250
   • Epoch   4/100: train=0.0892, val=0.0768, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0890, val=0.0762 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0879, val=0.0744 (↓), lr=0.000250
   • Epoch  21/100: train=0.0861, val=0.0724, patience=1/15, lr=0.000250
   • Epoch  31/100: train=0.0845, val=0.0709, patience=3/15, lr=0.000250
   • Epoch  41/100: train=0.0830, val=0.0698, patience=4/15, lr=0.000250
   • Epoch  51/100: train=0.0816, val=0.0693, patience=7/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 10 Summary - Client client_11
   Epochs: 59/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0439
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0495
============================================================


============================================================
🔄 Round 11 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0849 (↓), lr=0.000250
   • Epoch   2/100: train=0.0884, val=0.0844, patience=1/15, lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   ✓ Epoch   3/100: train=0.0880, val=0.0840 (↓), lr=0.000125
   • Epoch   4/100: train=0.0877, val=0.0838, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0875, val=0.0837, patience=2/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0869, val=0.0832, patience=4/15, lr=0.000063
   📉 Epoch 19: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0866, val=0.0830, patience=2/15, lr=0.000031
   📉 Epoch 27: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0864, val=0.0829, patience=12/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 11 Summary - Client client_11
   Epochs: 34/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0097
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0254
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2517, R²: 0.0138

============================================================
🔄 Round 12 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0863, val=0.0898 (↓), lr=0.000008
   • Epoch   2/100: train=0.0863, val=0.0898, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0863, val=0.0897, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0863, val=0.0897, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0862, val=0.0897, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0861, val=0.0895, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 12 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0267
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0986
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2517, R²: 0.0139

============================================================
🔄 Round 13 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0890, val=0.0743 (↓), lr=0.000002
   • Epoch   2/100: train=0.0890, val=0.0743, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0890, val=0.0743, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0890, val=0.0743, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0889, val=0.0743, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0889, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 13 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0909, RMSE=0.3016, R²=-0.0335
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0782
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2518, R²: 0.0137

============================================================
🔄 Round 17 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0959, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0959, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0959, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0959, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0959, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0959, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 17 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0410
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0509
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0155

============================================================
🔄 Round 20 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 20 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0485
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0419
============================================================


============================================================
🔄 Round 21 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 21 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0360
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0812
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 27 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 27 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0517
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0166
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 28 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.1109 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.1109, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.1109, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.1109, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.1109, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.1109, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1109)

============================================================
📊 Round 28 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0478
   Val:   Loss=0.1109, RMSE=0.3330, R²=-0.0289
============================================================


============================================================
🔄 Round 29 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 29 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0450
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0875
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 30 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 30 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0354
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0797
============================================================


============================================================
🔄 Round 31 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 31 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=-0.0588
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0238
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 31 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 34 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0926, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0926, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0926, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0926, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 34 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0427
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0460
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 37 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 37 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0353
   Val:   Loss=0.1004, RMSE=0.3169, R²=-0.0819
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 39 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 39 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0597
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0321
============================================================


============================================================
🔄 Round 40 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 40 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0340
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0739
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 40 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 40 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 46 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.1052 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.1052, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.1052, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.1052, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.1052, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.1052, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1052)

============================================================
📊 Round 46 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0455
   Val:   Loss=0.1052, RMSE=0.3243, R²=-0.0358
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 47 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0957, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0957, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0957, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0957, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0957, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0956, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 47 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=-0.0393
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0627
============================================================


============================================================
🔄 Round 48 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 48 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0306
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.1677
============================================================


============================================================
🔄 Round 49 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 49 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=-0.0421
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0650
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 51 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 51 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0433
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0400
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 54 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 54 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0440
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0389
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 55 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0975, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0975, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0975, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0975, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0975, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0975, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 55 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=-0.0449
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0945
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

📊 Round 55 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 57 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 57 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0417
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0553
============================================================


============================================================
🔄 Round 58 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 58 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0526
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0239
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

============================================================
🔄 Round 62 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 62 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0477
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0239
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 62 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 66 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 66 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0398
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0723
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 66 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 66 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 72 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 72 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=-0.0485
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0293
============================================================


============================================================
🔄 Round 73 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0933, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0933, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0933, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0933, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0932, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 73 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0518
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0059
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 73 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 76 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 76 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0482
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0472
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

============================================================
🔄 Round 79 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 79 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0302
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.1682
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

📊 Round 79 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

📊 Round 79 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 86 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0938, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0938, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0938, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0937, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0937, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0937, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 86 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=-0.0532
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0065
============================================================


============================================================
🔄 Round 88 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.1161 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.1161, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.1161, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.1161, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.1161, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.1161, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1161)

============================================================
📊 Round 88 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0425
   Val:   Loss=0.1161, RMSE=0.3407, R²=-0.0438
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 90 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 90 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0421
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.1592
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 90 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 90 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 96 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.1047 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.1047, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.1047, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.1047, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.1047, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.1047, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1047)

============================================================
📊 Round 96 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0502
   Val:   Loss=0.1047, RMSE=0.3236, R²=-0.0201
============================================================


============================================================
🔄 Round 98 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0934, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0934, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0934, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0934, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0934, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0933, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 98 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0474
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0320
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 103 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 103 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0467
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0425
============================================================


============================================================
🔄 Round 104 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 104 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0616
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0044
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 105 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 105 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0349
   Val:   Loss=0.0984, RMSE=0.3137, R²=-0.0774
============================================================


============================================================
🔄 Round 106 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 106 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0449
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0403
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 107 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 107 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3039, R²=-0.0537
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.1051
============================================================


============================================================
🔄 Round 109 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0928, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0928, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0927, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 109 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0465
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0334
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 111 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 111 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0420
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0468
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 112 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 112 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0339
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0821
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 112 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 114 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 114 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=-0.0558
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0092
============================================================


============================================================
🔄 Round 115 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 115 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0371
   Val:   Loss=0.0988, RMSE=0.3144, R²=-0.0919
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 115 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 118 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 118 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0451
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0498
============================================================


============================================================
🔄 Round 119 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 119 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0377
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.1033
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 124 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 124 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0541
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0076
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 127 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 127 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0434
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0809
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 134 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 134 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0425
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0436
============================================================


============================================================
🔄 Round 136 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.1135 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.1135, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.1135, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.1135, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.1135, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.1135, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1135)

============================================================
📊 Round 136 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0353
   Val:   Loss=0.1135, RMSE=0.3370, R²=-0.0647
============================================================


============================================================
🔄 Round 139 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 139 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0339
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0811
============================================================


============================================================
🔄 Round 140 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 140 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=-0.0445
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0351
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 140 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 140 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 145 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 145 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0557
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0080
============================================================


============================================================
🔄 Round 146 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 146 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0449
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0389
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 148 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 148 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=-0.0385
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.1107
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 148 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 150 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 150 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0561
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0583
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 151 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 151 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0339
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0769
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 151 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 156 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 156 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0301
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0977
============================================================


============================================================
🔄 Round 157 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 157 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0472
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0317
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 158 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 158 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0400
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0548
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 159 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 159 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0418
   Val:   Loss=0.0945, RMSE=0.3073, R²=-0.0916
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 160 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 160 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0399
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0536
============================================================


============================================================
🔄 Round 161 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 161 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0558
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0071
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 162 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 162 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0463
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0588
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 163 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 163 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=-0.0391
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0750
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 165 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0960, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0960, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0960, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0960, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0960, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0960, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 165 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=-0.0274
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.1277
============================================================


============================================================
🔄 Round 166 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.1021 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.1021, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.1021, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.1021, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.1021, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.1021, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1021)

============================================================
📊 Round 166 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0354
   Val:   Loss=0.1021, RMSE=0.3196, R²=-0.0696
============================================================


============================================================
🔄 Round 167 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 167 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0440
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0976
============================================================


============================================================
🔄 Round 169 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 169 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0437
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0732
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

============================================================
🔄 Round 170 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0938, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0938, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0937, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0937, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0937, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0937, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 170 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=-0.0448
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0457
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

============================================================
🔄 Round 174 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 174 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0425
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0679
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

📊 Round 174 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

📊 Round 174 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

📊 Round 174 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

============================================================
🔄 Round 178 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 178 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0479
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0355
============================================================


============================================================
🔄 Round 179 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 179 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0469
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0277
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0153

============================================================
🔄 Round 183 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0935, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0935, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0935, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0935, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0935, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0935, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 183 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=-0.0395
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.1159
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 183 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 185 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 185 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0459
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0320
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

📊 Round 185 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 188 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 188 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0411
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0759
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2515, R²: 0.0154

============================================================
🔄 Round 189 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 189 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0465
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0321
============================================================


============================================================
🔄 Round 190 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 190 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0252
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.1780
============================================================


❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
