[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f13be24-7354-4d3e-9c57-2bdbf242508d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d5629b-b947-414e-9285-cade35a264ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7863c5-1eba-4906-a0fd-52f49dc171ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f32e05-b776-413e-a87d-e738d6eeaeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc4c069-0e37-40f4-8071-9a123596380e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf79a3e6-157b-4e2b-9942-3784cf37f18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a917ae4-2090-4e1b-82fd-d22a13396cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bed66f4-8c52-4fae-9ac2-4eef27381c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b218d788-3342-465f-8e3e-a2ed29e7babb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c25a4b1-e91d-45a7-9b84-9822ccd86497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a37a2107-cc73-4a7b-aa9e-1d8f49049684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1ff874-3f5d-4b6f-b770-1c7895ca06f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649323d8-1ed6-4183-9abd-fb4e9dc02f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1783805e-2b9a-43c5-9100-3f6af71d65a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b4b715-85e4-4647-9f2b-8b327532d583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d01049-1a01-4d9a-847d-7cd1ed6f76e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 492a72bd-d348-425b-9f78-39ddcd3ccb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd25615c-3f81-4d85-8351-298d363e4be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cefe1476-43bb-4ced-be4d-bd0e50a6f31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05703b07-e0e2-4ae5-8793-ae327fba7702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23cada44-bde7-4699-b32b-f5958eef94fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a469f06a-8de6-488f-b8e2-2c27de91b850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1b3e232-b98f-4795-91e0-ed36567fbd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8025b51-b21e-46d0-ba85-e102a3d3c7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9fdaeaa-1564-41d2-bf67-68916730bc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932ecc9e-91f4-48e2-bbeb-8fad58d965dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0432bf7-b871-43d8-9860-e6f3d6453087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5d7430-a3c5-4aaa-9f13-809418075ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd0c921-fef4-4447-b690-e28fae7beb7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56b9cb95-392b-4870-8115-2b8d533c023e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274976df-9b22-41b0-8045-933a83e977ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38dab341-2894-4853-8b82-603347281de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68bd5b54-280e-4b8b-b3c3-9ba0d9e68f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64105b75-8051-4918-ab89-2b7e93e71f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a85ce9-d093-4ee0-b5bf-39d8cfbd06ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f5a63b-1590-4fda-ad5d-c2cd985b04e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03e38fdd-e038-4bcd-8946-ff27f6b215b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199646db-0886-4103-bd7f-fbd605e2f3d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de97afe9-3756-4c74-b9f2-a9ef24b57cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c7bf30-7927-4160-a79c-06cac5904a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10673c21-1fe5-48f3-90e4-af10e0aca34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce147100-a46c-45e0-95af-69b3dd950d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc5bb970-61cc-42bc-8e92-0f96456b42a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0726bf4-f32d-4d9f-b3fa-b0a27f9a7e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e1219e-33ec-4a5d-8d88-9d2f44506759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21a321a-4cb9-499d-a940-8d690a917784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18f3189d-6c48-41b5-ac18-4587853cf2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a886f2-e6e1-417f-8ddd-d5744dc29fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4c052b-fdfb-4f4c-920f-65eb67c0c616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d00fc9-ed7c-4b6c-a502-b11902961e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a53c0b-8a67-4e4e-818b-1e53a2d6d5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5139ace6-f443-464f-8379-5a3a1de4c605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4716a5dd-4691-46ca-b1d5-6c90dc0280ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2926c069-8b00-4daa-ae8f-6be5ebc5cb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6302e72c-592f-455c-94ac-fe5ec68a2bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d97003-ba0d-4aec-979b-64dc9f4f28c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af1109e3-bd24-4934-ac19-6b2a8d34050f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b0ab68b-3841-4d91-95d9-47e208aecf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cd52aa2-8d3b-441b-be1e-91320b85dd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b46b33bb-f491-4283-bd7c-e9a720398d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f785e86b-1dda-46a0-8704-764b85749220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f04c5c-fc73-419b-b34b-1c29c4d16be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47497612-f9ab-4604-99eb-7fe7d39142d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cff606f-a16d-44e1-aaea-be0d49d3e037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e98b6a0-6143-4389-bfff-dc8698dd42b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c218c52-4568-43eb-9bd4-97630c2df14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3799629-419d-4d6a-ae53-915dc3729233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09da788c-1fae-45b1-8a84-b1673103c115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd636f30-9b52-4044-95b5-b742560153bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d3f92c-58ab-4e03-a8f0-f34824e358a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f509780b-8a16-45f5-9828-8aea4a9a9bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbaddc0-0865-47b6-9b5f-0136bada80af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fdff2ba-1f60-435a-9610-fd6b83b075e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b881cc4-62be-4f28-806b-280626f59150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b24b80-daf7-4540-a25c-13d851711e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfbf11a-283f-4298-8745-5f80ae0fafac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea51c4b-3b2e-49d4-95f2-c87940e0ec4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8675332-fa1f-4b91-95ce-89ba46b3d8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0595e04e-fccc-4311-a8a1-f60e46e6c8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7b5c316-2ec4-4723-9377-1adf12b5bad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8517a0-0d0f-4978-9d59-6c5bafa0ced0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a293d592-57ae-483b-8d4a-d016f41a1008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71eb0098-3524-467f-989f-0a5386770165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74b1f522-64a2-4240-8123-95db6b797fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4002e410-cfeb-4e10-882d-83afb64c1728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be13053-ce96-4555-85ec-09cd748470c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ff30f1d-a779-4d9d-9a94-8dba9769c526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 281d27cf-4d5e-4577-973e-ac550835d6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763e0f64-68a8-40a9-9c53-22c3f186f875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c926a33-26a4-44c9-941b-60244cff32e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da3d46f-7222-4986-97b7-024084c20f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c8e39db-168c-4aa6-b0bb-66d40d34a316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad33fa3-ed17-434c-8491-36b4b03e5ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae50e6e-564f-4dc8-b816-edabe12ebe98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090f6112-d47e-4708-92e8-c3376b5a8870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 256b8e4c-85d7-4f79-90e8-508b4256b360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87aa8b98-a4a7-4feb-bbab-3745755661f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d99c562-5afd-4db3-933c-3a8bbc243861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7e64cb-f560-4698-9daa-9a9abaabfaab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eadbb8d5-993c-4f9f-9761-32317d45ddf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6593fa-49bf-43cc-91b4-0da89a386d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c76bf95-9a80-4af6-b721-553bcdd799d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1baadb2e-99ba-4f3c-a608-a7c96c3f5f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7b6a90-2edb-4c11-bdef-d9a7af0406fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37790330-0114-4985-bf73-06747fe3f2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d7a9a7-cab9-4e9b-b162-2cb1c5b72bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17647d8e-2062-4c1c-9bde-6042eb1f27df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0f10214-f57f-4609-b6ab-97ea4e14cc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637b2000-074a-446a-a39a-964f3cf8418d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4871e5-fb42-4d84-b619-abfb184da41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 192a9af0-73c5-4cc3-afbc-fc8efa15a11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5893801-f49b-4838-8267-40bf9ab896c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff621107-e5df-4bd4-9ad1-3b9045d2439b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7202ec45-1217-4309-b40c-5600637aebf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83000117-cb25-4c1b-b901-0a250331d1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409c817c-d76d-486f-b4f8-0a2fee4806c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62de105f-5ea5-49de-8743-88ec3165b7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 295ebce2-4b23-47cc-a788-c3d7049d3882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d9c8fa-f83a-43c9-9143-99ce6bf604d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc4fe886-b364-4035-940e-93c946a25a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51d09a47-8da1-41af-b2df-35a6cdbb9181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a77e2d72-8797-4e31-8418-b5111465caba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09682006-bb02-4978-ae05-a0a5082bf8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce76ea4f-d7c8-49f3-9aa3-16de6772021c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53c98d5-4477-4dbe-af28-fe07e930ed2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abc4c04a-a945-49a5-800d-6d8e5d64eecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd76f68-20c6-46fb-8020-2186aee9f1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1f667b-7e1d-4621-b73d-7bbc5490755f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59155c59-2db4-4d6a-b359-ac732fe38d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bfa458-04b7-43d4-8a34-02e01163f9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9080b19a-29a5-4a8f-8d29-856974199835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a9a632b-b71a-4efe-8c69-47b6b469b68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ba4d90-ca38-4b0d-8045-f38382e3c721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 855b37f8-3c7b-4323-b52a-69384a35a1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ee75ed-759b-4230-85cc-301c2f400009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b19e8ae-54ff-418a-88b9-3f0feba0206d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f988d21f-80ad-490e-8aa4-4abd2d94c5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5d198a-61d1-427b-8d4b-9519b4517484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9560da0c-eaa8-4100-a0f9-cb7f3f17754b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7377d82c-5767-4a6e-b252-7dbcd5a0484f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a013d360-1497-4c0e-b07e-daf7f8a14ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c399f91-7bb0-4827-9d33-d6523f51b13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1f79ad-3c78-4abb-b7e3-e65b17b935f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d2b2941-dd2a-4725-bb0b-bc71a9b48535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31322755-a403-410c-96a6-911bd575ae07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe3a40c-7176-459f-acba-638145e118ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351e3696-a588-4d4f-9a7c-8288fba02389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fff259e-9fa1-4b98-bb33-a5f0a54429d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3e6e70b-177c-4e80-8905-6a1a4af0c1b7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0881 (↓), lr=0.001000
   • Epoch   2/100: train=0.0823, val=0.0889, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0819, val=0.0890, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0892, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0811, val=0.0888, patience=4/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0782, val=0.0866 (↓), lr=0.001000
   • Epoch  21/100: train=0.0701, val=0.0836, patience=1/15, lr=0.001000
   📉 Epoch 28: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0542, val=0.0892, patience=9/15, lr=0.000500
   📉 Epoch 36: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 3 Summary - Client client_12
   Epochs: 37/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0665, RMSE=0.2579, R²=0.1880
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0533
============================================================


============================================================
🔄 Round 4 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0832 (↓), lr=0.000250
   • Epoch   2/100: train=0.0819, val=0.0831, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0819, val=0.0831, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0832, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0818, val=0.0832, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0815, val=0.0832, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 4 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0079
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0254
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2466, R²: 0.0146

============================================================
🔄 Round 5 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0759 (↓), lr=0.000063
   • Epoch   2/100: train=0.0835, val=0.0759, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0834, val=0.0759, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0834, val=0.0759, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0834, val=0.0759, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0832, val=0.0758, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 5 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0130
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0210
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2464, R²: 0.0166

📊 Round 5 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2447, R²: 0.0313

============================================================
🔄 Round 11 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0813 (↓), lr=0.000063
   • Epoch   2/100: train=0.0801, val=0.0813, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0800, val=0.0813, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0799, val=0.0813, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0799, val=0.0813, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0797, val=0.0812, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 11 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0341
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0170
============================================================


============================================================
🔄 Round 13 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0763 (↓), lr=0.000016
   • Epoch   2/100: train=0.0815, val=0.0764, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0814, val=0.0765, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0813, val=0.0766, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0812, val=0.0767, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 13 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0307
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0306
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2444, R²: 0.0337

📊 Round 13 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2443, R²: 0.0343

📊 Round 13 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2443, R²: 0.0344

============================================================
🔄 Round 18 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000004
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0803, val=0.0797, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0802, val=0.0797, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0802, val=0.0797, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 18 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0299
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0475
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0347

📊 Round 18 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0347

============================================================
🔄 Round 24 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 24 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0256
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0552
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0347

============================================================
🔄 Round 26 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 26 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0387
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0151
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0347

============================================================
🔄 Round 28 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 28 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0297
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0322
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 29 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 29 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0282
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0524
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 30 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 30 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0350
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0105
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 33 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 33 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0372
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0152
============================================================


============================================================
🔄 Round 34 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 34 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0284
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0488
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0347

📊 Round 34 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0347

============================================================
🔄 Round 38 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 38 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0335
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0123
============================================================


============================================================
🔄 Round 42 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 42 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0332
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0227
============================================================


============================================================
🔄 Round 43 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 43 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0277
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0560
============================================================


============================================================
🔄 Round 44 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 44 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0347
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0254
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0348

📊 Round 44 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0348

📊 Round 44 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 50 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 50 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0368
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0159
============================================================


============================================================
🔄 Round 51 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 51 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0313
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0389
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 52 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 52 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0353
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0248
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 53 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 53 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0333
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0324
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 55 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 55 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0342
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0260
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 59 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 59 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0352
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0160
============================================================


============================================================
🔄 Round 61 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 61 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0372
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0152
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 63 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 63 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0309
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0348
============================================================


============================================================
🔄 Round 65 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 65 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0314
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0176
============================================================


============================================================
🔄 Round 66 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 66 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0313
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0416
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

📊 Round 66 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

📊 Round 66 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 76 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 76 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0371
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0172
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 76 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 76 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 76 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 82 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 82 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0381
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0092
============================================================


============================================================
🔄 Round 84 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 84 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0297
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0464
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 88 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 88 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0308
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0357
============================================================


============================================================
🔄 Round 89 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 89 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0315
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0380
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 91 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 91 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0367
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0081
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 91 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 94 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 94 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0340
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0303
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 99 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 99 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0347
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0262
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 101 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 101 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0313
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0396
============================================================


============================================================
🔄 Round 102 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 102 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0309
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0416
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 102 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 106 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 106 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0357
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0232
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 108 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 108 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0326
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0348
============================================================


============================================================
🔄 Round 109 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 109 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0300
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0456
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 109 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 112 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 112 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0337
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0300
============================================================


============================================================
🔄 Round 115 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 115 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0310
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0430
============================================================


============================================================
🔄 Round 116 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 116 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0342
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0289
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 119 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 119 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0338
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0264
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 120 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 120 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0366
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0129
============================================================


============================================================
🔄 Round 122 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 122 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0397
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0064
============================================================


============================================================
🔄 Round 123 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 123 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0268
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0598
============================================================


============================================================
🔄 Round 124 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 124 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0343
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0147
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 124 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 129 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 129 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0346
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0238
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 129 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 131 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 131 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0320
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0372
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 133 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 133 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0306
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0437
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 136 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 136 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0333
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0307
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 137 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 137 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0337
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0324
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 138 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 138 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0309
   Val:   Loss=0.0724, RMSE=0.2692, R²=0.0441
============================================================


============================================================
🔄 Round 139 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 139 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0362
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0211
============================================================


============================================================
🔄 Round 143 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 143 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0321
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0379
============================================================


============================================================
🔄 Round 144 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 144 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0266
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0607
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 146 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 146 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0355
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0217
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 147 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 147 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0320
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0359
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0348

============================================================
🔄 Round 149 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 149 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0311
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0360
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 149 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 151 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 151 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0370
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0191
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 152 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 152 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0333
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0335
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 153 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 153 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0327
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0212
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 155 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 155 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0341
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0282
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 157 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 157 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0411
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0045
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 161 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 161 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0292
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0369
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 162 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 162 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0366
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0207
============================================================


============================================================
🔄 Round 166 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 166 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0357
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0158
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 166 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0350

============================================================
🔄 Round 171 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 171 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0347
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0251
============================================================


============================================================
🔄 Round 172 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 172 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0295
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0468
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0350

📊 Round 172 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0350

============================================================
🔄 Round 181 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 181 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0312
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0365
============================================================


============================================================
🔄 Round 182 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 182 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0290
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0466
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 182 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 185 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 185 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0294
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0499
============================================================


============================================================
🔄 Round 186 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 186 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0310
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0331
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

📊 Round 186 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2442, R²: 0.0349

============================================================
🔄 Round 190 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 190 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0317
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0404
============================================================


❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
