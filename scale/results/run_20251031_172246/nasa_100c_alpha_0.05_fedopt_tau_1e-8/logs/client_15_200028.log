[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cbff52c-fb82-4e36-87ed-04b561a8817a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9ab545-88ed-4f9b-b667-3996795bd922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a52b3fc-24ef-4265-af50-0906072c8d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f0d8eb-2675-435d-ad7e-c7303ff760bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afc6cc6c-6913-49ba-934a-af1a8dd2f0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00cf42b7-d2ef-438a-84b5-16100edd2fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a8bf0c-ff11-412d-99b7-408ae6a98cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958b89d9-78e9-4599-8ff7-db8998bb5675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 564dc5b1-56a9-44dd-accc-e27bb343a127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b8bd77f-0330-4706-b89f-1e65d591efa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0960e47a-0c1d-45ef-9a69-9bd611fa1c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe23090-734b-479d-b5a2-067e605da178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf8355b-8f8f-4787-93f4-c16c6cbf452d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dd59264-1b50-46bc-b910-cb126eb97dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 726c0fc9-609f-4569-baa8-d010a96c68eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da211bbc-c4ef-4ae2-bbd8-a7463cc6f340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce38ef5-84b4-480d-a2fe-68c554dc1212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d632580-98b6-444b-ab6b-43e9123d957d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e528a34-4b43-4119-80b7-d81f876ec490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c1eaf8-da52-4fa2-a1fa-7ac4c2511d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f593f98-18f8-40c3-a950-9210179c4114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c007dea1-6518-4809-8475-72daeb6e954f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939135fa-7765-4150-9e7d-d1dd8af5447f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef86aa8a-fc1f-4f5c-816d-5c4456597210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ea8475-d81a-4c2e-840f-40ee0abfe41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee51ce77-0267-40fd-b30f-b6725594f39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f9541a-cc2c-443d-b827-3186c4ca704d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a461c8ca-d2f6-4d0b-87b4-a8102b2e5371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a6c69e1-f0ae-4eb2-9ac3-a4f6094f656c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c06ab6-1cab-431c-9df5-11f83dcee84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e34aebd-f317-4839-a934-de88bacad05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f9506be-9eb9-4b02-9ae4-b50fc473e198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 814e21e2-25b7-4d24-b6bb-333983f0bafe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1014c8c-129a-4e3d-b7d5-850cffa13b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7eb8e6e-90c7-43f6-9f31-742425a8a748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03a5525e-5889-4aec-9795-6215e4fb383a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c200a464-d1bf-4490-89f6-b821860bfa80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f911a7-c87a-4961-8c92-837de8854daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd56cfd9-2cc5-4e3e-882e-5ed6a251b180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb5342a3-b557-452a-87f8-2d23f3a6ed10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff076f8a-a2f7-4b7c-b6d5-c59d4c4631eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4e2e85d-20e6-41e7-a717-d9a8d2f19568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 635bd2da-4f26-4c76-91fe-7c9f1f23a6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51dd062d-76ce-4476-b24d-cc5613dc34b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5edf708b-78eb-4c44-b9e1-c865a2bfd598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f6650fe-5399-4437-9a59-49fe401e6c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db411ac-80cf-48e5-acc1-4d56c8d66225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea324d3c-5d8a-452e-8f4c-886f704cd3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554d3717-fc63-47c5-9430-1e3edbae6b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3a63cb-3d65-4e7b-b233-be7557a9108d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0df70dd-3497-4745-be81-46ecc36f95fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d18974-d14e-476a-be26-777ee562d8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66bc07bd-d428-47a5-8685-4cbd26e1fe47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de792bd-fdf5-4969-a88c-fec20690374f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc6697a-85a9-481f-b8e2-b17eac635962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d293f6fe-2b64-4ae8-a3fa-e0545f8fa535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808b98f6-3ff2-4da6-88fd-8c2d50d26d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6fa6bb-7284-4213-84f8-5d3217aa874c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 263b0a94-b0fc-40bb-a8e4-c3718b5ee40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b3e589-97a7-443b-a1ee-db0d4d4c1305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b006e64-3ab4-46a5-a4ef-6519f0e69ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735500a2-569b-4fed-94c2-2463c9bacbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c9a0e1-7e03-4ddb-bdb7-7f00e9a5997c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53002007-a5ce-4d31-8082-e47953a35b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d9eed2-f99f-4b84-9f7d-b2e24cb83da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab44f101-313d-44bf-94a5-995293efe3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dbac268-373f-4c83-aa8e-76f076015b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63606578-34d4-4d03-82e4-289d4b3ccf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 072e1d94-476a-41b1-85f3-00f4d2d96f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f19f76-fe0e-4261-8bff-01c14f7950b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65164976-6fc3-4647-9fae-3502e2e3449d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64a8a21-8619-4098-ad12-2dcbb108c621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 489295f1-9984-41f4-aff0-9c6ecd1dccbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a557f8f5-7d86-4375-abc0-ff86cdbf01c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c2d175-7023-4fa6-a812-74171d18eaef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a28a6a3-14de-46a8-a98f-40f63be283fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d21fa0-05ef-44bf-8af6-64f0812cb6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac28480-dcc0-491b-ab8a-315ed55020ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f8b572-8af7-488e-9804-5804fcdb8c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34ff4c4f-014c-4fc9-8683-0aef4cff9fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a29d3f5-c1b2-4ef3-bade-c1705287d47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53de627-48f4-4981-8261-81c2845dbb9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe8871ad-8e2c-4b82-a291-ac29c7512024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a6bb353-9181-4a80-b65f-f0fc1b30b30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac30e6f0-719a-4e66-a1ec-8f0fe3c2db9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6760336-0a95-4798-9373-21e8c9f4f680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea52e8e8-0cee-4154-9409-c660c3c4c77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f1461ac-9255-4e00-875d-ebb2923e8e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a02f2d44-f171-4e04-91e4-7b6de098fe4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88fe5955-df80-4087-9865-94e21aa81129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a3804e-cf60-42e9-b26f-509e48dfda29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da4597d7-1be6-42e3-91c4-f678713932bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3cca209-a9b6-4e34-a4bf-915ce4fcbd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cc8d0b-1991-4bf7-8608-cf5cb3db9260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0981125e-9134-4b12-91af-6dcd909627c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c27ce0f-7ed8-4c9a-8462-c1602619a705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 358507dd-6fc2-45e8-b248-bb4f7b4545b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abc313e5-c94d-4fec-adde-8b8d80b9d431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 592c2596-0ce8-4032-9634-10696c297f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17d05e8-0017-4f42-a573-2b596c72e6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ace49a-24b9-4776-9b11-b2351ee3b7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb922756-8360-4049-9cd7-c276b3b57768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc56280-0a95-44c8-b3ea-928246c2a435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd283f83-9d7a-46e6-b2cd-fc8365c8d481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d24121-4df3-40b2-ae7b-e8f31960d12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18411ee5-28ce-4486-950f-bf1b26482cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f6a17e-17d3-48de-bf3d-8183a80d423b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e643705c-5aef-4551-92a1-e105f0bb258c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d44dd94-a577-41f3-b5f7-44209bf51c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef1686fd-2e9d-4abf-9cdb-f66bbd927044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14601a57-71d8-407b-876d-c040ff07fe93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5606a1bb-a1fb-4d3c-a6a0-7ec0511033ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f0c954-2c3c-439c-a93a-fc6a57e0e58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e946a036-ed86-4688-96cc-cbe63847079b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5dfe9e1-3563-4aea-9ed3-315f5af297a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60638945-c482-423a-a74e-bcb34c3666ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b395ce7-e5b0-427e-84d6-81f44c09d98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f774fd2e-7e8e-467d-a8f2-19d7d62f512b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4815ac7-62cb-4e88-b8a8-9fed92098d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b52f58d-b846-4920-9c44-fbb0f0605880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f633e094-00fc-4f04-8a78-0d669717d097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86abb135-00c1-4f01-9ca6-62e22024c5be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e615235-005d-403c-931b-c0a0e1845e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f529890-7e7e-4941-9afa-e2a2781f8b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b02cabe3-62f6-48d5-9ace-c61fe03b5180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10a4d802-cb48-456d-bd82-5f48a36a8c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df9cc204-392b-43f8-89d7-caf787f19859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46a84c1-4820-46cc-b090-e4fae204ae8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561e1019-9cf8-4488-80d0-9ba466d55a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 584a529c-10af-40f2-8a7c-1d2f83e8a768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c811de-74b7-4749-9615-b7d0a1447ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4dddee8-22b4-4d1c-8211-8bd6f52bc1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b9b3a5-c8f2-48c0-bb24-14d90b4f7313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9290a86-000f-4ea0-8832-17ecda2208ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c744fd3b-1b19-4ad9-af5e-70ec79a03998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92095400-6272-47c5-87dd-c10f4dbbb283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2565e87f-4064-4d10-87d6-53c5564172c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495cff24-fd36-4eef-b338-5ccc54ac5be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8948329d-32fe-430a-bd7d-7a0ee4e24ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a42cbe-6997-480c-a39f-c6b05e944e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f463bbc-10bf-423f-acfa-074eff8c7662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7cfb7a-24e1-48bb-92bf-5fa7f0e4ebd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d18b3f-12bb-4eee-983c-5ba1ebd7e69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859b1dcd-a138-4571-86f0-f3317cd42fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02b1fe7b-b03d-46d8-8757-c3cf5cb33ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8cc68fb-2d4f-4299-8459-7d621222e579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a6dd7f1-2594-469c-a270-60e47685b87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ede268-36e7-43e3-bd11-ac9e9ed2c4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe22c26-0c3d-4a8d-bed1-c0c88a1d54a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 241d6a79-9757-4216-a1de-5f8bf772b221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da0bee1-d07e-4e3c-b6bb-3c11d01224a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ffce0d-fd5f-4142-97fb-9ac9601d8bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3660425b-a0ec-41b5-8f94-75a3e93619a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a43247-b59e-4c8b-8b28-a69960f6e11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f438661-bae1-4daa-af45-592e328e2aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2bfd69-c565-4b4b-97ad-0fcbb548d186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e350639-91dd-4784-808d-734f350e8038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de62b098-9809-4f3e-8559-1324131e20bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31f80ac3-2256-490f-a3ce-524edfdf9b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3861499-cc24-48c7-a6e2-5b343514e750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64e389a-2455-47f2-9143-59ade5c84553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac04ebcd-3c52-4fd7-8e1e-bd3268b8ce3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8947e3d0-c3b5-4f2c-bd41-6ee1a389b8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7082c856-1cc4-4d44-90d8-bd0b6dcbb873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3fcbdf9-0468-4a94-a4ff-7df546652696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e36fbe7-ce3c-45d8-9a8f-454c46d4092f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b110d59-47be-4ce0-9aea-c1988a4059fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c215bbe-c39f-4c3f-8127-2fdb5bf58364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ea2416-4a69-4001-a4ff-2760b5b8931a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92a2cb1-3a5d-4e6b-8529-363d2538ce76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1cc99e6-8524-4beb-b4c7-4f40a7296ea1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_15
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_labels.txt

📊 Raw data loaded:
   Train: X=(875, 24), y=(875,)
   Test:  X=(219, 24), y=(219,)

⚠️  Limiting training data: 875 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  210 samples, 5 features
✅ Client client_15 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2445, R²: -0.0154

============================================================
🔄 Round 4 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0777 (↓), lr=0.001000
   • Epoch   2/100: train=0.0845, val=0.0775, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0848, val=0.0786, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0841, val=0.0787, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0837, val=0.0789, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0803, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 4 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0061
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0093
============================================================


============================================================
🔄 Round 6 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0992 (↓), lr=0.000250
   • Epoch   2/100: train=0.0794, val=0.0987, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0791, val=0.0987 (↓), lr=0.000250
   • Epoch   4/100: train=0.0789, val=0.0985, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0787, val=0.0984, patience=2/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0779, val=0.0980, patience=2/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0773, val=0.0979, patience=12/15, lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 6 Summary - Client client_15
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0235
   Val:   Loss=0.0981, RMSE=0.3132, R²=0.0077
============================================================


============================================================
🔄 Round 7 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0843 (↓), lr=0.000031
   • Epoch   2/100: train=0.0826, val=0.0848, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0823, val=0.0853, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0822, val=0.0855, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0820, val=0.0858, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 7 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0068
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0122
============================================================


============================================================
🔄 Round 8 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0806 (↓), lr=0.000008
   • Epoch   2/100: train=0.0837, val=0.0807, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0836, val=0.0807, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0836, val=0.0808, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0835, val=0.0808, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0834, val=0.0809, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 8 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0026
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0097
============================================================


============================================================
🔄 Round 10 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0838 (↓), lr=0.000002
   • Epoch   2/100: train=0.0833, val=0.0838, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0833, val=0.0838, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0833, val=0.0838, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0833, val=0.0837, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 10 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0052
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0069
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2412, R²: 0.0025

============================================================
🔄 Round 12 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 12 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0116
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0159
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2413, R²: 0.0019

============================================================
🔄 Round 13 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 13 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0068
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0045
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2414, R²: 0.0017

============================================================
🔄 Round 14 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 14 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0049
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0136
============================================================


============================================================
🔄 Round 15 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 15 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0007
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0114
============================================================


============================================================
🔄 Round 16 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 16 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0087
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0060
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2412, R²: 0.0023

============================================================
🔄 Round 18 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 18 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0077
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0053
============================================================


============================================================
🔄 Round 19 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 19 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0076
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0108
============================================================


============================================================
🔄 Round 21 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 21 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0076
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0027
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 23 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 23 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0082
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0125
============================================================


============================================================
🔄 Round 24 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 24 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0008
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0239
============================================================


============================================================
🔄 Round 25 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 25 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0049
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0087
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 27 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 27 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0064
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0068
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 28 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 28 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0001
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0325
============================================================


============================================================
🔄 Round 29 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 29 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0033
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0147
============================================================


============================================================
🔄 Round 30 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 30 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0088
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0052
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 30 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 30 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 30 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 30 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 36 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 36 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0071
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0043
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 37 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 37 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0055
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0100
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 37 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 37 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 40 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 40 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0047
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0141
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 41 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 41 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0048
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0101
============================================================


============================================================
🔄 Round 42 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 42 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0057
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0006
============================================================


============================================================
🔄 Round 44 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 44 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0026
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0215
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 44 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 44 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 50 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 50 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0076
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0055
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 50 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 50 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 50 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 58 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 58 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0082
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0029
============================================================


============================================================
🔄 Round 59 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 59 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0017
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0264
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 59 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 61 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 61 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0048
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0053
============================================================


============================================================
🔄 Round 62 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 62 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0074
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0041
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 62 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 66 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 66 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0062
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0084
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 67 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 67 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0010
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0070
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 69 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 69 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0018
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0175
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 70 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 70 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0153
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0273
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 71 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 71 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0054
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0105
============================================================


============================================================
🔄 Round 72 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 72 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0092
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0076
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 76 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 76 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0081
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0088
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 77 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 77 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0036
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0098
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 79 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 79 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0026
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0214
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

📊 Round 79 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0015

============================================================
🔄 Round 82 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 82 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0096
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0100
============================================================


============================================================
🔄 Round 83 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 83 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0084
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0046
============================================================


============================================================
🔄 Round 85 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 85 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0064
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0016
============================================================


============================================================
🔄 Round 86 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 86 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0115
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0156
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 90 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 90 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0052
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0063
============================================================


============================================================
🔄 Round 92 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 92 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0048
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0137
============================================================


============================================================
🔄 Round 94 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 94 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0092
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0034
============================================================


============================================================
🔄 Round 98 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 98 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0022
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0255
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0016

============================================================
🔄 Round 100 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 100 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0064
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0076
============================================================


============================================================
🔄 Round 101 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 101 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0078
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0012
============================================================


============================================================
🔄 Round 102 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 102 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0066
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0081
============================================================


============================================================
🔄 Round 103 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 103 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0004
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0273
============================================================


============================================================
🔄 Round 104 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 104 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0057
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0067
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 107 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 107 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0081
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0064
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 110 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 110 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0058
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0054
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 110 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 114 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 114 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0042
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0150
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 114 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 114 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 117 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 117 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0092
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0038
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 118 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 118 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0055
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0106
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 119 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 119 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0046
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0089
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 121 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 121 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0048
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0123
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

📊 Round 121 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 123 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 123 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0129
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0440
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 125 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 125 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0047
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0148
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 127 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 127 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0040
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0171
============================================================


============================================================
🔄 Round 128 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 128 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0087
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0023
============================================================


============================================================
🔄 Round 130 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 130 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0091
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0096
============================================================


============================================================
🔄 Round 131 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 131 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0119
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0189
============================================================


============================================================
🔄 Round 132 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 132 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0117
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0131
============================================================


============================================================
🔄 Round 135 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 135 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0068
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0049
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 136 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 136 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0073
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0034
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 137 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 137 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0103
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0088
============================================================


============================================================
🔄 Round 138 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 138 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0072
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0070
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

📊 Round 138 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

📊 Round 138 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 142 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 142 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0041
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0157
============================================================


============================================================
🔄 Round 143 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 143 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0033
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0198
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

📊 Round 143 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2413, R²: 0.0019

============================================================
🔄 Round 146 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 146 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0046
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0044
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2413, R²: 0.0019

============================================================
🔄 Round 148 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 148 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0082
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0196
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

📊 Round 148 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 152 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 152 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0035
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0151
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 154 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 154 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0062
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0056
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 155 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 155 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0082
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0130
============================================================


============================================================
🔄 Round 157 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 157 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0045
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0134
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

📊 Round 157 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 163 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 163 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0234
============================================================


============================================================
🔄 Round 164 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 164 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0101
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0065
============================================================


============================================================
🔄 Round 165 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 165 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0027
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0252
============================================================


============================================================
🔄 Round 166 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 166 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0062
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0037
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 169 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 169 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0085
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0064
============================================================


============================================================
🔄 Round 171 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 171 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0081
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0006
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 173 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 173 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0081
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0013
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 175 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 175 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0146
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0464
============================================================


============================================================
🔄 Round 176 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 176 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0063
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0078
============================================================


============================================================
🔄 Round 177 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 177 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0077
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0030
============================================================


============================================================
🔄 Round 179 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 179 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0119
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0197
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 181 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 181 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0067
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0032
============================================================


============================================================
🔄 Round 182 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 182 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0020
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0143
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 186 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 186 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0075
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0033
============================================================


============================================================
🔄 Round 187 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 187 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0051
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0024
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0018

============================================================
🔄 Round 188 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 188 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0047
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0027
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2413, R²: 0.0017

============================================================
🔄 Round 190 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 190 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0107
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0262
============================================================


❌ Client client_15 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
