[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853e41ff-f7ed-44de-90f7-cf03936473e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410ff318-9627-4a18-b495-f9d33b82d936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb9e06f-450c-4049-90f8-2f199776015b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88adf887-5ecc-4453-9ad0-ad94944d975b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05007969-ea5a-41ac-be47-9ba1b76941e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05f9eda-0093-4707-b24b-9f688b58d663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2851c112-4083-4eca-ae18-cde02b5466c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c953c74-9a94-49ea-a7e4-1a75cada767e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef1d7cf-5821-444a-9e0c-727a44e4972b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88aa68f6-1aa6-43ca-b134-57f9bdf39452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda27b46-7690-4a3f-8fee-277a37f55e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d535d8a-7aca-4d50-a7d8-2753631b5438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67403709-a60b-4014-8e1b-a5ca4325ad7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f799233-8d3f-4003-9cbf-2aabe5b7b0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b238f160-d653-4086-a51b-69b8ca5f8b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c660d0-0f18-4406-b001-aede5258e7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02464538-8196-4aad-b777-4b67ab226f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76150185-24e2-483b-9dc1-3c72b0fe8506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4673f288-6f39-4f14-86f0-12467908dba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196e6001-37e5-424c-a58c-f87dccb06814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09444f2a-2832-46b0-b0e6-d7cc87716b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a1bc1c-2b3d-44cb-a430-5d3d59a182fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0f4b68-a0eb-43bf-99e3-532ad47457eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a923571-aad2-4dca-84bf-3192a9967040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8d88a5-6a65-4fc2-9f56-2a86d4cfe2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81bfb00-82f7-474c-bcdf-de65face6a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11b3e2c0-495e-43ff-8555-4447057ed84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a1a434-a97b-48ff-a53d-f28e8afd9498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ac05ea-92f2-4577-bc8e-68423a3c46cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87f85720-333d-4207-bd9c-a8dfaf3fac5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918c8c34-ea4d-4a12-9174-452a3947c76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e565aab-4865-408e-8dba-df758ca4a10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5bd415-a582-4f29-8471-37fc8ed2888e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 909833e7-11ec-4e9c-a787-6c3f23d38a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 251f9621-d9b6-4e0f-b3d0-c5eb063c99de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06943e2f-4d2f-48ab-8f4c-020f7084e81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3102749-1718-45dc-9649-84aa8872087b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084bdf65-0fa3-409c-8b26-0206117130fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6fc5da-44c9-4a03-914b-9c9e2c4ee1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f9b97c-2ebf-4866-9b70-71283e6ae40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb466825-7098-4671-8417-eaf44ff3bfdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24633c62-10ce-4ba5-ba8f-36e575223ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 141713c5-0426-4c71-b1c3-74ae72708bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9f77d2-1978-48e1-b1e8-20647917b489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba8180d-7f44-416d-a018-0330bdc869f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa704a59-6afc-4d6c-b02f-9e1c103bcd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ddcb51-23ff-4721-9900-e007753b0a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1960ca7e-e37f-483c-89a0-eb544bc0a406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333a358e-c30e-431c-a8f8-2a8be29b374d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6bbe646-dfd8-4df3-9e6f-b7e6c1e80bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ac821d-bfe9-4cda-ad2e-58374718b172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c245ea55-1408-49e0-baed-1b189adda8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebcf423-104f-4a4f-b51f-fe59ef778d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5f75a7-8e59-4746-9c62-df19c63d7208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ddc4e0-340c-4439-abbd-6451ea7fea82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5c9571-7b67-4b3c-b647-efc37e2a024d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8917a308-a23c-4c2f-9c16-721384f690e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3999df5-59ea-4bcc-aaba-9f17bf94caca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32b105c6-be90-438f-b6be-cba421a1b4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60eb6891-f0d9-492b-a3d6-a11979fc07db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09804e8a-e559-4fce-9174-c37ae3fc283c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0600c808-d628-40ce-b0aa-2b796412493e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e22dbb-a25e-464d-8873-7b3441f8e80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00d7a8f-71ca-4a3e-aac9-74eb45742e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f45a316c-18b7-40d5-854b-b8d485c9c4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03f5136-a498-4098-82d8-768aad92a9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78a7559-5ca4-465b-86be-463127dce7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfae2d6d-3db7-44e2-a5e3-626b0ac6c4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8719b937-a1cf-4638-887a-c295209499d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e116b115-0940-4753-98a0-52af26aa11e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315859f6-91a3-4f62-acd1-37fa0faa2920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d372a1-4a33-4697-b6ba-f896125bd973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b9a102-e0c7-4a6a-9109-ae9a2965d5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 983d9a32-16b2-460d-85a2-de4aae327fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7d5e98-4f9d-4635-b442-31eabab661e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8380aa73-e002-416c-a582-dc75eb715a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd6829b-6710-4bb7-a4de-54cbd94c74df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa9dae6-9a53-4a3a-8dd7-e4c32b38e243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36338de6-e3ed-4982-acdc-b525d0e33491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 617218ab-625a-43cd-9156-9258d1003f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39af0359-9e1c-4516-a9d7-d47c8bb72fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7fe453f-c339-4c4b-a2b9-64bc74d3be61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ea89cd-f25c-4855-b2af-5bff665b3bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d62cf82f-fd0e-4b11-85bc-947685b04900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e815648f-6f2a-4787-9dba-8eabe6ee459c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62af73c7-6799-4c13-89f7-a4bf379592b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257fc4f8-66c2-4c8f-9efa-ba86d4971919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1c69b2-e38d-4b86-96d8-c6ac1f79d958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7d8ef2-0010-4a77-b8c6-c6ee26539f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f390c5-3079-467b-b8e6-b033c90c08aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f46004-2686-4716-b2ca-73fa71f87726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbcd3df-71bd-4d62-aba7-de824a8a6476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bab150c7-5538-49b3-b15d-ebc653a860ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da4b4f2-1348-429e-af0d-74abc3f87f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5179cb2d-6a0b-4d5b-a7cd-2429e4abff2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 634450e4-5c3a-49eb-b225-3002fbb0e7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b8eee16-42b8-4087-9843-9d57e982a089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9116621d-f47f-4db2-b7c4-2d0de6948d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd24693-d6ab-41ec-9e08-8095955e2dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5697b231-20c7-45e5-a105-0caa713c1b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a4de64-0bc0-4961-9e5c-8c253bffbf24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117cbcd3-2cb3-4832-b14a-769861273cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92515a82-9ddd-4826-a87b-201e2b10b803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfbb6073-9833-40b0-87a4-29e8bcb1092a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8abd216e-95db-41ff-a83a-073331a54511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33236c75-98c3-4b2e-8caf-78a73154a4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6733d733-9b3f-45a1-94e1-dead0c0b4e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91548fd5-6a0a-491e-a711-dc3ae3c6f071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1879ff4-f311-4670-8a83-a2be4e87778b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9ce6b2-f486-452a-acba-1676bfa8e7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69de91f-3906-49f3-aafe-8c412907301b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03dd8480-ebc5-4687-a302-856d9d290d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c82d95f-7be2-4926-99be-44a427bd1cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f8a311-e115-4e44-93b4-e0fe86fedf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15bcd2ac-eb77-4f91-a82d-4f4483950346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e134b98-767a-4422-a2c7-7e7dba44a645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb3d84b-6356-4a37-998b-9bc4dfec455c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 222294d8-14c7-4414-bb95-8bf069df6331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49804f60-31cf-45ca-a657-693722ebe1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2ca788-6a11-4440-aca0-46eb9a2a1d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da510f63-8e96-4a6a-82a7-709466793c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f2276c1-17a8-4c1f-a3dd-89d18e275c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fdb2706-2e95-4344-9141-e4e140002f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0a14a67-037b-4f19-b2a3-6a245cbe318f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80d2793-3610-40b4-ab70-dbbf1c396c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50b3decc-f93c-4f83-bf05-c5e8b923dd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8857495e-5221-434a-bb88-2400899c9b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93310c61-5f91-4144-820b-fd67fdf3630c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdaaa538-c112-41b8-bf87-c70edd4467b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce9d1e0c-2998-4e38-89bb-a18647653f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22846299-9af1-4ec0-9f37-79344057d7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80634138-977d-49c1-b245-c9514f93294c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5402c019-25c6-4d5f-9187-e7726c09b1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0c09e3-1941-4edd-bdfa-d86760769940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e4e4f36-1a9a-45d6-bf6f-6d8da8621a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1486ac5c-1541-4664-97aa-a9c7f6463296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa3ca720-057e-4ccf-a8ec-75931aa49956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 157820cf-681d-42e2-831c-f4999fca01e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a922e221-115c-4e2b-b92a-7e3f558be8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087aa33b-be62-4a96-a5d9-559f5c8fe916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f157d5e0-e52d-4f8f-986c-3e7fd95c809f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17dd6aba-43c6-4c22-9064-647c454873c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc94d9fe-605b-40eb-b8a3-284836d21620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19b635e-6331-43c3-9a9c-5cc5845d5f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd191bb-cd4b-4787-9c43-9f00e3541543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e97eb4cb-af29-4f7f-870c-8541e4dc22b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 275601df-5a74-4c7f-9348-3451258060ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e36926e4-4a6f-42a6-89b2-699416286006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c161c4b2-bfd4-4fdb-9d1f-759086cefc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21ce69e-ed27-416d-93a1-3b357af480e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 335798a8-845b-4bd0-90f9-228cbf0a68a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8eedfa4-8e19-4d5a-a4b6-7ce042ecf5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f91ae9-3772-423f-99d8-3379d0aaf7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a35370ce-3015-472e-b3e8-8a17979e64c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0af367-8579-4496-90db-eead72cf0f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b78ff1-5951-422b-9766-5faabbd4e06d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2452, R²: 0.0129

📊 Round 0 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2450, R²: 0.0155

📊 Round 0 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2440, R²: 0.0222

📊 Round 0 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2416, R²: 0.0399

============================================================
🔄 Round 9 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0836 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0810, val=0.0823 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0796, val=0.0816 (↓), lr=0.001000
   • Epoch   4/100: train=0.0789, val=0.0816, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0790, val=0.0812, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0757, val=0.0805, patience=5/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0667, val=0.0814, patience=9/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 9 Summary - Client client_16
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1015
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0507
============================================================


============================================================
🔄 Round 10 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0809 (↓), lr=0.000250
   • Epoch   2/100: train=0.0788, val=0.0805, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0784, val=0.0806, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0782, val=0.0804, patience=3/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0780, val=0.0804 (↓), lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0768, val=0.0800, patience=6/15, lr=0.000125
   • Epoch  21/100: train=0.0757, val=0.0792, patience=1/15, lr=0.000125
   • Epoch  31/100: train=0.0746, val=0.0783, patience=5/15, lr=0.000125
   • Epoch  41/100: train=0.0736, val=0.0775, patience=2/15, lr=0.000125
   • Epoch  51/100: train=0.0727, val=0.0770, patience=2/15, lr=0.000125
   • Epoch  61/100: train=0.0719, val=0.0767, patience=12/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 10 Summary - Client client_16
   Epochs: 64/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1109
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0811
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0773, RMSE: 0.2779, MAE: 0.2407, R²: 0.0469

============================================================
🔄 Round 14 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0849 (↓), lr=0.000125
   • Epoch   2/100: train=0.0771, val=0.0849, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0770, val=0.0848, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0768, val=0.0848, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0767, val=0.0847, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0762, val=0.0846, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 14 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0441
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0295
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2404, R²: 0.0504

============================================================
🔄 Round 16 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0772 (↓), lr=0.000031
   • Epoch   2/100: train=0.0786, val=0.0782, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0783, val=0.0789, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0782, val=0.0793, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0782, val=0.0795, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0781, val=0.0796, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 16 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0394
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0002
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0512

📊 Round 16 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0512

📊 Round 16 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 19 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0839 (↓), lr=0.000008
   • Epoch   2/100: train=0.0777, val=0.0839, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0777, val=0.0838, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0776, val=0.0837, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0776, val=0.0836, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0775, val=0.0835, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0775, val=0.0834, patience=9/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 19 Summary - Client client_16
   Epochs: 27/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0385
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0486
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

📊 Round 19 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0401
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0080
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 22 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 24 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 24 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0331
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0431
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 25 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 25 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0323
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0435
============================================================


============================================================
🔄 Round 26 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 26 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0364
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0389
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 26 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0513

📊 Round 26 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0513

============================================================
🔄 Round 39 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 39 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0331
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0467
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 39 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0513

📊 Round 39 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 39 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 44 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 44 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0388
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0251
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 45 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 45 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0368
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0359
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 46 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 46 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0301
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0591
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 49 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 49 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0344
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0447
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 50 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 50 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0385
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0306
============================================================


============================================================
🔄 Round 51 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 51 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0350
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0440
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 51 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0349
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0464
============================================================


============================================================
🔄 Round 61 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 61 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0390
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0286
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 61 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 61 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 67 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 67 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0389
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0281
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 68 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 68 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0334
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0465
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 70 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 70 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0371
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0369
============================================================


============================================================
🔄 Round 71 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 71 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0366
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0355
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

============================================================
🔄 Round 72 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 72 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0409
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.0198
============================================================


============================================================
🔄 Round 73 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 73 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0367
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0334
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0514

📊 Round 73 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

============================================================
🔄 Round 75 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 75 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0349
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0437
============================================================


============================================================
🔄 Round 78 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 78 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0325
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0562
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

============================================================
🔄 Round 79 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 79 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0416
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0197
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

============================================================
🔄 Round 80 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 80 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0333
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0512
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

📊 Round 80 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

============================================================
🔄 Round 83 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 83 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0346
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0484
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

📊 Round 83 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0515

============================================================
🔄 Round 89 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 89 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0378
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0331
============================================================


============================================================
🔄 Round 92 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 92 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0394
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0252
============================================================


============================================================
🔄 Round 94 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 94 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0390
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0301
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0516

============================================================
🔄 Round 97 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 97 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0354
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0407
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0516

📊 Round 97 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0516

============================================================
🔄 Round 99 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 99 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0387
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0314
============================================================


============================================================
🔄 Round 101 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 101 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0379
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0350
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0516

============================================================
🔄 Round 102 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 102 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0411
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0184
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0516

============================================================
🔄 Round 103 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 103 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0400
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0241
============================================================


============================================================
🔄 Round 104 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 104 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0404
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0253
============================================================


============================================================
🔄 Round 107 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 107 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0326
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0348
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0516

============================================================
🔄 Round 109 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 109 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0391
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0302
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0516

📊 Round 109 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0517

📊 Round 109 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0517

============================================================
🔄 Round 112 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 112 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0337
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0510
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0517

📊 Round 112 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0517

📊 Round 112 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0517

📊 Round 112 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2403, R²: 0.0517

============================================================
🔄 Round 119 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 119 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0402
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0214
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 122 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 122 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0346
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0038
============================================================


============================================================
🔄 Round 123 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 123 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0333
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0137
============================================================


============================================================
🔄 Round 124 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 124 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0374
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0298
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

📊 Round 124 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

📊 Round 124 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

============================================================
🔄 Round 129 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 129 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0311
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0654
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

============================================================
🔄 Round 131 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 131 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0378
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0341
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

📊 Round 131 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

============================================================
🔄 Round 133 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 133 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0395
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0067
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

📊 Round 133 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 135 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 135 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0381
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0300
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 138 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 138 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0344
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0483
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 141 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 141 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0351
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0461
============================================================


============================================================
🔄 Round 143 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 143 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0386
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0286
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2402, R²: 0.0517

📊 Round 143 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2402, R²: 0.0516

============================================================
🔄 Round 147 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 147 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0353
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0389
============================================================


============================================================
🔄 Round 148 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 148 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0409
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0189
============================================================


============================================================
🔄 Round 149 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 149 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0352
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0442
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 151 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 151 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0366
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0403
============================================================


============================================================
🔄 Round 155 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 155 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0366
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0400
============================================================


============================================================
🔄 Round 156 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 156 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0375
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0365
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 157 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 157 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0438
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0024
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 158 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 158 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0319
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0553
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

📊 Round 158 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 161 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 161 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0360
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0408
============================================================


============================================================
🔄 Round 162 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 162 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0393
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0275
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

📊 Round 162 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

📊 Round 162 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 167 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 167 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0360
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0434
============================================================


============================================================
🔄 Round 168 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 168 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0332
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0499
============================================================


============================================================
🔄 Round 169 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 169 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0381
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0327
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 170 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 170 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0423
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0184
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

📊 Round 170 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

📊 Round 170 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

============================================================
🔄 Round 174 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 174 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0417
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0192
============================================================


============================================================
🔄 Round 178 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 178 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0336
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0533
============================================================


============================================================
🔄 Round 180 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 180 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0335
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0529
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 181 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 181 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0364
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0409
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

📊 Round 181 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0517

============================================================
🔄 Round 184 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 184 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0372
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0381
============================================================


============================================================
🔄 Round 186 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 186 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0369
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0397
============================================================


============================================================
🔄 Round 189 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 189 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0412
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0236
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2402, R²: 0.0518

❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
