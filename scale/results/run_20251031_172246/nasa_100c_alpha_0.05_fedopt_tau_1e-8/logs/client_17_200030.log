[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c253fbf-7444-492d-a51b-70e4e8d36656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb3a23af-59dd-4ea0-8cad-441a95fb5386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d5a646-a02b-4a8b-9ec3-d3c69fd530a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da43102-5864-49e6-bd03-7f79a28b6be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1448095-0379-4b09-9a68-530805e45e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32f9ef1-6fb2-4b53-b87b-23c1ebec42cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ebd6d6-6cdf-4010-a1fa-1fb6edbfea7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 399325ed-a883-46ee-98e9-a0a8f18e3336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a79338db-8625-4889-9743-a16ac91941b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8a6f29-6807-49e5-a642-0fd86f833702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 621552a4-cdaf-4a1d-8a93-b4f0c56f97cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5244361-5949-4b2f-b59f-f32be9c9902e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f3c377-cb82-467f-b5b0-fc66b374857a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f20d5da3-c1c2-4dc8-96df-c87ec63067d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1316f0-75ca-405a-9224-5a18e0511894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8585cfd-513a-4e6d-b25f-5b0fc23f27f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c1c254-93d7-4330-8ece-69ecf7bc735d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7625beaf-d7f4-469f-b517-f67281db5582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6473b09a-3f58-4daf-8416-2c33af1da56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3f8dd8-d20d-4649-a95a-d0a168453c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1320e4b2-12f7-4ab1-9da1-3638f62b25a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 799d7d85-b9be-46f5-a921-34b99d55e85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012f390f-2198-417a-b156-7d259fa32a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71da269e-16f1-4838-b946-ea03ddf6fa6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d8a5b1-5710-4786-9eb4-170dd1f644fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62204e23-f5fa-42da-a102-60b429e43a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f1a65f-51ca-4231-8444-be092ad1bf9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979db74f-4276-4361-83ab-dd4834e736c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0228131e-85ea-4925-b2af-adc473b1d3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4893c1c5-e9c3-4466-a204-f0fcfe660c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a720d0e2-2a7e-428f-9eb8-fe371be6b397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b3dc22-28e5-4557-b6f8-d63191adb6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a761046-ea01-4c5b-8136-3ea9e822906d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0df82a43-f42a-4fe3-b817-2830139d271a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb432fcf-4919-46b5-8f2e-315114b8ff2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c0ef47-94af-46a0-a3a6-b2d938735d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4076a807-6eb1-437b-a5cd-9c787ff9b980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b815f0e0-c6ad-400c-b6f7-415a8aada544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c9c211-29de-46b0-b541-647c31586155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56860412-097b-47f0-b372-ff781f02a65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e813e0-bdd9-422b-bab9-6c603ac75a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4319db1-6d14-4204-b61a-6734a33480cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 171b381e-eab6-43ac-924d-f9dd29fbe24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048c0144-317b-46ad-adb3-8ecd2e4b565e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c8ff03-8f77-4f44-9df9-6760b4d7087c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c20abf-18af-4cfb-9bd5-231666ee114e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c3a3771-42f1-4886-a301-0eec53f9777f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025ce536-d42d-4a51-adf4-74f37f0b45d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d0462f-c7ca-4b57-a2b7-06ee3cdba23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0891851a-8772-4c25-9858-17acad036c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859da24d-eafa-4252-af95-71d9ee9f1e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6272bc-ed65-4ce9-a429-0ae46e525eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f59bf0-7524-433b-8c25-e2f1eee5f0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5cfe49a-8495-4e42-af5b-a67ad9085363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde6e1de-ab22-4561-8aea-748a67b2699b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f1fbd3-8904-4445-a511-095e8728a877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f19e5a-5686-470a-ad78-33e74f7fac39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 638c6d70-c88a-4f17-964d-e6893ebae181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b18e28-1382-44df-b47d-d3d337788d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d660ca2-28fe-4c36-8879-2af032a05d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6062b63-7eba-41e6-a47a-43b2ad7ce52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c489223-09d0-4129-a124-6fabcb4fc971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 427fcae8-f72c-4145-b324-5ab2bd9596e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 180fd888-a3c4-4649-80bf-9fe89c913790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fca83c1-7828-4f7d-989d-311fe2229c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9c1b22-530a-454f-ab79-4a302044fcbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c1537f-e889-422b-8b37-46836a49a258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec5bb3a-e9d0-4593-a60a-83fd3edcb850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85353729-94c4-4f77-b2e6-29aa802b7f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c059cb-3ca5-489a-9a0b-4b9650e160d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a090324-fc40-433b-b87c-56faa20f667f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e270a1bc-13a0-44f9-b3e9-379c00295e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49f2436a-f5f2-4de9-8659-a9b445af0178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfac619f-7254-4680-a325-bbbb4bbb4757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e88b1d32-edec-4dde-9e66-626c889bd7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad650cd-8055-41f8-8629-695cbe0b6309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef33bd8-34c7-4e07-b2f5-491c8c81b89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6a6603-df74-488c-a4d5-00447af3e52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fca721de-7205-4129-bb0c-9b880e9ef65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46da8a9-c3ec-4ccd-84be-637a7c8a134c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee806c58-9afe-459e-b47c-9f70c6f3ceb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b149adf-f146-44db-bed3-3d0ae4eaa0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a7fc68-675c-4370-84d5-9d53b40f8bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be4df30-6f08-42f2-b7dc-011f283b3977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5d2d7f-d518-4d33-9671-77c97e43b3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 692c273b-d8e2-4e71-8374-b5aeb6771429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1235c534-755c-4008-b68a-b8de1cdcec62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18fdddf5-4440-4aae-bcc8-bd8976950351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b69bd0f-a7e8-4a60-b0a7-141dc8c0f00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73610cee-eafe-4e1a-affe-7a27463c58d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3508ab3-a593-4fc0-af32-76d9d0c45fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6499a0-8f6b-4ab7-98cc-5aa8b624c885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7797197e-d5ec-45f4-b31e-1edd6ce4b22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f4a249-521d-47f8-96fa-7965a3498f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1f0f27-669f-40bf-8f95-be6b5a24cc18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cdc8e02-67f5-4b48-ad7e-68aad5004329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2055b9-ef02-4f84-b9c2-93120c3cde9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffe92420-936d-4270-864d-d7d3b0f585f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f5a5436-30be-4713-9ee5-16545a8e2f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9ff2da-7268-4c4b-a6b2-605f9539a318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557dbe10-9885-4807-9a79-ebb7eb045217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aedc531d-8184-46da-bc64-2ebfcf36da96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33a5eec-0a88-451c-9667-748b98ff70da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fdc2c59-7bc4-4710-b558-fc40ad060dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932bc369-fe75-4597-8539-75d94263d2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55340504-c326-4830-a0a0-5735cb03280e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e3047c-abdc-461d-9274-c16b66c757ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1801e21f-c5a9-4f1e-9159-f33735998c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb91b269-8a6f-46c9-8dca-1e3bd143693b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ca5df8-4d30-4ce4-9f7c-0ad1a0c27344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 956d1b8c-55fe-4a0b-a1e7-5c9a7a513d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 485ccc79-5a18-4c07-b48a-55530820a2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7711f816-2cd6-4791-8b70-1996f911a6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d2b0fb-dd64-4baa-9571-19f2ab54f457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1373f69-b31b-4096-b280-98c8d43361f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9306ffcb-09e4-461b-8cba-4bb243b57896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4daf7d49-64e1-49a5-9840-6dfd4ecdbe48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a684a6-322a-4a34-a8ba-3e49fb1ff2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11371195-60b4-4294-aba9-8bb848a86567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df39a973-eaee-4cea-a875-54082f78532c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e3ea15-abe7-412a-b349-615c1a200217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecdb0e9d-c802-4f4f-8b5f-ee12db9868d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6c1f1d-6239-483a-8be6-1a5bdda121cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 832b13d2-c49d-4c3d-902a-3e786300c161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c0d6974-ff3a-4f26-85e6-5e400302f896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451672a9-7f0c-4c26-92dd-84677eb57074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c7e3c27-a6eb-4672-a1fb-aff93b3f038d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af012f88-a147-4fb2-a3b4-6daa04818a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15adc747-63a0-4490-b484-2409b7600004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b72c598f-2b58-4254-81a8-4e4e8f64fec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9bc911-d9c0-44a0-ad10-57265f75fb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e77fbe-90b0-4ea0-8d8b-ba0d02550d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88e598fc-5b32-421a-8d6b-cc7914d487c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4d7673-f443-423c-8936-e5323ea940b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb66d4ce-1c5b-4fe9-9794-7eda2da98c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed60f949-141a-41ca-8186-cd97ca28e946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5860c8b4-72a2-43a8-92a5-7160d68542d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f9ebfd-86fe-4e0f-b519-9ae649c80597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 734ad883-bca1-4859-a21b-d560103adec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348470fc-1a04-412b-b555-dbab4dedff2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e27a52a-a96a-4629-a461-a26d89aeda1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81172029-bf93-4edc-a1e4-9fceac32d868
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_17
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_17/test_labels.txt

📊 Raw data loaded:
   Train: X=(1182, 24), y=(1182,)
   Test:  X=(296, 24), y=(296,)

⚠️  Limiting training data: 1182 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  287 samples, 5 features
✅ Client client_17 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2538, R²: 0.0004

📊 Round 0 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2534, R²: 0.0035

📊 Round 0 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2520, R²: 0.0125

📊 Round 0 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2515, R²: 0.0160

📊 Round 0 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2513, R²: 0.0176

============================================================
🔄 Round 9 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0869 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0787, val=0.0863 (↓), lr=0.001000
   • Epoch   3/100: train=0.0782, val=0.0866, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0778, val=0.0870, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0774, val=0.0877, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0745, val=0.0899, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 9 Summary - Client client_17
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0380
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0292
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2509, R²: 0.0208

============================================================
🔄 Round 11 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000250
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0802, val=0.0802, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0800, val=0.0802, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0799, val=0.0801, patience=4/15, lr=0.000250
   ✓ Epoch  11/100: train=0.0793, val=0.0799 (↓), lr=0.000250
   • Epoch  21/100: train=0.0784, val=0.0799, patience=10/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 11 Summary - Client client_17
   Epochs: 26/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0366
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0074
============================================================


============================================================
🔄 Round 12 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0839 (↓), lr=0.000125
   • Epoch   2/100: train=0.0792, val=0.0840, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0791, val=0.0842, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0789, val=0.0843, patience=3/15, lr=0.000125
   📉 Epoch 5: LR reduced 0.000125 → 0.000063
   • Epoch   5/100: train=0.0788, val=0.0844, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0785, val=0.0847, patience=10/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 12 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0162
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0309
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 17 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0736 (↓), lr=0.000031
   • Epoch   2/100: train=0.0817, val=0.0740, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0816, val=0.0743, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0816, val=0.0745, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0815, val=0.0745, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0813, val=0.0745, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 17 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0204
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0178
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

📊 Round 17 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 20 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0819 (↓), lr=0.000008
   • Epoch   2/100: train=0.0798, val=0.0819, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0798, val=0.0819, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0798, val=0.0820, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0798, val=0.0820, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0797, val=0.0820, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 20 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0190
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0178
============================================================


============================================================
🔄 Round 21 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0757 (↓), lr=0.000002
   • Epoch   2/100: train=0.0815, val=0.0757, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0815, val=0.0757, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0815, val=0.0757, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0815, val=0.0757, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0815, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 21 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0145
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0296
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0213

============================================================
🔄 Round 22 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 22 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0134
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0396
============================================================


============================================================
🔄 Round 27 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 27 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0196
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0026
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

📊 Round 27 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0213

============================================================
🔄 Round 32 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 32 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0222
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0021
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 37 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 37 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0194
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0128
============================================================


============================================================
🔄 Round 40 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 40 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0142
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0328
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 41 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 41 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0168
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0265
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 43 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 43 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0143
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0377
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 44 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 44 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0144
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0343
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0213

📊 Round 44 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0213

📊 Round 44 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0213

============================================================
🔄 Round 48 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 48 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0163
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0051
============================================================


============================================================
🔄 Round 49 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 49 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0185
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0142
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 50 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 50 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0229
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0021
============================================================


============================================================
🔄 Round 51 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 51 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0215
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0057
============================================================


============================================================
🔄 Round 52 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 52 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0196
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0151
============================================================


============================================================
🔄 Round 53 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 53 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0207
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0097
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 55 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 55 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0157
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0290
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0213

============================================================
🔄 Round 57 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 57 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0214
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0077
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 58 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 58 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0199
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0140
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

📊 Round 58 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

📊 Round 58 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

📊 Round 58 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 66 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 66 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0167
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0102
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 69 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 69 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0184
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0234
============================================================


============================================================
🔄 Round 72 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 72 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0232
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0026
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 74 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 74 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0129
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0310
============================================================


============================================================
🔄 Round 75 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 75 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0216
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0050
============================================================


============================================================
🔄 Round 76 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 76 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0200
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0144
============================================================


============================================================
🔄 Round 77 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 77 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0222
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0082
============================================================


============================================================
🔄 Round 78 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 78 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0194
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0156
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

📊 Round 78 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

📊 Round 78 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 83 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 83 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0223
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0033
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 85 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 85 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0191
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0003
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 89 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 89 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0145
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0384
============================================================


============================================================
🔄 Round 90 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 90 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0208
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0013
============================================================


============================================================
🔄 Round 91 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 91 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0140
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0086
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 92 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 92 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0162
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0287
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0214

============================================================
🔄 Round 95 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 95 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0140
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0401
============================================================


============================================================
🔄 Round 98 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 98 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0143
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0378
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 101 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 101 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0165
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0284
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

📊 Round 101 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 105 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 105 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0194
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0065
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

📊 Round 105 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 110 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 110 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0179
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0187
============================================================


============================================================
🔄 Round 111 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 111 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0158
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0305
============================================================


============================================================
🔄 Round 112 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 112 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0211
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0115
============================================================


============================================================
🔄 Round 113 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 113 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0165
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0286
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

📊 Round 113 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 117 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 117 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0178
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0139
============================================================


============================================================
🔄 Round 119 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 119 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0181
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0205
============================================================


============================================================
🔄 Round 121 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 121 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0181
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0219
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 123 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 123 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0224
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0100
============================================================


============================================================
🔄 Round 124 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 124 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0208
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0129
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 126 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 126 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0184
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0223
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0215

============================================================
🔄 Round 130 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 130 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0204
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0155
============================================================


============================================================
🔄 Round 131 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 131 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0226
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0034
============================================================


============================================================
🔄 Round 133 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 133 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0161
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0062
============================================================


============================================================
🔄 Round 134 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 134 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0175
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0258
============================================================


============================================================
🔄 Round 135 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 135 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0186
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0110
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 135 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 135 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 135 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 144 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 144 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0186
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0180
============================================================


============================================================
🔄 Round 145 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 145 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0216
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0053
============================================================


============================================================
🔄 Round 147 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 147 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0156
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0322
============================================================


============================================================
🔄 Round 148 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 148 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0153
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0334
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 150 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 150 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0181
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0033
============================================================


============================================================
🔄 Round 151 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 151 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0255
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0160
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 152 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 152 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0177
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0239
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 156 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 156 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0211
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0093
============================================================


============================================================
🔄 Round 158 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 158 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0195
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0186
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 158 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 160 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 160 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0139
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0416
============================================================


============================================================
🔄 Round 164 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 164 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0183
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0223
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 168 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 168 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0225
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0069
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 169 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 169 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0179
   Val:   Loss=0.0700, RMSE=0.2647, R²=0.0259
============================================================


============================================================
🔄 Round 170 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 170 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0168
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0264
============================================================


============================================================
🔄 Round 171 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 171 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0208
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0124
============================================================


============================================================
🔄 Round 173 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 173 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0193
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0195
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 173 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 173 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 179 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 179 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0170
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0147
============================================================


============================================================
🔄 Round 180 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 180 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0176
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0196
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

📊 Round 180 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 184 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 184 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0217
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0168
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

============================================================
🔄 Round 185 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 185 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0176
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0256
============================================================


============================================================
🔄 Round 188 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 188 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0240
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0001
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2509, R²: 0.0216

❌ Client client_17 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
