[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 677228c2-b415-4ef9-a01a-7cf8bb51e6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f931c6c-f4e8-45b3-abe6-e8fab4b4273e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b07b037-88ac-43de-94c5-221270ed83d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c61b3fd4-8eac-4f36-982a-889aef8af11d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98360675-b6c9-41a9-bda0-19b38b35d5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaef1d31-22c0-455c-9823-08a7de382af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ccf2071-a182-48fe-814c-8402e619a089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9a5e3f-e658-476a-8886-7f860b032dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c5bca5-6211-45cc-af38-e1e2a6e782bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90005fda-10e4-43cc-9d2b-086f53c2bb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2df1cd-1889-47cf-8926-4dc7227d2249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cafb068-e052-4ed6-93a2-df65f6f16dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6791ba-bff3-42d5-9d91-fe9d6ebffc99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2949b56f-19b8-4ad6-890b-735fcaf9842e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4df232-65a1-4e84-8235-42397e0317d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eadcf97-f2f7-4c81-b489-5aad168fa9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29c89ec-28f4-4ca9-8657-1ffa8e24ba9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91eee4d3-7b9c-432a-b155-28568efa8cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2447d136-d765-4463-94f8-2a136d2f0757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0510f929-54ee-4093-8e48-d18a7dc36114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2ab18ba-e6c1-4523-b024-ab6c424ff618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c865d41-ea1a-46f0-817f-5700649105b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5910fb-8498-44de-8b98-1fec1945050b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b7a5485-1b21-4e23-9bc1-fe7575397833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dbe3870-8ecd-4e0d-820a-fff6dc47ebc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4748cb36-2dfe-4adc-b42d-833af50f18e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbc57429-3c8f-45c0-9f01-7459ebdc968b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c97a5f-f8a7-46c6-ace3-38b7b9d6da5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb6a40a-4bb0-449e-a0cb-5e69547b41e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da6043c-5f1a-4de6-a74d-d197dfd1b43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7ca61f-1895-4847-9f23-244f0b78dbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b39d39e-9276-4336-b7b2-ff6410283719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6392a5e0-3f8c-4376-a502-10d04e523d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe556caa-8bf2-4690-b29f-d58f682ff0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90fd8ddf-7454-426f-9d29-8fecfb6a54a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 034de989-a1f9-4786-95fd-788d24bc42b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d05ba9-5be3-4e06-8c70-2f23e1030cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ae53cc-5797-4d6f-9562-771c1062a742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb393430-cc58-4b0a-aff9-83bd36b1e602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ff2a645-9b0b-4651-ab3b-13164140014b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f7c291-7696-48c6-a6c1-83761b4f007d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b620e1f2-6cca-49fa-8695-2b2f65c750af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3dbbf2-7608-4c75-9a2f-f2ddd01d7ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5bea276-b76f-4889-927e-679b089dfc7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51b8a5c9-3715-4fa8-9e2e-5a260fddfb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74af9a54-6e5a-4bf9-b487-68c33bb0eeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201b7c18-960c-4ffb-8e4c-97d32624367a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad10a1d-b25a-4a84-be29-c7e6e4458d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdc817b-bc34-4519-81a7-f81c2619856a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ab03572-d1e3-4f45-af3e-45a60b4150c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 726b7a0b-aeb9-41ad-8d5b-9e253b61b0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 027793cb-ceeb-4f6e-9415-8e8e90723b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9911eddd-b65e-47d1-af69-b72e863ffaa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45705ab-8a46-4956-b312-f044bf0a8d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b32868-c5f3-4185-bb5b-0709bd90315e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6c154c-44ea-4cbb-95a9-4aa9fbe5d9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2d2bb3-9688-4507-9810-53563e58e748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e17c213-9bbd-414e-a91d-d241e4e66cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8ee607-f60b-4a64-ac7a-08ba2e0dc14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63a588b-b6db-4b8d-a5ed-ab98e363d75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87cef40-3648-4931-ae44-bf34c53dc697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06a5cf8-ec50-4cf5-abf4-4c58373e63ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45d18a7-87de-4869-b327-1667ee98e55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2f60c1-e9a0-4469-adc9-40374bff74ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80273c67-1123-4811-b2ac-882a27949594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c10f7ad-3f32-43b2-8c60-bad08edb6602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71467381-c1a1-4bfb-b39d-32266ac85389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb1df19b-053c-4c57-bac3-23a6aa1650d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faad1e5b-1135-437c-93d9-e2498ab957a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f74cc2-bf7a-41b8-825c-8c8558f0b9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca7db5e-d7a7-48cf-b774-dd49bc013058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97778aaf-4070-4530-a0f2-c44d1a5cfd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b5315e-e90f-4083-b9fe-1f9b688a8849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f3f062a-0ef0-447a-b5b1-809ce6626b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a637eb-af3c-430b-9787-07e7eb596879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64f1b513-86db-4710-bde8-8009b7084e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1dc03dc-df21-4baa-bfa2-17510325a14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fba89c-faed-47f9-ba63-85079bfbeaa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fdc8cc4-a79f-40aa-8a8f-83bff33f2a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf0b42de-b546-4576-baf2-354aebba74e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d875c815-1a12-45c8-b669-50ef86cf41a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f07b3fd8-ae60-4b67-9bd3-528e1e4ab176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b472c61-b321-439d-b620-40facfab1130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6fc638-efeb-401c-aa92-aa99d6cae5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d75cfd-0ec9-4f0c-834a-7ef052a25ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d604d7-4c12-4e3f-8317-772992336d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f725018c-2b11-48d8-ac62-1d8f44d105a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc82de9c-e863-4d17-9c96-048d1cd99ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0458ac-4414-4162-84a1-ae5ca97dec97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 657a30de-2ec6-4ba0-8279-64554455d98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170e17db-d4aa-4ac6-8b8f-2c9413bd9a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51875495-873c-4832-8f0c-e01a6f961c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ec4a2d-e5df-4e67-91e4-49e855d46486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a0472c-f3c1-461f-9a94-fcb666f3629b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b96194b-026e-4ec7-b72b-cef6d7a4e576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d6f54d-622e-4291-91fc-976cc9c74a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ef15f8-3077-4f83-9098-20cdc94f5605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f28d19e-61b8-4636-9ab8-0756b077e581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ec247f-2b6d-428a-832f-19ecf07d0a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9b1696-7c5f-4b93-af04-b90def0232ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf3f2f9-5f76-4d32-872c-ccfd276a0951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b31f4e-c4a4-4e32-adae-2ef5d27a82a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dafd1005-16fc-4627-8b3b-60f2999e4682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 380cbd5b-0996-40ce-ab53-f6d0dc55b09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f5b949-fc24-4f68-af3d-48dff2f0053d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0f66e7-7d18-4bc0-8f48-70ef8d89e286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33276a2-6f50-424a-b170-6a60d9f1f95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 659e29d5-e75b-4c6a-868b-d7a6db9f4bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3786ea1-ba23-46b5-b2c9-864f27ef201a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d531c8-1a29-487c-8a08-ef0dc9961827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 327e7f4e-2eae-4498-b906-5be8d08bbffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6210cddb-18dd-4d63-b268-bc26d4199869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69301f29-dbf9-484f-85e1-aca82c841eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8538ecf7-84ff-4002-8ef2-a15d4fd2b6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27afe563-1c35-4a0a-9c4b-eb5c9dbba972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f22b08b-5876-4244-9ad9-12f5f612a8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a187654-fbf2-4135-8b7a-3aecb0575348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b31568-98bd-41ce-bcd1-462108cd491f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3527775-bbf4-44e9-8405-e942421b1453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8149aa9-723f-4edc-98ec-820bf01e2fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9bc61f-51ee-4f37-9e21-7398b22d67b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a821ec8-d644-478e-acea-5a1a6aae9c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e4072b-1784-4241-8435-9cc4584d4ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b1ca3fb-ea95-42ef-91c6-738e54731495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70eafc92-1db3-4496-98e1-e1f8bf8a7737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc0f7716-8d50-4594-81b3-62fdded96d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7189585f-7aa8-45e2-a347-7673a9190dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0189f180-db8e-47d6-9304-0f2038387124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d5f07a2-16a2-4044-8315-9449ac4c5a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40c54cdd-9028-42a8-80c1-ccddeef40a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947d89a9-07b2-4051-9daf-e1d2b366ce11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac0c1a8-c695-432f-8e9c-bfd815042a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3fb6ed-be4c-40ff-aa3b-3d3b0da32092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01671871-a0a9-450f-b15c-625a3487cff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1098c74-47b1-4ed2-a53f-01ac95d8dda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318b291b-99d7-4aa2-92d8-ebfe14cf88c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25761e0-42df-4e26-a832-12c520ef187c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d7738a3-2a8f-449d-970e-e9cc8e09bd4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff5f957-940c-4812-a841-d583a980270e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b36f6160-833f-4862-8ac1-5463d85f978e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(2028, 24), y=(2028,)
   Test:  X=(508, 24), y=(508,)

⚠️  Limiting training data: 2028 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  499 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0827 (↓), lr=0.001000
   • Epoch   2/100: train=0.0871, val=0.0861, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0885, val=0.0818 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0869, val=0.0805 (↓), lr=0.001000
   • Epoch   5/100: train=0.0861, val=0.0809, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0851, val=0.0802, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 2 Summary - Client client_20
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0292
============================================================


============================================================
🔄 Round 3 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0817 (↓), lr=0.000250
   • Epoch   2/100: train=0.0852, val=0.0819, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0851, val=0.0820, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0850, val=0.0823, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0849, val=0.0824, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 3 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0014
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0132
============================================================


============================================================
🔄 Round 4 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0767 (↓), lr=0.000063
   • Epoch   2/100: train=0.0856, val=0.0769, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0855, val=0.0770, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0855, val=0.0770, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0855, val=0.0769, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 4 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0048
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0004
============================================================


============================================================
🔄 Round 5 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0805 (↓), lr=0.000016
   • Epoch   2/100: train=0.0855, val=0.0802, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0854, val=0.0801, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0854, val=0.0799 (↓), lr=0.000016
   • Epoch   5/100: train=0.0854, val=0.0798, patience=1/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0854, val=0.0795, patience=7/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 5 Summary - Client client_20
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0045
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0609
============================================================


============================================================
🔄 Round 6 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0864 (↓), lr=0.000004
   • Epoch   2/100: train=0.0842, val=0.0864, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0842, val=0.0863, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0841, val=0.0862, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0841, val=0.0862, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0841, val=0.0861, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 6 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0066
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0300
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2587, R²: -0.0151

📊 Round 6 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2591, R²: -0.0199

============================================================
🔄 Round 12 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 12 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0267
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0058
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0219

📊 Round 12 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0222

============================================================
🔄 Round 16 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 16 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0227
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0164
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0222

============================================================
🔄 Round 18 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 18 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0222
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0516
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 22 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 22 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0298
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0062
============================================================


============================================================
🔄 Round 23 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 23 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0212
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0203
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 24 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 24 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0250
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0053
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 25 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 25 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0239
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0091
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0223

📊 Round 25 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 27 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 27 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0263
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0022
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 29 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 29 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0215
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0286
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 31 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 31 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0155
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0619
============================================================


============================================================
🔄 Round 32 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 32 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0193
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0351
============================================================


============================================================
🔄 Round 33 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 33 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0100
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0794
============================================================


============================================================
🔄 Round 37 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 37 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0191
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0382
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 38 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 38 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0237
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0125
============================================================


============================================================
🔄 Round 39 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 39 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0228
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0121
============================================================


============================================================
🔄 Round 43 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 43 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0199
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0264
============================================================


============================================================
🔄 Round 44 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 44 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0164
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0391
============================================================


============================================================
🔄 Round 45 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 45 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0278
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0084
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 50 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 50 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0203
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0228
============================================================


============================================================
🔄 Round 52 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 52 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0223
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0199
============================================================


============================================================
🔄 Round 53 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 53 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0230
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0118
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 53 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 56 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 56 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0175
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0361
============================================================


============================================================
🔄 Round 57 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 57 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0160
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0437
============================================================


============================================================
🔄 Round 58 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 58 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0221
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0187
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 58 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 58 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 65 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 65 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0222
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0155
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 65 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 69 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 69 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0127
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0560
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 71 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 71 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0276
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0122
============================================================


============================================================
🔄 Round 72 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 72 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0266
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0020
============================================================


============================================================
🔄 Round 76 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 76 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0180
   Val:   Loss=0.0961, RMSE=0.3099, R²=-0.0320
============================================================


============================================================
🔄 Round 77 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 77 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0185
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0539
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 79 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 79 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0241
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0213
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 81 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 81 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0146
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0708
============================================================


============================================================
🔄 Round 82 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 82 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0210
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0206
============================================================


============================================================
🔄 Round 84 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 84 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0167
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0399
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 84 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 84 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 87 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 87 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0200
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0266
============================================================


============================================================
🔄 Round 89 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 89 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0194
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0287
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 89 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 93 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 93 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0260
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0182
============================================================


============================================================
🔄 Round 94 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 94 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0263
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0135
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 95 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 95 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0215
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0191
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 100 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 100 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0188
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0329
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 100 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 100 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 100 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 100 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 115 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 115 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0178
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0344
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 118 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 118 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0181
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0403
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 118 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 118 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 118 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 118 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 126 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 126 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0142
   Val:   Loss=0.0996, RMSE=0.3156, R²=-0.0531
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 126 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 132 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 132 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0137
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0467
============================================================


============================================================
🔄 Round 134 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 134 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0204
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0633
============================================================


============================================================
🔄 Round 136 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 136 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0137
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0545
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 137 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 137 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0234
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0348
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 138 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 138 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0164
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0417
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 140 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 140 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0248
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0213
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 143 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 143 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0216
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0170
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 145 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 145 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0169
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.0344
============================================================


============================================================
🔄 Round 146 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 146 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0190
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0293
============================================================


============================================================
🔄 Round 148 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 148 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0179
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0315
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 154 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 154 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0166
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0838
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 154 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 154 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 154 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 159 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 159 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0111
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0617
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 159 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

📊 Round 159 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 163 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 163 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0190
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0325
============================================================


============================================================
🔄 Round 164 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 164 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0232
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0111
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 164 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 169 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 169 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0227
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0150
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 170 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 170 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0155
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0421
============================================================


============================================================
🔄 Round 173 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 173 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0184
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0320
============================================================


============================================================
🔄 Round 174 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 174 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0174
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0515
============================================================


============================================================
🔄 Round 176 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 176 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0280
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0087
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 176 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 179 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 179 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0234
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0148
============================================================


============================================================
🔄 Round 180 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 180 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0259
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0122
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 180 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 180 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 185 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 185 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0295
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0027
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

📊 Round 185 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 187 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 187 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0196
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0341
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2594, R²: -0.0225

============================================================
🔄 Round 189 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 189 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0178
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0404
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
