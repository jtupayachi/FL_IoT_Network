[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b3dfeb4-730f-45a6-a8e1-2ba248f7b2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 380f60aa-af8d-4f7f-8b48-3523c8929c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acb51f7-ab91-4bc4-9d26-8f056c5d684a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c3d582-12be-432f-bee3-0ce2454b1a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89874fa7-5c81-4c5f-afda-36ac43d1ddef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ca1360-c425-4b21-8a2c-8231a9e318e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c198aa-aa68-4665-9a52-ab4e47227269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83386ced-4f39-4017-9e90-9f0bcbd6909d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a4c95b-d0ce-4c3c-8f2d-048f37b33009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2add5b4d-38bb-4239-bc5d-76c45cc30a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f7e4a5-64c3-44df-bcac-0fea41129776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee71b26-a7d8-41e2-928f-91906960399e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2eb380-7ab5-4a98-ade4-bbc327c283ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3842a562-4927-4a19-8642-f89af181b3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 402771ca-89e2-4198-9022-3fdc36a0f0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c00da4-b294-4446-9031-7f815f2fd959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa690eb-e076-471c-8f36-a650a4c47d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce45462c-5171-48f2-94b0-257b885b253d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9bfd49-1293-4780-be31-516cedbd3071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f7e4a9-8b7b-4221-9e72-392f8ecc4f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1771736-a6e7-4acf-a987-a13226603f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdee659e-dfd1-474f-8eb6-19e5c5673085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64b43518-6417-45fd-a7c5-ec9213e3cb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9bf39fb-6423-4f3b-81a0-0b9fefe2c6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915b16da-456d-478c-87e0-36e446f3c263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87282070-7e2d-4c92-aca7-f6e46fdb8f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c0511f-02c8-4efa-9f72-4dc9e07f54e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee4f75f-600f-4444-a80e-a699cc397eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e290df77-707d-43a5-8a01-0fb5a442273a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 400d8c2a-1a29-4dda-8c39-f2dcc5f1c421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87035370-a299-4f99-a0b5-28a3acd0b619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9ab568-9af7-47a3-bb1d-dbad8e715171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495d9c2f-3803-43b9-9ee3-942eea710755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message febdc002-c7a0-4c12-925e-df92a6375f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58c9ebe-5168-457c-8577-190bd4ac2a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e87476af-74e6-487a-b808-0dc0c1940a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b80397a8-3eec-4d86-9aa6-d92cd06faa36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a868f8-3789-43b1-8b36-ac8e90acf914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69105a98-52c4-4239-aa0b-2dc70ac6dc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65869379-7150-4ad5-bfcc-34378ae7f7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25fdcffe-b9a1-4f9b-aa22-a86d1d95d977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d00ef25c-2b40-4803-9759-f80fabdac7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c18666-9e39-422a-b0c2-3a6619d9789e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece1b0a9-cbae-4c94-85f5-19e1af49fbfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7104125-6fe3-443b-9be5-bbdcbaa03fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af0fa86-bc45-4f07-9203-e2d29024b9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 219c513b-8927-458e-918e-212d5e8a413c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b6e07d-c7fa-40d6-8721-6d452803e84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f97399-ec2d-4f1a-9354-7c76a9e270e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faaa17fa-0794-42ee-98b4-10d3b43d5e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e972543-576c-4f9f-8546-1f4c16877ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a7a062-c74e-41af-b93c-0a17cfea98d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6104cab0-f51e-4610-b9d0-b1e63b034f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd93c6c8-8258-4fb7-a43b-b3e0c144487f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c26ad75-17a2-46fe-aadd-a994c90d3c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f31297b-6f89-4fa8-95a5-74d208162bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73bb55d-7db8-492f-9191-b387722d4c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fe375f-e45f-4673-ae5a-da8ce3721a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b5ed00-8a87-4aff-8ef5-ea92868ab4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770cdd05-58dd-45e3-bec5-9e5bdac1d693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bca9247-8d37-461f-8221-e8710b0e1788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58305cc4-4c41-4d58-ade6-a7226d00dbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bfb8685-622e-4afe-8ffb-116df6e9a3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b83084-aa73-4887-81d7-566a998fbc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f40c138-10bc-42c2-a45f-cc6ba92bf78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6307a76-3d9c-47e8-8220-cc07543d919a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b067e40-509f-45be-be9d-86d3d12231ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde36a6a-0439-41f2-bb7d-b771bba1d28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4924ff78-f879-4cfb-99d2-19960dcf368b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fb27f64-7795-4d7a-97e5-8b426e968f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8c9bbe-1634-4548-b898-e204f3dfade8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4f777c-41ce-48ac-a9ec-14d8b2dee26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4c9395-2a8b-4037-9374-5e49a741f1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f16b9c2-7e3a-4cf3-8903-c0bddbc524cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd739b60-1870-42c9-80ca-c8898cf2e2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa143fb-04fc-48c5-9352-ee9fd468bd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 997a1606-6526-4c6d-b24d-ad994ce46ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6db23a23-0e46-4edd-b239-d91aa0e390ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01690b50-1acf-4ee9-9b52-dd3841581a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91cbc9bf-3549-46a2-95ca-7d6a18119cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ba24e4-8a39-42f7-be5d-e7545185c46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ae21b3-6b2a-4358-a35d-3ab442b23439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f671c5f-7f4f-4d27-8163-4abbb0e04bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23fedda4-0f83-477b-9fef-ee334af0a48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0118c8ef-da69-4f7a-8c45-0eec40ad5330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b435f9-d686-4ec4-a2f0-f69e3732589c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 261e6771-0744-4f58-a40a-0cd4b1d88f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0c4fabf-0a4e-4670-b4dc-9d566c2cabe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4955588-7e97-4cb7-9ad5-0b7336c1ade4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38be3129-c2b0-4767-a909-336845b63bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a3fbda-c885-467c-934c-18a4f7a89b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba20f9d-9623-4a5a-89a2-a921f24caa7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41625d8a-36a6-4af9-9178-e60d79f41db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a4ee1b-38a7-4561-9b46-5e2d55d1c512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab1f956-b17c-44e7-993f-e60dd507d270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2441a85-d664-443c-b453-f7ede0b5f784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f55e7f4-e69d-49da-97ec-fccc01f90db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a2b82c-c531-41c0-a82b-c4a5b5e2e0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fadaee9-2889-4824-ab1a-b1a3a95a637e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de40f8d6-45c6-4103-9ed3-00e4f1504391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feaff2d1-1cde-44d9-b6c7-c9217833e734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c68319-31c1-4002-b230-1f2f7c647641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22d6dfa4-88c0-4875-8e58-2e1ed69c4638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ad47f5-ecb1-421b-8b0c-9fd729b82565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a375c0f-2ddd-4348-a0ca-fff27485be0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82bcdfe3-b494-4121-8e85-e4ffb40b1d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0743094f-95cf-435b-8a13-4cc0ed224516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74b3c49-b807-4963-9737-d27315e9c5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6bffac-4d72-4374-b4f6-1a6f12fffeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f25fcb0-264e-489e-bb03-f561392bd843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cacd13f-64ac-42ac-acf0-2358da9e0f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8525538e-936c-4a13-8b10-a1c38a284b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb6541fb-de1e-4c04-b4c9-8a7d9381b9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a48a06-8b54-4140-b22f-da10403d6a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3285edb-ed3c-4175-8e70-48f239855d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016f3276-d6e6-4ff0-b646-8b16e0aa1221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd2be75-3999-4526-9ce6-1b4c4140a38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d0f315-d659-4a0a-a226-91463044a512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8cb445-6fe2-4481-ab84-41cb6a7cda96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e4163a-f638-4469-9b2b-58bfae8f4b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f965dd9-93aa-4583-977c-fb16ea557314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324b4114-c3ec-4b74-9a95-28aa670a340b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc50dfe-c3e5-4351-bf6d-91f658eb7a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b453402-85c5-4cef-89a2-76836227e1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb4f75a-0367-4bca-9cdc-d8e6d0b5b0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d122717f-28fd-4124-86d8-090c077d2e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c8048d-ef8c-409b-abe3-7de167ceca4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8a5b3b7-c4b3-45a2-b9df-2dd3d16f5b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5985b6e2-a16f-4680-8600-a3b6a70d3af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8daac146-8751-447e-a83e-e292c52df732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8269595c-7c9b-4783-9026-1e356aa14f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b550e3-0295-477e-8dec-b31a40bb6afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81adc7d8-e27e-4a10-bd75-5c65a458042f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c732db35-70e0-4435-ba10-749f24c46dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcae667f-81c2-4b9a-96bf-140a4e984114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5df73baf-68a1-4503-840a-76794bb0e75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6343a27-813e-43cf-8060-b743a1aca0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53d80f90-2788-4caa-9d4d-dd86d021c93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f548c515-4abc-44c1-a023-f20c0ebcac1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab61866f-3d9b-4032-b325-252927e53419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d8b234-e347-42c7-821f-68225c7fdd47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5aceb32-166e-4cea-b8e3-9b575ecb9b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bdcd114-18d0-4178-8846-53e059b8aa6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2928611-8efc-46bf-b5c7-916c2b250882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec8f09f-68b2-4b57-89c1-07137c179867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b16303e-362f-4ea9-a53e-3e3af805af2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73ec418-85b7-4d94-9c5d-8a55bc06e8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf394d0a-7148-4b77-b1c0-2eb715cc342b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d7162dc-8e3e-4499-a336-ca2db9370d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5810d570-ecb4-4cb4-98e6-76cd89da5022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44696698-9c3a-45be-b867-08cdd0dcc09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6a9884-2781-487a-8309-77d647b87edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baaae2a6-cd90-4fe1-91a6-48f4962897c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1021e63-6d11-4e53-82ed-ef518860220a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d28c35c-9925-4ad7-8274-4e545d8b0deb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(1494, 24), y=(1494,)
   Test:  X=(374, 24), y=(374,)

⚠️  Limiting training data: 1494 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  365 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0859 (↓), lr=0.001000
   • Epoch   2/100: train=0.0843, val=0.0855, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0841, val=0.0852 (↓), lr=0.001000
   • Epoch   4/100: train=0.0838, val=0.0851, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0835, val=0.0852, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0819, val=0.0870, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 2 Summary - Client client_21
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0105
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0094
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2470, R²: -0.0075

📊 Round 2 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2472, R²: -0.0077

============================================================
🔄 Round 4 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0789 (↓), lr=0.000250
   • Epoch   2/100: train=0.0855, val=0.0788, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0853, val=0.0788, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0852, val=0.0788, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0847, val=0.0790, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 4 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0055
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0065
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2478, R²: -0.0120

============================================================
🔄 Round 6 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0843, val=0.0856 (↓), lr=0.000063
   • Epoch   2/100: train=0.0839, val=0.0855, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0839, val=0.0855, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0838, val=0.0854, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0838, val=0.0854, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 6 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0094
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0096
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2480, R²: -0.0128

📊 Round 6 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0166

============================================================
🔄 Round 8 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0853, val=0.0839 (↓), lr=0.000016
   • Epoch   2/100: train=0.0850, val=0.0839, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0849, val=0.0838, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0849, val=0.0838, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0848, val=0.0839, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 8 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0186
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0239
============================================================


============================================================
🔄 Round 9 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0781 (↓), lr=0.000008
   • Epoch   2/100: train=0.0870, val=0.0781, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0869, val=0.0782, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0868, val=0.0782, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0866, val=0.0782, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0864, val=0.0782, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 9 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0260
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0130
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0206

============================================================
🔄 Round 10 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0886 (↓), lr=0.000002
   • Epoch   2/100: train=0.0852, val=0.0886, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0852, val=0.0886, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0851, val=0.0887, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0851, val=0.0887, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0850, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 10 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0256
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0452
============================================================


============================================================
🔄 Round 11 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 11 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0276
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0243
============================================================


============================================================
🔄 Round 13 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 13 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0343
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0207
============================================================


============================================================
🔄 Round 14 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 14 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0278
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0287
============================================================


============================================================
🔄 Round 15 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 15 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0301
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0338
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0224

============================================================
🔄 Round 16 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 16 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0330
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0268
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0224

============================================================
🔄 Round 19 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 19 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0341
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0125
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0222

============================================================
🔄 Round 21 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 21 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0269
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0375
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 21 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 21 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 26 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 26 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0243
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0469
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 26 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 28 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 28 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0264
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0427
============================================================


============================================================
🔄 Round 30 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 30 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0287
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0722
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 32 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 32 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0297
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0276
============================================================


============================================================
🔄 Round 34 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 34 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0290
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0341
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 34 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 36 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 36 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0294
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0292
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 37 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 37 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0266
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0391
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 37 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 40 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 40 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0317
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0274
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 40 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 40 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 45 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 45 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0262
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0511
============================================================


============================================================
🔄 Round 46 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 46 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0242
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0533
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 50 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 50 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0305
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0290
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 53 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 53 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0329
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0258
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 54 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 54 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0298
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0264
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 54 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 54 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 61 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 61 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0297
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0299
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 61 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 64 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 64 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0285
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0335
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 64 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 66 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 66 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0283
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0367
============================================================


============================================================
🔄 Round 67 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 67 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0275
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0364
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 69 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 69 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0317
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0159
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 69 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 74 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 74 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0319
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0195
============================================================


============================================================
🔄 Round 81 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 81 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0297
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0272
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 82 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 82 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0293
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0363
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0219

============================================================
🔄 Round 83 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 83 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0282
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0354
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0219

📊 Round 83 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 85 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 85 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0304
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0318
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 88 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 88 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0273
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0420
============================================================


============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0253
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0434
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 89 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 94 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 94 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0260
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0413
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 106 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 106 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0293
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0369
============================================================


============================================================
🔄 Round 107 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 107 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0306
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0229
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0220

============================================================
🔄 Round 109 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 109 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0301
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0268
============================================================


============================================================
🔄 Round 111 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 111 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0286
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0331
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 113 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 113 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0316
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0231
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 114 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 114 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0277
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0460
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 114 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 114 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 118 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 118 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0253
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0445
============================================================


============================================================
🔄 Round 119 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 119 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0339
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0151
============================================================


============================================================
🔄 Round 123 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 123 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0280
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0468
============================================================


============================================================
🔄 Round 125 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 125 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0294
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0289
============================================================


============================================================
🔄 Round 127 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 127 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0311
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0221
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 130 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 130 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0249
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0760
============================================================


============================================================
🔄 Round 131 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 131 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0272
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0382
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 133 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 133 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0257
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0554
============================================================


============================================================
🔄 Round 134 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 134 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0240
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0548
============================================================


============================================================
🔄 Round 135 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 135 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0300
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0256
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 135 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 139 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 139 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0278
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0346
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 139 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 139 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 139 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 139 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0222

============================================================
🔄 Round 147 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 147 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0349
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0083
============================================================


============================================================
🔄 Round 148 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 148 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0349
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0187
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0222

📊 Round 148 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0222

============================================================
🔄 Round 151 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 151 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0306
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0240
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0222

============================================================
🔄 Round 154 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 154 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0279
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0345
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 154 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0222

============================================================
🔄 Round 162 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 162 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0293
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0347
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 164 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 164 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0300
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0358
============================================================


============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0308
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0302
============================================================


============================================================
🔄 Round 169 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 169 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0310
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0218
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 170 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 170 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0315
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0210
============================================================


============================================================
🔄 Round 171 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 171 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0315
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0217
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 171 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 174 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 174 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0332
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0149
============================================================


============================================================
🔄 Round 177 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 177 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0289
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0328
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 179 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 179 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0268
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0507
============================================================


============================================================
🔄 Round 181 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 181 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0242
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0560
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 182 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 182 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0335
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0194
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 182 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 185 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 185 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0314
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0198
============================================================


============================================================
🔄 Round 186 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 186 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0332
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0158
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 187 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 187 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0334
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0146
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 187 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

📊 Round 187 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0221

============================================================
🔄 Round 190 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 190 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0319
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0172
============================================================


❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
