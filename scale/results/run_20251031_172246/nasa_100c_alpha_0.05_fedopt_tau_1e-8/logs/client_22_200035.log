[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d1c0d8-f0b6-4ec2-845b-af55e91f9786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d87a40ba-23fd-4a11-b622-ec9956c2410f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5270cd3f-2449-44cb-b479-16c8510d044b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213e13f4-ef28-4505-92b8-0ef98f014d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd41274-29e9-49b9-b537-0529fdf628d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4781cd47-71b5-40fd-98a9-32c5d489b97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c777c1d-9908-4d07-aa39-4f6b490e4efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e57be6e-2754-45c8-851f-80ace26c245b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dffa5c27-0e48-4374-b1ad-ee1c98207382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322777f2-2c51-44d8-9476-65163a5e84ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ba87e6-ee7d-4c17-aafd-04a62189555a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c88702a-086d-410b-a717-627589a18298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0ef65e-9d8c-49a8-822c-1fef23855d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa0419a-9f40-467a-93fd-ba192782b2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15f512d6-260e-4bae-9127-c1816b82a9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55ab8fc-2eba-470e-b77c-bf320ab6dc6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5055cdbd-881d-4571-a9de-5850b2f85e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6e43a2-7d8f-4ae8-94ed-43af7ada3cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7035bf44-8dd0-480d-a84e-216a3cdba9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2766545a-15d2-4939-a539-5295571f874c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9275acdc-b8e5-400a-9195-bd095e9b2411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223c5b45-d01e-4ca9-8682-7e23d898b335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c04c9b-0113-4a1b-a177-bd851ccb771b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad25329e-4bca-4904-b103-e76e3ec20408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2813f7b-b6c6-491e-8fdf-7e69901caf26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a46ddbe-3f54-474c-9513-864bff30a518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03cd9946-86c5-4e03-8c22-abce6a23994e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df82f647-f3a5-45f5-b2de-425eb9d130b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379f565a-2cd6-4a7f-b74b-b367edac72a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc32103-bf62-49f3-9a10-391360794af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af75c382-7e9f-44f4-a4d7-63e4911e84f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 009b8bca-527b-43a4-9db6-e9e8581c50da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3166bc-6054-46f0-a96b-264664f0de82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf892bc-4a1a-49b3-b70e-8342551a1fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0024aaa0-78a3-40c6-8d14-7f570774d124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5772a3-46f0-4b1d-b06a-73c0fc36fb15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81f8aec-4c18-47c0-b1a7-642458a97ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e83d4a-5541-4bc5-ad0c-7500b39bb898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee484f8-be48-4727-aa87-857c08355a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4eb63d5-c6fe-4a24-918c-bf6a7b67b9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e0fdb3-c61d-4337-9dad-1d0080832a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 728e86b9-56a3-4102-8aad-f371ccac7e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4638aa-55ea-4655-b8e7-79a58b2f7386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8523cba-4a1e-4a07-9c93-57d5695336fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba8aae8c-393e-45e6-a38b-d1359abc825f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f561bf6-291d-4996-9e82-62e4a2c8463e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dddcc9b-2513-4e19-97d5-570bc848203a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3a1d2b-06c5-4d05-8194-2a4a35cdf142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3014b260-6b3e-40ec-9ed1-8e2c2de1ade0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ebf1ccb-042f-45bb-9389-4091ab67106a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba5f3f20-85de-4101-9831-2cf8d9a78ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf25c0cb-db47-4905-8f3c-b8b3cd279b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e7eb4b4-0fb7-4000-af9a-8afa74684503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ea8351-2684-471c-954b-b3ae0c67e108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e41557-a0b5-4ad7-8f3a-1f933bfbfac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5b0115-a741-4eaa-92fa-d4d9d46a8781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4559e7cd-77b7-4d45-8ef7-f9f76bc00646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3813cbb5-d54e-4554-9e0b-56e5c63c5af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa15faa-5637-4ca4-a1f7-9030aae52460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be90cd85-ed67-494b-b307-9e726b1588c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba8bd41-bfd2-43b0-88d8-6339283fb415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef10e74-1753-4ad1-bfc0-53907a8d391d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6ffc1af-fd17-425d-8254-65dd058a97d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73cc86e-11c5-4740-b3ae-6595bb60ab84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ef3346-ef41-419b-b491-98bef6ca1871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acdfa8c1-4788-44e6-ba89-7d981e255eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cc62d7f-93c6-4b18-bc55-8a98d5622ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8637268a-b9fd-4c1b-91cc-53e920d424fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef347ac2-9682-4995-94a5-0e0d248e48e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0893f092-1d97-4584-9a1b-712e71aa2271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20825f04-1920-44c0-9d71-6dba73c78cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a521e01-114d-4fb7-9e5a-36c47f577b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9cc03b-2373-4d5e-9608-de4e6003f542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a6c1ef6-ab44-4c3a-a29d-8a4fa79b75d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e0548d0-1d5b-4c11-b766-1dc8ee50c42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b3afc9-27ee-417f-82fd-3171df7dc194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354717cc-b33f-4114-8b21-07ec7e6b728b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ecdb33-051c-46b0-a245-ae0e5b63bfb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ef86f8-7203-4233-8b31-64c948a7ffc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe7742b-0824-42fe-b9d7-2bdfa15d5355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4629d28d-f9b0-4d31-87c8-05b990514902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc77708e-8793-413e-b34a-03c74d9d7597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cbf1354-a34f-4183-8c9c-578ded805116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee2c534-3694-4d95-8604-d06289f3a6cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a96ecebf-0487-43d3-91a6-12b5d786bdf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be402c91-2200-4eb0-9cda-dc9bec3a1ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563dd963-f2fd-4941-815e-8367d67ec091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d34badd-3de2-4c6b-8ff2-3ef5f9336247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c8045d-b69f-4c4c-ac1f-7b2eeb3d839a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aba8a2c-46ea-43aa-9bf9-b209d2c8cc8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d5a9be-ea54-43be-8374-6da060d17bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a63e84-2686-4927-83db-88569c7564e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf373f1-8bff-45c7-9692-3a912cd3c9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35895d63-0f43-4913-8e2e-b798265cd07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77043b25-a671-456f-a00e-16ed3a657767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac1549f-ffca-4cf0-bdfb-b24333a391e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89596a2-8654-4bc3-8860-8d130b7d65c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4f691e-8866-4e94-bbb9-0e193bc1586b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54fc2d75-3cde-473a-ba32-be264478021d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfedb63f-5b99-435e-ab3c-d1edc249367c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b3e5a20-e8b5-4043-96c0-b1bb7b760e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0c3cbd-6a3d-487f-a9a0-b8b9a2abd36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6f1edb-10c2-4d33-9c7f-062764a57d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd4527b-2bfe-48ba-82e3-6ce76d4fc28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e086a78-221b-434a-ba91-e3e4bbe3d4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a75858d-f61b-45da-b761-6bd56fcad3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7381591-c264-4e1b-831e-e88e42e1e9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd3695a6-bef8-4461-99c3-c441c1a0ff80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b70c9d-1203-496d-b521-308e2bd56aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859a814b-87ca-4686-8071-59eda456161b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8568c10-cb57-48f8-a56a-65908472df91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1007c951-f9a0-4053-b47f-0597db6418db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 003ea47a-d334-4550-a428-dd9c6d7a0ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f505be1e-210e-44a6-8ee7-84aea73a72b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc872290-ca58-4a30-9fa6-2a5556161e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e91fedc-2d9c-40f1-8adb-eb81de441df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62018ca8-8063-43c2-8899-cc4c5918e7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c0389c-3a30-44a0-9c45-134ffcdbe358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f484bef3-b550-4780-b8be-22255a1ce8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdbca48c-ba5c-43bc-98dc-3a2d99becf61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae08375-b934-4b32-92da-88c105982783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc97cf4e-64b6-4865-9984-263259c80d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b919831e-d07b-42e7-ab35-882711df2cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3331b82-42e9-489c-a747-31752f4bc0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceabd3ce-f893-4d8f-9086-87e375e49e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dfaec2e-1674-4ac6-8812-0b14f47758ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0261b791-d94f-41fe-aa66-63a4e8436cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb1fbff4-4eef-4d54-ae7a-4644265b243b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f22f16d-c421-4d0f-80ba-bae90dc1775a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c6aacd-c929-4ea6-a2fe-cda6b6814696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 597511c7-3a68-41e4-8a45-a934f7af4041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00cf9d14-5b50-4808-838e-b274313139a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9fbb94-9aa9-4a6e-b97f-fcc23a4e5efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae5b09c-b1c3-40fd-a198-d34f1249b777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d1e726-fc58-4686-86cc-2ba8aad9ccaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a854e5-4b7f-485e-b5b5-ebab3afbbec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f444b77-f70f-45fc-a432-b717343bb0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb64022-f2a2-4d97-a848-f89b8991ae0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56613977-1d10-4bc0-969e-8eccad6594ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9524e3dd-194d-4ada-846f-18c7544d7a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5d455fb-e7f5-43d5-853b-ecfac2cd8fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 222834ad-3f28-4cf8-928e-05a652b05abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b93a072-4fca-44f7-8aea-4d21e0c637aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 395079fb-f3c5-4266-b61c-6026db55860a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(1312, 24), y=(1312,)
   Test:  X=(329, 24), y=(329,)

⚠️  Limiting training data: 1312 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  320 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2435, R²: -0.0035

============================================================
🔄 Round 2 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0830, val=0.0808 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0832, val=0.0802 (↓), lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0803, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0824, val=0.0804, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0814, val=0.0810, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 2 Summary - Client client_22
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0012
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0101
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2426, R²: 0.0035

============================================================
🔄 Round 5 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0753 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0827, val=0.0747 (↓), lr=0.000250
   • Epoch   3/100: train=0.0826, val=0.0752, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0825, val=0.0754, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0823, val=0.0753, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0817, val=0.0758, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 5 Summary - Client client_22
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0117
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0357
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2425, R²: 0.0043

============================================================
🔄 Round 7 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000063
   • Epoch   2/100: train=0.0814, val=0.0782, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0814, val=0.0782, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0813, val=0.0782, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0813, val=0.0782, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 7 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0092
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0207
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2426, R²: 0.0043

============================================================
🔄 Round 8 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0880 (↓), lr=0.000016
   • Epoch   2/100: train=0.0786, val=0.0880, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0786, val=0.0880, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0786, val=0.0880, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0786, val=0.0880, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0785, val=0.0880, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 8 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0120
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0124
============================================================


============================================================
🔄 Round 9 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0792 (↓), lr=0.000004
   • Epoch   2/100: train=0.0809, val=0.0792, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0809, val=0.0792, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0809, val=0.0792, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0809, val=0.0792, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0808, val=0.0792, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 9 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0066
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0367
============================================================


============================================================
🔄 Round 12 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 12 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0153
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0009
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2424, R²: 0.0053

============================================================
🔄 Round 15 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 15 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0138
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0268
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

📊 Round 15 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 19 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 19 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0156
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0177
============================================================


============================================================
🔄 Round 20 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 20 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0173
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0003
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 21 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 21 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0176
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0098
============================================================


============================================================
🔄 Round 23 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 23 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0172
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0092
============================================================


============================================================
🔄 Round 26 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 26 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0171
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0115
============================================================


============================================================
🔄 Round 27 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 27 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0205
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0002
============================================================


============================================================
🔄 Round 28 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 28 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0127
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0180
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 28 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 30 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 30 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0147
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0139
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 32 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 32 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0184
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0072
============================================================


============================================================
🔄 Round 33 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 33 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0162
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0137
============================================================


============================================================
🔄 Round 34 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 34 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0143
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0230
============================================================


============================================================
🔄 Round 35 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 35 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0155
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0191
============================================================


============================================================
🔄 Round 37 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 37 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0173
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0120
============================================================


============================================================
🔄 Round 40 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 40 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0132
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0213
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 41 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 41 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0144
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0239
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 42 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 42 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0157
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0135
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 44 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 44 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0167
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0129
============================================================


============================================================
🔄 Round 48 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 48 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0139
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0136
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 48 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 52 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 52 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0147
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0207
============================================================


============================================================
🔄 Round 54 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 54 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0140
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0170
============================================================


============================================================
🔄 Round 55 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 55 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0183
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0014
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 58 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 58 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0163
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0022
============================================================


============================================================
🔄 Round 59 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 59 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0210
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0042
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 61 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 61 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0152
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0124
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 62 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 62 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0181
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0085
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 65 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 65 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0236
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0155
============================================================


============================================================
🔄 Round 66 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 66 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0084
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0370
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 67 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 67 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0169
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0110
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 67 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 70 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 70 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0158
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0167
============================================================


============================================================
🔄 Round 71 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 71 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0153
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0205
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 71 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 71 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 75 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 75 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0111
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0329
============================================================


============================================================
🔄 Round 77 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 77 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0179
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0096
============================================================


============================================================
🔄 Round 79 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 79 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0182
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0074
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0048

============================================================
🔄 Round 81 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 81 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0199
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0023
============================================================


============================================================
🔄 Round 82 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 82 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0181
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0098
============================================================


============================================================
🔄 Round 83 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 83 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0182
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0066
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0048

📊 Round 83 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 90 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 90 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0139
   Val:   Loss=0.0825, RMSE=0.2871, R²=0.0237
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 91 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 91 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0186
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0065
============================================================


============================================================
🔄 Round 92 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 92 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0194
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0048
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 96 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 96 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0188
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0061
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 100 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 100 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0141
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0211
============================================================


============================================================
🔄 Round 103 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 103 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0205
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0044
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 106 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 106 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0175
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0084
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 109 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 109 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0215
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0088
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 109 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 115 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 115 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0160
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0076
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 124 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 124 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0101
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0376
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 128 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 128 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0187
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0061
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 128 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 133 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 133 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0150
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0204
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 133 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 133 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 133 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 137 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 137 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0151
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0060
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 138 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 138 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0215
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0143
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 140 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 140 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0131
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0290
============================================================


============================================================
🔄 Round 142 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 142 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0100
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0406
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 145 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 145 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0170
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0114
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

============================================================
🔄 Round 147 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 147 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0162
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0162
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

============================================================
🔄 Round 148 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 148 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0140
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0244
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

============================================================
🔄 Round 151 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 151 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0151
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0068
============================================================


============================================================
🔄 Round 153 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 153 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0201
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0040
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 155 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 155 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0190
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0028
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

📊 Round 155 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

📊 Round 155 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

============================================================
🔄 Round 159 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 159 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0166
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0138
============================================================


============================================================
🔄 Round 160 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 160 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0129
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0304
============================================================


============================================================
🔄 Round 162 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 162 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0262
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0266
============================================================


============================================================
🔄 Round 163 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 163 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0135
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0165
============================================================


============================================================
🔄 Round 168 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 168 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0200
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0009
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 170 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 170 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0178
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0046
============================================================


============================================================
🔄 Round 172 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 172 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0212
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0064
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 175 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 175 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0144
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0230
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 177 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 177 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0154
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0205
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 177 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 184 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 184 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0139
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0271
============================================================


============================================================
🔄 Round 186 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 186 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0146
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0237
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0050

============================================================
🔄 Round 187 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 187 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0160
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0063
============================================================


============================================================
🔄 Round 188 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 188 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0225
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0094
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

📊 Round 188 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2425, R²: 0.0049

============================================================
🔄 Round 190 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 190 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0195
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0005
============================================================


❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
