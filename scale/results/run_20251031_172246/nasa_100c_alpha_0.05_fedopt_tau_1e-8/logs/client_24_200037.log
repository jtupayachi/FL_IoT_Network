[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f05d9fb-85ca-4460-8ce4-a184f8cb279e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c24aed-4a1c-4690-b903-293a6f6081f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6941c92-37f3-4357-8045-29a23c7126c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2991c4-742f-424d-840a-c4bfbe255991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498bed57-0157-46fc-a253-91be32c18aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69613181-55c3-4dcd-b6e6-aff44a3a91d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a3ca11-5740-472e-9230-2fb6c2ebff52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cf43b4-9d8a-4ac4-9005-480add9a3dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a22746-7fe8-43b3-8ce9-257443eb9227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4461b7b3-cf7c-44a6-9c29-965324193784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dacdeed-65e9-47c1-acc2-8016363cd331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd7e820-bc0e-4daa-a1e5-7ec8c787db3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f1f773-a266-4382-8d75-8dc23ffb06f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20ebbb0f-f78d-4849-a2e3-31ea6c39202c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 059a2af0-d30b-4de7-92ae-7cdf77896d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f84200f-36cd-4206-b25c-c804694ec796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf93d79-65ab-4cf2-b328-daf539123345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4334d99-83ad-49f1-919b-dfc481282d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b6382f5-cb8a-4a44-b40a-7b6dbd8d70b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055b04fe-31b9-4d97-8a2c-6de5ee761fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 956d4efd-032b-41f1-ba43-704950602a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8731b8c4-3634-4e8b-b53e-654de9149a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message befa2e18-e5f9-4420-a501-8b05d7c2fedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d9f09f-d850-4b61-b962-6e96d7ab2ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1447e4fd-eb96-4a02-87e9-05b3d7110b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c98f534-99bc-47c8-ba73-8254ed9b525c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 466f6715-d35d-4d57-8ccf-75d0e8343e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b25e8e-343f-4853-b130-26cc45a866a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46836b42-48aa-4afe-a233-3604c577e34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a7f726-2673-412f-bc56-cb9fcde15773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2caee432-76a7-46a3-866b-50df2dd08a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a0e7cc-cf96-49e1-9dcc-9d61c9d94915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d09da6-af5d-46b3-8fe4-31df16351697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bfea175-d77c-4b5c-bc93-bd08e54bd643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f199bee5-3354-49f7-a2bf-5904875da235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55d8c48b-dbd0-491f-ba28-478690644ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb1d7f1-1346-4fcf-9c65-7440e80c2c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef42a3f2-3c80-4674-aa4b-70fbbd60fc9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc005cf8-aa13-45c7-a96d-e0b1ab90e7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d7fd62f-de03-49ba-b176-4ecafaf32d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f800aa8f-b2b7-4bbd-86e7-efc6271a1c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9e5a03-974b-43c6-af91-21c7a0708d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a8051a5-c3d4-4b64-b897-3e2363aaf6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e61720-1ae4-42c4-bc0b-23a3f7ae86fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45759fb-501c-4195-b8ca-adc05591a172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f4a4e2-9618-4661-9707-ed7de8de11de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4543a2c7-fd5e-4dab-bcbe-871aa781815b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 260d9235-864b-4d83-bc6d-183e04be8bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3e75e2-a363-4b5f-8853-b54dcb52df57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa68b16-c2ed-4761-a40b-e1f3078d5596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08eeb2dd-2b7a-4723-ad0d-efab169a61ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55a144e-7acc-4d1c-a1b2-7636236fbac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e604d866-a59b-414f-b32e-9b679f062912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b665d74a-d9a2-42dd-ab6c-2a7677ce83d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939ed236-4b09-48c6-b89e-6fb69757056b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4901bded-59dd-4d9f-a652-214a92a2e232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b156e70-3008-4ee8-aab7-963520f50868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade34a19-7daa-429f-9cd3-a1a222f12fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b843f92-d7ec-4f42-b292-c0d48dba52a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ebc5502-6db0-47c9-841b-5e2e40b6a3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca199748-eae1-461b-ab45-7882e8e806eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dffdd02d-cf08-4b33-9f19-9047fcb6b7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94499ec-aa10-4aaf-9799-92e5f4a81d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84359e2d-dcd6-4d86-b9d0-f89a2920e2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67027d4-dfc6-4e05-b8d2-70e61e605c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdace9d6-9bb0-427b-a3f1-f9d398f3a3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a521aa-2bfb-4fe3-b9cc-6af6cd18a97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f250639-bac5-44e1-9635-2debe810964a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f7e399d-efa0-47ae-a80a-49bbc9bb4608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d60138-cc0c-4d71-a351-4b7b8708854d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5adb214e-840f-4f62-9611-364c8541909b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f4cf16f-eea2-4ac1-860c-89348ec2e3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b476408-8c65-4bd2-8ee8-0524bd2ab90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1deb8d5e-e5b0-4ae5-a719-02a64ba8cae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 735a181f-f282-4bc1-befd-cbd3170a7ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29cabeaa-3b1c-4fbb-9ac2-fac8810ddf21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c673834e-5375-4740-b6e4-cdf29b5a2a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 398dca4c-a0bf-4f84-b201-051f96f2412e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94db5743-39a7-408b-a257-9a697377e96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4935ef-e1b6-4354-ad24-ff876b0019c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54afe0f1-32b6-425f-8452-1bf0c65271e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0030079a-44a4-476d-889f-1a5017f99cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb112474-d4e3-4a28-a497-20d37dc23c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f69384-c565-40c5-aa3a-428276580772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abefdf1-9788-423e-bff3-ff8a67adf8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3fd713-da5a-4b41-86e8-ef63a2e6499c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d22c9139-2c89-4bc3-b0e0-b4bddea7cd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fedbbc8a-8113-4b21-bd6b-68c8dc5c5d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec8c8bee-d4d1-44e2-82fd-ba6388d74202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a77872a-6790-481d-831d-b6f7a229fa57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798faa12-2757-4e2d-ab6d-3d5241c046e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda4e74e-3061-4118-98e3-c90d5a4b376b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f713689b-79bb-4ddf-a701-cf7f0e5311dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4a0366-ba31-4494-aef6-cf4cce2b627e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1734429d-aa1d-49e2-a92f-99501d6d8b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec19c8f-786b-48db-b37f-723811db8ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d93fc85b-5d04-459b-97ab-8a8e2558b6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab1589a-bfde-4091-aa1c-57c759988966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2454b4-6f6b-4c02-909e-818201ccf1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab544c2-eeb9-4bdf-91e9-10cd4059d774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d96a7c2d-f7bc-42ae-873a-d173d51034d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0a3315-feb2-4f62-b004-af6c7b0f2299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee4df121-e098-46bb-a879-f61ec9a6ddfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60de4382-8973-484d-9fc1-0255472911ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caae3217-b52e-469a-a98e-69006f8fa773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6430829-933e-492b-abf9-12ad7bc2af23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ffc4d1f-24cd-43d2-b9b8-c82a036c4edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f105639-dcb9-4f1b-be0f-a14c6c13d41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206d79e1-6440-4692-9595-6bbf44df346a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216e0f30-6381-4f81-81f3-eb2f7a3dcb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ad0316-43b2-4686-9aff-190bf0babcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf21365d-ddc6-4560-acec-5c251a28581c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8ebed8-5b14-42cb-9fd3-52a33f71659e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1f0dd04-a577-463e-aaab-25a231f0bd99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046477dc-7f3d-4d5e-97a0-75f214343c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7fdaf5-ce54-402d-ad6c-1348ef814f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89e9764-0c52-402f-adfc-e899d32ea8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0dc73da-e880-4165-b6b9-8e5ee547a1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f8045d1-2ae3-4843-88f4-0ba014ac593d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fef7d2a4-22e1-48c7-b753-992eeb352c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5d5f4f8-1d0b-4e0b-8c17-6b232c475902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6589d80f-61f9-4b2f-b8f3-d29e1a0aa22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651e86fc-fab5-43dd-aa68-c29ed2c0533b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1bf934-3cba-4420-abe3-26aa6921993d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d11e865-f37b-4de7-803b-e1bcd2c8b743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02501dd1-77ea-4e1f-98f8-946dc1908baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60cff7c8-6cfe-4878-bfe6-98aaee0e54e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd409590-2a95-4834-a458-d3b672625cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea9abb1a-f593-4760-a8ad-71854ee3e5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15e7bc7-7b23-4923-94e9-bc5bee3ff809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a7813c-78f4-4b0b-8550-af263fd5159e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e58a24-aefc-4883-9552-e570ca56714b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa5c2c96-9a5a-45e7-a5e8-c46bf8fd8a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e557417e-0726-457f-9dbf-4ed358cd69a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message accca4ea-af29-47cb-bd0c-ec22e3ef333b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc07f80b-769d-4462-bdab-2762d0193943
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(849, 24), y=(849,)
   Test:  X=(213, 24), y=(213,)

⚠️  Limiting training data: 849 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  204 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2344, R²: -0.0048

============================================================
🔄 Round 3 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0904 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0858, val=0.0889 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0849, val=0.0877 (↓), lr=0.001000
   • Epoch   4/100: train=0.0844, val=0.0878, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0844, val=0.0879, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0828, val=0.0873, patience=1/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0802, val=0.0882, patience=11/15, lr=0.000250
   📉 Epoch 25: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 3 Summary - Client client_24
   Epochs: 25/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0184
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0015
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2346, R²: -0.0080

============================================================
🔄 Round 5 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0850 (↓), lr=0.000125
   • Epoch   2/100: train=0.0853, val=0.0852, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0853, val=0.0853, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0853, val=0.0852, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0852, val=0.0852, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0850, val=0.0851, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 5 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0059
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0187
============================================================


============================================================
🔄 Round 10 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0908 (↓), lr=0.000031
   • Epoch   2/100: train=0.0854, val=0.0906, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0853, val=0.0905, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0852, val=0.0904, patience=3/15, lr=0.000031
   ✓ Epoch   5/100: train=0.0851, val=0.0902 (↓), lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0848, val=0.0900, patience=6/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 10 Summary - Client client_24
   Epochs: 20/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0157
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0389
============================================================


============================================================
🔄 Round 11 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0832 (↓), lr=0.000008
   • Epoch   2/100: train=0.0878, val=0.0833, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0878, val=0.0833, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0877, val=0.0833, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0876, val=0.0833, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0875, val=0.0834, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 11 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0262
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0280
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2355, R²: -0.0160

📊 Round 11 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2355, R²: -0.0166

📊 Round 11 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2355, R²: -0.0168

============================================================
🔄 Round 15 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0870 (↓), lr=0.000002
   • Epoch   2/100: train=0.0870, val=0.0870, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0870, val=0.0870, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0869, val=0.0870, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0869, val=0.0870, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0869, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 15 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0312
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0206
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

📊 Round 15 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

============================================================
🔄 Round 17 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 17 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0305
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0332
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 19 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 19 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0237
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0579
============================================================


============================================================
🔄 Round 21 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 21 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0302
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0278
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 25 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 25 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0325
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0204
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 25 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 25 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 25 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 34 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 34 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0288
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0359
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 36 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 36 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0266
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0416
============================================================


============================================================
🔄 Round 38 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 38 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0272
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0388
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

📊 Round 38 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

============================================================
🔄 Round 40 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 40 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0287
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0378
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

============================================================
🔄 Round 41 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 41 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0302
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0480
============================================================


============================================================
🔄 Round 42 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 42 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0308
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0374
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

📊 Round 42 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 42 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 46 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 46 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0247
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0508
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 47 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 47 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0266
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0435
============================================================


============================================================
🔄 Round 48 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 48 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0260
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0584
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 53 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 53 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0287
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0418
============================================================


============================================================
🔄 Round 55 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 55 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0235
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0602
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 55 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 58 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 58 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0306
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0267
============================================================


============================================================
🔄 Round 59 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 59 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0295
   Val:   Loss=0.0997, RMSE=0.3157, R²=-0.0297
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 59 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 59 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

============================================================
🔄 Round 65 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 65 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0294
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0348
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

============================================================
🔄 Round 66 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 66 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0282
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0371
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

============================================================
🔄 Round 67 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 67 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0300
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0372
============================================================


============================================================
🔄 Round 68 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 68 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0320
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0197
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0172

============================================================
🔄 Round 70 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 70 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0335
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0318
============================================================


============================================================
🔄 Round 71 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 71 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0295
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0308
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 71 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 79 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 79 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0285
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0343
============================================================


============================================================
🔄 Round 81 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 81 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0287
   Val:   Loss=0.0950, RMSE=0.3081, R²=-0.0437
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 83 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 83 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0343
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0154
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 83 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 86 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 86 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0275
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0410
============================================================


============================================================
🔄 Round 87 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 87 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0353
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0082
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 92 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 92 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0197
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0726
============================================================


============================================================
🔄 Round 93 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 93 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0334
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0142
============================================================


============================================================
🔄 Round 96 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 96 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=-0.0377
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0004
============================================================


============================================================
🔄 Round 97 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 97 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0323
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0237
============================================================


============================================================
🔄 Round 99 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 99 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0280
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0410
============================================================


============================================================
🔄 Round 106 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 106 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0272
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0447
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 108 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 108 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0287
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0411
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 110 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 110 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0301
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0520
============================================================


============================================================
🔄 Round 111 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 111 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0306
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0268
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

📊 Round 111 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

📊 Round 111 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 116 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 116 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0267
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0430
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0173

📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0174

📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0174

============================================================
🔄 Round 127 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 127 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0351
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0079
============================================================


============================================================
🔄 Round 128 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 128 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0304
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0269
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0174

============================================================
🔄 Round 133 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 133 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0308
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0301
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2356, R²: -0.0174

📊 Round 133 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 137 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 137 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0257
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0544
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 137 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 141 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 141 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0251
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0520
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 142 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 142 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0271
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0468
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 145 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 145 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0326
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0179
============================================================


============================================================
🔄 Round 146 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 146 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0335
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0193
============================================================


============================================================
🔄 Round 150 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 150 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0284
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0726
============================================================


============================================================
🔄 Round 151 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 151 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0294
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0320
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 154 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 154 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0261
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0464
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 154 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 156 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 156 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0325
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0214
============================================================


============================================================
🔄 Round 157 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 157 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0294
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0489
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 157 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 157 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 157 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 164 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 164 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0314
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0292
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 164 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

📊 Round 164 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 168 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 168 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0270
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0412
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 171 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 171 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0277
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0377
============================================================


============================================================
🔄 Round 174 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 174 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0299
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0283
============================================================


============================================================
🔄 Round 176 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 176 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0285
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0376
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 181 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 181 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0306
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0416
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 182 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 182 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0359
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0090
============================================================


============================================================
🔄 Round 183 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 183 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0279
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0367
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2356, R²: -0.0173

============================================================
🔄 Round 185 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 185 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0255
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0559
============================================================


============================================================
🔄 Round 186 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 186 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0290
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0379
============================================================


============================================================
🔄 Round 189 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 189 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0304
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0489
============================================================


❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
