[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c9a2cd-dcfc-4768-902d-375c84eab1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d30c81ba-54dc-404e-8441-7f0f6bee3e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 696cfbde-9fea-4b42-908d-fc9a210f7982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f84d7f98-69ca-4447-acc4-22818b62819c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 052f8a9a-5dfc-4632-a56b-0a687a518541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a21e912-545c-41d9-a807-2879c703284e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0643be03-8347-42cd-bfbb-494051322523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb95cc3d-bcad-4e39-a44e-c981a27af8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca15ecc8-463e-4a3f-8c3f-56a571efd121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb0e3b94-0b77-4e2d-b363-17df3538175c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556b51ab-fa51-4e79-9301-348e35287990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c99d1af0-e743-4cf3-b186-161ae73ab3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39034027-920c-47b1-abc8-f4b86012a182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a45523d-c8a7-47c6-85dd-b74b60259e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8782e3d-504d-4742-a0eb-3868efc13c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf037be2-7249-4841-bff9-13d3666fc9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94e2e2c-8d25-4ed9-9836-8b26c207766c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac5cd1f-fd21-4f66-a281-364abee09f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d140b45e-19bf-4097-9642-a169e34e81ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5ff55c-4996-4960-b643-f4e6812aa662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1976345-f688-4cc3-93b6-ff17441a8c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e34769-fe03-4923-bd2e-7da09aa657a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e905d34-ecd5-4e36-9759-b6315048bcd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082e6f1d-d320-4a8e-a6e5-5d467c19965f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3a7e32-9bd0-470f-91b0-2bb0dc93b4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 344ed362-c1a5-40af-ad82-9922e204e714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912aae8a-504b-4b9d-ab92-4d57bd6b4f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba0b251-cd82-4374-a6a9-2506de766f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9235bb4d-98da-4a7e-969b-e9b02164cdb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ffeefb7-1548-4bf2-91da-03d5359ee68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1b0739-edd1-45ea-a4ed-1f7483c17ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b19090-852c-41c3-8aec-d46a3f41d799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60caffa1-56c9-4a7a-9776-393ac64a948d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f12001-71db-4baf-83fd-fb1391064411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a21479ec-68b4-459b-a040-303873508a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10132493-2dd5-418d-bed2-718642a87e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93dbb753-f8dd-45eb-8f1f-9c5f7f740d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195c4661-db80-4169-8565-0d9829f5a1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d49a3450-1e7a-49b7-a5a1-58c4dc46990f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a27350e0-1619-449e-8b95-a9eba50ea5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92504257-e630-40c0-9054-4e0fbe8b7341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264928ec-a68e-496a-aa59-df308df54512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8883af01-1503-4b47-8fd6-6c9395f2a4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dbf5d37-bcc8-4144-b33f-ec8b0b2a560f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c245009-d6ec-4148-bf78-30063c3506d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8044cd-4ac5-43ac-a9b5-75caa147d30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac2cbcf-7220-4e65-a08f-3c7e61e90cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1dafc4c-1cc8-4f10-b3ee-9558f0c2d1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cf0902f-bc0f-4921-bd91-8c61099f15ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc3dfec5-79b8-4811-9059-daf10a588398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5785b560-23f3-4210-b6b0-1a5d55148747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6f07cd-77d7-4d0c-b399-cb7436839ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f497e5-96f1-4619-87eb-01d0982f8928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b771f7a-78b2-4a9e-938b-d9e3becb4611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3750641c-4241-4fc6-8db3-abeb7374c7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67502465-151f-448f-b576-64f2c0adf41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8036c2-9e10-4d14-8f5d-03ce293c89f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab744a5a-486d-4d37-992c-0a08bdff371b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b601c88-1aec-4ba8-870c-f93ccf698a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 800269bc-2952-4932-8c04-f9fc744402f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a791b6d-5712-4d8f-b219-f77dfbb2eba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d649c123-828a-4c74-a6c2-e0ec0a826655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7980dea1-f35a-4503-a874-edd30b79b0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4402cb17-5b21-46df-b475-bb59df62d080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56332630-171b-41ee-97d6-fae59a062bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ee208b-9ccd-4569-9836-016027ee0f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ea38bc-e8a5-4653-90ce-f43bb25e38c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80172214-dfef-41d1-9bce-2021093e6777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1700f39e-9dbf-4d0b-a97c-1f1edea36319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9e6e56c-9c8c-4be4-af44-9bb8abdfc7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd52cf57-d821-46c0-92b4-e7441f3267b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25320bb9-df15-465d-a8f9-0469f2001309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60218d9e-a25d-4fd6-b0ed-6b109a258a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba557ec-24cb-4d14-9c90-bd12fbb0cdd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3bdc7eb-ec6f-45f8-b335-bf44034f54fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 588821e1-32c9-4862-9f3c-ce5e912543b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5afd3ff-cde8-43c5-9cf8-c5705b3d2296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bddf946-0358-4fa3-bc10-bc2a49b8bb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e5f6ad-3f90-454c-b709-9c0fccd41294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b248b481-f5d6-4137-9cae-ed68c4849008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3f2267-bb33-4c02-a7c5-e98a90ebda58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a75b4a7c-fd45-4798-9be8-852e550e927c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724c1fd6-f27f-4989-92f7-1346689f2b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c98041-cf47-47b8-b22e-8ddadf71e2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c370488-9da1-4faf-885c-19d49a86bb73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c236e1a1-ff20-4433-a313-c2a7521dc8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db0a3923-57f5-4863-ad4e-b77cb063ae5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c09916-f324-45a9-ac2f-41ee665e72a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3901f13-3213-464a-b09b-6c0aa4712ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ab89ee-afb2-4503-85c6-082e0ee432b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a132f5-e1db-47ac-9ef1-25ac83bf7bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a11ee3a-4520-4320-8751-c4d45485dac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693cb319-bc9e-4d4e-b3fe-1d86b5b44606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14ed634-076f-4a66-88ec-ad2a62e8b78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2043bec7-d3b0-4634-98dd-d6b49fb5f48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d1219a-d54a-476e-b469-8b3e208ea1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e562725b-7051-4199-846b-800999cd0051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5678c0e-58af-4bed-8255-67bad2745383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a097bca5-94f2-49c1-9a57-840d7dc0a46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d33dac-cdea-4709-be8e-7639da39ed4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71d34d5-d3be-4bf3-923b-3ca9374d2891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac00f97-2f6a-4661-9dc4-abfb6c5ad485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5939de38-ac53-48cf-ab54-b9ff5f1dd747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13aefd98-2544-4e11-bf0b-885c98dcc9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e63b578-6a5d-4b62-9e28-c6a9815ea85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac6a2a4-8ade-4f37-b621-86809ccf1567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f111848-382b-43c6-aa80-0ba90a95cbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0587fd2-f7a3-4f08-b3dc-eb0c91cf0187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488592a2-0b85-403e-9385-75b926c13356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b1f128-a3eb-41c5-a3da-afa652f88e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf237ef6-e76b-4fb3-8a2a-e263d3f501b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2891b182-2ca7-46da-9b83-c8bc8940dbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de19d43-b96b-4b2b-a6ab-451b49f22074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987be7bd-7cc0-4888-ba3b-d3b5d9fcc085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d39b1136-da76-4945-adcb-13503d814eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5a367e-5744-4c2f-8105-86a247271288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b107513-1e4c-459d-ab73-893d3e79d3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0625ea9-e71d-4636-b1d1-6ac4d2acba57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e342fe6-537b-42a0-a01d-69a528436c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24752990-3bb9-481f-9796-2404983eb796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69eb9a61-6d71-432d-a316-8a4de3fd796c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6875b7-e673-489d-a3c1-c4b26cf64f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52aa6e74-c97c-42bc-b1be-d2a003d31dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb9a75e-61e6-4de9-8e57-3a0d72884254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975c4985-8524-4f1f-8ede-25f05da3ecc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0864233-4ddb-4f9c-a819-0bd824aca3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b7917cd-be4d-4f7f-9793-0a8cec56f84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6226e7c-8e30-4eee-a40a-72e807249041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c89810-d80f-4113-bf6f-8979c249a8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf3210ce-1977-4a42-a4ba-af8f2f2f0b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e3a779-4348-4d16-84e1-512661e8e5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae63bc4-3136-450a-bda6-800b19748ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee00b31-97c4-4621-8855-26aacdcfde34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcd7da7d-46df-49d8-b5b4-81c4476b5f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aff7955b-3d4d-4961-b69e-db3ab10b3692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d8de132-b432-4198-8e40-86bdf26d5059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdaf03a6-61fd-485e-8776-1bd13a86c8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b809dc67-04b0-4bf0-8385-1f7514b5b121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb5b0bfa-b27e-448a-9415-223a4038172e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a162f1ea-829c-4c2c-8921-89bb306029d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475ab453-0081-4af6-8ccc-df231b44afe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09acb839-d7ea-41db-9c24-4ca6fbb45b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95dbe457-6af8-4c79-be55-627cb45f5b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b36e73f-a714-488c-ae08-9bd3be83e092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5dfdb0-f9d1-489e-b2dc-66d6c4553bb9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_25
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_labels.txt

📊 Raw data loaded:
   Train: X=(1671, 24), y=(1671,)
   Test:  X=(418, 24), y=(418,)

⚠️  Limiting training data: 1671 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  409 samples, 5 features
✅ Client client_25 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: -0.0001

============================================================
🔄 Round 5 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.001000
   • Epoch   2/100: train=0.0867, val=0.0931, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0845, val=0.0916, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0912, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0838, val=0.0917, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0823, val=0.0918, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 5 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0143
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0006
============================================================


============================================================
🔄 Round 6 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0881 (↓), lr=0.000250
   • Epoch   2/100: train=0.0834, val=0.0882, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0831, val=0.0882, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0828, val=0.0882, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0827, val=0.0883, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0820, val=0.0888, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 6 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0062
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0229
============================================================


============================================================
🔄 Round 7 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0837 (↓), lr=0.000063
   • Epoch   2/100: train=0.0847, val=0.0840, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0846, val=0.0842, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0841, val=0.0848, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 7 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0010
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0324
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2416, R²: 0.0030

📊 Round 7 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2416, R²: 0.0027

📊 Round 7 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2414, R²: 0.0036

============================================================
🔄 Round 10 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0934 (↓), lr=0.000016
   • Epoch   2/100: train=0.0822, val=0.0935, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0820, val=0.0936, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0820, val=0.0936, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0819, val=0.0937, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0817, val=0.0937, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 10 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0059
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0031
============================================================


============================================================
🔄 Round 12 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0834 (↓), lr=0.000004
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0847, val=0.0834, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 12 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0027
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0152
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2412, R²: 0.0053

============================================================
🔄 Round 15 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0735 (↓), lr=0.000004
   • Epoch   2/100: train=0.0872, val=0.0735, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0872, val=0.0736, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0871, val=0.0737, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0871, val=0.0737, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0870, val=0.0739, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 15 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0058
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0011
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0050

📊 Round 15 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2413, R²: 0.0052

============================================================
🔄 Round 19 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 19 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0070
   Val:   Loss=0.0831, RMSE=0.2884, R²=0.0144
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2412, R²: 0.0053

============================================================
🔄 Round 21 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 21 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0078
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0038
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2412, R²: 0.0053

============================================================
🔄 Round 25 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 25 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0070
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0136
============================================================


============================================================
🔄 Round 27 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 27 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0017
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0089
============================================================


============================================================
🔄 Round 30 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 30 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0038
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0014
============================================================


============================================================
🔄 Round 31 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 31 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0128
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0316
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2412, R²: 0.0053

============================================================
🔄 Round 32 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 32 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0099
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0211
============================================================


============================================================
🔄 Round 33 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 33 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0061
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0130
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2412, R²: 0.0053

============================================================
🔄 Round 34 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 34 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0053
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0059
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2412, R²: 0.0053

============================================================
🔄 Round 37 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 37 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0087
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0025
============================================================


============================================================
🔄 Round 40 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 40 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0068
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0013
============================================================


============================================================
🔄 Round 41 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 41 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0058
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0005
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0053

📊 Round 41 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0053

📊 Round 41 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 45 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 45 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0013
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0286
============================================================


============================================================
🔄 Round 46 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 46 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0073
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0100
============================================================


============================================================
🔄 Round 47 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 47 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0040
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0313
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 48 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 48 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0001
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0305
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 48 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 48 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 48 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 48 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 60 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 60 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0051
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0015
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 62 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 62 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0046
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0031
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 62 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 62 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 62 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 71 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 71 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0012
   Val:   Loss=0.0994, RMSE=0.3152, R²=-0.0163
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 71 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 71 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 76 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 76 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0032
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0084
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 77 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 77 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0037
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0007
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 80 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 80 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0054
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0044
============================================================


============================================================
🔄 Round 84 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 84 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0029
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0063
============================================================


============================================================
🔄 Round 86 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 86 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0093
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0156
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 87 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 87 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0031
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0016
============================================================


============================================================
🔄 Round 88 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 88 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0031
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 90 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 90 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0025
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0058
============================================================


============================================================
🔄 Round 92 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 92 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0058
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0091
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 92 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 99 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 99 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0052
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0065
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 100 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 100 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0054
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0071
============================================================


============================================================
🔄 Round 101 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 101 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0007
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0176
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 102 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 102 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0014
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0097
============================================================


============================================================
🔄 Round 104 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 104 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0040
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0009
============================================================


============================================================
🔄 Round 106 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 106 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0101
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0213
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 106 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

============================================================
🔄 Round 108 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 108 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0003
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0134
============================================================


============================================================
🔄 Round 109 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 109 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0051
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0011
============================================================


============================================================
🔄 Round 114 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 114 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0028
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0045
============================================================


============================================================
🔄 Round 115 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 115 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0013
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0245
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 115 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 119 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 119 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0034
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0033
============================================================


============================================================
🔄 Round 120 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 120 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0036
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0480
============================================================


============================================================
🔄 Round 121 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 121 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0012
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0233
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 124 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 124 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0023
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0096
============================================================


============================================================
🔄 Round 125 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 125 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0070
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0104
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

============================================================
🔄 Round 130 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 130 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0032
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0040
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 130 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 130 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 130 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 130 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 135 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 135 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0055
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0384
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 137 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 137 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0030
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0022
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 138 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 138 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0085
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0011
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 138 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 142 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 142 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0013
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0087
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 143 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 143 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0081
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0172
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 143 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 143 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

📊 Round 143 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 153 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 153 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0032
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0031
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 155 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 155 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0036
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0087
============================================================


============================================================
🔄 Round 156 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 156 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0004
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0344
============================================================


============================================================
🔄 Round 157 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 157 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0024
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0070
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0054

============================================================
🔄 Round 161 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 161 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0057
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0068
============================================================


============================================================
🔄 Round 163 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 163 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0063
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0049
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 163 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 163 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

============================================================
🔄 Round 167 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 167 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0065
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0115
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 167 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

============================================================
🔄 Round 170 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 170 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0061
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0058
============================================================


============================================================
🔄 Round 171 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 171 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0005
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0124
============================================================


============================================================
🔄 Round 172 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 172 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0066
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0001
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 172 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

============================================================
🔄 Round 178 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 178 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0037
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0005
============================================================


============================================================
🔄 Round 179 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 179 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0008
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0195
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

============================================================
🔄 Round 182 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 182 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0079
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0091
============================================================


============================================================
🔄 Round 183 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 183 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0047
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0042
============================================================


============================================================
🔄 Round 184 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 184 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0037
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0006
============================================================


============================================================
🔄 Round 186 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 186 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0067
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0087
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

============================================================
🔄 Round 188 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 188 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0018
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0071
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

📊 Round 188 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0055

❌ Client client_25 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
