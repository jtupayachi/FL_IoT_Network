[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3751176-f24d-45fa-a2c8-59c556872ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 591d0f8f-5f7d-4b51-956d-3011b6b2979d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73fdf7ed-8fb0-4f64-88d8-521b0681534c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a55c3f32-e0ea-4216-957f-bbe5d73e13c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 336e81e4-c033-48c7-80a2-e014861f4fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f41ce25-994f-497b-a61f-c9b6e2a53fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a8d73fa-c385-4637-861d-140f62697e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a95475-11a4-42b4-a348-6788ae14456c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4965041-c897-4063-867d-0df4d398dd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 855fe385-b526-4d0a-a1dd-3e005b158c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9118dae6-39c2-4ad7-8eda-6cec90a4e4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790ebebf-f119-4779-bf18-9da488f666a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2932ea69-2945-4683-b7ce-0c5df376ec7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e93d205-cb6f-4b58-8501-607609f423d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 472e468c-4c48-450e-9a63-ed293a0cff29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6e5f51-b797-49d1-8d1d-cb3176a5ad81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61dd109a-10c6-44fb-aaa7-a36f9e08bb4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c99743e-23b7-45e1-8019-93b5b82b65f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc306c1-bfc6-4bbf-a8c6-c4396ebf5dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec13ca0-a623-4dce-9e2d-5c8c6c6ed8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a8412b3-eff4-4d35-8d00-521b056e07b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 515661f3-c260-4aef-961b-d85038489f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30144142-7e5b-4068-b223-cc7070b7fd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f736d87-ecac-47c0-bfd6-dffbd499a106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d6fa18e-ca0d-404f-95f5-591d882b21eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b031b5f-c478-4e23-9d7a-60976c135b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73098fc-bc92-4656-a62e-444dd3cdbb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac0aa743-a5ba-4ac0-8119-23019b87bfd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20485cc5-1dcf-429b-9eb9-ecb3dcc742a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bd9a6e-09ac-4a0e-a8a6-6af6f4f402fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 329f2371-6f51-4522-abdd-16ab99af1f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89322f82-ba08-4572-861b-43b2d41e5001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 735b3e2a-47ff-4750-8337-771ee155c116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c48530-d2ae-4558-9372-ebe44f36b112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00e7e9b8-91cd-48aa-a981-dd650cb67666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa480164-4ed6-4b5a-912a-ec1147d0cc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af22bfe-87c8-4110-bd06-5cb7902064ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac03f848-2ddc-461d-b652-ac6090a7705b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b91b34ee-08f1-4d9a-8f2b-177d93c4401b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ef5522-8b51-4324-b024-8c26d7ad03be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb372126-3bae-45ed-8f7b-9990caf7a09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b5f13e-8282-44c7-bbd6-acf43b1e11d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c035b9d-c420-4080-863d-ae0a7d178b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb460e4f-766b-4947-9e2d-fea1f6027bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16346a9-dead-4d49-a17e-010d368bc2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bffea534-d795-4737-9a74-d72f3a526944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cae46d0-92bc-4e4f-bbd2-6a5e68c95d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d1583fd-eba3-411a-ac85-34268582043c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc64eb2c-740e-4d45-b006-943bd5b11d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bcfcc9e-77d6-4647-ab1b-a2eac54236a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f890a5-c1a4-4bc2-9956-5cabf8c210d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f9a5b0-b6fe-4014-8c62-ae9cca617802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec572672-6dd3-4e8e-9e32-f8374e94aa46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b65721-8b28-42a5-905c-4f364347018e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204688dc-1f6c-440a-831e-6fd0802b3c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36643b8e-7153-4208-98c4-da8752e8c630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3dfe3b0-c8f1-4e82-a298-d090543392d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0a6740d-85c0-4f7f-986a-5cc37b6887d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd062f0-34b0-4db1-b9c1-9dc082a23f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b889180f-8466-41f9-85ca-e3cac2027060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92a6111-de64-44c3-b8f1-662ca7e6ee76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5e6d15-f874-4c1d-b98a-507c73911339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e556b8cd-2718-44e5-b92b-5f3adcccf5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76faddd5-0ba7-43da-8d11-fcfce80d5ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d98142-183f-48c4-a212-31e1dd065773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf0ed4f-d193-4a84-b433-2cd6625009c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa12176d-1343-4cc0-80a7-9a06dc8e04a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cc8bec7-4e84-4318-835d-caa09dcac9c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909e2219-86e2-4b67-9bff-bda423bea9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e87fdf1-1a71-41e4-8808-3999d331887a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94129a9c-2f49-4e94-bfa6-9bd54dc4b229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de8a408-8508-4a07-89a4-b8fd61e70344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf28ee1-9de8-4bc1-b6c9-bd27c2ee527b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e092a114-82f0-44cf-9568-41db391ddd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f95a5d1-bd58-49c0-bc15-c978d28b6e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c398301-686e-4c78-bc2c-cedf726f33b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ba0275-9cf5-409c-84fb-e14b2d3cb2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a6fc6a-26f7-4b69-b4ce-c9a731444cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be101029-5d40-4bd0-ab71-3fdc2aa6fbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8601c36-a632-4475-b1f4-4268f0b27f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c0ce48-5a3a-4960-92d5-3e9f7a774a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9e45fa-58d1-46d5-a270-48c66137f7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edcf26b3-b7a2-4b1a-b5ce-aca7099e6e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd40c784-6615-42fc-ae9e-863bc2b3ae2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0312cacf-1f90-4a4d-978f-43f3c1a32f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1b62ac-a85e-4bfb-a63b-eee404c70af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b482c3a4-d9cf-4281-85f2-57bbabb85867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77821611-d021-42a6-b6b0-e212cbc681e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19338c62-0434-4673-9211-f66230a3303c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99bf35ab-fd5c-4a3f-bce6-e748c11312da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 881bf572-02c1-4e98-8c41-b1b9e55141ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46743a7d-c255-4c34-8003-aa1cade2600c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfb72d46-3dec-4607-ae82-c421bcaa3b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0821e001-bb22-452c-850e-df8f21e359a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c5f91fa-fcb3-4852-b042-9f9e8f7bb396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d12124-d35b-4534-90b2-7c1721e4db76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cf31b63-0dc4-44e2-b7a7-03e3165dc3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad926a2-fdfc-44de-a538-c456633ae9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec54debb-81e9-43bf-b3ec-d7d7cd0ba5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc68cf12-e0f6-4823-95f6-03910559b583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27a9d87-b5df-4c38-9822-199c0bd76e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037def85-1a3a-4eeb-b1c6-e919c205a30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b488a316-28e1-4995-8acc-439e19f9899e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70efb22-b567-45fb-b0c2-cd7afdfffd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b7d7f5-1ec6-4e03-a49f-5a70742e5ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4acb6c9-eb66-45e9-a441-4386530300a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 745babe9-0ab6-433f-9d26-c3ad78ec65e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0ff279-63c7-4a52-bd7d-2dfd97304088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53569aeb-775c-4fd4-a8e7-e1d0118cca75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9a7843-7d12-4155-91ee-75a56faebb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 402655d0-6f6f-4b8d-b398-c52cd7b444c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096c31ca-c298-4616-91ad-670a20ff1498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9a09fd-fc4a-4970-b350-842085f0cd66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44317ac1-5a01-409a-b3c8-bad933fea5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899a7840-096e-4aca-b630-d2db0c352a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7613eb-3c46-48af-9849-474852dc4435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b308632-4a0c-4e06-8e90-056de2f5898e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe805eb5-15d2-4360-92c1-94c01364795e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9294411e-1fdf-44b4-8c23-c5023c609e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d2baa6-11d5-4381-a97f-bee6ae9773db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32cdc887-ca7b-488a-8eac-8be53f5397a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bb8b662-958d-4774-86fc-915b03aa7125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67386623-0451-4527-aa00-0dcdaa8aa66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5524ccb-095c-4e65-9af6-be8252a9e30b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ed21ee-ea5c-409f-b5ad-3b8c0e053a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53f6821-2ed5-4ce5-92e3-f4195f3081b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9f5df0-0bae-406f-b0e0-c372022e3633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4262f6a-0726-48f0-8130-d9f91e5a77e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4581c4f-690f-4afd-9f75-ec9264ce201e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38519532-d210-45a2-986a-25cf92dd5727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c269725-6393-4e7b-8b68-f1801adf245a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a288c45b-eb94-4351-8415-831e526bcff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d400194-dbf2-44f6-9e46-fe001a094d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ea06ca1-cfb2-4af1-a0a1-2b5b2179c917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e667f274-a972-4dd9-82ae-3fd72763fd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf51672-8710-46b2-a4d7-583b2588d066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a00a54b-26d8-4a84-b667-ea32e1e279ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6266477e-a644-48b7-a6d4-c09bf98e8206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed56b8d-239f-4d4c-94f6-ceea4dad63da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c922ae-6258-45ec-a2d5-935f56d0ecf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e0b239-061a-460a-a052-52ed395bca8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032c8600-1733-4227-8511-c470fd72d399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23400d0-5af2-4f81-a47d-be84318256c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90af25a-cb3d-471a-8cfb-53b83ded7900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47f4a60-f7af-4579-af9c-3a9b30ea9170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a1e8fc-97bd-4a18-92c7-2200b8eb62f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d2393a-1b2c-4eb3-9eb7-db2aea7a3703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944a9c8f-f82d-4ad9-9ec2-d6e7c2128771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 638cccdd-a9d8-48fd-9d99-5d42692c45a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32ca1a08-a81b-4d3e-a8cd-e1da5adf833f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec6c6571-c6e7-4c75-8e8b-8ec40a4bc550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d2e5b6c-585a-4962-bc63-a66bf28b7bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45117f55-a4ae-4dd6-aa7b-8e7139a2d8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66f2739-c445-43cc-a5d8-89416804a712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e9bb03a-c5b3-49c2-959b-5b3d0eb09820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f204a30-4e52-44fd-a653-10bc5ef14d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb5ce22b-f9ed-4154-91ef-c38cc0b33bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32854e4b-beac-4711-8155-ad2f9476a4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9796f831-d920-4bbb-975a-0f92e5f67118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb1a510-db92-4dba-b18c-33a7993bd950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af6db523-46e8-4186-ae8f-e46e462af076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a7c6fa-5f72-41be-a754-407302c353d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a71b2f-151c-4a2a-aade-924b69684dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b62f9ac-fc58-4f30-be84-7253654f64e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a750833f-5546-4ca7-8149-95a5568daa9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a9d37b-800e-42f9-9598-89911d0ef05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8869675-7660-4359-805b-d9ec6e0091c0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_26
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_labels.txt

📊 Raw data loaded:
   Train: X=(1231, 24), y=(1231,)
   Test:  X=(308, 24), y=(308,)

⚠️  Limiting training data: 1231 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  299 samples, 5 features
✅ Client client_26 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2598, R²: -0.0001

📊 Round 0 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2599, R²: 0.0000

============================================================
🔄 Round 4 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0752 (↓), lr=0.001000
   • Epoch   2/100: train=0.0836, val=0.0750, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0832, val=0.0748, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0830, val=0.0745 (↓), lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0743, patience=1/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0802, val=0.0734 (↓), lr=0.001000
   • Epoch  21/100: train=0.0742, val=0.0746, patience=10/15, lr=0.001000
   📉 Epoch 22: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 4 Summary - Client client_26
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0518
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0392
============================================================


============================================================
🔄 Round 5 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0666 (↓), lr=0.000500
   • Epoch   2/100: train=0.0856, val=0.0664, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0854, val=0.0663, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0851, val=0.0663, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0850, val=0.0662, patience=4/15, lr=0.000500
   • Epoch  11/100: train=0.0844, val=0.0656, patience=3/15, lr=0.000500
   • Epoch  21/100: train=0.0830, val=0.0640, patience=2/15, lr=0.000500
   • Epoch  31/100: train=0.0808, val=0.0624, patience=3/15, lr=0.000500
   • Epoch  41/100: train=0.0772, val=0.0621, patience=7/15, lr=0.000500
   📉 Epoch 44: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0621)

============================================================
📊 Round 5 Summary - Client client_26
   Epochs: 49/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0774
   Val:   Loss=0.0621, RMSE=0.2492, R²=0.0870
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2598, R²: -0.0017

📊 Round 5 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2599, R²: -0.0038

📊 Round 5 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2597, R²: -0.0036

============================================================
🔄 Round 14 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0920 (↓), lr=0.000250
   • Epoch   2/100: train=0.0784, val=0.0920, patience=1/15, lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   • Epoch   3/100: train=0.0781, val=0.0918, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0776, val=0.0918, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0775, val=0.0919, patience=4/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0770, val=0.0923, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 14 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0241
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0111
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2597, R²: -0.0038

============================================================
🔄 Round 15 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0753 (↓), lr=0.000063
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   • Epoch   3/100: train=0.0819, val=0.0754, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0818, val=0.0753, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0818, val=0.0753, patience=4/15, lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0816, val=0.0751, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 15 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0101
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0386
============================================================


============================================================
🔄 Round 16 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0758 (↓), lr=0.000016
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0825, val=0.0757, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0824, val=0.0757, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0824, val=0.0757, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0823, val=0.0757, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 16 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0124
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0207
============================================================


============================================================
🔄 Round 17 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0894 (↓), lr=0.000004
   • Epoch   2/100: train=0.0788, val=0.0894, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0788, val=0.0893, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0788, val=0.0893, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0788, val=0.0893, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0787, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 17 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0133
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0106
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2596, R²: -0.0038

============================================================
🔄 Round 18 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 18 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0203
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0345
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

============================================================
🔄 Round 19 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 19 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0159
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0033
============================================================


============================================================
🔄 Round 20 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 20 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0181
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0139
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 20 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 24 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 24 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0094
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0269
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 29 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 29 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0094
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0269
============================================================


============================================================
🔄 Round 31 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 31 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0138
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0081
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 31 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 31 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 31 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 31 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 31 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 38 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 38 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0157
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0010
============================================================


============================================================
🔄 Round 40 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 40 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0148
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0002
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 41 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 41 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0164
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0011
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 42 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 42 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0160
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0016
============================================================


============================================================
🔄 Round 43 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 43 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0199
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0242
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 47 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 47 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0163
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0007
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

📊 Round 47 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 50 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 50 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0190
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0185
============================================================


============================================================
🔄 Round 51 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 51 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0142
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0092
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

📊 Round 51 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 54 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 54 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0081
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0202
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 60 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 60 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0095
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0137
============================================================


============================================================
🔄 Round 63 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 63 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0150
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0048
============================================================


============================================================
🔄 Round 65 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 65 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0118
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0195
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 65 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 65 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 65 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 69 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 69 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0174
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0148
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 75 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 75 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0162
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0165
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 76 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 76 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0154
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0013
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 78 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 78 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0172
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0553
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 79 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 79 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0110
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0183
============================================================


============================================================
🔄 Round 80 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 80 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0177
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0190
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

📊 Round 80 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

📊 Round 80 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 83 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 83 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0174
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0068
============================================================


============================================================
🔄 Round 84 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 84 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0065
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0365
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 86 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 86 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0128
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0144
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 87 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 87 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0166
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0001
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 89 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 89 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0170
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0024
============================================================


============================================================
🔄 Round 91 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 91 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0089
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0055
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 94 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 94 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0154
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0037
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 95 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 95 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0093
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0298
============================================================


============================================================
🔄 Round 96 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 96 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0101
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0237
============================================================


============================================================
🔄 Round 97 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 97 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0141
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0088
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0033

============================================================
🔄 Round 98 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 98 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0130
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0039
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 102 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 102 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0163
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0048
============================================================


============================================================
🔄 Round 103 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 103 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0074
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0343
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 107 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 107 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0185
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0153
============================================================


============================================================
🔄 Round 108 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 108 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0145
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0023
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 109 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 109 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0071
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0391
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 112 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 112 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0066
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0144
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 114 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 114 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0158
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0050
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 116 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 116 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0168
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0020
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 116 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 120 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 120 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0137
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0052
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 122 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 122 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0077
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0324
============================================================


============================================================
🔄 Round 123 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 123 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0216
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0166
============================================================


============================================================
🔄 Round 125 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 125 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0139
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0113
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 127 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 127 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0107
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0116
============================================================


============================================================
🔄 Round 128 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 128 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0163
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0047
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 129 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 129 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0123
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0162
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 133 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 133 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0148
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0067
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 133 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 138 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 138 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0075
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0364
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 139 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 139 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0159
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0056
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 139 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 141 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 141 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0139
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0100
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 142 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 142 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0137
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0102
============================================================


============================================================
🔄 Round 143 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 143 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0127
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0094
============================================================


============================================================
🔄 Round 145 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 145 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0237
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0343
============================================================


============================================================
🔄 Round 146 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 146 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0185
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0163
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

============================================================
🔄 Round 150 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 150 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0094
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0238
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

📊 Round 150 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

============================================================
🔄 Round 152 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 152 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0183
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0050
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

📊 Round 152 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

📊 Round 152 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 152 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

============================================================
🔄 Round 157 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 157 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0109
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0229
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

📊 Round 157 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

============================================================
🔄 Round 160 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 160 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0082
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0153
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 160 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 162 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 162 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0139
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0066
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

📊 Round 162 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 164 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 164 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0115
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0161
============================================================


============================================================
🔄 Round 165 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 165 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0189
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0193
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 166 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 166 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0245
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0380
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 166 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 166 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 176 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 176 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0194
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0124
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 180 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 180 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0047
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0263
============================================================


============================================================
🔄 Round 182 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 182 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0116
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0164
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

📊 Round 182 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0035

============================================================
🔄 Round 185 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 185 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0139
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0093
============================================================


============================================================
🔄 Round 186 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 186 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0192
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0225
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

============================================================
🔄 Round 187 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 187 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0123
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0174
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

📊 Round 187 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2596, R²: -0.0034

❌ Client client_26 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
