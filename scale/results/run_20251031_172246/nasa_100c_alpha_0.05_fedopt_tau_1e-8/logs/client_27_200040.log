[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3db6861-fc50-40b4-ba41-312075828ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72673523-a65d-49af-996d-6d0bde499608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 169e9f52-8f74-4fed-b6c8-f019a1bfe526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fda5c67-6d9d-4451-9e2f-970b5dfebb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca52567-3ff7-47ac-813a-5fb20a02896f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9093622f-0d42-4d5e-83c4-df8438fa73a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe22324-cdff-4bdb-a4aa-ca6a501f7a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a92c874-36b6-477c-a69f-f6a3659538df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67e2697c-5b37-45c9-a526-3f0ded9f54e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f630d91b-db91-4715-8f2a-73805b0b52ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d260cd-c4a9-4c39-a0c7-46d633830a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66501ae-bc04-4964-a185-add73c7126c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd80528-31f7-4b22-9f64-5ae7889db385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17b20ea-13f8-4715-92f0-407bfe805e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa60f70c-104e-4209-ac53-c712db460825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55cf3f4f-27f5-497b-b599-2a7f52e1e7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dda0ec3-0522-486b-8b27-ce430fccebd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6ebdcd-16a6-4fc7-91c0-2a2ce4b797bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c416c9-a36e-46d6-837d-37af9205afcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4384b29d-c7d2-4671-b13b-5b36bf26f850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb776b5d-a94b-460d-8fc5-92d3fcf6ff27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34afd701-b713-4c99-aea4-8c88050e37e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4390fa45-d99a-4bef-b143-e81349c5a84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 625369de-e5d0-49d1-914f-ab62949df996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28932d1c-bb2f-42af-9318-97fa74928f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14fcaf2-72ca-4d34-af69-288738e5fc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9affadcc-c8c8-4595-a004-18d7c97c5fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a5144a-29bd-4c9d-8068-02eb49b41d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b80b1c17-7d45-4541-aed8-8d19113367a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30fc2ea-02bb-4428-bb76-e9faf38a0435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9708651-4258-470b-8ab3-e1f784a0199d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7366b3f9-5865-4d2b-8826-e8b987e22038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14bccc7a-2610-4326-9bf7-76451820da45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012d716a-bafd-4e3d-a851-d8f55a5acac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa30549-46f8-4074-9029-ad7781021e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80180c6c-282e-4a9a-ad2b-c233bdadbc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a342113-78e7-4340-9eda-1a1655c83906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e510a77-65b8-4e24-a0f4-6443b66e8975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5740e484-563b-4ebb-b540-de6755f6a36b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016b85a0-1eab-4aa3-8f41-b03e685a2fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb126e05-c35e-4643-890a-65ee4779886e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cd8b381-424c-4f2e-81ff-774d95a4274c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f322c4a-78e7-4ec2-9882-42b370e0d384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d222fac6-13ff-4521-a39c-d2ca35985468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4800868-4790-4a55-b243-abdbac797a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489baecc-b1b0-4344-b444-f795c243d1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34566661-3c55-40f3-8e62-48f5554eb89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41d8fc3-b3e2-45f9-9479-34cf83f13a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dae100-ef5f-47d9-b889-2d90371b0ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6990e6fc-152b-46c5-af6f-5947ad3bd203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94a7a04d-94cd-437b-b845-5d432034fd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c23f0b-48df-4546-8085-991a80457a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c46d046b-e75e-4c8f-8339-549690e4dc1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0824f2-b5e7-459b-9e3f-e8388f059e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598f474c-73fb-48e3-9d14-e83e7c204061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5319ff3-95dd-4745-b59a-5491b7d9f28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a8154d-7692-4fa3-9b99-ea0ef2d48fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c7f8756-5078-482d-9821-c52e099420e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d55f37-dbc7-4c74-ad7e-fa1ed5fb9561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0dc4ca-534a-4d34-82c8-8c23fd404b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb05c83e-14c9-4b07-a795-38828929b9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e81ba285-fdb6-4d8c-a3d8-2ed6814b068a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df1b2f6-8a8f-40b9-a465-76206d23ff9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e57837af-7880-47b4-9b34-7764fc148879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02000221-7a74-4fb8-ac62-225fccf19b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b53f21-942a-4c05-b61d-e99c4f00c8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ce47c6-7863-460b-bf2f-397459978a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7674558-846a-4ebc-b0ce-5acc271bc99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4beb43e9-3044-4d0c-a86b-abbff875d92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd13f8f-6c7f-440f-8c5a-0f68857f02bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd5b283c-7375-4d94-9d6b-7fb346d0af31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ffb0b4d-2f10-4c96-83fe-6e84d5d012e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75f40caa-63b3-4ad0-8dc1-7be072a57d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88605f3a-a0bd-416d-a908-648a1c5fc9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49572a65-f273-46be-9dd2-2593c53af323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44568233-171a-46f2-8c9a-8fa11979f92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 449b4eb9-6650-4b3f-af76-7ff76ac34f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0eebfa4-5a99-4cf7-85d7-d57fbdc55619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271c7d18-fbf5-4296-a70d-ad685df012e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab2d349-7392-49a2-81d0-64ee1d657374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cc46e8-2794-4e47-8cc5-ff7141b60428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 766bef3a-5990-4898-bb94-a3978ed54f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cd57dff-a356-4992-b59b-a66fe260285e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63eef3a1-4b08-45ed-b9f6-b7a2b8b07e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 162cf5f1-7ba1-4226-8545-bbd438a9da01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ea198a-6100-471e-b707-f20362b8b09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4b632b-30bb-4de3-bef4-28b1900b970e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51ff008-90f0-4f19-bb89-d78a612a5a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1faa4f95-5df2-423c-807c-7acec8e6f55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9078da9e-57e4-465c-a6b2-4b144cc2243d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f34998-0595-440c-b217-b3b4f0c1fd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a226ac5d-37fc-4c01-a696-da33f77289c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1efeb123-47eb-4328-9cc3-d1660ff32aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c435a496-aaab-47c5-bcd5-436c6f9cb4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fe2c8d-4f20-4c81-8229-5c8a6c9d7aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814a41e5-abbd-416b-80c0-a1e775aa2d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ee7634-bd45-445c-b8e4-9ed8973458c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a485cb8b-0950-49d4-9cbe-5c2a01ab9c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d55bef6-4f83-4443-a3b0-ffb40bb38f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 914690f5-1c69-48a7-aa60-4af53bcbf43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4fc80a-7c4b-40bf-96c8-9c2c8b283407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb596bbe-fcb6-4731-899c-3996cd32768a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565da61f-ab3a-4445-b2fc-4393b76cbbb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7423671-a659-48c4-8d28-8266d6577ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee8aedc-4a0c-4b1a-829e-a420aea4199b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c46b8f8b-b05b-43ec-a234-437a72326376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e514a768-407f-4c70-baa8-342710b9fbfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4a2137-e0fd-4414-80f1-628461551f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 648daf87-30d7-4f80-b586-d9e783ae85b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69e790b-f2d8-45a5-ab4a-536461b65acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16cb602b-e095-41ec-bfe6-cedbad90ebde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f564893-e91f-4f55-8092-f4436962b8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d24346f-5cbc-4ff3-a8d8-f25e75d1d010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61535c6d-56bd-4f86-a240-2e71e23f5a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 172f8c18-0b38-42e3-8db2-43781b391198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8730ac-4985-4b29-8ade-5d702093b0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59fb2868-9143-450e-a415-5d49fbfe3adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 093ae365-1e63-4df6-920c-1ac68e346a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f5f5eb1-0107-42ea-90bf-a230a0cc35f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40465e89-be2d-4b1c-8ad2-ff5eb62db60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc25ad2-2fc7-4765-949c-3c41155d240d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5be9c0a-561e-4882-88ac-f1414b086c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da92d2a-7d37-441b-960e-49ed3ae84580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31186ff1-d660-4394-bd49-7ded353d5bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0a3bdfb-ef76-4010-87bd-9bc16c8175d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf41eb1d-020a-4d18-b2c2-a14bff778ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 775b21d0-d21f-485a-94ad-ccc2a60e8d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d029c52b-034d-4d00-ad6c-c9cd7aeca11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56b899b4-10b3-4564-845d-976bfc859164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d4afa7-f3a0-4727-a98d-3f5a446a8a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cafd5d0-7690-4774-8a87-86b5f3ade616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d529b94-151a-44e9-87e2-fefb7e1db67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b05dacf-3a65-4dad-8bf0-9a50dfde1111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3391940c-2940-448d-9a0d-175efe44f2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bca5155-4e3d-4608-a081-1afbf1e98ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e01cd91-9cba-49be-80ea-d851794c6951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aced7b0-1a36-4ab6-9aac-ef4a377934c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d07b7f-39db-4c9c-9a0e-80b259f13b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524b5813-a148-4a79-a2e0-ff6092692cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d00bc6e-2316-410e-953e-a3de9967b0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5390e2-b844-4d7d-b209-b068fb5ab7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b498efb8-1564-4261-ac0d-a28db1ab688f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e591ee9c-d09c-4b36-9293-5570eb311300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a941e91f-ad91-466d-9610-3ef80c6bef99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf4c4aee-3ef5-4256-a840-b3723a2e910c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e97967f2-4b34-433f-a404-56c8dd929cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0d0e75-9be2-4057-b2fc-e29a33064aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b914b9-fb90-463b-835e-43d943434f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3fba1c4-7c6f-4b97-9655-2073c4c8726c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3273cd3c-dcbd-4393-8a8a-b887797b36e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10909c11-51f3-4332-907c-463f8fa3c71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2177ddb-9c89-4609-a781-1de15001baa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c02f5b-3466-4a91-89e7-02d7a389e1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 290c6fb4-d12d-4427-b36d-91433f4c5222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608fb892-467a-4e7c-aeb9-d2ffa8d4ba86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eee9e5a-73f1-4e23-b250-231040d6543c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_27
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/test_labels.txt

📊 Raw data loaded:
   Train: X=(999, 24), y=(999,)
   Test:  X=(250, 24), y=(250,)

⚠️  Limiting training data: 999 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  241 samples, 5 features
✅ Client client_27 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2610, R²: 0.0026

📊 Round 0 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2606, R²: 0.0046

============================================================
🔄 Round 3 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0821 (↓), lr=0.001000
   • Epoch   2/100: train=0.0799, val=0.0841, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0799, val=0.0852, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0796, val=0.0854, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0781, val=0.0835, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 3 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0113
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0076
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2605, R²: 0.0056

📊 Round 3 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2595, R²: 0.0104

============================================================
🔄 Round 6 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0734 (↓), lr=0.000250
   • Epoch   2/100: train=0.0817, val=0.0735, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0815, val=0.0738, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0813, val=0.0740, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0811, val=0.0742, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0753, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 6 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0159
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0011
============================================================


============================================================
🔄 Round 7 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0870 (↓), lr=0.000063
   • Epoch   2/100: train=0.0786, val=0.0869, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0786, val=0.0869, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0785, val=0.0868, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0785, val=0.0868, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0782, val=0.0867, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 7 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0130
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0086
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2583, R²: 0.0162

============================================================
🔄 Round 9 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0810 (↓), lr=0.000016
   • Epoch   2/100: train=0.0797, val=0.0810, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0797, val=0.0810, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0797, val=0.0810, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0796, val=0.0810, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0795, val=0.0811, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 9 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0177
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0068
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2583, R²: 0.0173

📊 Round 9 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2582, R²: 0.0188

============================================================
🔄 Round 13 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0758 (↓), lr=0.000004
   • Epoch   2/100: train=0.0806, val=0.0758, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0806, val=0.0758, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0806, val=0.0758, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0806, val=0.0759, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0806, val=0.0759, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 13 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0169
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0249
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0195

============================================================
🔄 Round 14 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 14 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0223
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0059
============================================================


============================================================
🔄 Round 16 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 16 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0176
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0273
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0196

============================================================
🔄 Round 19 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 19 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0161
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0279
============================================================


============================================================
🔄 Round 24 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 24 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0170
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0247
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

📊 Round 24 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

============================================================
🔄 Round 26 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 26 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0195
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0091
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

📊 Round 26 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

📊 Round 26 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

📊 Round 26 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

============================================================
🔄 Round 31 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 31 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0199
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0071
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

============================================================
🔄 Round 33 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 33 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0205
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0152
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

📊 Round 33 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

📊 Round 33 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

============================================================
🔄 Round 39 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 39 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0227
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0086
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

============================================================
🔄 Round 42 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 42 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0157
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0190
============================================================


============================================================
🔄 Round 45 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 45 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0184
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0076
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 48 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 48 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0162
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0306
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0197

============================================================
🔄 Round 50 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 50 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0207
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0165
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 51 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 51 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0211
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0026
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 53 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 53 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0192
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0218
============================================================


============================================================
🔄 Round 55 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 55 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0200
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0169
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 56 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 56 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0240
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0028
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

📊 Round 56 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 60 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 60 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0231
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0043
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 61 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 61 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0169
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0222
============================================================


============================================================
🔄 Round 63 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 63 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0181
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0214
============================================================


============================================================
🔄 Round 64 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 64 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0120
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0480
============================================================


============================================================
🔄 Round 65 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 65 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0193
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0133
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

📊 Round 65 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 70 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 70 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0156
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0336
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

📊 Round 70 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 73 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 73 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0206
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0123
============================================================


============================================================
🔄 Round 75 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 75 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0217
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0290
============================================================


============================================================
🔄 Round 77 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 77 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0234
   Val:   Loss=0.0668, RMSE=0.2585, R²=-0.0178
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 78 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 78 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0116
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0393
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 78 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 78 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 81 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 81 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0173
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0255
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0198

============================================================
🔄 Round 88 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 88 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0224
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0082
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 88 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 88 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 88 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 88 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 96 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 96 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0220
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0031
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 99 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 99 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0208
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0163
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 100 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 100 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0181
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0257
============================================================


============================================================
🔄 Round 102 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 102 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0187
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0235
============================================================


============================================================
🔄 Round 103 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 103 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0154
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0239
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 103 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 105 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 105 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0308
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0218
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 105 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 111 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 111 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0214
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0070
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 112 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 112 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0164
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0315
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 113 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 113 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0205
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0166
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 113 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 115 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 115 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0225
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0060
============================================================


============================================================
🔄 Round 116 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 116 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0229
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0009
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 116 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 116 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 123 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 123 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0180
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0207
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 124 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 124 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0230
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0069
============================================================


============================================================
🔄 Round 126 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 126 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0190
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0016
============================================================


============================================================
🔄 Round 127 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 127 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0196
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0137
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

📊 Round 127 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 130 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 130 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0160
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0347
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 132 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 132 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0235
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0072
============================================================


============================================================
🔄 Round 133 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 133 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0197
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0206
============================================================


============================================================
🔄 Round 136 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0618 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0618, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0618, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0618, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0618, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0618, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0618)

============================================================
📊 Round 136 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0182
   Val:   Loss=0.0618, RMSE=0.2485, R²=0.0242
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 142 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 142 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0231
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0025
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 142 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 148 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 148 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0207
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0166
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 148 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 150 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 150 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0137
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0335
============================================================


============================================================
🔄 Round 152 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 152 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0257
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0075
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 152 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

📊 Round 152 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 155 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 155 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0219
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0082
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2581, R²: 0.0199

============================================================
🔄 Round 158 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 158 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0193
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0091
============================================================


============================================================
🔄 Round 159 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 159 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0093
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0433
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 160 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 160 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0148
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0391
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 161 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 161 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0194
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0189
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 164 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 164 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0169
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0326
============================================================


============================================================
🔄 Round 168 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 168 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0251
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0135
============================================================


============================================================
🔄 Round 169 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 169 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0139
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0295
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 172 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 172 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0191
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0037
============================================================


============================================================
🔄 Round 173 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 173 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0142
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0403
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 176 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 176 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0244
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0000
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 178 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 178 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0162
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0322
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 179 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 179 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0236
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0015
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 180 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 180 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0191
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0080
============================================================


============================================================
🔄 Round 184 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 184 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0175
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0300
============================================================


============================================================
🔄 Round 185 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 185 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0190
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0065
============================================================


============================================================
🔄 Round 186 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 186 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0215
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0132
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 187 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 187 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0244
   Val:   Loss=0.0709, RMSE=0.2664, R²=-0.0010
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 188 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 188 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0228
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0020
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

============================================================
🔄 Round 189 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 189 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0150
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0394
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2581, R²: 0.0200

❌ Client client_27 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
