[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf2a728-a272-4475-a7e2-ee2ca833c5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa6a656-f994-4102-b14c-151e57d54955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8484f9b9-8ec1-43bc-b77d-ac4b14b36d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36677ea-e20f-46ac-a2c1-ece32529d0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6799a74-517f-41dd-81a8-885a3f34a85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5238cd-c72e-4aad-9024-f19caeae31f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d25e55-c35e-4611-821b-01c00ad04dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76c15d9-d842-4dac-bd86-5bbbb380952a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07a69461-de31-43a6-af4a-fb628c4927c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d140d48a-54da-496b-9720-e00c9c3617f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34336c35-6d2f-4cf6-8cdf-9515109e188f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f55fb14b-9c3d-43b4-b7de-19eca5d454a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628074d7-d91c-449b-852c-a8f4fd1cf2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b7e599f-337d-4548-bb12-ab797575da15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 142e7176-eb90-46b1-99f4-b023b429a104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a08c2f2c-f936-4eac-b6cf-f88677e21cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0017fc94-6988-4e81-b8cd-ba41507125ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44091f0f-8684-4a18-8a34-fa4ccb0a1f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ef518a-6281-47d8-b8ef-23d5a9ecd571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92bc63ff-5bbe-4159-ba51-c8adbaf31dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbed3ba9-ae9c-468f-9722-76c8444535ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bbb8d8-2496-4211-a12f-d4938390b789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee4fbf03-a7bf-4d1d-b9a6-5d5b1abb5a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7900061-7399-4c90-a1cd-dc6b680f2758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5f8a12b-b4e0-4c1a-8d4d-0c05ddbdea77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b3c2ac-5be0-43f9-834f-fbd5d1e40f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64fc8eb0-0ef7-42e4-aedf-fa699d1c681b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6a809e1-56f2-4b47-be9e-e304a0fe75fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377dc976-d00c-4ef3-a628-71e4018cd07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164fa1e7-8f80-4868-a2e6-70200a4c9c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ddfaaca-a9c5-4069-ab4e-52695521d1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b2f62e7-6e6a-4481-9fe7-00e7b29b3640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486c97d5-3cb4-4ff5-9c7a-13b138182ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83ccfa6-ae5f-4f51-8153-54bef249f26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0daaf2bc-f9a0-4285-ac4f-8731c8c3929d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964a2276-414c-49f8-a632-727b80d1342d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6010c2d4-1fdd-4303-851a-ceddfa07b1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8996f871-18ba-44bd-bc79-c09261f408a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9778b414-2d7a-4175-a4db-18cf74ea934f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ea88ba4-52e3-4e8d-893f-48671e6ca16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1a9ee6f-3c7d-4d57-8e8d-e712ab678544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36fbabfb-4911-4a28-9749-d91d11a74043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8834a9db-fa43-46d0-8de7-3e1850d7cfde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3558cb79-712c-41f7-b75e-7450f802690e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ca1368e-8907-4eb6-bc7b-1a5d9643f20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c38b66e-4d47-4d0a-9680-10e9afbb2c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 609244ba-9dc6-4f6c-839b-95565144bc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11aded82-d351-44d5-9fcf-57235fc6e6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ca8405-2771-4ef1-b04b-594e34279d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46806af4-cf4c-42a0-8945-7287e879ca54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e6c21b-4a5e-44d1-a85f-9645926bcfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d12815-7fcd-4e97-b02a-95c124be7d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0073afb3-c263-4f59-9e06-e1f72d0cb952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ccaa7f-7a71-4bfd-bc78-9ac4cc593fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf78660-61b6-4968-b62c-d8a54304a897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d111644-202c-46dc-ad1e-e877182e9123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a80cb9d-056c-43af-8db6-57bfb7602bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3cc2b6-712b-4504-b6c5-fd915eed36db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c7ac5f-be5f-498e-ba38-b60b67f6c79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b9e32d-3f88-43b0-93c7-59209d24baa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b65212f-0fa7-48f0-9a17-4cb87f850a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec32cd8-e297-4db7-a2e7-5aa67d440710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 071d05f7-8528-42ff-b863-2c2f0e8993a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8ad5fc-047c-4d75-a60f-ff7fd8067600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03eba663-ae4f-4577-803a-fd1a08f8fd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838be5bf-57ad-44b2-b8a9-ff081212127b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26310b29-b198-4a96-b58f-06a8a711f9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb3a1db7-ca2c-4cce-bcaf-fbb04a34ad2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24aca2f4-e08a-4cd2-b415-f84935c5ea74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf57037d-ad4d-45cb-9f81-9be197d4a6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cfe9a21-2484-4e08-9c0c-f6b30acb0b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a07f8fb-2f90-43b9-a97d-79ceed937c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bef4bd-6752-406d-af23-c2faecd6f3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdfd325c-d31e-48e5-b960-b9fc30574693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61bf05d9-c9a7-472f-93c5-96ce3ab58298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85640b33-3b83-4ec4-8c03-bbfd1fe9dbd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2e6969-4e6c-4d34-94d5-188e4c37bcba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12acad36-8851-4869-b720-83a4a9ccb8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f1b528-04fa-49e6-8291-3a7868bf858d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 476e254b-8969-4d49-b86b-0cd9f67e583c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d57d464-99b2-45b7-bb51-e4556908ca54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc996284-1934-4fdf-9e2a-13441f898f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd2245cb-7367-4912-beba-698d1c87a2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f6c6fb-ee55-4eb0-8003-aff36f3b2abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c247b3-b428-4c4d-a17d-e46c717b9dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067ca482-fc44-4d05-87ea-eccbcad0bd02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528c07c6-84de-4161-b1ec-0cfcef912a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beb72d89-4ca0-4c9f-8049-0325146a88dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc3a506-9561-4395-832e-48fc4885e586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d17a134-bbf5-408b-8061-9801c5e1c994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd0177fb-2f7f-4489-8779-dfabb7dff383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e45ce94-da56-44c3-8198-f325068466da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b848f1-3a58-4932-8190-2062dd008b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56fd8222-e96e-41a8-b7dd-877c82ea9d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5936c049-34d7-4a13-895f-408914691376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57233b64-f511-4c4f-8b7e-e883a9663f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3427ce7-da10-433d-9e75-76e6e7ce81ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bed339a-95f0-4c3a-8bbe-430d4668b723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc91f34f-f215-41ef-987a-cbbb4620cdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f00bc56-7edf-441d-a568-4a4bf400e75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29f6550-7324-456c-a795-673294b6c8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b769c9b-623b-4c92-9ddd-be247dd9a9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b14e380-80b0-4db4-9538-caf0952132b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8341fcda-d1fd-4220-b29f-fc99a5df9fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3ab1d7-716e-4ae8-8613-7fb9685a0723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c331bb-d4ec-4b12-b58b-87fb0dd7daac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2af718e-4dfe-4451-b5a7-4915d5bbd331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d44a045-766d-4fd1-bf4f-465ad43cd76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b35e428b-a02b-4b3b-ae28-615c8064b84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec3eebf-7d02-4f0b-b3dc-2ec38fca2290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb8d413-fbb7-490e-81d6-61a1a3bcc30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db3fc5e-a7b0-4e8f-b3f8-423a9a5de883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b95c00c2-52e8-415d-879b-64bd88d1cf12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79484fa-5131-41ac-9d3e-f707329c6084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fff071f-4a40-4d0f-8aaa-6c332f960153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90b0413-5f7f-4f9c-80f0-d8acabda990e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7fc20d-f94b-4505-a4df-a830488e35fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6df290-f092-4cdb-b1e6-81d68e0a92e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296b3719-b801-4dd9-a23c-95a04ec3a30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3675ca96-ebbc-4477-8ffc-5ed4c799045e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa92a68-6937-403a-9cab-3a2b4adb40f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c29dd23b-3f11-4333-a820-60c1eb2d306e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1dbc7b6-8ba3-4474-af0c-320b34a77c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c616a7-37b8-47a6-99ef-eabebc26f25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6d5092-6309-452d-9ed7-d218cd76f959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170b2c61-0dbd-44d1-b2ed-ffe2111f2620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3478e5-c3a2-4e41-9c8b-d6cc2aecbc56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac678c4-1607-4519-b7b9-40746a6b678f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46bbd904-99fc-4aaa-b284-6767b3bf4183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14efbabe-e8e8-4489-9409-dd9a57fe55df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f112f4-a264-404a-8f30-08bb5b78122c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c686487a-6ba6-412e-b413-4c997e16f485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f41dd7e-345d-437e-a2b6-81e91546b426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 985ada88-b702-496e-9b7b-79078e95c87c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f593a6be-93c3-41a3-8d4c-dcfd9d828c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8615f258-fdde-4107-8b9b-16b1aed02554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 534f1c51-5301-4d41-be4b-8bd73ea56c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b89da94d-422d-4ad1-986f-42514f7066c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f76f38f8-6c12-461a-9677-7b54fec2f8b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86538ce4-352a-4adb-a69e-3ab2b6fec9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2bdebb8-b976-40d6-97fa-32b89cc41030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbce98f2-b6d7-46fb-b12a-955f39a5fb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8956f2c-51d6-4e46-83cf-29124d07884e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e3ce968-ff33-45dc-93b5-ce387549640a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c834f1-86fb-42be-9967-47e5c4575d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca21836-ad76-4439-9712-731061c1f7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad821b9-e6e8-4490-a6bb-ce65448dceac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa4ab45-4e5e-42df-9caf-62498812d7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79fc876b-e2fb-42d5-b66e-56f3faf05181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fecfcce-3165-490b-8c20-bca01893a7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d68ab5a-fc38-4494-925f-706175c77a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6700e37a-2fc1-4c8b-8276-4a1373370fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b34364b-f4dd-48bf-a7e6-c7f913a20da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d835b2-ea93-495b-bcf9-8f62e66ab27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25fc6010-99ee-449a-bec2-7518aea58845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf08afa-0587-4314-a6b3-e816cf52a55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18aca740-5043-486c-b1c4-172ab9c18023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051c62aa-b1c6-4c62-9a1a-7255effce707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c98889ae-eb33-4a02-a59f-97b69bb40ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ac8430-e9e4-4f7a-a0d6-de41f6361879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1886cfdb-cff1-4b28-9cbe-aaca94e4a788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c09ca83-c707-4186-95b9-94a99762aba8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_28
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_labels.txt

📊 Raw data loaded:
   Train: X=(1617, 24), y=(1617,)
   Test:  X=(405, 24), y=(405,)

⚠️  Limiting training data: 1617 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  396 samples, 5 features
✅ Client client_28 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0013

============================================================
🔄 Round 3 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0885 (↓), lr=0.001000
   • Epoch   2/100: train=0.0871, val=0.0901, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0866, val=0.0912, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0858, val=0.0904, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0902, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0845, val=0.0899, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 3 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0035
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0001
============================================================


============================================================
🔄 Round 6 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0820 (↓), lr=0.000250
   • Epoch   2/100: train=0.0869, val=0.0822, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0867, val=0.0825, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0866, val=0.0827, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0865, val=0.0828, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0861, val=0.0830, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 6 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0000
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0163
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2464, R²: -0.0071

============================================================
🔄 Round 10 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0899 (↓), lr=0.000063
   • Epoch   2/100: train=0.0855, val=0.0896, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0853, val=0.0895, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0852, val=0.0893 (↓), lr=0.000063
   • Epoch   5/100: train=0.0851, val=0.0892, patience=1/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0847, val=0.0889, patience=7/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 10 Summary - Client client_28
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0005
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0057
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2463, R²: -0.0079

============================================================
🔄 Round 11 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0802 (↓), lr=0.000016
   • Epoch   2/100: train=0.0883, val=0.0802, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0883, val=0.0802, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0882, val=0.0802, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0882, val=0.0802, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0879, val=0.0801, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 11 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0072
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0132
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0069

📊 Round 11 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0069

📊 Round 11 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2463, R²: -0.0075

============================================================
🔄 Round 16 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0875 (↓), lr=0.000016
   • Epoch   2/100: train=0.0862, val=0.0875, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0860, val=0.0876, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0859, val=0.0876, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 16 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0077
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0264
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2463, R²: -0.0075

============================================================
🔄 Round 18 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0952 (↓), lr=0.000004
   • Epoch   2/100: train=0.0846, val=0.0952, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0846, val=0.0952, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0845, val=0.0952, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0845, val=0.0952, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0845, val=0.0951, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 18 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0078
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0125
============================================================


============================================================
🔄 Round 19 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 19 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0073
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0237
============================================================


============================================================
🔄 Round 20 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 20 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0082
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0279
============================================================


============================================================
🔄 Round 21 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 21 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0065
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0238
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 23 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 23 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0113
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0016
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 25 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 25 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0031
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0515
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 25 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 25 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 30 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 30 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0152
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0035
============================================================


============================================================
🔄 Round 32 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 32 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0045
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0331
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 34 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 34 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0109
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0011
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 36 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 36 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0058
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0199
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 39 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 39 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0057
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0229
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 40 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 40 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0067
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0217
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 41 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 41 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0109
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0013
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 41 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 41 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 41 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 41 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 41 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 50 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 50 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0078
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0128
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 52 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 52 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0077
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0143
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 52 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 56 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 56 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0087
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0099
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 58 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.1023 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.1023, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.1023, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.1023, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.1023, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.1023, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1023)

============================================================
📊 Round 58 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0085
   Val:   Loss=0.1023, RMSE=0.3199, R²=-0.0096
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 61 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 61 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0130
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0066
============================================================


============================================================
🔄 Round 64 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 64 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0058
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0237
============================================================


============================================================
🔄 Round 65 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 65 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0099
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0070
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 66 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 66 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0167
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0007
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 67 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 67 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0073
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0258
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 69 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 69 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0062
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0339
============================================================


============================================================
🔄 Round 70 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 70 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0076
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0134
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 71 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 71 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0136
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0024
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 71 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 71 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 74 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 74 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0074
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0150
============================================================


============================================================
🔄 Round 76 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 76 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0020
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0373
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 76 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 78 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 78 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0026
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0353
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 78 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 78 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 78 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 82 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 82 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0092
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0113
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 83 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 83 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0093
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0299
============================================================


============================================================
🔄 Round 84 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 84 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0028
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0363
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 84 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 84 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 84 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 84 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

📊 Round 84 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 96 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 96 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0095
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0102
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0070

============================================================
🔄 Round 97 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 97 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0099
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0062
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 98 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 98 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0125
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0039
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 98 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 98 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 98 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 106 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 106 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0056
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0217
============================================================


============================================================
🔄 Round 107 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 107 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0080
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0138
============================================================


============================================================
🔄 Round 108 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 108 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0068
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0227
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 109 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 109 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0121
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0002
============================================================


============================================================
🔄 Round 110 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 110 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0097
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0046
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 113 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 113 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0073
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0188
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 114 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 114 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0089
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0100
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 115 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 115 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0117
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0033
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 119 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 119 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0035
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0342
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 121 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 121 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0161
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0185
============================================================


============================================================
🔄 Round 122 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 122 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0027
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0441
============================================================


============================================================
🔄 Round 123 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 123 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0038
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0289
============================================================


============================================================
🔄 Round 124 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 124 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0096
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0092
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 124 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 124 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 129 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 129 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0053
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0244
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 129 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 134 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 134 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0112
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0012
============================================================


============================================================
🔄 Round 135 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 135 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0099
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0184
============================================================


============================================================
🔄 Round 136 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 136 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0103
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0113
============================================================


============================================================
🔄 Round 137 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 137 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0144
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0119
============================================================


============================================================
🔄 Round 138 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 138 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0071
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0235
============================================================


============================================================
🔄 Round 139 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 139 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0133
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0077
============================================================


============================================================
🔄 Round 140 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 140 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0144
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0241
============================================================


============================================================
🔄 Round 141 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 141 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0066
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0273
============================================================


============================================================
🔄 Round 142 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 142 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0068
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0224
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 145 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 145 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0103
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0169
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0072

📊 Round 145 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0072

============================================================
🔄 Round 148 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 148 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0083
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0111
============================================================


============================================================
🔄 Round 150 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 150 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0075
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0255
============================================================


============================================================
🔄 Round 152 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 152 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0125
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0169
============================================================


============================================================
🔄 Round 153 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 153 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0122
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0447
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0072

============================================================
🔄 Round 156 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 156 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0082
   Val:   Loss=0.0966, RMSE=0.3107, R²=-0.0113
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0072

============================================================
🔄 Round 157 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 157 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0139
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0104
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0072

📊 Round 157 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 164 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 164 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0136
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0029
============================================================


============================================================
🔄 Round 165 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 165 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0058
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0359
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 165 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 168 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 168 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0101
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0078
============================================================


============================================================
🔄 Round 169 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 169 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0106
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0020
============================================================


============================================================
🔄 Round 171 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 171 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0067
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0212
============================================================


============================================================
🔄 Round 173 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 173 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0098
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0077
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 173 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 175 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 175 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0094
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0174
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 175 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 179 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 179 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0043
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0275
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 179 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 179 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 186 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.1011 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.1011, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.1011, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.1010, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1011)

============================================================
📊 Round 186 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0098
   Val:   Loss=0.1011, RMSE=0.3179, R²=-0.0058
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

📊 Round 186 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2462, R²: -0.0071

============================================================
🔄 Round 190 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 190 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0178
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0169
============================================================


❌ Client client_28 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
