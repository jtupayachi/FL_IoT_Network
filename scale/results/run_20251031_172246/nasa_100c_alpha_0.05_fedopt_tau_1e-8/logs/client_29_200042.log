[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3afa4e66-1156-48eb-b065-7ba1c9f0c257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e4d44a-cdc9-464d-927b-10280d80daf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad186fcf-d32e-4b68-bc8a-4386eeda9aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c4003d-b393-49fb-8d2c-95780b3606b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfcaedb0-47b4-4e22-b904-cd4c28d12922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626ea3b9-ec06-46f0-a8ba-67dc0ebee002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce1a7e5-42cc-4863-ad8c-7b10843d3fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5c57dc-426b-4063-85e2-98b87de8f568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fdcc251-0f9f-4ae9-9dd5-47250b6ba2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eaf3d47-cc9d-4cc1-9d6a-30c4386715d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9558dc1-7d2b-452f-aa0f-3f813876b049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d323f143-665a-4a59-9b22-e0843f201285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e916cea9-e77b-4fcd-93ef-99e258ceeb15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e32c02-88c6-4f61-87a3-e3b0daf7cf4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd14eeb0-b1dc-42dc-a8bf-807a3acc6b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db76951f-7f5b-4294-8839-b442a8477e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40bcfc9b-53b8-4045-a178-48b4d1c00ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d6c31c-d7b7-4af8-92cd-2c510e63b6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1cda82-f58b-43aa-9f2f-6cc882d820e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a65c8b-f199-479b-8856-825d04b96647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ee9a97-b5df-45b4-a7c8-d1224771960b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b623701-f6cd-42df-a404-d65b12cc37e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18f3ae7-9ffa-4174-8a43-a881267a5802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d8d5677-b1b8-457e-9122-93996bd0d07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6448cc5d-6d71-466f-a09d-74e903e3ddf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3beac9fd-a63b-45ff-b685-9705567df163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 691fb5bf-60be-4a2a-a79a-0894841c081d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba5b2f4-a522-466e-b042-0004c16670e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f784cdaa-04dc-4606-9e12-683f67709f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03caf06b-87bd-492e-8b17-b40546f8d4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24cf5573-e937-46c5-826d-da141076783e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837c1a02-88f4-499b-9c34-4333fe33d147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3edc69f-07a8-48b7-bd40-f0ad9710f105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf1a80f-e703-4455-b63f-8b5bb3739d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8601b60-80e4-4dc0-ba5a-d9f782d1d5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3f9be44-7d7d-46b8-b886-fc9ad91205bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413f27f3-34f7-4f0b-bb0b-a44bc87f1f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 066804c7-8122-4b83-a9a0-28fa01611a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f827a0a9-bc35-4d48-9ff9-8a67dc445a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6568755a-3d14-45d1-9d2f-4bace7df77f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622ad644-7c89-4967-abb7-827ce5f1177d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5bbc9b-6955-4e60-8bf3-aa490ab86217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19b0b5c-3724-419d-a842-2a1c8d91456f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e70bd8-2dc7-407c-8ed8-117dd1b72095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a5ad96-a87d-405c-97ad-fe6dd6edb429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b5cb41-2626-4d54-a307-ad8cb8c266e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aeb3b0b-d9f4-4d77-a0c9-59ce33b14099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9e6bfdc-4754-4bdb-bf45-7abc9b227979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a955c99-2fed-4a01-b69a-c34a3fdbd60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e713f27-4739-4904-9f3b-1789e951cbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859bff78-4c9a-4eb5-8de7-948fc0fe01ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76c891e-ffd4-4285-8a0b-08e0957c477c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e9e92d-caf3-4e16-a4ff-e23af8adeb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd8db3b-8c2f-4101-9d84-4d592909d506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e8581a1-1070-49ae-bc87-12ff4ec0e5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aea7db25-379f-4e55-be43-991f08005196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a041fd9f-f261-4218-bf4f-9fd17855b749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af96f8f5-c0d3-48d2-99a0-91fad463184a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10475860-7a3a-4e6c-bac9-9e6fd18c51a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ca91d4-1fdc-4b8c-8cd6-029880760cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c06a23-8a3e-425a-b3a9-656d814774e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa17a14a-b047-45f9-a8df-d3481dbbc8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df98f51-4b20-4af3-b924-1f095dcfc115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b19981-0d4f-44fa-a3c7-6467a4a7dae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b597d78-e823-4402-95e3-de928243d29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f70140-d5ad-4837-b141-e9c3667de6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 573380ae-da3e-4acb-b630-a113eff8fa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2830555a-e76c-4d47-b0a7-3c163f1f2897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bfb5684-da7e-4380-bad7-a9669dfd8ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b1522bc-b044-41b2-b25a-137d81a0e03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e163315-77ef-4fc4-9318-4480f513d2bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48eae36-a690-40ce-9293-8d97c3e6594f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fba070c-3ce8-488d-b1fe-7b3484851d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6f3e63-8f53-4df8-9281-ec73fceb2890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e43a035a-8046-4d91-8b4d-f99853fb9a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05bd450b-d1d0-462b-8254-292a1e67cdb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf6cb8cc-c029-4ae4-9964-44d67bd9817a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eadaadff-7f3a-4375-96d8-f0e5198c1706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a344c6e6-7f54-46f7-b141-6f25a783521a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47c95194-09c8-4eda-837b-cc255a503271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9ced3dc-59e8-4731-b058-446e6db57aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6023504-4a36-42e4-b1c0-4b1ed06a3668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7798a578-372f-47f3-bb31-d1cf7d0ed13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a0cb7c-52c9-4ced-bc80-2a71fb3d11ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f602088-9964-4899-8436-d43dddcbf014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f219b56-4ab3-46c7-8946-236ce89c775b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5e7b0d-5398-43b2-9065-cfa31527e34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f1e5a4-d432-4af9-afeb-bc827865aa90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77cf70a3-133f-4b83-82ae-f2dba980820e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74788bd1-a3af-43bf-800b-cb515e7b1408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5554cddc-55cb-4d29-aa2e-6df4207b7e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697b5b8a-c5e3-4abb-bdc8-bd1306e7cef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfbb2c4d-ac49-444d-920f-95fbb8d289ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd7d5c7-50bf-4187-b838-e13dcd96f7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d50a51fa-962e-4820-bc08-253a5965e8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0f4f020-fc27-4188-bfd8-839c9895b718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce2f58d-77a3-46f9-9e9b-8d332d5cb583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02e4642-bd7b-4729-8d62-7f72186c1f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30ec5ffc-a608-421f-b06d-283747c1961a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d073014e-fc23-4ef0-988a-e19b42151229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e63ff15-f95f-4060-8a9c-41c809310701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2700d63b-19db-4a7f-8e61-5c9c0953e8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a599343-551c-4758-9a82-0d11197f911f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b6c314-f820-4dd2-a1e1-5d6c2c3a6159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d45d43-8adc-47ef-bfb5-5ff62aa77e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa36503-30c6-4e5b-bf3e-94450a66c2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a9e4bf-d50c-4224-b139-3097deed6ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 338d68ca-5823-4b12-b29b-5eaa6018487d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c3a984-703e-49cb-89b9-9a01a6a3de5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b84ce4-b2f8-4f6e-a5bc-62c726d1abf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32f00e4f-6ab0-4cbc-be05-65bd2745ad41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 409e93d8-b9b4-466d-a995-a518476aefaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9ed30d-90f9-4160-862d-a27ed2329c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7223c405-5709-4ce0-857f-eca695eeb978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f231de89-a0de-4d6a-b3d5-11d59ef4259c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd0bbfc4-6ad5-421e-88d9-dc3e311f5539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb14c7c-eb87-4b3c-a1f1-3f6b587f7d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89e8222-863d-4fcd-8880-d2835352f689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bbfd751-a5c7-408e-a639-d297d6abe590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18bdb013-0380-4e72-90fa-317f1ce231ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 369c185d-a7b6-4359-b900-b8b15f559b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf659bf-0158-4dc6-a6b9-1673ee7e30da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896d60e6-c00b-44a4-b640-727e09c4e3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8386ddf1-7924-419c-b976-c498eea63919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6b5f6a-e0f4-43b9-a842-08ef6b439388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71786e1-cba3-4521-b15c-2878c216fe32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93fea12b-899f-415e-a345-83cb12307c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d54a9d-5761-4c8f-97a0-0fe8e31a2d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bb3b5e-f19c-4577-9d01-498ad2d87b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e3d77c6-91c1-4cd8-b4d7-7fb14be4a75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa55aeb-2bd2-481f-9402-82ce9e57ae0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e4407f-f647-4d0a-9e97-ccc9f166d0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f4ce1c-7ea4-47bf-87a0-e89fea5c575d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d74eb11-5966-4031-a538-b03253ed72cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bdbf38d-fede-43e0-87f6-7414e7e227da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a31521c-61d3-4f26-9132-8afabd737de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae08cc7-d301-4584-a797-68cb75f813a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba8a4c32-d706-41d4-b6bd-b4323d4d9a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c84a500-c44e-4f39-a16b-10513915d298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f74ca8-b029-49c1-8529-8a4acd70646f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac83ec6-cd9a-4609-bfed-8a2b044165ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8baf2aaf-5a9b-4a51-a27a-a8a80c6ce7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 197ae74c-f00d-49a3-a328-d2cd8d7321dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71fdb45-fab1-4091-8847-d98fc4d584d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46048161-3f14-48fd-82f0-95d4356298ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd41e022-d1e5-4fe9-a4bc-4e0832ba8869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1dd441-e15e-4f01-a0f7-f9fa0752364c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b913af1-ee02-401e-9440-005f4df76b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008f9fd4-b2ad-4adb-b94b-6975f3732662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18fa2397-a940-4c22-b90d-5e91e37ed0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d2fff0-c010-4ef4-b382-98201a4065a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c415f721-669f-4e6c-a8cb-1097f38e8608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a17b360e-f999-4e3a-b603-1f31b7e438c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e3aaf7a-beb0-4055-b4ea-27660bff332e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062e8c58-d1ca-41e0-aca2-0f3b762cd164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e478d96-3a90-415f-8288-51549fc6aa3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa16ee6d-e21d-4aec-b8a2-33f5a996852d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6719d803-6229-4adf-b265-ca37318a59b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd88011-4cef-4848-8fc7-5542abeb360e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a9e6e8-0c55-4651-9a41-0c6b8f5d456a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b22872c5-c2b0-46a9-8e79-986590940a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03a32645-347b-4d69-a5e7-591a35e513d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed192632-41ae-496c-a645-ae0ff973d16c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_29
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_labels.txt

📊 Raw data loaded:
   Train: X=(2503, 24), y=(2503,)
   Test:  X=(626, 24), y=(626,)

⚠️  Limiting training data: 2503 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  617 samples, 5 features
✅ Client client_29 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3197, val=0.0913 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0955, val=0.0858 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0844, val=0.0836 (↓), lr=0.001000
   • Epoch   4/100: train=0.0833, val=0.0836, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0832, patience=2/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0816, val=0.0838, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 1 Summary - Client client_29
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0053
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0089
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2519, R²: -0.0215

============================================================
🔄 Round 2 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000250
   • Epoch   2/100: train=0.0816, val=0.0898, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0812, val=0.0900, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0810, val=0.0901, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0808, val=0.0903, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0905, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 2 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0037
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0064
============================================================


============================================================
🔄 Round 3 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0830, val=0.0857 (↓), lr=0.000063
   • Epoch   2/100: train=0.0829, val=0.0856, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0828, val=0.0855, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0828, val=0.0854, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0827, val=0.0854, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0824, val=0.0852, patience=10/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0822, val=0.0851, patience=5/15, lr=0.000016
   📉 Epoch 25: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0822, val=0.0851, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 3 Summary - Client client_29
   Epochs: 31/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0063
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0039
============================================================


============================================================
🔄 Round 4 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0780 (↓), lr=0.000008
   • Epoch   2/100: train=0.0850, val=0.0780, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0850, val=0.0780, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0849, val=0.0781, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0849, val=0.0781, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0848, val=0.0781, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 4 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0017
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0057
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2499, R²: -0.0059

============================================================
🔄 Round 8 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000002
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0846, val=0.0805, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 8 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0114
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0047
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2498, R²: -0.0066

📊 Round 8 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2498, R²: -0.0079

📊 Round 8 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2501, R²: -0.0090

============================================================
🔄 Round 12 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 12 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0085
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0175
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2500, R²: -0.0090

📊 Round 12 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2500, R²: -0.0094

============================================================
🔄 Round 14 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 14 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0120
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0104
============================================================


============================================================
🔄 Round 15 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 15 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0124
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0179
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2498, R²: -0.0087

============================================================
🔄 Round 16 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 16 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0068
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0464
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2498, R²: -0.0087

📊 Round 16 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2498, R²: -0.0087

============================================================
🔄 Round 18 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 18 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0123
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0052
============================================================


============================================================
🔄 Round 19 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 19 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0062
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0249
============================================================


============================================================
🔄 Round 20 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 20 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0105
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0081
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

📊 Round 20 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

📊 Round 20 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

📊 Round 20 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

============================================================
🔄 Round 28 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 28 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0161
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0141
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

📊 Round 28 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

============================================================
🔄 Round 30 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 30 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0064
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0810
============================================================


============================================================
🔄 Round 31 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 31 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0131
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0078
============================================================


============================================================
🔄 Round 33 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 33 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0140
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0070
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 35 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 35 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0108
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0067
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

============================================================
🔄 Round 36 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 36 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0097
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0232
============================================================


============================================================
🔄 Round 37 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 37 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0126
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0003
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0091

============================================================
🔄 Round 38 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 38 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0095
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0276
============================================================


============================================================
🔄 Round 39 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 39 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0113
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0220
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 40 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 40 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0115
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0095
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 43 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 43 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0085
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0177
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 44 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 44 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0114
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0154
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 44 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 46 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 46 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0122
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0019
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 51 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 51 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0143
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0027
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 55 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 55 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0150
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0036
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 60 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 60 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0101
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0120
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 63 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 63 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0081
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0188
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 64 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 64 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0066
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0248
============================================================


============================================================
🔄 Round 65 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 65 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0051
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0513
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 68 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 68 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0070
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0242
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 68 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 68 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 68 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 72 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 72 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0130
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0201
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 72 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 75 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 75 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0075
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.1052
============================================================


============================================================
🔄 Round 76 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 76 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0101
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0175
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 78 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 78 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0072
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0238
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 80 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 80 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0083
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0209
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 83 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 83 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0111
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0051
============================================================


============================================================
🔄 Round 84 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 84 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0095
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0620
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 87 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 87 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0123
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0009
============================================================


============================================================
🔄 Round 88 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 88 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0129
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0014
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 88 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 88 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 91 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 91 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0109
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0065
============================================================


============================================================
🔄 Round 94 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 94 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0066
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0282
============================================================


============================================================
🔄 Round 96 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 96 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0070
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0222
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 99 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 99 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0060
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0312
============================================================


============================================================
🔄 Round 100 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 100 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0118
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0142
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 102 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 102 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0174
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0149
============================================================


============================================================
🔄 Round 103 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 103 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0100
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0101
============================================================


============================================================
🔄 Round 105 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 105 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0087
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0229
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 107 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 107 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0123
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0001
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 110 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 110 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0111
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0123
============================================================


============================================================
🔄 Round 112 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 112 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0101
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0099
============================================================


============================================================
🔄 Round 114 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 114 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0160
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0026
============================================================


============================================================
🔄 Round 115 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 115 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0115
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0188
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 115 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 118 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 118 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0100
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0153
============================================================


============================================================
🔄 Round 119 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 119 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0174
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0202
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 121 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 121 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0138
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0041
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 123 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 123 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0110
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0069
============================================================


============================================================
🔄 Round 125 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 125 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0097
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0119
============================================================


============================================================
🔄 Round 126 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 126 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0061
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0240
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 128 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 128 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0049
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0333
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 130 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 130 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0084
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0213
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 131 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 131 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0168
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0120
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 136 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 136 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0169
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0159
============================================================


============================================================
🔄 Round 138 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 138 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0094
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0135
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 139 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 139 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0112
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0069
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 142 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 142 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0112
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0135
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 144 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 144 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0030
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0694
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 144 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 147 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 147 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0069
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0312
============================================================


============================================================
🔄 Round 148 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 148 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0118
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0077
============================================================


============================================================
🔄 Round 149 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 149 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0079
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0509
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 152 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 152 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0155
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0090
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 158 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 158 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0096
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0123
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 161 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 161 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0060
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0307
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 167 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 167 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0138
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0068
============================================================


============================================================
🔄 Round 169 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 169 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0205
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0323
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 169 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 171 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 171 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0083
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0461
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 173 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 173 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0129
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0013
============================================================


============================================================
🔄 Round 174 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 174 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0096
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0259
============================================================


============================================================
🔄 Round 175 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 175 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0130
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0008
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 175 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 175 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

📊 Round 175 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0093

📊 Round 175 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 183 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 183 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0153
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0097
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 184 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 184 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0038
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0427
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2499, R²: -0.0092

============================================================
🔄 Round 185 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 185 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0136
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0016
============================================================


============================================================
🔄 Round 187 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 187 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0136
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0073
============================================================


============================================================
🔄 Round 188 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 188 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0128
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0110
============================================================


❌ Client client_29 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
