[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b6bcc18-767f-4e9a-a573-5ab9859ea4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d301bbb1-d634-4ff6-80fe-b5512bea02fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8604f14-0f2f-4ac4-a7fa-2e239539a0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a03ab1-5a75-476f-bbce-6f5e87b2be80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f60ca91-dd8e-4be6-a9c4-aac8ac787a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d559c5-4400-4154-8698-55be08434f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b08a7e4c-4fa2-4ad3-b495-036110925324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ae75e4-0ef3-4185-9135-5728553be06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd555a68-680b-4fc2-b705-028eb52b1116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73991f3-c324-4399-80fe-37f9dac05e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ee2346-e9f0-47aa-a939-33e1c6022708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472ada8b-8d68-4fbd-a867-b74959296c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b44b6f6-72fe-48bf-8dd2-61605f72acdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9cadf3-46a2-4c21-9deb-27f1c5a4311d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbcd412c-bcef-47d6-ae43-26841bb68551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab80eedd-6575-406a-ba3d-54f81f6be865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d922375-0ade-43d9-8c1d-9e882c7963a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a586b0b6-035d-4b35-9b9c-bedcf3a05732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82fb6071-4762-4c64-87a1-05fca1d1eb76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1d23d63-c57d-4040-8a9b-e5d99e9e5ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7eb1db0-23ab-41d6-99a7-641d1a3685e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 114fc3cc-b971-438c-bae5-46a175ecc61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47ca139-5516-43af-840d-8fc50615abe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25df0ecc-f9a8-4a50-bd14-0f276d359b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07492e3b-7d96-4296-8f9f-390213f9303f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a098b82c-9a7e-4c42-8562-b3716033afae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ed885ff-09c0-47e8-a5db-f9f7f4b3a74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e1ecf3-bc3e-43be-8055-30c9b25e0c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bb3005-e913-4d40-b0f6-01bf94321e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d55e007-53d8-445a-bd5b-87833cc134a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898a9041-deca-4b89-8ada-dc9f8bee1d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78300484-e1cf-4795-afad-b7989f2f050b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1ae0de3-7d45-44d7-8288-57b03ae18d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25961f85-2f8a-4b11-ae14-20146bfcd948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d644b23-d4bf-45fa-9c2f-e290feb61843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36006fc-57ec-4955-b19a-341676a800a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744fc0b1-80ee-4a99-9b46-fbe0bdb8892f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecbacb49-89ab-4357-8bed-94fff781e072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa5de09-8219-4f61-9e43-95255dc5ff7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23a3337-32cd-4906-b0cd-1a1850cf6e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e88b15-3554-4b8e-86d9-e5bcdc0f3d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5d4f04-14dd-40d9-b8e5-b6ea0d884986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200244b9-c0f1-48f1-a69c-a18be41aac82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719ca3c5-646b-4229-8f77-54b584d6df6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48cd200d-551d-49a4-9dc1-87fd441adb4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea54ced1-ab1e-4062-addb-5495dd5c1726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5440839b-f7c4-40f1-80b3-a7b6379fb70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9144eae0-7c0b-4eac-8b36-cdc001e326fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c14a0cf-9f30-4b1b-9e6a-674c380ae2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba1eae4-9ff4-4dc2-83a4-b3ba6ad4e435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 238ad56f-e890-41a9-a20f-d030b3f8819d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a8552a-f563-4617-b914-2105b0868224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2450045d-7e6e-49bc-9a70-6f89490daf9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beefed0e-4348-4674-a4a8-c3a111b30733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33861fe9-5d94-4b6d-841b-72a5582432ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a408b67a-f07b-4111-b64b-c5fcbd97772f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e32698-3a95-40c2-b657-fcc3cf8e1147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9686d359-ea36-498f-b854-2e688426d9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f8c8ab-9762-41c1-8f17-4498f57f5b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5c0dc0f-168a-4b7e-bafd-3fdb00834342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ecf3f59-d505-4053-821e-955b6307aaf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be352299-b7c5-4969-a1ec-101762119b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f2469d-e806-4287-bf81-8aa5e521e2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caa4c697-0769-4743-8054-cdb8e31c9498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57beb097-edf4-47c9-ad3c-ece70f9c4db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b86e46-612d-4d71-bb99-c9f2f3ebbcc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb56ea82-3064-41a1-9ffc-d03b1c42832e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719a170d-9f27-406c-bb4d-66cca1719228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40658770-87e5-4042-a474-b56827999466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d45e4e68-3a12-4a8e-9222-eb37b165c308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed2ce222-132d-4d17-b87d-17fdff341b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7da49313-9ef6-42f6-932f-a5c22bf773b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adfa9e2-5f55-4c91-af59-5ae27757e580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89a48da-92c5-4411-86ce-a7929e25a498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6892522a-c4f1-43f5-b848-9f7671fc5fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf69a0f-3bbc-40c4-8326-9c8354b0939b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14b9c16-2d4e-4d44-899b-c737540701c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4129c3ec-8b26-4cb4-8fa1-fa31e7b5c7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58f67a3-3b9b-41a9-a7ff-b037efca1791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ed5938-cbac-4722-88a7-36f2e9ad02b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50381375-f6a2-4f7f-a94e-63d59b282630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16e42a8-c2bc-448c-abc1-01adc7df34e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2914c44c-3d9c-4a36-b569-7dc80e23edb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb12876-2721-4137-ba52-eacad03dff27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c3da02-ba0d-444e-a1a7-e51358060cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c203b9-973d-4a29-a8bf-db959829cd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3398bd8-dffd-4e87-bd5d-5710c1af8098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbc9c4d-cfc2-487f-8aa1-121b77026bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb50395a-238f-4e2c-bb15-2ecb83ca3850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 500f34ba-ca75-4ec7-820b-817d09aa44c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62bd5dfc-be1f-45b1-beed-12c4e2bb2d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f102106d-57a5-46a2-8da5-6fc0f71204f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edcab96c-3075-49d7-b836-255e46e31b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e7a294-a97e-4a3b-82bc-6713c99d76c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6923206d-4763-4afc-b644-0d5d3fd0ed8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73292bf-1a62-406a-b140-f2f24d278294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f070052-755a-4c52-9e73-8aa1e6e691ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6040a39-f3b2-4bca-9171-8145e79d6455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e663374-9cd9-4c41-bb3c-b04eed890d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623fc946-1b96-402b-bcd6-807e23e8eed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d0e4f7-9813-4286-ba85-1afa99c4b52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee4de707-f7bf-44ed-8716-04ccdac6ef51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d746133-45e1-46cf-a3c0-6f55c5a77634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3269adc-3e13-4d10-aa67-31549643e3b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7170d9-e33b-44b2-9e37-934fbfa390a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb45c87f-d535-4eed-9f24-caaaf3514b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2462073a-9eb0-4568-b032-a58f438afedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ff9868-f7aa-41bc-9784-dacf98aa1db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a090e56-e6a2-42b6-aa14-e2762f9ce7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053a0116-9b7d-4852-b442-f387fd5e8d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae5aeee2-c1f5-4ca7-8eae-a7374b1b0849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 114ed290-086e-4d03-b49c-ee27b15dc265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4cb74d-7870-4ff9-a796-472a0b33190f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3c38d9-500a-4f28-bd6d-f84cf03969e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83767a94-f5e7-42f5-8302-f3ae720df866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ec2651-fdea-463f-b942-27f8a25a13e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38bdbba8-bfd0-4809-9e9c-c1d07e5f24da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7365d2-fedb-4ac5-818e-677a968b2fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3355ea9-b312-4d7d-a9b4-19ab0d08c353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4154da47-44d6-4ff6-ab6e-277db4f3576e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ea3e11-f8d4-4a30-97d9-f54c935d0340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb05d39f-024e-4d5e-8448-f412a6410701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c16555d0-30e1-4a7f-accb-c48265debf9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2f8a2c-c3e9-4944-bc15-71a24812c79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b48bb97c-c28c-4d1d-b9a7-45a9a94c81ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee712109-bf18-4009-aae5-85bed6fbdbac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0510e137-cf81-4ca3-b111-ed0e50998ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a5c754c-fa18-4c80-b1f8-5e778567a8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6145758-fffb-4de1-8ed8-19d690f37215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfcd222b-a135-44df-afcf-f02e82dc4367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25b1511-d6aa-45cb-89d5-75a95ce5ae22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f9da801-db16-4895-8234-d67dacbc2ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c9a76b-bbda-40da-a879-a3f3f41c4fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa8772f-a124-42d1-b0d9-ad19aeca59c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b8d1185-f6c7-4e3c-978e-09d1652f5468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 394e5beb-0222-435e-86ec-684f975dcee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d868b97-cbd8-43b2-b130-dfa7e8ce4986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53449fa5-dc0e-49a8-88a5-f576440454c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6927a38-d413-4ac9-8981-0139230c405c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec391588-a7a1-4f29-8c98-d77880fdb3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b6e55d-7522-464d-ac3d-8cd34794c239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c422ed4f-0e0f-4496-9346-0235737b8d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6995c7-8d90-416a-b4f8-7e9b7923e321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f869c70-2750-4646-89e6-90a3c1142e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c08f018-d2b4-4ce1-864b-1f5ccf8eb476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c193f6-6088-4e86-9b71-8927450f1c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79798520-573d-416e-b418-27fb7e6b04b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d9e43a-08f3-4ce3-85bf-a7d62e6d191e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b7d669-2572-41f2-bf92-a422971d845d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bcb0099-69d4-4a02-96e7-5037cd36f1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f95e7c-7c86-4684-9cef-195aa1a53105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7366190a-ee4a-4a05-8b03-0777028d0c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec124f3-2f68-4fcb-b64b-412616e7e470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ae01a43-a4b0-4a13-b050-04ba611f73c2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_30
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/test_labels.txt

📊 Raw data loaded:
   Train: X=(1432, 24), y=(1432,)
   Test:  X=(358, 24), y=(358,)

⚠️  Limiting training data: 1432 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  349 samples, 5 features
✅ Client client_30 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2503, R²: 0.0020

============================================================
🔄 Round 3 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0787 (↓), lr=0.001000
   • Epoch   2/100: train=0.0795, val=0.0789, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0799, val=0.0781 (↓), lr=0.001000
   • Epoch   4/100: train=0.0795, val=0.0779, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0790, val=0.0779, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0770, val=0.0779, patience=8/15, lr=0.001000
   📉 Epoch 15: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 3 Summary - Client client_30
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0134
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0156
============================================================


============================================================
🔄 Round 4 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0837 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0780, val=0.0830 (↓), lr=0.000500
   • Epoch   3/100: train=0.0774, val=0.0831, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0772, val=0.0832, patience=2/15, lr=0.000500
   📉 Epoch 5: LR reduced 0.000500 → 0.000250
   • Epoch   5/100: train=0.0771, val=0.0831, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0763, val=0.0830, patience=9/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 4 Summary - Client client_30
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0090
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0031
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2503, R²: 0.0023

============================================================
🔄 Round 5 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0802 (↓), lr=0.000125
   • Epoch   2/100: train=0.0779, val=0.0797, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0778, val=0.0798, patience=2/15, lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   • Epoch   4/100: train=0.0777, val=0.0799, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0776, val=0.0800, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0774, val=0.0802, patience=10/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 5 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0077
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0287
============================================================


============================================================
🔄 Round 7 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0808 (↓), lr=0.000031
   • Epoch   2/100: train=0.0773, val=0.0805, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0772, val=0.0804, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   • Epoch   4/100: train=0.0772, val=0.0803, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0772, val=0.0803, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0771, val=0.0802, patience=4/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008
   📉 Epoch 20: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0770, val=0.0802, patience=14/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 7 Summary - Client client_30
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0122
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0054
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2506, R²: 0.0007

============================================================
🔄 Round 10 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0827 (↓), lr=0.000004
   • Epoch   2/100: train=0.0766, val=0.0827, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0766, val=0.0827, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0766, val=0.0827, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0765, val=0.0827, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0764, val=0.0827, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 10 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0123
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0128
============================================================


============================================================
🔄 Round 11 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 11 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0109
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0246
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 11 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2504, R²: 0.0025

============================================================
🔄 Round 15 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 15 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0190
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0062
============================================================


============================================================
🔄 Round 16 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 16 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0154
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0078
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 16 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 16 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 16 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 22 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 22 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0157
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0035
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 23 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0652, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 23 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0120
   Val:   Loss=0.0653, RMSE=0.2555, R²=-0.0010
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 24 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 24 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0077
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.0342
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 24 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 24 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 28 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 28 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0152
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0039
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 31 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 31 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0092
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0193
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 34 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 34 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0157
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0020
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 39 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 39 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0157
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0004
============================================================


============================================================
🔄 Round 40 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 40 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0111
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0255
============================================================


============================================================
🔄 Round 41 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 41 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0075
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0327
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 41 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 41 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 47 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 47 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0171
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0001
============================================================


============================================================
🔄 Round 48 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 48 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0095
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0190
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 48 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 48 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 52 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 52 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0122
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0194
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 52 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 54 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 54 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0190
   Val:   Loss=0.0746, RMSE=0.2730, R²=-0.0094
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 57 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 57 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0189
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0186
============================================================


============================================================
🔄 Round 59 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 59 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0137
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.0047
============================================================


============================================================
🔄 Round 60 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 60 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0067
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0391
============================================================


============================================================
🔄 Round 61 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 61 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0165
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0016
============================================================


============================================================
🔄 Round 62 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 62 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0184
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0117
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 62 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 66 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 66 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0169
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0002
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 69 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 69 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0106
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0272
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 72 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 72 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0159
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0050
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 72 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 76 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 76 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2738, R²=0.0096
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0277
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

📊 Round 76 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 79 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 79 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0153
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0056
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 81 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 81 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0115
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0211
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 84 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 84 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0090
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0327
============================================================


============================================================
🔄 Round 85 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 85 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0148
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0089
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 87 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 87 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0123
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0014
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 92 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 92 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0196
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0827
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 93 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 93 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0130
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0148
============================================================


============================================================
🔄 Round 95 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 95 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0170
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0003
============================================================


============================================================
🔄 Round 96 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 96 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0119
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0219
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0023

============================================================
🔄 Round 100 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 100 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0166
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0024
============================================================


============================================================
🔄 Round 101 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 101 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0190
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0146
============================================================


============================================================
🔄 Round 102 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 102 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0126
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0184
============================================================


============================================================
🔄 Round 104 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 104 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0126
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0040
============================================================


============================================================
🔄 Round 108 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 108 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.0173
   Val:   Loss=0.0963, RMSE=0.3103, R²=0.0030
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 108 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 110 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 110 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0124
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0181
============================================================


============================================================
🔄 Round 113 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 113 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0088
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0151
============================================================


============================================================
🔄 Round 114 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 114 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0100
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0280
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 117 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 117 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0134
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0157
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 118 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 118 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0104
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0062
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 118 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 120 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 120 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0133
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0160
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 122 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 122 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0107
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0255
============================================================


============================================================
🔄 Round 124 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 124 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0171
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0010
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 124 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 128 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 128 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0055
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0092
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 128 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 133 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 133 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0124
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0170
============================================================


============================================================
🔄 Round 134 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 134 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0120
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0174
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 135 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 135 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0146
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0109
============================================================


============================================================
🔄 Round 136 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 136 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0151
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0072
============================================================


============================================================
🔄 Round 139 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 139 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0125
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0192
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 139 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 141 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 141 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0227
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0175
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 141 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 144 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 144 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0136
   Val:   Loss=0.0686, RMSE=0.2619, R²=-0.0030
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 145 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 145 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0102
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0220
============================================================


============================================================
🔄 Round 146 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 146 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0142
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0127
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 151 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 151 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0163
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0115
============================================================


============================================================
🔄 Round 152 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 152 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0099
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0179
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 155 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 155 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0060
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0317
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 157 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 157 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0128
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0177
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 159 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 159 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0154
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0081
============================================================


============================================================
🔄 Round 161 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 161 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0105
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0224
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 162 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 162 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0195
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0140
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 164 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 164 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0184
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0228
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 165 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 165 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0119
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0225
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 168 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 168 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0064
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0410
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 172 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 172 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0170
   Val:   Loss=0.0697, RMSE=0.2639, R²=-0.0163
============================================================


============================================================
🔄 Round 173 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 173 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0159
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0028
============================================================


============================================================
🔄 Round 175 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 175 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0186
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0406
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 175 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 175 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 175 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 181 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 181 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0115
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0059
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 182 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 182 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0115
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0012
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

============================================================
🔄 Round 184 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 184 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0146
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0103
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

📊 Round 184 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2504, R²: 0.0022

❌ Client client_30 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
