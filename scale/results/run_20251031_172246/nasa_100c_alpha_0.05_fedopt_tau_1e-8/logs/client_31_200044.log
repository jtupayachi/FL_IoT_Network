[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1d81440-b87b-412f-809e-cfdfb045434c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc0270d-9629-47f1-962d-34d35b997d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7336532-22a5-4f8c-8a1a-47c63b1ade51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbba5392-61e3-44a0-8de9-8c90d65ba751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f9436e-94f5-4488-ae00-194211d294ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1d420e-a51a-40fb-b4f2-9843747690fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d6c3c8-ff9a-4727-aa87-faefda20d6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86354ecc-2af8-4f41-9e64-82aa96f0f9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b0c4d1b-5d87-4aa9-91d1-015a6ade299c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820cfd9a-ecc9-4c89-97db-279fff05421e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 169abff7-f0a0-41dd-a5c4-b22e8117a4d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5afcdde-0888-4829-a793-262716f7a5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2017d51-7ce6-4b82-b459-2154de3634a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9f7518-8a3b-40e2-ab70-66bed87abfa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915f2301-6ea0-49c9-bef8-16a7f1227b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a63a337-6eff-4bd6-9bb2-26d782f4bc8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a31c33-bfb6-4256-be5c-e1e3d6d76170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d87de6-4cad-40b2-b73b-71eb1cb1957a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d10019-2d2b-435f-a5b3-08a5e6b060c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3707edd1-ee24-43ed-9261-30d8af929dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bab8f69-6c1d-446f-9bab-7d6f8bb6e8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e09a41df-e7ba-4e65-aa80-3a458b565701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ff3a1a-25ea-40c5-b951-500a90fdfe66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d47fce-7639-4819-ab98-ff9e3524ddbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e06020-824e-463c-bf28-225b0e1a8580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e58782e9-1769-4ce1-98af-cc89ba72889e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8119858-f994-4734-b805-428c48cda889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e18e60-4c13-4813-9af4-763cc93a440e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8b7f3a-a6d3-4b0b-9eea-2387e78c3873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b27383f-ba46-4658-9138-9f7116a1bf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0e0707-e620-4727-a5fd-2fe46d1b5cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93abc5b5-d957-45c1-90c7-2ad6b6464555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f05325-5d58-40d4-96f7-e69626744761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ae25251-1585-4eab-afa0-054adf85bfa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a496009f-b843-4483-bf7f-ef011b260ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61055f35-05a8-4f3e-a1fb-b0d29065aa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36483a48-1bde-4d4a-8717-fc5e30df154f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666b2fe6-78e6-4f4f-90e1-a1ed3a1f396d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a61ed8-2095-49f0-8aa4-0c2c48289928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6633f087-ff11-4ef8-8b9a-a8f7d7ad13a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2156529-74aa-4328-a200-3f2d96d4a3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12009d78-f72c-4640-bbcd-ff174db81a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 529abae1-81ee-4b8d-b2f2-9e8b93c12614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ed5508c-7379-40bc-b9d7-2a0dcd102948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message defbe31b-a515-43bd-8ec0-534c6f762fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550aeb2b-1d10-4e7a-b560-08464348907d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11468939-966f-4eae-9a6a-2fa3afc42ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba3fa22-a4b2-4f1f-b306-137c2117bf48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a33bad-d7ea-43bd-bf1a-3483f346eca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10b86de0-b3df-4d50-9d3c-0c180c011e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eba7003-95c8-4004-9c61-71cc9d7df5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619df365-bf40-49dc-9904-104d3ee2afe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e813250e-2bed-41c0-819d-435377ced694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e133fe6a-6943-4967-a793-2216231dfb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de15d53f-4076-4c32-b5a9-84d6e2f397b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65dd706a-3d4f-4026-a389-9acf1c77c58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32b88d42-b025-49d0-943e-b4fc667dba99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f9d741-de11-4c9b-8470-38a5b495a06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c0e649-5a8a-46db-8407-818524f7ed62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8760b33-40f9-4e75-b8ac-696665e08862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1835f959-d8f9-4241-9be4-48715fd17e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2ebf03-d9ff-4038-9971-e5af5ff220ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1d5ae9-9870-4809-a2ef-2d116bf97544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6858013-ebf1-4c3d-9540-1575c6628e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793847a9-4559-4b88-a6df-0d04ca53dcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff4a8c2-8ceb-4def-b69e-704cc4ecfd1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97370a1-3765-4eee-8b99-5df696b6f9c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f437a9e-a2cc-498e-8559-a496c198bd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 386e1aec-133e-4d1b-8cfc-379b6a2c9dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51d6d4e4-75b0-434b-95dc-e41eaa852bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dda7590-5bac-40bb-b062-b7a28b96d9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b35c2c3-bfef-4e65-8ce8-144b350bd8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d38a9c81-d2a4-48b1-b06e-3f9a9665b527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88393402-3a2b-4e6c-839d-8fe5a121eac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad58d0ef-2b31-46d4-902c-38b59de9f119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9d7ae4-64ed-4cf5-9c4b-cdb616f6ade0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f245a6-f428-42cc-8faf-fcf08f911d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb06bd8-4c57-4ad8-9482-bd0b9800ac94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6645639e-f58a-4af3-a99f-4fc7de5763bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098ab0db-34b3-4509-912b-161b44ce1b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d82cce3-c397-4cf8-a65b-142d12e63b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adabc2c9-db7a-4139-aced-a8f83a1fbf55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cfd5828-0854-43aa-b1a0-9ce5429edbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84785c35-e1d7-4c81-b560-14b633d6bde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43065005-ace0-4f2e-b870-bd725e19d8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d05ffcac-f9a7-4847-906a-22bf0dd8f5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d8e5ec5-cfed-489b-b760-ca280ab69cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41c2bf4-24d8-498f-b7da-0eb401b3f097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c4fc84-e40c-47b3-b565-fcf8cc725e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee7ba5e-a038-4255-a2f0-34ba5755a973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d852b2-1af1-4e0c-93b9-aca4420061a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151c2ea4-b039-49f4-a4df-741d566d3f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818f6ddd-e158-4ef1-8d0e-610f63152bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 283cca15-d668-4e9a-b471-51a4697daed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a69854-c857-4c88-9cdd-b286145cf32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef05251e-beda-47d8-a44b-1ba008a10d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faeda51d-7741-4b0a-af3b-409bfec340cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba4ff2b-c60f-45d3-8e14-147c9323384c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e440bca7-14b4-4d74-a2ba-66469b596b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c2583e-2981-45d1-805a-bef0005061b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66279d8b-33bc-492b-bf71-e9f8c510ecbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6022c22-7f6b-4738-a7b2-33d6e86b6182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac4ac4a-71e4-4c69-abb6-d20f06479239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0fa10fe-bbe9-41b1-a4c1-3020d0348259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c3971b-adfc-4471-9972-1f77370a6e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c45b2d6a-7d58-4ef5-8d05-d547fb3f479a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744c75a8-c966-4f1a-8dff-28dd37abfcd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c23184-d7b5-488a-ae6f-b12370972dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15767e9-aee7-4304-b6a3-f2aac2f83f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0465bdf-7994-4125-a21d-157f27c5451c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6a69b7-84f0-4dd1-ac8b-1dbcff07d017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb970f8c-b728-4650-a097-87b50488ef63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b54064-72c5-442f-af9f-dd0f044bc981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8313a8e-fded-441d-b950-f4de0f459892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0620f5a0-e2d2-4c60-802b-3a452abd7fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db43c19-9518-4603-b8f2-d225021c2038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c3068a-fe7e-4f74-a68d-24a40fa90000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad02ed96-9eb1-404a-adcc-67d552433391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21142fb-833a-4e66-a3b7-1ee8f942cbbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3f82bf7-9d7f-4f22-977e-c73d55e3db3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49378305-feb3-4fc2-bab6-39761fd5a2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86beca8c-e674-4c37-abee-13a7ee9e246f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ddc5592-39e4-492e-9eef-c78acfab7f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb1ad18-63a0-4cac-b610-f5c6fb5a6213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f31976c7-449b-4e01-8f95-6fc3b1ae656e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4078963-4c5d-4964-8ddb-9117fa569ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17c7a14-1f53-4da9-8840-4271168057f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe58733-1a8d-410c-86c6-00ec7a47ed75
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_31
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_labels.txt

📊 Raw data loaded:
   Train: X=(1351, 24), y=(1351,)
   Test:  X=(338, 24), y=(338,)

⚠️  Limiting training data: 1351 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  329 samples, 5 features
✅ Client client_31 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2483, R²: 0.0095

============================================================
🔄 Round 7 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0897 (↓), lr=0.001000
   • Epoch   2/100: train=0.0801, val=0.0901, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0799, val=0.0891 (↓), lr=0.001000
   • Epoch   4/100: train=0.0793, val=0.0891, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0786, val=0.0881 (↓), lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0747, val=0.0915, patience=6/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 7 Summary - Client client_31
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0590
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0112
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2470, R²: 0.0173

============================================================
🔄 Round 9 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000250
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0810, val=0.0781, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0809, val=0.0779 (↓), lr=0.000250
   • Epoch   5/100: train=0.0807, val=0.0778, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0796, val=0.0769, patience=3/15, lr=0.000250
   • Epoch  21/100: train=0.0776, val=0.0757, patience=5/15, lr=0.000250
   • Epoch  31/100: train=0.0757, val=0.0752, patience=9/15, lr=0.000250
   • Epoch  41/100: train=0.0742, val=0.0751, patience=8/15, lr=0.000250
   📉 Epoch 46: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 9 Summary - Client client_31
   Epochs: 48/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.1120
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0783
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2463, R²: 0.0236

============================================================
🔄 Round 13 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0826 (↓), lr=0.000125
   • Epoch   2/100: train=0.0794, val=0.0826, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0792, val=0.0824, patience=2/15, lr=0.000125
   ✓ Epoch   4/100: train=0.0790, val=0.0821 (↓), lr=0.000125
   • Epoch   5/100: train=0.0788, val=0.0821, patience=1/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0783, val=0.0820, patience=7/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 13 Summary - Client client_31
   Epochs: 19/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0502
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0467
============================================================


============================================================
🔄 Round 15 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0777 (↓), lr=0.000031
   • Epoch   2/100: train=0.0810, val=0.0778, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0809, val=0.0779, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0809, val=0.0780, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0809, val=0.0780, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0808, val=0.0780, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 15 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0461
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0252
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2462, R²: 0.0241

📊 Round 15 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 24 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0837 (↓), lr=0.000008
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0794, val=0.0836, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0794, val=0.0836, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0794, val=0.0836, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0794, val=0.0836, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 24 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0380
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0635
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 26 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0781 (↓), lr=0.000002
   • Epoch   2/100: train=0.0808, val=0.0781, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0808, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 26 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0420
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0311
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 28 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 28 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0473
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0276
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 28 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 30 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 30 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0365
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0662
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0245

============================================================
🔄 Round 38 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 38 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0379
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0704
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 38 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 41 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 41 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0385
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0642
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 41 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 45 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 45 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0404
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0573
============================================================


============================================================
🔄 Round 46 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 46 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0423
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0492
============================================================


============================================================
🔄 Round 47 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 47 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0408
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0557
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 48 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 48 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0403
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0443
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 48 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 48 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 53 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 53 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0453
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0220
============================================================


============================================================
🔄 Round 54 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 54 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0417
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0473
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 57 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 57 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0419
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0453
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 59 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 59 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0438
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0401
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 63 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 63 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0464
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0263
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 64 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 64 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0407
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0555
============================================================


============================================================
🔄 Round 68 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 68 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0419
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0490
============================================================


============================================================
🔄 Round 69 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 69 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0351
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0510
============================================================


============================================================
🔄 Round 73 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 73 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0451
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0372
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 74 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 74 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0375
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0241
============================================================


============================================================
🔄 Round 75 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 75 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0424
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0480
============================================================


============================================================
🔄 Round 77 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 77 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0443
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0334
============================================================


============================================================
🔄 Round 78 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 78 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0447
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0369
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

📊 Round 78 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

📊 Round 78 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 86 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 86 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0388
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0638
============================================================


============================================================
🔄 Round 87 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 87 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0457
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0365
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 89 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 89 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0431
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0463
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 90 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 90 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0452
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0341
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

📊 Round 90 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 90 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 95 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 95 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0413
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0531
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 98 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 98 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0468
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0140
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 98 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 112 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 112 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0382
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0527
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

📊 Round 112 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 115 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 115 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0381
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0621
============================================================


============================================================
🔄 Round 116 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 116 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0354
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0718
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

📊 Round 116 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 119 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 119 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0421
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0505
============================================================


============================================================
🔄 Round 120 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 120 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0414
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0380
============================================================


============================================================
🔄 Round 121 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 121 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0477
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0261
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 124 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 124 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0415
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0520
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 126 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 126 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0466
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0261
============================================================


============================================================
🔄 Round 127 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 127 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0431
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0404
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: 0.0248

📊 Round 127 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 132 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 132 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0404
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0471
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

📊 Round 132 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 134 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 134 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0415
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0510
============================================================


============================================================
🔄 Round 137 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 137 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0389
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0644
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 138 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 138 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0489
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0195
============================================================


============================================================
🔄 Round 139 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 139 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0434
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0434
============================================================


============================================================
🔄 Round 140 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 140 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0449
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0397
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 151 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 151 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0424
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0481
============================================================


============================================================
🔄 Round 152 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 152 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0405
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0435
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 154 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 154 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0528
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0093
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 154 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0246

============================================================
🔄 Round 156 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 156 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0406
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0591
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 161 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 161 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0400
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0581
============================================================


============================================================
🔄 Round 164 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 164 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0445
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0415
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 164 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 166 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 166 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0497
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0195
============================================================


============================================================
🔄 Round 167 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 167 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0426
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0430
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

📊 Round 167 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 174 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 174 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0436
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0432
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 177 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 177 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0468
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0309
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0248

============================================================
🔄 Round 184 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 184 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0437
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0396
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

📊 Round 184 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: 0.0247

============================================================
🔄 Round 189 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 189 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0413
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0340
============================================================


❌ Client client_31 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
