[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afdb2ee2-a687-45ae-b4ee-b49c601c06f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c98ca0b-26e7-4589-9b64-5876a734e11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97a4ffc-2a7d-4b81-ac03-035a4052b92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b163b08-5647-49d7-947a-f9e3622e3ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc114ee2-e0b8-4660-b594-3f67c50eb563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72863083-d866-41bb-a340-702027762a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff4544b-6077-475e-812d-07f2d2233cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944c6c16-3596-4423-8102-e1cc4d1c539c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a34304c-0285-4e23-9516-6c7395c83c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292cbed0-686d-41b2-b038-c60091bb8553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03731b7d-339e-48f9-b07e-31c72666d2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e51588b-777b-4126-9f71-13b1d6bf2b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a42d9f1-4913-4cab-b569-1d75997267d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 290422e5-8d99-40ab-a50a-e832df0260ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5397564d-5dd9-415b-9925-2636464ab57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db43cf63-a380-4608-88e2-40575ac59fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caa65949-1949-4191-b512-33ca17e824b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9faa7dae-e560-4ad7-94f1-c558edb3359e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb2d0af-df81-4edf-8bcf-589a878b2267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89d9704-b6bf-41a9-8ee1-7b7353dbfeeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951b61bf-a028-4609-b1d2-f9fb6ad4eccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b63203-18ac-4217-b79e-fde24f1356b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa3cef4-c634-4d19-adc1-08c468746b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55183735-8800-42dc-8214-6e07adb6ff6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b239980e-5500-456b-95a3-8eded02756f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831f27d5-fe67-4e9e-b7d2-f0218797ab34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b83fe09-8ed0-4bac-bbd8-b1b168ff11f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d5ab83-b7e4-4e93-aaaa-59df4f905142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f46005f-0ca2-4478-90ae-c28b67d3899d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f58210-7c4f-4580-a131-fe503bcc4a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8792f0f-b986-4869-99a0-ed95cb9e78ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274cf937-7e89-4fd0-8500-b5efe9f99b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b884e258-c032-4077-829f-55e563f461ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc3b8ec-0db0-420c-bc93-38b1eb05d161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a527b0c-61df-40fb-b7b3-87611ec40476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6fbdf8-21b4-49c9-8815-4a4dbf7f2235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a111b8-4d78-42c0-aa43-39171136b2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d540fd-0c78-4ef4-a49e-062c75397dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de7edec-39dd-4373-aa80-0be2edf91bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6193cb-d6de-4d50-917e-2114543a32bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71a3e10-7b90-4199-a767-223eae13b47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86cceb3-3d3d-41af-b3b0-8ed71f0bb5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 949309d7-7b0f-4a32-b309-6cbae4d8bc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9537b8a-d516-4dd8-9b82-e57e141add29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33cf3c19-9eea-42ec-9487-fb28a329b61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1ca32a-d557-4908-841a-afc05867e154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 102147a2-aea2-4441-bf86-fa9366c10024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2fc7d3-9214-4d0d-b2f2-9da1b8b03993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44dec3c4-27e4-4d41-a7bd-d771e3e3fe67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6783ff1b-ed3c-4850-a3e7-651b206d789d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21695e0-f60e-473e-bd2a-8809b0aab675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7996d7b-56c2-4b65-90ab-7624dbddb9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebca817a-5551-4759-b28a-845a06bf36bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49727461-4b0d-4b05-aa55-76c0fd167abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c4808a-4644-4ccd-83cf-b8cc4c7238c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18638b43-2285-4a0f-ad40-d67a91b3ebba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a960297b-2a90-49ff-ab09-e0921f48511d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10814f3-2a38-4e48-9d6c-9b55b730fb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 687ad3be-11ea-4e33-a771-6b7d529e2a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05a3b0ef-abb2-48f1-bbfe-6e8ac9992dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef180ed4-425b-4fe0-bedc-970fcdbac753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4bc2fb2-5a4b-4935-a30d-03d42e4b36fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3431869f-1b58-41cc-b435-dc0027476d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc52809f-dc0a-4b0c-a7cc-e7347e2e9f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21261b6e-2b54-4eae-aaa7-ff7b033af101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e9b17e-9239-4cd4-ae70-67328b0727a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a9be1d-7b05-4856-9e67-c31d3a532996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4938b4-cf28-4181-a1b4-e48ee99edcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d7be30-38ce-4188-9d1c-cd9c289119d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c4c572-36c1-4d1e-b437-54d0bc54d41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a2be3a-e3d4-4aa4-8e5f-85b1d0d79ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67582b7d-791c-4367-9eac-85fd2c38c572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a07513c9-6755-42ff-9e71-b639cc0283fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868a9efb-ef7b-4038-8084-1165b1f05863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f4d014-3e8e-4e5f-928f-e5b0412d0e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a60250-9044-48c8-a26d-8a46d9199901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e72f859-5035-44cf-a6f5-1dfcfc78f95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60269cac-d847-48ee-a8c3-45222b1840d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 811b7cf8-032e-4075-a989-4094278a6312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4363695-4ba6-4a5c-af93-ae84faa6b990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c090f0e-c1dc-4414-9302-24d3e3777623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d30dc64-6b40-4fc1-93bf-ec79e58fc759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c61f5ec-d664-4729-9647-155e536b28a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb187d9-6b82-4dc0-afb3-46c731fdb17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d3e915-0249-4dee-88d2-6d553b37a213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49085a0-a810-452e-8035-61eb419b9991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c6d854-fdb4-48e6-a0ee-8373c09fffd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22f615df-4d91-49fc-a627-52dd3a6e5db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274c2cc4-87f0-4b06-8454-eb7091bb761d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afc1320-1e38-4330-83eb-778eb48aaa81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c175240f-d0bc-49e9-84db-1afb34cfc1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d9f0aa-3810-450b-b751-eb7fd45beb7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af371936-6c56-46f7-b2b8-8e02c8b1f677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea868945-8b8d-4a98-aabe-b31c80719ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41eea3aa-8b8c-4efa-ad60-52fda8fc335a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f5d67f-9dc9-48cc-948f-007b0e64e1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ecadddc-703e-4161-a95f-b0576eef00d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6943edb4-c145-4789-89f8-af6b338ffe16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97705f08-8bfb-4248-9cce-a223df217d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450ee6ae-3516-445f-8451-97f1155e496b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 777c3790-c920-4c13-be0b-ae46bd15ce14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13af50af-963d-4b8c-90e3-dc90199a873a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6b1b3a-f32f-4985-a78f-f1de4125f6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239ea1c5-67ad-411d-8cb6-e36fee05546b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45050ec5-2f7a-4fdd-8ee3-386da6a88180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a74c496-d3be-4ae2-a836-1222ad1dc5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a022af-1555-4ec3-b2e8-141ea801315b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69e147ae-d8fc-4128-a349-4b3cd3fd1a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afa0de5-5eaf-4043-9f61-ce0cdf64faab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e6781f-67f2-4d71-b6ee-c13f498ac9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8d942f-e0cc-4b83-acf1-38c9808c11e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5131eca0-99ad-48f0-aa71-c7ceb2ee863f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9735573-c7b5-4413-a1e4-1c3ad4f3868e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c1acf7-85f8-4855-91f6-b12222a367e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82408be5-35c6-4df9-b7af-23f17fed0b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 866225d8-ba17-489a-adcb-219c01ffb137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e8d491-f66f-438c-bc2d-38814403024e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86550321-fd4e-444e-b3de-9ebb84bb4ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02255bcd-1b94-427d-96d2-10ef3565f925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e52bd234-c05a-4655-9cbc-6faecabe5b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb0971b-8624-4cc1-b4cb-d670f49ba2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00155aa-659c-4d07-b007-85aa01cc3028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 314736b1-cd86-4ca6-87a5-6388d64f5292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d553f8-c5b0-4b63-8346-c24885afaa32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c22e0049-8ccc-4649-9b91-ae1480b9d88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efa571ec-b677-47ff-8741-3c0b148f6efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b27a027-8c4f-4d65-a762-3d97f90e951f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f73f78-aaa5-46b0-b6e2-9dce61a63cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ce7a273-30cb-4fbe-be80-a8bf93885937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32088200-be92-45f4-ad52-e93c24fd64fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ce6659-7650-4059-82b3-8f812862dc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca0b9fab-8ad0-4fd1-a9cf-3ba16ab6eea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939c5160-e47a-4b22-8282-4809c3768089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7351f0fb-a6ee-4157-8e6c-88093d74bb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de14323f-11dc-4902-8673-af05434aaa63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fccdbd-5ebd-45e9-8373-b502d8e8d7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4de3cf-6294-460c-9039-037ab6c891a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f584476d-eb44-4fca-a9ce-8b8a065efbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378cb9bb-d28a-4e40-85e5-ab2f774f2d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2627f2b-2d30-41e1-9666-8128f7c6f86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 286753e5-176e-4fc7-a0d6-8e58c02ac6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ff786d-6d70-4721-bd15-2b37afd12c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03e38bd4-9baa-45a0-b0ab-f883f99c6bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0dcce2-9c52-499e-9e95-377ba3f0d416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a473b0-e6eb-434d-a3db-dcf1fad2b92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8f5f0d-1657-4f63-8141-c120cc375660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846293b3-0e61-4ede-b06c-e8efff582c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e20d19-223b-4f53-8580-9bf0661324e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0bf3668-c81e-44bd-b707-c09ba3326159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91bcd0a0-9e88-4b63-b644-fd9fed4c1e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d6951c8-e164-4cbc-8837-c5fdb3c750ee
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_32
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_labels.txt

📊 Raw data loaded:
   Train: X=(620, 24), y=(620,)
   Test:  X=(155, 24), y=(155,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 611 samples, 5 features
   Test:  146 samples, 5 features
✅ Client client_32 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0729, RMSE: 0.2700, MAE: 0.2315, R²: -0.0018

============================================================
🔄 Round 2 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0723 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0927, val=0.0685 (↓), lr=0.001000
   • Epoch   3/100: train=0.0922, val=0.0683, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0909, val=0.0692, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0907, val=0.0694, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0890, val=0.0721, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 2 Summary - Client client_32
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0092
   Val:   Loss=0.0685, RMSE=0.2618, R²=-0.0125
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0725, RMSE: 0.2693, MAE: 0.2312, R²: 0.0033

============================================================
🔄 Round 3 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0939 (↓), lr=0.000250
   • Epoch   2/100: train=0.0845, val=0.0939, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0842, val=0.0941, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0944, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0837, val=0.0947, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0832, val=0.0959, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 3 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0004
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0001
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0725, RMSE: 0.2693, MAE: 0.2313, R²: 0.0034

📊 Round 3 Test Metrics:
   Loss: 0.0719, RMSE: 0.2681, MAE: 0.2300, R²: 0.0124

============================================================
🔄 Round 7 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0876 (↓), lr=0.000063
   • Epoch   2/100: train=0.0868, val=0.0875, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0867, val=0.0874, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0865, val=0.0873, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0864, val=0.0872, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0860, val=0.0869, patience=5/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0858, val=0.0867, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 7 Summary - Client client_32
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=-0.0016
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0002
============================================================


============================================================
🔄 Round 8 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0894 (↓), lr=0.000016
   • Epoch   2/100: train=0.0863, val=0.0895, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0863, val=0.0896, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0862, val=0.0896, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0862, val=0.0897, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0861, val=0.0898, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 8 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0091
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0052
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0714, RMSE: 0.2672, MAE: 0.2292, R²: 0.0187

============================================================
🔄 Round 10 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0812 (↓), lr=0.000004
   • Epoch   2/100: train=0.0868, val=0.0812, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0868, val=0.0812, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0868, val=0.0812, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0868, val=0.0812, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0868, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 10 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0012
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0518
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2293, R²: 0.0179

📊 Round 10 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2294, R²: 0.0179

📊 Round 10 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 13 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 13 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0070
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0187
============================================================


============================================================
🔄 Round 16 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 16 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0121
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0014
============================================================


============================================================
🔄 Round 17 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 17 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0117
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0109
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

📊 Round 17 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 21 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 21 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0105
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0063
============================================================


============================================================
🔄 Round 22 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 22 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0103
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0220
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 24 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 24 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0046
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0298
============================================================


============================================================
🔄 Round 26 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 26 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0111
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0018
============================================================


============================================================
🔄 Round 27 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 27 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0079
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0520
============================================================


============================================================
🔄 Round 30 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 30 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0046
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0596
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 31 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 31 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0106
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0036
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 35 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 35 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0063
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0413
============================================================


============================================================
🔄 Round 36 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 36 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0108
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0079
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 39 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 39 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0079
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0154
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 42 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 42 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0079
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0174
============================================================


============================================================
🔄 Round 43 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 43 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0070
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0196
============================================================


============================================================
🔄 Round 44 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 44 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0099
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0109
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0183

============================================================
🔄 Round 47 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 47 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0045
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0253
============================================================


============================================================
🔄 Round 48 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 48 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0003
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0496
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 51 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 51 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0128
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0103
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 52 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 52 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0165
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0234
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

📊 Round 52 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 54 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 54 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0104
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0407
============================================================


============================================================
🔄 Round 56 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 56 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0051
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0256
============================================================


============================================================
🔄 Round 57 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 57 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0107
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0116
============================================================


============================================================
🔄 Round 61 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 61 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0136
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0023
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 62 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 62 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0110
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0012
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 64 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 64 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0060
   Val:   Loss=0.0876, RMSE=0.2961, R²=-0.0225
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 67 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 67 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0080
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0129
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 69 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 69 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0096
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0072
============================================================


============================================================
🔄 Round 70 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 70 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0071
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.0274
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

📊 Round 70 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0183

============================================================
🔄 Round 72 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 72 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0134
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0085
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

📊 Round 72 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

📊 Round 72 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

📊 Round 72 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 83 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 83 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2961, R²=-0.0140
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0113
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 84 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 84 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0151
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0131
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 85 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 85 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0144
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0121
============================================================


============================================================
🔄 Round 86 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 86 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0133
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0276
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 88 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 88 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0130
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0051
============================================================


============================================================
🔄 Round 89 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 89 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0053
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0321
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

📊 Round 89 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 91 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 91 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0098
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0067
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

============================================================
🔄 Round 93 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 93 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0111
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0019
============================================================


============================================================
🔄 Round 94 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 94 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0170
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0179
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

📊 Round 94 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0184

📊 Round 94 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

📊 Round 94 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

📊 Round 94 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 105 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 105 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0095
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0085
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

📊 Round 105 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 108 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 108 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0087
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0471
============================================================


============================================================
🔄 Round 109 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 109 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0126
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0060
============================================================


============================================================
🔄 Round 111 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 111 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0107
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0108
============================================================


============================================================
🔄 Round 112 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 112 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0111
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0022
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 113 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 113 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0153
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0216
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 116 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 116 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0112
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0069
============================================================


============================================================
🔄 Round 117 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 117 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0139
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0049
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 120 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 120 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0144
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0093
============================================================


============================================================
🔄 Round 121 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 121 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0083
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0125
============================================================


============================================================
🔄 Round 123 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 123 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0121
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0030
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 125 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 125 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0119
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0146
============================================================


============================================================
🔄 Round 127 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 127 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0122
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0038
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 129 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 129 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0111
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0071
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 130 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 130 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0076
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0169
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 132 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 132 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0087
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0325
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

📊 Round 132 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

📊 Round 132 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 138 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 138 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0116
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0006
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

📊 Round 138 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 141 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 141 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0118
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0003
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

📊 Round 141 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 144 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 144 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0035
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0362
============================================================


============================================================
🔄 Round 145 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 145 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0144
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0036
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 146 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 146 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0108
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0329
============================================================


============================================================
🔄 Round 147 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 147 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0032
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0407
============================================================


============================================================
🔄 Round 149 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 149 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0026
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0401
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

📊 Round 149 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 153 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 153 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0091
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0102
============================================================


============================================================
🔄 Round 154 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 154 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0148
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0125
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

📊 Round 154 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 160 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 160 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0083
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0125
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

📊 Round 160 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 165 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 165 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0114
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0022
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 169 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 169 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0030
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0329
============================================================


============================================================
🔄 Round 170 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 170 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0138
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0057
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 172 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 172 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0080
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0281
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 174 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 174 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0115
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0021
============================================================


============================================================
🔄 Round 177 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 177 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0109
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0461
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0185

============================================================
🔄 Round 180 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 180 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0091
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0094
============================================================


============================================================
🔄 Round 182 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 182 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0068
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0278
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0714, RMSE: 0.2673, MAE: 0.2293, R²: 0.0186

============================================================
🔄 Round 185 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 185 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0048
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0301
============================================================


============================================================
🔄 Round 187 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 187 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0089
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0180
============================================================


============================================================
🔄 Round 189 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 189 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0162
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0109
============================================================


============================================================
🔄 Round 190 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 190 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0110
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0159
============================================================


❌ Client client_32 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
