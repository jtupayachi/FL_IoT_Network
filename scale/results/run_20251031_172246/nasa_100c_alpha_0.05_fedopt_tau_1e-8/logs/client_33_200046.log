[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b669a3-9ead-405b-aebe-48f18bce7164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 653a0b97-ee7f-4668-94b2-6015600925b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1a10c07-4095-42e3-b62b-3369c5643a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9539a1-1190-4178-889f-114f5af98f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e737136-ed2c-44ad-bddd-0d541af3e635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cb2ec2-492d-4aba-b0f6-c0727e7ef682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e3cc4d-75ae-4c87-9236-29788fc1cb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be119883-227a-4180-a475-cd3c7d66c67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33fa21b8-243d-43c5-9ef9-6f60f1a01532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a209665-a71a-4407-82b7-0b8adf6bd3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d632286d-0bca-45bc-ac16-c01242306312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e20abc9-fd4d-4dc2-a5ae-e50151f799b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be523178-c40b-4320-a9f1-f019074782e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 729c037f-6b00-476e-bd78-86b2a2403705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa2a281-30d8-4887-8fb6-a1156eddf788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daed2d3c-c125-4799-a34f-26ce8e393ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19c3399-3aef-43e8-9e69-376df699acf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33566108-55c8-4ee2-8217-df0315138917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bbb7496-13c0-41e3-b6dc-64e04a966ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f6c30da-46d3-4559-9f9c-aa72bc64b9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a295c15-36b1-42d1-acba-e93d5c51cd9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d83859-8e38-4857-894f-c27be39beed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8972e5d2-78a3-45cd-aa12-f72d4a0b11a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bde7f76-ac4b-4db6-9023-6ed6a05478eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 626813f7-8c71-4830-bc2d-ba386062def6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11aa00a6-c6f4-4cd9-acbd-b997f239f422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edbcec5b-0348-4761-b2bc-8a06f5ae5fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd33933-ce24-4aa7-abfa-2a3692fa52c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90736f2a-3c38-453e-aa15-5067b1d34955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a72ba982-deea-4075-be0d-c8baf2a10d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3866032-1bed-4074-a7bb-842c060aa356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 028f98ed-73f9-47ee-b834-29809a81d5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4102afab-2080-4854-be73-39e83c366179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a8baf6-e3bd-4523-9a04-a57ee57a0038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0723fe3a-6e8a-4a59-88d4-350722217cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0d69e4-4265-4540-bfa1-3c32e2b53c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab10a115-3bde-423b-897e-59fcb36ca76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c577fa98-17fc-42a6-94a4-b05bb5b041eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eaf5a98-159d-4a75-964d-74c1b6e11aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb890ad-f2d1-47e5-85aa-d49786ae33ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a863e62d-ceb6-434f-a99e-1c814718bc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc42b5be-833a-4413-896e-29d490812a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2dd4da5-3113-413e-8a05-35f897a4387a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abe3a5ba-5eaf-478c-a2ba-168914c0aa82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f814b08b-c889-40b6-bedb-226923d0f515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61328d65-a29a-46c3-9da8-f3a6b54039a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cd4642-aafd-4137-a1e1-8ebf6bb3d238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa1445c1-7705-4bbd-95aa-30e4dcaff682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12aac79b-5c86-462d-a517-997a2b236e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3940831-dd20-4099-b4d5-a6b117f48ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6489c0-bc4b-43fe-bc89-a138d79d8325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ebaef8-9c40-4a37-bb50-5b17bfb62a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a628138-8751-4f89-8017-fab5f0d89a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033a586f-8a19-4034-837e-f5909a36bd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45aa6da4-2b20-4fc6-b37f-a3f5a6bdceff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 652323b1-af8d-4e26-8a8d-b676954689e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8f2fde-b5f9-424f-9d8c-945a7049d697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf25df9f-e2be-4ff5-b600-cf982c24881e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a412235-5253-4b4b-a555-9d28ea503171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca790f7-86ac-412d-a648-b4d27b542465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9121400d-9e97-4d28-a84d-b7e5c973a999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e79aeb-4b0c-421d-bcc6-70cd9593c076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091bdd38-06bb-45e0-be6d-db8082869020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a261aa6-b336-4a9f-8a8e-dc56d27fd874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dfd385e-e94a-47b6-8f8c-b6c257335890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a825c9a-c2ba-45d1-bf6a-a5494c0cf304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239a02b9-617a-42e8-8542-3a7aa92120cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f266192-bf91-4e63-8b81-fb04a0b4def5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002d880a-884a-403c-9f33-99c9d1d6940d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 880d4cb2-db6d-4dd4-af64-1af9be87a415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87a071f-01f8-4f7b-8760-15a8343a2748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa167f3-85cd-4a43-a726-27bf04cf3e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7259818a-b229-42cd-8337-2b9e78a6478a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67dc7f42-3da9-44d4-a90f-b80282ef80a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98df87de-b7ea-44c0-ac97-9f3bf5bbf798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2768b84f-d742-460f-91c0-cdc069d78ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6acc4bf8-4200-47f8-998d-0073e8f7a75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b858421-223e-4749-b7a9-bf2b2cab563b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f75a032-ec23-4358-a7d3-5ee03b2372c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab5c274-cbfd-4c9a-8f89-33d7f81326c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29478ab4-c8ae-4d04-9ce4-af229e5e03a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc2c578-8cd4-4097-a12e-85daed243fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09dd88c0-b64d-47c0-a357-341c774aa261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f971f225-bbd0-4375-bcf4-ab546a3cdaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7b9545-5ed4-468d-aa7f-e7aad9ebaa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672bc359-5a91-40b2-a456-ed60987dd6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76906fa5-4358-43be-b597-9f50da2f6fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8130542a-bf7b-4de0-bfe2-9e793654cd40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf2c2ab-c108-44d9-b662-c30122d3a038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2deef01e-6d00-4a39-bb75-7ff754358354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e8ab972-5f61-4578-b2d4-4ef7eda1222f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2507dae8-49c4-4526-96aa-300dee4414c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaef3752-cb94-4ed8-812b-3f50dff3b7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01b26ec7-7320-4e2b-8ff5-40dfeaf0081b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087e3a74-27e7-4786-b602-d1c7c52a7631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2bad3fd-c4b0-4f04-9751-1e40ce0e49fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa435b6-ff60-4a5d-92df-607c1f667bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e259d5a-9417-48f4-a858-fb903cc8d77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b896bf71-4356-4b91-9904-13285cc32491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2de16ed-bef3-4cf0-9e6b-adf3ec794f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d38b25d3-b1c1-4338-8333-403ad92a1675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9cc6d58-1b82-4d89-91e9-4fa15682d6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f54e03-f0be-4e7e-8e72-2031e4eb31e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7b7506-ac03-476c-9157-151e0f0fb976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c9f2f01-62bc-44ce-ae26-8d116f00f935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebe886f5-897d-4517-8002-b775566e3c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685e3c7e-c5d6-40a7-b71a-9423c3bf571a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c74b19-9b3b-40eb-ab55-1164ca7cf1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c23388-8dd8-461e-8483-f68d4dece804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af1d9e5-19b7-42d3-a6dd-29b260789f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e50c27-ca69-4700-be51-2c9047e5fb94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a039c841-1f9e-4be5-b714-2e687826099e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9c6be8-e2b3-442e-9133-62c820e07f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795d1840-8547-4c7d-a43e-3ce307f34e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a81294-d26b-4838-a5fc-61ce254e2404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e39c9a-75c1-4606-b5d2-e591f43ada81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66079247-5cb4-448f-a013-d27606723694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ca553d-d3cd-402b-80e0-6aa7b8c97190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72dfafe4-8f89-4820-ab37-f210a48b9879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0042f13-0a42-4411-a044-45d465b91072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d8843fc-a213-4237-920a-a3addd941075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6340b84f-1472-47a7-813e-b4922545b576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df59f4b8-bf37-4254-920f-a92a9b291168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768bddf4-19f5-47a1-b4c2-1ea671cf29be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10f7547-cfc6-4289-ab03-0d2faa34b09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba35f00c-cb92-4f48-a28e-239d9002644d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a265ab6-1b9b-4156-ba75-c46b16e6f298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c493bbdb-8ca5-4dde-b107-b9f412a2d4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ef53e9-393a-4e34-9f4e-44d01a0c65b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae726d2-d438-4132-8258-c9f3a16d78df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f06eb9b-51b0-4719-b733-4b12e047c101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1652087f-0bdb-4182-ace7-4dab8e523ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf9c94a8-5467-461b-8a2c-25e907c35c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7270950d-3865-4573-98db-f3cd90571c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9421da88-bcf3-4984-8e7e-ab88b738e4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dab3294-6e58-4bc2-84b5-82b3c760e916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9266fa6-0c71-4881-82d0-2ef95f4b578d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdb7ff8e-cd39-4835-96e4-edde399bc66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f04b3d3-91f6-4dab-accc-cb0534b08d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8123c735-15f8-4728-a3f3-60c4aefc1192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d4d303-8ed8-4347-8c81-d05748830478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59250c22-4eaa-449e-a21f-32825f79eb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4291e269-1656-4ab6-bf87-dad3631a681d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_33
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_labels.txt

📊 Raw data loaded:
   Train: X=(2282, 24), y=(2282,)
   Test:  X=(571, 24), y=(571,)

⚠️  Limiting training data: 2282 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  562 samples, 5 features
✅ Client client_33 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2558, R²: 0.0098

📊 Round 0 Test Metrics:
   Loss: 0.0849, RMSE: 0.2915, MAE: 0.2553, R²: 0.0133

============================================================
🔄 Round 4 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.001000
   • Epoch   2/100: train=0.0798, val=0.0809, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0793, val=0.0806 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0786, val=0.0801 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0778, val=0.0794 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0720, val=0.0741 (↓), lr=0.001000
   • Epoch  21/100: train=0.0670, val=0.0731, patience=4/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0582, val=0.0798, patience=14/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 4 Summary - Client client_33
   Epochs: 32/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0675, RMSE=0.2597, R²=0.1735
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.1186
============================================================


============================================================
🔄 Round 6 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0844 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   ✓ Epoch   2/100: train=0.0784, val=0.0824 (↓), lr=0.000250
   • Epoch   3/100: train=0.0779, val=0.0827, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0777, val=0.0825, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0775, val=0.0824, patience=3/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0764, val=0.0817, patience=1/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0754, val=0.0810, patience=4/15, lr=0.000063
   📉 Epoch 26: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0749, val=0.0806, patience=3/15, lr=0.000031
   📉 Epoch 34: LR reduced 0.000031 → 0.000016
   • Epoch  41/100: train=0.0746, val=0.0805, patience=13/15, lr=0.000016
   📉 Epoch 42: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 6 Summary - Client client_33
   Epochs: 43/100 (early stopped)
   LR: 0.000500 → 0.000008 (6 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0750
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0385
============================================================


============================================================
🔄 Round 7 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0777 (↓), lr=0.000008
   • Epoch   2/100: train=0.0794, val=0.0776, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0794, val=0.0776, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0793, val=0.0776, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0793, val=0.0775, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0793, val=0.0774, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 7 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0362
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0210
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2523, R²: 0.0378

============================================================
🔄 Round 8 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0822 (↓), lr=0.000002
   • Epoch   2/100: train=0.0775, val=0.0821, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0775, val=0.0821, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0775, val=0.0821, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0774, val=0.0820, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0774, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 8 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0401
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0458
============================================================


============================================================
🔄 Round 9 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 9 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0452
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0224
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2507, R²: 0.0480

============================================================
🔄 Round 12 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 12 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0613
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0328
============================================================


============================================================
🔄 Round 13 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 13 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0584
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0485
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2507, R²: 0.0484

============================================================
🔄 Round 17 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 17 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0603
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0427
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0500

============================================================
🔄 Round 18 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 18 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0660
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0237
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

📊 Round 18 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 22 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 22 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0526
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0778
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 23 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 23 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0543
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0728
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 24 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 24 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0550
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0718
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 28 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 28 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0668
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0229
============================================================


============================================================
🔄 Round 32 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 32 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0609
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0432
============================================================


============================================================
🔄 Round 33 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 33 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0601
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0198
============================================================


============================================================
🔄 Round 36 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 36 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0587
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0579
============================================================


============================================================
🔄 Round 38 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 38 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0583
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0328
============================================================


============================================================
🔄 Round 39 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 39 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0541
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0538
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 41 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 41 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0549
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0681
============================================================


============================================================
🔄 Round 42 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 42 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0626
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0310
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 44 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 44 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0623
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0374
============================================================


============================================================
🔄 Round 45 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 45 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0623
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0426
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 46 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 46 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0543
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0664
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

============================================================
🔄 Round 47 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 47 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0633
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0344
============================================================


============================================================
🔄 Round 48 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 48 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0610
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0473
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0502

📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0503

============================================================
🔄 Round 52 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 52 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0610
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0446
============================================================


============================================================
🔄 Round 55 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 55 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0575
   Val:   Loss=0.0799, RMSE=0.2828, R²=0.0582
============================================================


============================================================
🔄 Round 58 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 58 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0580
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0548
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2504, R²: 0.0503

============================================================
🔄 Round 60 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 60 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0520
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0849
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2504, R²: 0.0503

============================================================
🔄 Round 63 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 63 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0584
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0566
============================================================


============================================================
🔄 Round 64 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 64 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0585
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0576
============================================================


============================================================
🔄 Round 65 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 65 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0680
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0215
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2504, R²: 0.0503

============================================================
🔄 Round 67 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 67 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0536
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0473
============================================================


============================================================
🔄 Round 71 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 71 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0624
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0402
============================================================


============================================================
🔄 Round 72 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 72 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0639
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0333
============================================================


============================================================
🔄 Round 73 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 73 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0592
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0546
============================================================


============================================================
🔄 Round 74 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 74 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0649
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0282
============================================================


============================================================
🔄 Round 75 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 75 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0593
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0568
============================================================


============================================================
🔄 Round 77 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 77 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0501
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0938
============================================================


============================================================
🔄 Round 81 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 81 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0610
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0306
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0503

============================================================
🔄 Round 82 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 82 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0563
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0619
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0503

============================================================
🔄 Round 85 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 85 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0600
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0473
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2504, R²: 0.0503

============================================================
🔄 Round 91 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 91 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0588
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0339
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0503

============================================================
🔄 Round 92 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 92 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0573
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0526
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0503

============================================================
🔄 Round 93 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 93 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0571
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0546
============================================================


============================================================
🔄 Round 97 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 97 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2750, R²=0.0580
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0575
============================================================


============================================================
🔄 Round 98 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 98 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0557
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0714
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0503

📊 Round 98 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 104 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 104 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0592
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0533
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 105 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 105 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0569
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0531
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 106 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 106 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0541
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0698
============================================================


============================================================
🔄 Round 108 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 108 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0526
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0846
============================================================


============================================================
🔄 Round 109 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 109 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0504
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0923
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 110 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 110 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0609
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0492
============================================================


============================================================
🔄 Round 111 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 111 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0552
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0664
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 112 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 112 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0574
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0636
============================================================


============================================================
🔄 Round 113 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 113 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0650
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0312
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 114 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 114 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0640
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0399
============================================================


============================================================
🔄 Round 115 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 115 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0634
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0405
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 121 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 121 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0551
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0707
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 122 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 122 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0586
   Val:   Loss=0.0670, RMSE=0.2588, R²=0.0560
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

📊 Round 122 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

📊 Round 122 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 131 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 131 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0628
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0318
============================================================


============================================================
🔄 Round 133 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 133 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0580
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0624
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 134 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 134 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0668
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0198
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 136 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 136 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0583
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0585
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

📊 Round 136 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

📊 Round 136 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 147 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 147 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0591
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0558
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 150 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 150 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0622
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0448
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 153 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 153 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0610
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0483
============================================================


============================================================
🔄 Round 154 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 154 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0591
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0562
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

📊 Round 154 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 159 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 159 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0607
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0452
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

📊 Round 159 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 161 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 161 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0544
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0640
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 162 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 162 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0584
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0596
============================================================


============================================================
🔄 Round 165 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 165 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0587
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0599
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 167 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 167 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0602
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0527
============================================================


============================================================
🔄 Round 169 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 169 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0585
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0610
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0505

📊 Round 169 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0505

📊 Round 169 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2503, R²: 0.0505

📊 Round 169 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2503, R²: 0.0505

============================================================
🔄 Round 178 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 178 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0583
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0597
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0505

============================================================
🔄 Round 180 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 180 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0609
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0496
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 182 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 182 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0477
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0949
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

============================================================
🔄 Round 183 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 183 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0592
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0575
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0504

📊 Round 183 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2503, R²: 0.0505

============================================================
🔄 Round 185 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 185 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0579
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0629
============================================================


============================================================
🔄 Round 186 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 186 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0648
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0345
============================================================


============================================================
🔄 Round 188 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 188 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0620
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0377
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2503, R²: 0.0505

============================================================
🔄 Round 189 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 189 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0571
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0648
============================================================


❌ Client client_33 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
