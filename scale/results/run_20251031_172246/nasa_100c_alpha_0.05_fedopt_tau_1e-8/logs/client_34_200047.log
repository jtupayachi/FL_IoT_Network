[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2509c972-6eef-4e62-b19c-71cb44911ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d57e375-a1c1-4a78-b6c4-2468f88ee6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9a2d80-055e-496d-9442-68e9f9b38de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ea2a89-6317-4165-b909-85e587c50622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf232e3a-c4ef-466a-898c-bfa03685ca14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 755d4bd7-8e8f-410c-bea7-7fe29a26c5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5524b9-2de0-4a08-9a84-8139216ccce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaee7770-669f-4d3f-8bf2-bbe882683665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68a7a95-fa0f-4700-9030-d62f3ce76c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7f5a9f-5562-4b5b-bc6e-f4548f5acc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b093d105-f60f-4e9f-bef5-6e09d5ae8851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2a50aa-54ad-4cfa-9741-072375c23716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a3edc60-10cb-48d4-974a-bd3b30127603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bc6494-3223-46aa-9f86-c2c6807787ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748a5782-6482-423e-ab69-61609b666435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539f6729-3f31-455d-b925-9aba0416267c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c80fc02-a459-4645-a5f1-4476f0108dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66aa11a7-ad78-444f-9022-5da5cf3b189c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad78679c-fd41-4510-a6c8-f12d2e9516f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 870c45da-39fe-49b2-a327-27ef18bb3542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8a7955-f81f-4c6f-a8bc-7a2e0e5ad8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71cd40e6-6f84-4ce0-98fc-f1b9273c16d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca8e21b-aa53-4efe-a365-8cf906683f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8767eca5-1d6e-4217-9689-460843a31e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3a779d-2b66-4327-9b6c-32ae76cf90e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad77d68b-4dec-43d5-bd13-75eb3be961b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e87629-f766-4f35-a0aa-edc7fa661475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06e57c5e-783d-464c-b679-0b8ecbfe1974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef9ad05-0a49-4b6a-bbcb-2f09c1af2fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce71aa6-747a-4bce-bf97-61c41aea914f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51817755-4e6d-4f70-896c-051c3d739f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73480a13-97a9-4ac8-91e8-8fec9a373bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eccb93d-9b67-4bfb-9e29-7800188747b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d97e451-6735-483f-a407-a6c3a345c612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e30cbaa-6955-4b4a-8bae-aac3c492a0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de3cd54-b0da-45e4-bd5e-5074adaac7f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e431240e-89a2-4c72-98e2-a1e69877733c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f81dc764-1e0d-45d1-99ed-ba5ad4968160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 230ddf08-fe8f-45fd-bfef-67fbbee9ed91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1a88fd-3999-40a3-b811-060dd2860684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3db03d7-5ecc-498f-ae29-a36a9d744d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8672613f-d72b-4976-acff-57828bcc27b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab917d45-6629-406e-88d0-703af1eda948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ff233c-6313-4ba6-bc81-38f0c44046ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eedbf065-f33e-4979-b912-d58bdd2d18dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6a9530-e0ab-47b0-87ca-573bdc7e78fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6edf3308-a3ea-45ca-8c05-898bd342c0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07bc2b20-430e-4aa7-9cfa-7c11ec6a9326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20ba5f45-be67-4207-b3cc-703787cca370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2aa678-546b-4677-9d2b-a0d9a32ec3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa756a8-cb1e-42c0-83e1-26521935dbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ed6608-16bf-4472-8378-36da5ef184dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97dc94d4-c275-478e-b3e0-acd3f87e276f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8559553-f7d0-4212-a6e3-b00409f74240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5682d6f-7bbe-4af4-b0df-8bb4dfce73eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d71b754a-13d4-4c61-8fb4-d1a9c162d6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bdf05f3-81c8-4d00-a5a3-3866f644beca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aeeed72-b85f-404d-ad90-9420a916ba65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e20321-b54c-4ab0-aef8-6f57948c57bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40ffb2de-0581-4c8f-9f0d-480c3c25540c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abaa745a-2aad-4068-b1f5-8ade15a2540d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d40fc6-f7b0-4a3c-9598-7e239b060899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f5c55d-8184-4179-8c98-09fb53e204b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f14d7a-cff3-4428-84a9-f04d8d5dfd9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a649025b-0d82-4f63-81de-11c393978145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed6f194-5882-4d51-8865-ad15a681ea1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d6ee48-77cc-41c9-bda9-0434b8004ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03de208-dfd5-4119-b666-9db38a983f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e3c5f0-0412-43c9-95fb-5ca81b8f0027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0815cfbf-18ab-4ccd-8591-6c3dabdf903b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7580ceb-e5ec-4f91-9280-df7d9f08cd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c54826-b2aa-435e-9268-52d9283a8f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2366cf6-36de-4308-a1f4-57a15939b282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c3e2852-3a96-452e-a1e1-e7d6121a3bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6061e5a0-2a1f-4c07-9ad5-276f55ceb8f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message accd678c-57e2-4783-9e29-8072d30bd47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee34da2d-c1ab-4e0d-8eaa-02434b939b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba64656-e048-4d5b-86e0-bedb576b9bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f67b5d-4585-4ee6-afe3-02673a712067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa7646f8-6faf-4e36-88ca-de1cec1f141f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491ee0d9-592b-4f79-88f9-d8448ebd7d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcdb987d-2eb6-49c6-960d-fafe116662ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8dd54a0-c597-4a37-ac8f-855c1dd56b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ac2436-1b2f-462b-9d53-2da69fe56e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc5de621-b87d-48c3-bbcb-61145c11af3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe0c83b-9004-4c8a-bda2-eab26015761b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98091c7e-7ce6-4f7f-bd60-f4e4d7123321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb769838-df90-4667-bda0-84598b703f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe12b71-99f8-4fec-ad36-f1caf6762381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a8978d1-d3e5-4a4e-bc57-4641f6da3b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2ee453-1f70-4e56-8973-ed299241ef4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2647aba1-1ad8-4bc4-814f-22d2de040db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e67095-9ed3-4dff-bc5a-15e5c94ed1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1684b7-e098-442c-a8a2-7a5524ff0b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac9d6ec-3433-443d-909d-9134d8501b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9abc98-b3e1-4589-81c3-b988df7577f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f034762-9891-4d16-bb77-f30db5f0f304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8ec27c-1fb6-44be-9b16-cfcceba0fc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1294735d-c5c3-4d47-9bff-c45a5cef0612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693d31f7-e869-4b6f-a345-5689c04c7d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78af637c-8303-4a89-b607-de3d0ce8c51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b086107-75ef-453f-bfe5-39ea75b762a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e65d94c-3568-4075-bc9c-fc25602d4c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 783b072b-3ce3-4ba8-be4b-fa2d7991e8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a629f2-fadf-46ee-a0fd-9a8c1617076f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02717f5-55a1-4618-862f-7d881a6367fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c771a0-c98a-42b8-ab9f-30dc1340264d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3216c9-a22f-45f4-b585-fb65a359e8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b20a38-710d-4c9f-8bdf-97d71282d8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cff59cc-79c9-4ff5-8808-792348c1091b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54bb935d-6a27-459c-96fe-e4d52a410b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9296d09b-f52c-4820-a89d-c83f645f4718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bbabd0a-a7d2-4a86-ab38-b34159d2e726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ba716a8-7c9e-4044-9857-c3b12cd0b179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9c58fa-15a8-4d8a-978c-c88e3a0d96f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10b2dfa7-0870-4992-b793-0a1daaef41f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5534f49e-0c45-4067-83ac-171559df689a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f96c8ec-2b24-4ee1-b72c-0d94e5d6fa0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3128fb-6de3-43b0-b996-1abb3ef0aba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdfe65d7-88d8-4b4d-b720-0ffb5fbdd707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c47260-c0a0-42a9-8102-a3277bec71c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd168f33-c840-4145-9498-065cb8d18f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04bfb54-b051-4c8f-8b81-ccac04d80ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcae97ae-267b-415d-b88e-391afce795a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5105e290-a1c7-4741-a628-9a87ce604bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe7b3f1-b8f3-49aa-a6ca-4a30248f5b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0c48c2-5ca9-46a0-9128-adc51472eacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae86c8b1-dd92-4ae4-a9ac-05a10d4c59f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7caa843-ead9-4332-b5a2-d17b2a70403c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6561290-254e-402d-9a02-cd296067c1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dfcbd80-10c8-4b31-8b61-0bf68893761d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55ba40f5-d61e-4378-a725-273eb6e8d43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d8e93e-6db2-4e2e-9d98-07410a67c4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19844e62-2967-4a3a-b75f-a1596fe85e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8ddc84-bceb-4b8e-b813-fcc8b9ec3281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22276f4-3eaf-4b0a-ae07-12e91906ad5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da34302b-ada2-4cb8-aace-e6ae9578c25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82f6712-de7a-4c40-b6f2-acace680c5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e06137-2436-45f7-85d8-1edf0c1be776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 768c2e84-9422-4d0c-9d13-22dc0a7e26a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21f150b-2aad-4f81-9521-06622f6bf4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83df2ebc-5a81-4467-941f-ed324555d72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0afe1b9-17e8-4ac6-8265-1de5105b4e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e49eb5d6-04e0-4bd5-a304-f0caba6c6d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 287381aa-650c-4f5a-9970-f4b32b93e530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c8b845-718d-4a96-aeca-c2860045358f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6db468f9-07b5-4007-895f-6aa80275c354
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_34
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_labels.txt

📊 Raw data loaded:
   Train: X=(1148, 24), y=(1148,)
   Test:  X=(287, 24), y=(287,)

⚠️  Limiting training data: 1148 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  278 samples, 5 features
✅ Client client_34 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0938 (↓), lr=0.001000
   • Epoch   2/100: train=0.0830, val=0.0941, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0839, val=0.0891 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0826, val=0.0875 (↓), lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0875, patience=1/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0785, val=0.0852 (↓), lr=0.001000
   • Epoch  21/100: train=0.0659, val=0.0844, patience=2/15, lr=0.001000
   📉 Epoch 25: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0585, val=0.0872, patience=12/15, lr=0.000500
   📉 Epoch 33: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 2 Summary - Client client_34
   Epochs: 34/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0660, RMSE=0.2569, R²=0.1889
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0512
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2483, R²: 0.0164

📊 Round 2 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2468, R²: 0.0299

📊 Round 2 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2461, R²: 0.0367

============================================================
🔄 Round 7 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0810 (↓), lr=0.000250
   • Epoch   2/100: train=0.0792, val=0.0811, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0789, val=0.0810, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0785, val=0.0809, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0782, val=0.0808, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0760, val=0.0804, patience=1/15, lr=0.000250
   ✓ Epoch  21/100: train=0.0723, val=0.0793 (↓), lr=0.000250
   • Epoch  31/100: train=0.0696, val=0.0771, patience=2/15, lr=0.000250
   • Epoch  41/100: train=0.0677, val=0.0764, patience=8/15, lr=0.000250
   • Epoch  51/100: train=0.0663, val=0.0762, patience=8/15, lr=0.000250
   📉 Epoch 56: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 7 Summary - Client client_34
   Epochs: 58/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0665, RMSE=0.2579, R²=0.1933
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0853
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2435, R²: 0.0564

📊 Round 7 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2433, R²: 0.0578

📊 Round 7 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2433, R²: 0.0580

============================================================
🔄 Round 14 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0774 (↓), lr=0.000125
   • Epoch   2/100: train=0.0778, val=0.0774, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0775, val=0.0775, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0773, val=0.0775, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0771, val=0.0775, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0763, val=0.0773, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 14 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0568
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0550
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2431, R²: 0.0590

============================================================
🔄 Round 15 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0703 (↓), lr=0.000031
   • Epoch   2/100: train=0.0802, val=0.0700, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0799, val=0.0698 (↓), lr=0.000031
   • Epoch   4/100: train=0.0797, val=0.0696, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0796, val=0.0695, patience=2/15, lr=0.000031
   • Epoch  11/100: train=0.0793, val=0.0693, patience=8/15, lr=0.000031
   • Epoch  21/100: train=0.0787, val=0.0690, patience=9/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 15 Summary - Client client_34
   Epochs: 27/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0649
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0676
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2431, R²: 0.0594

============================================================
🔄 Round 18 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0785 (↓), lr=0.000031
   • Epoch   2/100: train=0.0781, val=0.0789, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0778, val=0.0791, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0777, val=0.0791, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0776, val=0.0791, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0774, val=0.0788, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 18 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0491
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0354
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2430, R²: 0.0596

============================================================
🔄 Round 19 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0773 (↓), lr=0.000008
   • Epoch   2/100: train=0.0786, val=0.0773, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0785, val=0.0772, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0785, val=0.0772, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0784, val=0.0771, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0781, val=0.0770, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 19 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0522
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0209
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 24 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0779 (↓), lr=0.000002
   • Epoch   2/100: train=0.0787, val=0.0779, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0787, val=0.0778, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0786, val=0.0778, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0786, val=0.0778, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0785, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 24 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0542
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0341
============================================================


============================================================
🔄 Round 25 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 25 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0508
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0482
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 30 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 30 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0522
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0390
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 32 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 32 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0519
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0441
============================================================


============================================================
🔄 Round 33 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 33 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0491
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0531
============================================================


============================================================
🔄 Round 35 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 35 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0516
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0462
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 37 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 37 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0504
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0496
============================================================


============================================================
🔄 Round 38 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 38 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0482
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0567
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 39 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 39 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0437
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0707
============================================================


============================================================
🔄 Round 40 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 40 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0445
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0668
============================================================


============================================================
🔄 Round 42 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 42 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0516
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0319
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 44 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 44 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0503
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0442
============================================================


============================================================
🔄 Round 45 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 45 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0491
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0555
============================================================


============================================================
🔄 Round 49 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 49 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0469
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0635
============================================================


============================================================
🔄 Round 51 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 51 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0543
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0310
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 52 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 52 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0504
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0286
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 54 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 54 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0552
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0081
============================================================


============================================================
🔄 Round 55 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 55 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0451
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0684
============================================================


============================================================
🔄 Round 56 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 56 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0470
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0555
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

📊 Round 56 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

📊 Round 56 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 65 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 65 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0549
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0143
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0597

============================================================
🔄 Round 67 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 67 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0444
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0225
============================================================


============================================================
🔄 Round 68 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 68 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0503
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0488
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 70 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 70 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0510
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0451
============================================================


============================================================
🔄 Round 71 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 71 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0476
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0566
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 74 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 74 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0448
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0689
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 75 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 75 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0518
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0284
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 76 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 76 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0505
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0498
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 79 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 79 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0476
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0593
============================================================


============================================================
🔄 Round 80 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 80 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0479
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0609
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 83 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 83 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0488
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0583
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

📊 Round 83 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 86 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 86 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0481
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0575
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0598

============================================================
🔄 Round 88 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 88 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0509
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0482
============================================================


============================================================
🔄 Round 89 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 89 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0514
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0477
============================================================


============================================================
🔄 Round 90 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 90 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0513
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0450
============================================================


============================================================
🔄 Round 91 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 91 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0502
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0453
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

📊 Round 91 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

📊 Round 91 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 96 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 96 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0504
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0496
============================================================


============================================================
🔄 Round 98 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 98 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0481
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0484
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 99 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 99 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0487
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0578
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

📊 Round 99 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 101 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 101 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0533
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0215
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

📊 Round 101 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

📊 Round 101 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 108 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 108 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0464
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0464
============================================================


============================================================
🔄 Round 109 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 109 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0519
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0309
============================================================


============================================================
🔄 Round 110 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 110 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0509
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0436
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 113 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 113 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0542
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0353
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

📊 Round 113 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

📊 Round 113 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 118 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 118 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0508
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0466
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

📊 Round 118 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

📊 Round 118 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 123 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 123 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0483
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0457
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 125 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 125 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0423
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0643
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 126 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 126 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0553
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0330
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 127 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 127 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0524
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0338
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

📊 Round 127 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 129 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 129 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0496
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0367
============================================================


============================================================
🔄 Round 130 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 130 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0500
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0385
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 132 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 132 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0523
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0406
============================================================


============================================================
🔄 Round 133 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 133 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0524
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0337
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 134 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 134 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0568
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0239
============================================================


============================================================
🔄 Round 138 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 138 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0501
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0531
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 144 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 144 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0535
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0349
============================================================


============================================================
🔄 Round 145 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 145 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0547
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0290
============================================================


============================================================
🔄 Round 147 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 147 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0557
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0258
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0599

============================================================
🔄 Round 150 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 150 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0474
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0404
============================================================


============================================================
🔄 Round 151 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 151 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0496
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0267
============================================================


============================================================
🔄 Round 153 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 153 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0510
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0495
============================================================


============================================================
🔄 Round 154 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 154 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0484
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0583
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 158 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 158 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0465
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0605
============================================================


============================================================
🔄 Round 159 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 159 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0493
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0484
============================================================


============================================================
🔄 Round 160 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 160 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0491
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0495
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

📊 Round 160 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0600

============================================================
🔄 Round 163 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 163 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0519
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0314
============================================================


============================================================
🔄 Round 165 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 165 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0462
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0701
============================================================


============================================================
🔄 Round 166 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 166 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0439
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0348
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

============================================================
🔄 Round 167 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 167 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0528
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0411
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

============================================================
🔄 Round 171 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 171 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0555
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0331
============================================================


============================================================
🔄 Round 174 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 174 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0508
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0472
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

============================================================
🔄 Round 177 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 177 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0494
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0536
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

📊 Round 177 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

============================================================
🔄 Round 179 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 179 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0568
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0194
============================================================


============================================================
🔄 Round 182 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 182 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0457
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0497
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

📊 Round 182 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

============================================================
🔄 Round 188 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 188 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0469
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0616
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

📊 Round 188 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0601

❌ Client client_34 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
