[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1cdd97-a6bf-4ceb-aa57-af34380d6677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ca979b-8747-48e3-bb4b-54c904159f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb4328ba-2b69-4c00-8bcb-51a5eb4a661f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9333f4-977a-48fb-ac47-787a26ed0f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655a3ea1-6473-42cf-bc9e-5709ef0ae030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc1d0d6-13f9-45d9-9611-5eb8aabdab9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed403271-23ab-4a5b-8e69-da1d45048f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0275e1f3-16b4-40d9-86e5-3d051a671c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048fd04d-b121-4459-a016-7d28f94be2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41f7583-90fb-496f-baf0-031d042f13e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58ea61a-b517-4d3a-a636-75e6a45d9b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c52e6a0-7930-4692-bf5f-e556d803dc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d1daa1-dcca-459b-850d-5382de2aeb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7461ee-1b3c-4573-823c-f26e15b66e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d4880de-e855-4e05-abd5-482a26f3c4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a217cc-78cb-43d7-a314-5a995cff660e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ae89e9-8a2f-4112-b0f4-c6a9b47b5985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13e0c3f-4b8a-451a-80ea-41ebfffeda37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf16251-08f1-40ab-aeeb-2d4e4fea485e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34484c9-f98c-41c3-94cc-b3ca103f1650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5267cc47-00c4-40ed-a172-f2cd7dfa1174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec9d1901-3f98-435b-b909-4c852c9bcbb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 094b39f2-a383-40b3-b57a-fa8162386f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e9f2cf-2bde-45bb-8895-fa822a58a26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7365b65-6464-4942-96f7-944da2a0c869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43136533-77eb-476c-8ddd-83bf1643c064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a116f0c4-dcf4-479f-a940-5daec160819a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07bc64b4-5a94-4148-9797-f7e33fd908ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a425503-e948-45e2-9643-89b1e3d26c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37efc317-6c9c-4083-a9e1-be9f6603aaab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292a6b5b-3c6c-431b-89b0-3e38166f3a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db14135-0fe5-449c-be42-fe2fec086c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a5bcac-9394-4dbd-b13a-8e47271d829c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06085cda-2772-4142-a579-228861ab619b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2101541a-c153-4ea2-81cf-a2ef48c3f1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b02a5c-7c4b-4d4b-8b49-1a35b2b1a8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1800c9a-c041-414a-9a33-b60b12cd1a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24223660-9700-4888-841a-cadbd0cd8994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 778376f4-fa7f-42f1-9f8e-223ae6881f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ca4448-a0a9-497c-a57e-534001c5d1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b17105b3-ec51-4b92-a2de-73453f0701b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f4e139-caa8-489b-acbe-1d7a3d263652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a742d828-18a3-440d-a9c9-c44db854fee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f921137-b1a4-4481-b411-d369bf2f61dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 826d8ef4-a06f-41d9-be92-ee9119211a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa44034-0d60-469b-af75-28bf6b0fa657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e236b9d2-6d18-4cba-a360-ff9d8d007590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 139f4d43-1087-4615-a4e8-b1c947fbf354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d778748-48a7-4c72-b96a-4c2ed840f9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da2e62bc-0a8e-454d-ad17-e64af9c03712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383cf8ea-5e1e-43d8-bb60-3aa16b6b7ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af9f5bf-fe86-430a-b4d6-7750eab33582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef83ee2d-e77c-4aba-bf87-71e1b8082204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d2a800-cb04-4a62-a6fd-e47c9811a191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb5f3ae-23ff-4036-ab5d-2d4a898d537d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1d7c526-4b70-4a5b-aeeb-1e4c73bdc78c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5154e25a-40d7-4fef-96da-f5a3fa375f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d922e25-c35a-4e4a-849f-0c52718fdb73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb3c3ac-2faa-497b-aea6-7dd7c3b9d8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc99833-64fe-4c8a-b3d1-96264db29219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fbc2368-e16b-4b84-babc-12f552d73e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98659f07-f9d4-4451-acf1-afcef62a804a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad4ad68-dd4c-4f35-98e7-723ccb0befac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81f3db6-ce85-4908-a305-b2fe399c80f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d299fa-b853-4ffc-91c0-19e5cfa7a7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6feb71-ef10-4d72-afc0-10a029ced3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7596dfc-4a44-48f2-a9f9-9694a6d7d2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078841b3-c2c4-46be-ab8a-f72de3f776ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f093132-d186-431b-a4d9-afcd46dc20b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a62b3c-0d9b-4e82-afcd-3f533b21a691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a645dd4-15d1-4cb2-ac5f-3011d1e4f12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea89267-abbc-449f-804e-a4e412bda1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b74d5f58-42c6-4f0a-8a87-f9ed1b23edb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db5f0fae-5f27-4fbc-b768-ad6f360fe521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d0b77b-fc3f-4304-b1c8-91195f839f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0855330d-6110-4564-8318-1acd150abbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dccb4ec1-35ee-4447-8f7d-2e6649d5a2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9cfa5d4-4c63-4860-a990-0f9b88bfeaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c35ddf6-924a-4bdb-bfbf-1b18588ce3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31baaa7-c27e-44b7-8ce6-b5b644091f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ab1403-2fb3-4fc2-ae83-5b8d6dbaee3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c8230a-c01f-4cb8-a145-922e2aac96d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68dabb14-2a9b-4394-aaab-1dc93225a4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878a1a73-5bb6-4232-9600-61552a01d0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9154efd3-5d94-4fde-86cd-edd82e41a3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82df07af-a3ca-4e7d-8a05-073c3116ce63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46052c2b-ee42-4c34-86cd-153c53e4c459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6b2e95-6e3e-4c93-83a7-0c624a49567e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2649dc44-26e6-45c6-ab84-b52dc1ef9b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9cf5480-d908-491b-adc5-0fce7ad99e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b34ec2d-e0db-4ccd-a7bf-d5be58c9d107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b1b99d-aa9f-4f5d-ad54-21dbb71def4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e04007-f60a-417b-971b-a7544d5c19a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ea6c64-e883-4e24-9d11-28e8672f49ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693be5f6-7761-4d99-a4b5-82206553bfb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8041a42-8d03-4c39-a76c-22b2c983aedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8912ec47-0947-4a59-9f43-222530816748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939f8f81-f188-46f5-a634-680ed97b24e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a99b4b0b-be92-46d4-9206-bb60e3bbebe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a812656f-aa30-4136-9391-d40e4d9ca0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2e492b-2867-4d68-8fbd-93411a085df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d82062e-99c3-40a5-8cb0-8bdb2fffaded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e8b68a-35c9-4410-be01-6cadd3343128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30796d8e-f236-40e9-b41d-c85f7198c99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 412fb41c-a056-4679-bf0c-14d36878d4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 391b2f7a-3754-483e-a368-e6dda98cc229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc4024f-852a-4ffd-a3cc-9a33cb094cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15aeb75-67a1-4e6c-b834-ae4440c80eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240cc1e5-526d-4e50-92e2-429300dec9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b059b0-37bb-4a6a-9d71-df3bd399a7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7d7795-c105-4792-a721-b739ea1cf45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43b6dc9-59cb-4873-9861-80ec47869cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ed04f3-e17c-43df-ab38-667ae758bbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38352c19-5186-4423-a52b-5336d67c7942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64ccd7f-b001-4e8b-a659-cc4eea95bad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc65b2bb-0c1e-44da-853f-0d96e2e33aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb032a02-dbf9-410c-b94e-a223d336f67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e650b15e-d4c4-427f-9111-5dbc92c190b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33a8472-dbe6-4324-8afe-1cc418693ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5675b96-f1c5-4d32-8e19-43e709597aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e79cac-999f-4fc1-9934-ede112ae6c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d47c985-3f99-491f-9cc4-b6a0d29d794e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18d0df39-3da2-4139-b2c1-cf2b188333c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 316df780-f492-4d8c-9be2-9e2a5c8592a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac976d45-8163-4da0-82da-3cd0d50e0ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83a3068-1139-41ca-8d15-45fa49e509ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11696788-1172-4375-9bd0-8e1bfe5fd1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6563d49d-1e0b-4457-9761-88cdb90acc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2c8988-e9a4-433b-94f1-1dd51f611edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9a4ca2-a1c9-46e0-862a-0a458f052a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a559c3cb-5d2d-4039-a819-473c429a26d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16a79695-2394-47db-8d2a-138e456e8d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b849f91a-7d0a-4c3a-a356-991ebc2932c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34f33d4e-1f3a-4ced-8296-2854d45b77cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1e3d0f-f07e-450a-8b27-cfc78f6d0d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00edf22-bfc8-41cb-8a00-a8bed5cb189f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855f0996-f7e2-40ef-8cbf-1c879685b7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd63c348-0f80-4830-9513-03051cd35e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5165f209-24c8-438a-9cc5-e8a5d3993724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898d6f21-35d4-4ad2-8570-a46e50563d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a6c7ff-6121-4847-9c57-e3fb711fcb54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8b3466-fcec-4275-b013-858a5bc61270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a415222-3f60-42be-95e5-0858c54fa0d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1905988-1f0c-4e18-ae3b-fb15a5d904ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81284cf9-f847-40ce-83a1-391a8847132e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8484303d-badf-491c-94a7-9106d7318271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e089cc-c8e8-4e5d-a106-f45c360a8fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690b844e-3600-49b6-b307-d04f90162778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751a62f8-425f-473f-bbff-faa6b487242e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5731125-8064-45d8-9826-da71561753eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97937fd4-289f-4481-95bf-9546b4db571a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98bbc338-f590-4949-95f6-7ca977ca04aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d2292d-a023-4a95-b007-13615590d686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791d2493-abb5-4729-bfb8-9936f4a260c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b57ee6-5e72-4f05-ac1a-18876fcbc0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564777f6-1eda-45b4-b8cd-420d19940590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d41405f6-6b78-4911-851c-ad0e454f82e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 910bd556-6afe-4ecd-81d7-e7468b3e3384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da2e6b4-7f57-4790-abf0-dba0c0b9f1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e76134ab-a9f6-40c7-85a7-4bb4a77e8803
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_35
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_labels.txt

📊 Raw data loaded:
   Train: X=(1627, 24), y=(1627,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1627 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_35 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0794 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0884, val=0.0781 (↓), lr=0.001000
   • Epoch   3/100: train=0.0879, val=0.0781, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0874, val=0.0782, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0871, val=0.0784, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0850, val=0.0789, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 3 Summary - Client client_35
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0056
   Val:   Loss=0.0781, RMSE=0.2796, R²=0.0050
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2463, R²: 0.0059

📊 Round 3 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2460, R²: 0.0092

📊 Round 3 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2455, R²: 0.0127

============================================================
🔄 Round 7 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0931 (↓), lr=0.000250
   • Epoch   2/100: train=0.0825, val=0.0933, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0821, val=0.0933, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0819, val=0.0933, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0818, val=0.0933, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0811, val=0.0936, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 7 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0073
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0062
============================================================


============================================================
🔄 Round 8 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0849 (↓), lr=0.000063
   • Epoch   2/100: train=0.0844, val=0.0850, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0842, val=0.0851, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0841, val=0.0851, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0840, val=0.0852, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 8 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0125
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0059
============================================================


============================================================
🔄 Round 9 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0767 (↓), lr=0.000016
   • Epoch   2/100: train=0.0867, val=0.0768, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0866, val=0.0770, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0866, val=0.0771, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0865, val=0.0772, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0863, val=0.0775, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 9 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0100
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0078
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2446, R²: 0.0207

============================================================
🔄 Round 11 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0882 (↓), lr=0.000004
   • Epoch   2/100: train=0.0837, val=0.0882, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0837, val=0.0882, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0837, val=0.0882, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0837, val=0.0882, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0837, val=0.0881, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 11 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0197
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0179
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2445, R²: 0.0212

============================================================
🔄 Round 12 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 12 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0071
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0055
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2444, R²: 0.0221

============================================================
🔄 Round 15 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 15 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0073
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0300
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2444, R²: 0.0222

============================================================
🔄 Round 19 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 19 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0135
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0023
============================================================


============================================================
🔄 Round 21 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 21 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0083
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0232
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2444, R²: 0.0226

📊 Round 21 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2444, R²: 0.0226

📊 Round 21 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2444, R²: 0.0226

============================================================
🔄 Round 24 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 24 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0044
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0408
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2444, R²: 0.0227

============================================================
🔄 Round 26 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 26 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0127
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0077
============================================================


============================================================
🔄 Round 27 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 27 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0115
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0141
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0227

============================================================
🔄 Round 28 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 28 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0176
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0102
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0227

============================================================
🔄 Round 31 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 31 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0098
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0125
============================================================


============================================================
🔄 Round 32 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 32 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0103
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0187
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0227

============================================================
🔄 Round 34 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 34 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0111
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0155
============================================================


============================================================
🔄 Round 35 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 35 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0114
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0112
============================================================


============================================================
🔄 Round 36 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 36 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0150
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0033
============================================================


============================================================
🔄 Round 37 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 37 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0095
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0129
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0227

============================================================
🔄 Round 39 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 39 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0158
   Val:   Loss=0.0985, RMSE=0.3139, R²=-0.0275
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0227

============================================================
🔄 Round 41 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 41 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0149
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0109
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0227

📊 Round 41 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0227

============================================================
🔄 Round 45 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 45 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0131
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0029
============================================================


============================================================
🔄 Round 47 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 47 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0158
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0026
============================================================


============================================================
🔄 Round 49 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 49 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0179
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0190
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 54 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 54 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0077
   Val:   Loss=0.0960, RMSE=0.3099, R²=0.0199
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 55 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 55 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0107
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0053
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 55 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 55 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 55 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 59 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 59 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0094
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0223
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 60 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 60 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0134
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0072
============================================================


============================================================
🔄 Round 61 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 61 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0032
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0202
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 61 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 61 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 64 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 64 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0178
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0157
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 65 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 65 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0105
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0154
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 67 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 67 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0084
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0260
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 68 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 68 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0104
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0169
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 69 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 69 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0113
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0011
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 69 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

============================================================
🔄 Round 72 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 72 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0068
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0109
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 72 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 72 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 72 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 72 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 72 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 81 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 81 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0139
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0026
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 81 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 84 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 84 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0031
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0162
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 85 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 85 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0147
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0032
============================================================


============================================================
🔄 Round 86 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 86 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0116
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0115
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 86 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 86 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0228

📊 Round 86 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 91 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 91 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0110
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0086
============================================================


============================================================
🔄 Round 92 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 92 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0129
   Val:   Loss=0.0723, RMSE=0.2690, R²=-0.0011
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 95 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 95 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0106
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0185
============================================================


============================================================
🔄 Round 97 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 97 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0105
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0191
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 97 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 97 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 102 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 102 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0180
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0151
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 102 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 102 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 106 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 106 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0071
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0316
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 109 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 109 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0094
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0236
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 113 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 113 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0116
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0149
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 120 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 120 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0041
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0171
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 121 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 121 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0090
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0235
============================================================


============================================================
🔄 Round 123 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 123 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0158
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0147
============================================================


============================================================
🔄 Round 125 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 125 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0103
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0003
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 125 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 128 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 128 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0129
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0097
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 130 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 130 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0098
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0234
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 132 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 132 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0175
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0123
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 134 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 134 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0150
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0020
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 134 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 134 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 134 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 134 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 142 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 142 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0159
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0028
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 142 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 145 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 145 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0118
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0143
============================================================


============================================================
🔄 Round 146 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 146 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0139
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0063
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 147 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 147 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0124
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0098
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 147 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 150 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 150 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0075
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0321
============================================================


============================================================
🔄 Round 153 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 153 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0157
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0069
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 154 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 154 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0072
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0323
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

📊 Round 154 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 160 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 160 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0140
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0003
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0229

============================================================
🔄 Round 163 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 163 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0069
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0332
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

📊 Round 163 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 166 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 166 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0111
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0146
============================================================


============================================================
🔄 Round 167 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 167 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0065
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0302
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 170 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 170 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0080
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0266
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 171 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 171 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0087
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0087
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 174 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 174 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0145
   Val:   Loss=0.0955, RMSE=0.3090, R²=0.0015
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 175 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 175 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0125
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0028
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

📊 Round 175 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0231

============================================================
🔄 Round 178 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 178 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0146
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0028
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 187 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 187 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0075
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0302
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2443, R²: 0.0230

============================================================
🔄 Round 190 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 190 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0051
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0431
============================================================


❌ Client client_35 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
