[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2f5ae2-f0db-4e0c-b8e2-f71c3becf3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e0e95f-ef8f-4ed7-a943-e8f206ec32b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c0c669d-e9d6-44ed-a51c-d6a45f37c7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c6c7216-3307-4ca7-aed1-20d214920e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f30c2f-21ca-4f7a-8fa7-f2244e6e1241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d9df4b-0f63-4afa-9e1f-3816b78f38c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 729bee15-36b3-4302-9047-a71887acbac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1b90968-3c70-48e8-ae05-2264806223a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b44648bb-09b9-421b-b96d-ccabcdf642f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b596f3cf-ef34-4e17-a517-8e5f48c77260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315b60f2-ef64-488a-a015-2f00e4fd302f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f67f7877-243b-4e1e-bfa6-3b031f4f65a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92f3fa9-ccad-4483-96a4-74f8c245c393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62ecf1af-3845-44b9-9f39-eb54799fe6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959094aa-2d9d-4386-ac66-576081ab6645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e485ed4-4915-4209-b0f1-46bb0dcf23bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87428ffa-d835-43a4-a00d-8cc161ae5689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64ecd82-3680-47a3-99fd-914526923374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2201ebd2-3c53-459f-b3d8-d01247fe6026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef160de9-f333-4588-97cb-e6660cb222cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 999731c2-7105-49d7-a680-e9e6f48469c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b30aa575-cb5b-4b39-8cf3-d676468107f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd97014-5d30-4e48-aac1-5ed3c36fea23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 370b587f-6c8e-4d3e-8005-55d761fed2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdf23319-6ef8-41c5-82ab-84b73060b9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9919dd5e-91b4-4759-9c0c-6820de7c184c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e898c8-9950-459c-991c-51ec27b96cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 085fef76-fa9f-4c6e-a254-111401a7d19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5af705ed-2987-4485-9d5f-427dbea587d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a48b68a-1418-497f-8131-2ac1f2df44cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df64318a-6874-431c-a02c-f1363249cfc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0b9b97-b928-489a-ac4a-476dbff5b290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc03c45d-18dc-4e2b-8534-79f1c6d4a319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ce3ef6-bc04-4f00-9b4b-c198326eea97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f67f0f-c5b5-445f-9b67-9d80366866ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472c5c2b-ed42-4079-b52c-3563b81a10fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc447f33-9961-4a74-bddb-76fa62df7d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1290212-fb21-4e09-9051-e97a50914d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c2afa6-b82c-488f-89c3-cfeb71ef2f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21cecee-cf25-4166-a27b-fb3dd69d3f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901028f6-2c97-4e0f-9549-0d0f06e707d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58ed3a5-53f2-499f-8a33-c96372d52935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbbdfe26-f3b4-4056-bd8b-2785f439e4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13322a68-fc64-40f7-a388-7b80afe1c893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 034c7b6c-3972-457c-a54f-d8b423d26bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e599a10-fcd6-4840-bec9-1890802fe891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ad57171-8e3e-4224-9e6b-53d3d192610e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8614e4fc-8951-4785-adad-b3d9e0f74c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 422b5a77-60ac-4fe4-a5b2-56103454ecec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbb842e-1d0e-4de9-a3a2-bd045301c56e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a120a23-e378-4b8f-afe1-bc2033fdced2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786e8b82-cdf0-4c0f-b387-bae9e87947bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 088088ab-3d1f-42ce-9baa-b63c8fb25b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2443c33f-c907-4ce9-b26b-f3610d57f17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed9ef7a-c475-42aa-883d-513bf0a5806d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a04814-ba63-4e2b-9b75-fef98689951e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f8194f-79cf-467a-a711-21171d2d3c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac3ebfe-47fa-4000-95f8-e361edeb9893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14275f76-8871-468d-9b38-0ee6346fde95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087d7fbf-edce-4bf1-8fd9-6b457080e24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d16f822-ff84-4469-a06a-3ede50b82259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce368b6c-9efd-4a42-8605-7d94e5fabbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6febf0a-31f1-40a8-a77f-81d6a4c0dba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68a59de-ac86-4d7d-8c01-e99867d6e7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd8cd76-d727-4ab5-8c45-8bc1dd89aeec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c8352d6-f180-4dab-8fe2-629dcbc29a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14cc9e5-5510-4ce3-8b21-6c3699a74dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eba6a66-6299-4123-bafa-305ce5118dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d1be4b3-4c54-4d3d-9a06-3296c1f85605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 896bd77e-0885-4817-8a47-1b806658f6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28146491-7840-4a3c-ae4f-9b902f2fee7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfedf056-295b-4ae2-88bd-166dacc050f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ed2ade-0f87-4807-8924-6188498defdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1242931c-ebb0-47f8-b4ec-b1b550cddb91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42654de5-7847-4cd6-9eac-b0d34fa722d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad3e51a-3983-4e9c-a55a-d35423f178c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a52ef4-a92a-4591-9746-1e35a4816c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38363162-71e3-4683-bf93-d3d8f5b23396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ab5932-c477-46e3-9db1-5430586eb3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2fdfe5-6a91-4f31-9186-686ef8debca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f26c166d-877f-49fa-a231-7930aa5e7798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf61e49-eeaf-4894-b403-214b25bb1f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4e0331-d90d-4950-88ee-37a28fdcef20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e47164d-3158-44ae-bb4b-97d3751f84e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175dd69c-9df8-4283-84e2-620692fb6ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239b06e5-4ef7-4a15-b2f9-1687a37626d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 324db309-3459-44a6-86e7-5d8ad36ce1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda8209e-d467-4992-a3d3-7e618942f12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf56d37a-00ae-4b15-869a-beceda2877dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c07b00a-c921-4fc0-802c-d5aba64d1861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae98337-5e54-4c6a-8f74-7ff6188c4170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d94585-f632-472d-9ddf-e77ab54bc825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4afadfbb-a379-4782-ba30-18e978177a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a79c26-023b-4ec4-98b0-04dad4f6b673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54a6b65-24dd-4d34-8e55-479f65fdedf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0db618e-5003-4b9b-bbb1-07f4b011a27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee0e3bf-e41e-44ed-b0e4-5fb140df33e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fdc39b2-5278-4074-ae8d-fbf57af2a0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a918b4-b322-4852-9757-9685dedb6799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66ba53b-352b-49b7-a6fe-e4560e430aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65fb9daf-778e-46ca-a564-89ea50740c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1cb7f20-f1e4-4e10-a7eb-e9f74669fd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b4d2734-6a33-42cb-814b-f4c219670785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c6aacb2-2073-41b8-8bab-e93179df66c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 504ac965-6f75-494d-8304-b0d4908aa9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e075aa0d-7cfc-4604-a9e0-7f00fd110a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca9df49-6164-417a-8cb0-160ec21c55d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5f9143-596f-4f71-b011-d517a609b9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a050e97b-fd8c-4a2a-8790-428793691c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a045b274-ddba-481c-8feb-b6c59cc68940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05074ab5-d9e3-459e-aed9-81da047794f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded1b508-4e0e-4309-9455-a079ea256ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a6aae81-db5f-4cd1-b60f-ff3f4d78e840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b56704-c1fc-46a8-9387-8667427f31c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd227e4-0a6b-420d-9f9d-a8b7933e133a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a1d4fd-ec72-4c5b-abdf-6938fffc84c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c3a31d-af03-430f-a911-d5b25eb54152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d25af4e-8b63-42c2-8e2f-af6da2fbcc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 273d5cdb-74f6-4f42-92f9-4822875e2530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611d9ea2-48cc-41bf-abc8-47cf7e48bac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41cd05c-4902-4584-bc59-406c35263932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac435d4-1f07-422a-89cd-9414b1f32b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f975a5-aba3-48ab-9358-51fec4ca4b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d008820-e8e2-47fc-965e-c5a8d4221a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41646a80-2454-42b7-b4ea-fdea6c0ca77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ca8e91-6987-4159-9262-9ef538d8a1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2d79d5-21e4-40ae-aee2-d91bdcfe1652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f4c4251-7c83-446e-93dd-6c8905bffd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4f0ffb6-3bef-48bc-bbab-f8c36770218a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20860e92-e3cc-47f2-be81-05cf26f37f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce4aa15e-04b4-44e0-a604-f4c41fb95f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b510fc4a-1f58-445c-827c-0ef71635db79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10879692-facd-4e01-a9a1-2bacb289e993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b83387-5b0b-439c-99e6-2746df8d14ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c0cf68-9569-406e-8bb8-3389ae0baa0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0513a242-9b0f-4794-bf6c-b8a180cb138b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59882af7-2829-4da7-8f4b-b5d9c909678d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f71adf9-d2d8-45be-9deb-15024b32ce05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3729321f-450b-4572-a619-e9ec9fb56272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec2364a-e1fd-414f-9a43-e9eed53f930a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b1f139-0f7a-4f21-a0df-d3ca96ba1769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb130d4b-7d9f-46d4-adaa-05805d47e75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd30fa0-a552-4f06-abf4-5e9acf607733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f11dfcb-ee7a-4b34-8564-6a5b56c62d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3886afd4-adb5-4a64-8d83-73ef38207f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d7b914-edd8-446f-947f-21a2391e1cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44db06c8-341a-4ebb-b5dc-2b05435d1ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895d01e4-f498-4da9-b710-da229b6b110e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbc780b-783c-44af-8517-3659c3d2df20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2391caca-93fc-4e89-8ae9-931a6c05e8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeda69b4-beff-430d-a8cb-283223b66aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d261ae-293c-4512-82e9-e6af89529945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54bd06d8-a5a8-4c5f-80b2-38f0fe47eadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3084306a-827d-4f14-b8cd-f86bd6566e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7b9298-9c24-4ee0-8230-d864fc08b8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d45b7661-d3e8-4227-97bf-1d96095aaddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cff7098-3d0f-4b8e-a1b9-7e8749af586b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8131196b-2371-4ba0-95a0-02e26ad856c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a60c4e4-f1df-4b38-91f4-414c0a44ee60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b993d7d4-b9c9-47d5-9f55-0e179324588b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17657a7b-55fc-4468-a3c6-58dacc14dca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82646eef-1ad8-4682-88ad-57ad2a1c33aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eb610f4-a50e-493b-a001-683c2ca42e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8381cb89-3c99-4cec-9ac9-ca3c92ea183b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a4ea00-28ac-45c3-845d-33ca43181638
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_37
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_labels.txt

📊 Raw data loaded:
   Train: X=(1276, 24), y=(1276,)
   Test:  X=(319, 24), y=(319,)

⚠️  Limiting training data: 1276 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  310 samples, 5 features
✅ Client client_37 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2427, R²: 0.0043

============================================================
🔄 Round 4 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0797 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0861, val=0.0778 (↓), lr=0.001000
   • Epoch   3/100: train=0.0854, val=0.0776, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0842, val=0.0777, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0841, val=0.0777, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0814, val=0.0777, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 4 Summary - Client client_37
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0143
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0025
============================================================


============================================================
🔄 Round 5 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0921 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0804, val=0.0910 (↓), lr=0.000250
   • Epoch   3/100: train=0.0802, val=0.0912, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0801, val=0.0912, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0801, val=0.0911, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0796, val=0.0907, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 5 Summary - Client client_37
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0079
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0217
============================================================


============================================================
🔄 Round 6 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0783 (↓), lr=0.000063
   • Epoch   2/100: train=0.0834, val=0.0783, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0833, val=0.0784, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0832, val=0.0784, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0832, val=0.0785, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0829, val=0.0786, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 6 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0112
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0072
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2415, R²: 0.0139

============================================================
🔄 Round 7 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0865 (↓), lr=0.000016
   • Epoch   2/100: train=0.0811, val=0.0865, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0810, val=0.0865, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0810, val=0.0865, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0810, val=0.0865, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0809, val=0.0866, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 7 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0137
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0063
============================================================


============================================================
🔄 Round 8 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0715 (↓), lr=0.000004
   • Epoch   2/100: train=0.0844, val=0.0715, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0844, val=0.0715, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0843, val=0.0715, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0843, val=0.0715, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0843, val=0.0716, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 8 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0136
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0140
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2406, R²: 0.0212

============================================================
🔄 Round 12 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 12 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0202
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0182
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2404, R²: 0.0222

============================================================
🔄 Round 14 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 14 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0231
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0078
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0226

============================================================
🔄 Round 16 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 16 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0208
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0229
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0225

============================================================
🔄 Round 17 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 17 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0250
   Val:   Loss=0.0970, RMSE=0.3114, R²=0.0099
============================================================


============================================================
🔄 Round 18 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 18 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0246
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0000
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0229

============================================================
🔄 Round 20 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 20 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0229
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0097
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0229

============================================================
🔄 Round 22 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 22 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0196
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0269
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0229

============================================================
🔄 Round 23 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 23 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0197
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0282
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0229

============================================================
🔄 Round 25 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 25 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0246
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0049
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0229

📊 Round 25 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0229

📊 Round 25 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

📊 Round 25 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 29 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 29 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0176
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0337
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 30 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 30 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0200
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0199
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

📊 Round 30 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 33 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 33 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0234
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0138
============================================================


============================================================
🔄 Round 34 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 34 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0241
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0099
============================================================


============================================================
🔄 Round 38 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 38 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0227
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0162
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 40 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 40 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0168
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0365
============================================================


============================================================
🔄 Round 42 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 42 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0228
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0165
============================================================


============================================================
🔄 Round 43 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 43 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0248
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0090
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 45 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 45 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0264
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0084
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

📊 Round 45 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 48 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 48 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0204
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0254
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

📊 Round 48 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 51 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 51 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0212
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0200
============================================================


============================================================
🔄 Round 54 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 54 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0201
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0269
============================================================


============================================================
🔄 Round 55 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 55 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0207
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0243
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

📊 Round 55 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

📊 Round 55 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 59 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 59 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0221
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0074
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 60 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 60 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0192
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0292
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 61 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 61 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0184
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0285
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 64 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 64 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0205
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0251
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 65 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 65 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0226
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0081
============================================================


============================================================
🔄 Round 66 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 66 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0190
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0301
============================================================


============================================================
🔄 Round 67 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 67 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0206
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0253
============================================================


============================================================
🔄 Round 68 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 68 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0178
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0305
============================================================


============================================================
🔄 Round 69 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 69 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0238
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0109
============================================================


============================================================
🔄 Round 71 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 71 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0145
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0364
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 75 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 75 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0233
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0060
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 77 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 77 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0193
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0066
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 77 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 77 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 77 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

============================================================
🔄 Round 84 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 84 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0236
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0118
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

📊 Round 84 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 88 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 88 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0237
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0053
============================================================


============================================================
🔄 Round 89 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 89 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0228
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0087
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 90 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 90 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0222
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0189
============================================================


============================================================
🔄 Round 91 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 91 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0239
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0118
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 92 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 92 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0215
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0114
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 94 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 94 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0206
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0160
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 94 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 98 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 98 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0241
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0111
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 101 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 101 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0197
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0264
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 101 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 101 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 101 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 106 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 106 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0225
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0173
============================================================


============================================================
🔄 Round 107 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 107 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0194
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0300
============================================================


============================================================
🔄 Round 109 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 109 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0214
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0147
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 110 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 110 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0222
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0109
============================================================


============================================================
🔄 Round 111 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 111 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0205
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0207
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 112 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 112 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0190
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0276
============================================================


============================================================
🔄 Round 116 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 116 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0235
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0100
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 118 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 118 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0231
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0139
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 119 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 119 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0194
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0140
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 120 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 120 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0202
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0257
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 120 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 123 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 123 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0237
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0117
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 125 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 125 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0191
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0186
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

============================================================
🔄 Round 126 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 126 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0254
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0037
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 126 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 126 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 126 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 133 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 133 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0259
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0032
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

============================================================
🔄 Round 134 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 134 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0202
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0270
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 134 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 136 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 136 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0245
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0033
============================================================


============================================================
🔄 Round 139 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 139 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0209
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0121
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

📊 Round 139 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

📊 Round 139 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 147 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 147 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0191
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0160
============================================================


============================================================
🔄 Round 148 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 148 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0224
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0158
============================================================


============================================================
🔄 Round 150 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 150 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0230
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0091
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

📊 Round 150 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 155 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 155 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0187
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0327
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

============================================================
🔄 Round 156 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 156 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0226
   Val:   Loss=0.0956, RMSE=0.3091, R²=0.0186
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

📊 Round 156 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0230

📊 Round 156 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2403, R²: 0.0231

📊 Round 156 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 161 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 161 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0200
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0254
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 168 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 168 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0216
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0207
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 168 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 168 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 168 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

============================================================
🔄 Round 177 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 177 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0239
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0085
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

============================================================
🔄 Round 178 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 178 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0221
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0201
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0232

📊 Round 178 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 181 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 181 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0186
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0263
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 181 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 181 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

📊 Round 181 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 187 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 187 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0183
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0066
============================================================


============================================================
🔄 Round 188 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 188 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0248
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0006
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2403, R²: 0.0231

============================================================
🔄 Round 189 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 189 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0245
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0086
============================================================


❌ Client client_37 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
