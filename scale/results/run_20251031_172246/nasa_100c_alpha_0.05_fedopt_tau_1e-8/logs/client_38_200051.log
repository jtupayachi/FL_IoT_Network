[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf456f4-64a6-4fe1-85cc-6c96539bd426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3508bedd-ce89-48a7-84fe-51db714604b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc5f6816-7132-4505-99f8-5655058f6312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ec0b88-0e86-4aca-9c7a-f5a86eee7eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f8fb32-afc9-47aa-84d1-6044c0f36e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 374ffe9d-31da-4b77-aae1-b7cf66a45d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d5eab6a-1805-47c9-ab34-9f027f9d2d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f62beb0d-aca9-4c10-af30-d635ee421540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1a00c3-c02e-427f-96f4-bb7f1f68503d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894878f3-135f-4482-bfe2-ca370751897d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49f5a5a-f390-46d4-9205-80b1b89c9c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8832dd0e-4634-4b65-897d-25598996cf5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e332164-cca3-41ee-b572-8b3d0468126d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02fd67ad-a1ee-423a-ab3f-f74019706e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3e52cc-b97d-492d-8385-7801b0c81d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd446f1-086e-4976-ac40-8dda48e2939d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5490e6d-e464-4b89-87c5-de62f0ed8aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0b8776-5f9e-426c-a1fe-7ac771d67ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91013d4c-60ec-4160-97f4-3f94b8cdb613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac1c5d1-fbcb-4147-8954-ae6b590e108e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27df21bd-e4c7-4689-b825-b75e0996d06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb278c2d-577d-4ea6-94f4-4d9e9d104271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4447a1-2267-406f-ad45-a520cfff97fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d68c29-0f1e-41f4-8773-8d4e48484edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 645d6fad-7c4f-46d8-8f61-1df869e22175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92579bfb-506c-4d7c-86ec-350fb9ac2d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9363ef44-eb1f-4e4f-a454-7a4567448d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e046fc6a-565a-4320-852e-8086b445df56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e96751a-fa74-4cf8-b340-0f048cc6a609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc847a6-d6fb-4498-88de-f30dbb3a2f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24085a62-6b47-41cd-a655-356d67e69012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4bd473c-1c1b-424c-bc16-a17b526f6223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee97c58-6e15-45bc-beb4-022fd17dec03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6e265dc-a1cd-473f-b698-93c21151a770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0182f8-26ac-460f-ba21-912ae7217c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d58a7be-7e0a-467d-9de4-c5913674049b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7651841c-eef9-4e3c-bddf-dc7cf67a8bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d271cb-0d28-4de0-ba0d-dc848851a20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fffe24e-4a20-4bcb-9c48-8fb2e006383c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1160ba-384c-47fd-991d-56823c698760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7703e4be-c932-4c1f-89dc-19d202af2758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de49f717-4fbc-455a-b23e-3ada30471eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29336401-dc6b-4f98-a736-2c9e6511837d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c186ecfe-292c-412e-948b-3d683457831f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844e975f-c8a9-4b20-9960-24e4fd367e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cdf694d-05d8-4962-a421-ca418bf24ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5782028f-bd58-4577-b3cf-ebce4cdbaa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e259b0b3-f4cd-4f18-8ecc-aa9326107e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca7b955-b7ef-4be9-badc-e3154a9e612a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c194a79f-ce6d-4d7c-8daa-18152dee535e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3fd94c-3fb4-497b-9250-58500be1e16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46397cc4-8ac8-46f7-9e67-985ddc1c7868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568eb9ca-b1ee-42df-a2c8-d32fd1d4040e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52f6d006-0ccc-4cc7-932e-eee3021a99ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2119aad1-619b-4cfe-80c3-846c4eee2525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8249f82e-430e-40cb-8e8f-f0278659bbc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca902f08-0c55-4a30-aef1-eea679bb9b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c264b0-9e94-42b1-87a2-bb2a2c57058a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c85229ef-9f96-4184-81f8-00380f46f9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd9bd083-62b4-4418-bc6e-2a58a4a7c717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5ecf52-7d6e-4fa0-9d36-88abc232cab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c4d57b-9f26-44a5-90ed-ff4a224a160b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41fe0abf-c7f3-4257-91a4-760261b84e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5392adf0-a6dd-4f3f-ab28-c283eefd92d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457e2fc1-57cf-4ae9-9584-6c092f9a8941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ab1563-fc9d-49bd-bdf8-185962a53c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d04b9b6-943e-43c4-8840-2d4d9fa39dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c650d2-dd2e-4bc9-bc53-1596d2ea6b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ab0cd2-86f7-43e9-ac5c-988892de3dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a46d4938-0b16-4b9f-bc92-bdc7ef8c877a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e49bbe-81b9-4c65-a442-b744f3f00223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080faff1-b992-4235-ac08-535e96e3759a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2839da95-6074-44bd-ab57-c92965fe283a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bcfdb3c-baa1-4aa2-bd30-9bb9b1be11f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5244c850-1a4f-430c-a7a8-e44c15b443c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e881b3-dfe0-4bd5-90db-9fe1c6e2fe22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f434131d-efcb-4980-a971-1dfffc41acf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3151320-ca02-4ca5-8a87-b60c583c0bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48377ce9-da03-491c-81e0-5059cf4c4ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ac1d5b-d5ab-4fa1-94ab-3ea4a5ea2a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6adb4db5-2cff-4fbc-8708-4137aeee1b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f9d5fc-2f0b-40e9-8b2e-091f71a4876d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbdf0d6-385a-4b4c-b1ba-631a715e74e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c89bf91-032f-47e1-a5c9-4bd5d4b38ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c1a2be-d5a6-4ff4-8785-436401fdffa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a323550-8c8b-4d19-9f25-37a5f4772028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b24b29-7b50-4606-90f5-12d1d40d8929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8860302-7db5-4dcd-92ae-1eceb25a0de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13fedbc2-5f34-4f52-8988-4d7f07b3eabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e17d9325-b9bf-4c29-9fca-a774d82d1a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3966777d-41f1-40d0-ac4d-88f5c2660967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1bbe65-be5b-466e-a3e8-b079fceb83d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc78736d-8762-47b2-a747-86e0c7fe7977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046219eb-8e7a-47f0-a47b-dd0c2a539597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c16772d-e9cb-45a9-843d-7b4f5a14c507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21e1d7f-5403-45f1-8b15-f138355217f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06e951ba-a517-43d3-b187-0f51142c6079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76501085-7cb0-447c-bc2c-bce65426aad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2613f887-2092-4c34-b958-a8a68d9ea0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 290abe65-5a9d-45e0-ac2f-164b64d89226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f450807-0aa9-47f7-9818-443a221370fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ce48bc-63f8-4151-bb4c-91fe91458746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7903e985-b38e-48e3-813f-cbdc5026a351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 634db98a-f175-4eb3-93fb-0bda82a50f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04280fd-9c4a-45e2-9947-6fb657619ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2619cd-a50d-4b48-9038-3828e3fd36b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683da3b3-fb29-4cca-ad6f-2503eb2689ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a341174c-f6a2-4d98-8b73-6fe733fc15e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5937dd0-8226-41c9-9c67-00a4095052ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cca7861-8ce3-429d-b055-4cadf6b7742a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b4c306-1948-49d9-a004-5f9af73bc270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91f0a50-3966-4b8a-bfdc-b41b8d757b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac8a0e1-2f42-4cdf-9967-eb660c40aacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde65a93-1837-4f98-86e7-b9f692e0d05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8bdd9c4-29cb-41ac-8944-0a6b554c52c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a68cc9b-de5a-48bb-8edc-3fe18da1fe0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7d31c6-5cf2-4c4d-980e-95dc4d727c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e89847a-0c79-4394-8720-f986a92e1174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ba980f-ff4d-4462-b555-26c07e1cd6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09d9b643-24c1-41ea-83e9-05a41c268639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d2bc22-be54-4f05-929a-496ed6981db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e86c910-80a1-49e7-a8a1-009836bd1e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a491a826-4af2-4bbe-b387-ec73c773ef6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19ec75f-3a65-41c6-a157-e8b0edb69ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e1193d-7b1c-4be0-8d97-01547bdb2523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd28b7b-3ac3-4f2a-9fd0-244e430f720e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cdddf89-5730-49e0-bf2d-36e374044548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f7bfd9-1c0e-49ef-b59d-548951f263e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6cb9a8-a354-4625-a952-767eb6d22a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94f9760-b3dd-4bd5-afd2-8e28b6465136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eccf41ca-2a94-4c1b-bdfa-82b77bf5d93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c48cd9ab-9a67-4bd8-a687-a743354d57a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a598fea-fb91-43fb-839f-8666298be19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c596a9d-9d6f-4c66-a1e4-674858d27604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6df8c6c-55ed-4491-9563-592b44399295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f9d212-0846-4eba-808f-eeeeb777af72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62fc89d3-4e29-4a9b-ba1f-ed9e970845d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d16c7d-9f45-4c1e-a042-6001c9dfdfea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0229be8-95f3-44b1-b03a-070161b32396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2c5ad3-4118-49e5-8548-daadc0782311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b734f1-7de5-436d-a10e-9fbc82a1f1c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628ea2a7-411f-4e0a-81cb-d7c6dcd82b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e20b825-216a-455f-9440-9a243a8af533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40425ac-a25c-41b7-aea9-40abeb474d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa73b36-eb79-40a4-8475-3186ed99d347
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_38
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_labels.txt

📊 Raw data loaded:
   Train: X=(847, 24), y=(847,)
   Test:  X=(212, 24), y=(212,)

⚠️  Limiting training data: 847 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  203 samples, 5 features
✅ Client client_38 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0885, RMSE: 0.2976, MAE: 0.2611, R²: -0.0119

============================================================
🔄 Round 2 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0773 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0861, val=0.0743 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0873, val=0.0733 (↓), lr=0.001000
   • Epoch   4/100: train=0.0850, val=0.0730, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0843, val=0.0727 (↓), lr=0.001000
   • Epoch  11/100: train=0.0831, val=0.0712, patience=1/15, lr=0.001000
   ✓ Epoch  21/100: train=0.0761, val=0.0668 (↓), lr=0.001000
   • Epoch  31/100: train=0.0664, val=0.0678, patience=8/15, lr=0.001000
   📉 Epoch 34: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 2 Summary - Client client_38
   Epochs: 38/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.1519
   Val:   Loss=0.0659, RMSE=0.2566, R²=0.1159
============================================================


============================================================
🔄 Round 3 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0818 (↓), lr=0.000500
   • Epoch   2/100: train=0.0814, val=0.0821, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0810, val=0.0826, patience=2/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0807, val=0.0830, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0796, val=0.0833, patience=10/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 3 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0131
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0044
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2583, R²: 0.0018

============================================================
🔄 Round 7 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0752 (↓), lr=0.000125
   • Epoch   2/100: train=0.0819, val=0.0751, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0816, val=0.0749, patience=2/15, lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   • Epoch   4/100: train=0.0813, val=0.0748, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0811, val=0.0747, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0806, val=0.0744, patience=5/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031
   📉 Epoch 20: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0802, val=0.0742, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 7 Summary - Client client_38
   Epochs: 21/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0306
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0332
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2574, R²: 0.0041

============================================================
🔄 Round 12 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000016
   • Epoch   2/100: train=0.0799, val=0.0835, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0798, val=0.0834, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0797, val=0.0833, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0796, val=0.0832, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0794, val=0.0829, patience=5/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0792, val=0.0827, patience=15/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 12 Summary - Client client_38
   Epochs: 21/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0256
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0107
============================================================


============================================================
🔄 Round 14 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0769 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0819, val=0.0769, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0818, val=0.0770, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0818, val=0.0770, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0817, val=0.0770, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0816, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 14 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0176
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0112
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 22 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 22 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0167
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0245
============================================================


============================================================
🔄 Round 24 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 24 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0203
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0102
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

📊 Round 24 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

📊 Round 24 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

📊 Round 24 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 29 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 29 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0175
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0209
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 29 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 32 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 32 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0173
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0203
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 33 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 33 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0165
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0187
============================================================


============================================================
🔄 Round 34 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 34 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0138
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0303
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 35 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 35 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0210
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0160
============================================================


============================================================
🔄 Round 36 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 36 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0258
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0098
============================================================


============================================================
🔄 Round 37 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 37 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0238
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0040
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 42 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 42 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0188
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0159
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

📊 Round 42 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 45 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 45 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0202
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0071
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 45 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 49 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 49 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0175
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0216
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 49 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 49 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 49 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 49 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 58 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 58 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0174
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0188
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0056

============================================================
🔄 Round 61 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 61 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0148
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0310
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 61 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 61 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 65 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 65 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0190
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0157
============================================================


============================================================
🔄 Round 68 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 68 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0185
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0179
============================================================


============================================================
🔄 Round 72 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 72 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0117
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0429
============================================================


============================================================
🔄 Round 73 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 73 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0172
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0224
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 75 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 75 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0165
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0257
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 75 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 77 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 77 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0191
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0017
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 81 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 81 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0202
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0164
============================================================


============================================================
🔄 Round 82 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 82 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0176
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0113
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2568, R²: 0.0057

📊 Round 82 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 87 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 87 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0179
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0201
============================================================


============================================================
🔄 Round 88 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 88 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0164
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0204
============================================================


============================================================
🔄 Round 90 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 90 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0151
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0310
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 94 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 94 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0236
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0072
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0057

============================================================
🔄 Round 96 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 96 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0176
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0118
============================================================


============================================================
🔄 Round 98 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 98 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0255
   Val:   Loss=0.0692, RMSE=0.2631, R²=-0.0240
============================================================


============================================================
🔄 Round 99 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 99 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0208
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0022
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 101 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 101 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0242
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0110
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 102 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 102 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0083
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0486
============================================================


============================================================
🔄 Round 103 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 103 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0150
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0195
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 104 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 104 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0204
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0102
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

📊 Round 104 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 108 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 108 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0211
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0065
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 109 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 109 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0100
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0278
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 110 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 110 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0180
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0018
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

📊 Round 110 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

📊 Round 110 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 114 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 114 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0148
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0339
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

📊 Round 114 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

============================================================
🔄 Round 116 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 116 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0171
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0097
============================================================


============================================================
🔄 Round 118 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 118 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0131
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0382
============================================================


============================================================
🔄 Round 120 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 120 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0126
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0400
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 122 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 122 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0170
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0202
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 122 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 127 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 127 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0209
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0062
============================================================


============================================================
🔄 Round 130 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 130 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0214
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0061
============================================================


============================================================
🔄 Round 131 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 131 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0132
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0383
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0058

📊 Round 131 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 133 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 133 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0211
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0073
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 133 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 140 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 140 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0083
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0277
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 140 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 143 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 143 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0207
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0067
============================================================


============================================================
🔄 Round 145 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 145 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0196
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0107
============================================================


============================================================
🔄 Round 149 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 149 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0183
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0186
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0060

📊 Round 149 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0060

============================================================
🔄 Round 152 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 152 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0204
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0007
============================================================


============================================================
🔄 Round 153 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 153 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0193
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0118
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0060

============================================================
🔄 Round 155 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 155 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0233
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0072
============================================================


============================================================
🔄 Round 156 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 156 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0281
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0260
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0060

📊 Round 156 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 160 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 160 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0154
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0184
============================================================


============================================================
🔄 Round 161 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 161 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0123
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0275
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 161 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 164 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 164 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0197
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0003
============================================================


============================================================
🔄 Round 165 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 165 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0208
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0003
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 166 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 166 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0212
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0074
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 166 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 166 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 166 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 173 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 173 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0193
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0095
============================================================


============================================================
🔄 Round 175 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 175 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0189
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0134
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 177 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 177 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0172
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0229
============================================================


============================================================
🔄 Round 178 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 178 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0164
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0248
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

📊 Round 178 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0059

============================================================
🔄 Round 180 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 180 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0164
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0274
============================================================


============================================================
🔄 Round 181 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 181 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0255
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0096
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0060

============================================================
🔄 Round 184 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 184 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0146
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0252
============================================================


============================================================
🔄 Round 185 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 185 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0135
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0235
============================================================


============================================================
🔄 Round 186 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 186 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0180
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0193
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2568, R²: 0.0060

============================================================
🔄 Round 187 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 187 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=0.0218
   Val:   Loss=0.0656, RMSE=0.2560, R²=-0.0033
============================================================


❌ Client client_38 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
