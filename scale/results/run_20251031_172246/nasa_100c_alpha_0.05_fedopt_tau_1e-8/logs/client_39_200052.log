[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e8700a-faa6-48f8-bcff-d1bef128e9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40b9989-b321-4202-b957-49b5e96663cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0e21a7-8ccb-443b-916d-5638c7f90842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07be7b91-3af1-4aeb-a24c-fb2540e03aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e40d440-a972-4704-aad6-613c1fecd137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f6e940-8aa3-40da-bda2-e81f3a7ca503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49f5c90f-59ff-42a6-908d-fe06b48e20b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8d24af5-2c01-4eee-ae01-76ff1db95909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca39c243-a5fc-4724-bf37-e76ed53590ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a28bee8c-238b-4f43-bcf8-9c4641c0ec85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7592bad2-d264-47e2-9b03-ad276eeeaaa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7589f740-2b10-4dae-ae48-f487027c68a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d556ed44-34db-461f-bad3-4181d3a7e02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef65185-b2e1-4b5b-aef6-3edcff04c95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f841b2-6abd-486a-8d95-eb1acee70257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2a03220-8bc2-42e8-8fed-f810bb258e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6186f7ab-e88d-49b2-83b8-1222d16e7790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a492a90c-a90c-41e6-b90c-65de81202a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecbdde24-2710-42c1-bd45-e47c01877f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf65cbe-7acf-4927-9300-0b0068733547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 913c821f-ec9a-46fd-ad8e-7523c146c94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59d799c-fd78-4252-a407-44ada43f7245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc26cbf-b32d-4827-a58f-19388474e41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb77d7b-f2a2-4c57-9681-50291afc17d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547dcb20-e3bf-4c0f-987f-9549577c98b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb953580-36e6-4c05-bf52-29485f287c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16b1c8df-5728-4e77-a778-931d57e46fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ad6c06-2ee6-43dc-be1a-b40aace43348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32549ce6-a42a-4855-be46-5e775817f133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b33ec7-4173-4867-9267-2a8944600610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0de8adb-5ca2-42ea-b3b4-46f89be55cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e286e2f7-98ae-49ff-82d2-500d96cc2b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a97aab-a494-45cf-9ec4-6eca6bdc324a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc126b1d-c2cc-48e1-97dc-c9fd3491683b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fb40226-4327-4dee-9f7a-5866e507d607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d90347d-ae7a-4956-b1dc-307d9fa6378d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6b3bd1-bceb-432c-aa0f-d9eb1e0f774e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54fc96db-dca7-4aff-be00-c18b855dc4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a172668-df85-4ecf-a0a6-97ea90a1ecf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27130138-bb6b-414d-97a1-a458b58bc4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9f2f42-87e8-424d-9e93-e1df92fd407d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b15105-3a2d-47a9-96d7-59ae2b5be4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0a608e-9dea-4adc-8291-cf548a6da72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22e1ea1d-c745-48cd-a63c-25e4e5d01559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a21e09-fed2-42c7-a244-0d8c739dc140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b11439f7-a2ce-433c-b83f-52a3180e5e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469b67a3-ed91-4238-822a-b1ab73ebd3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68405c3-d434-4d4c-979d-f809716c2e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3050af67-11c6-4af7-b018-30dd817f54cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 968dd286-8228-4edf-99f2-0ebe402cd112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5507caa0-0e0a-436d-9748-96c8a8593625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2ea6bdd-7385-4209-9ced-870379ff4e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c501a1-5516-4747-8e3c-2293faac0361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4f639a-1cad-4862-ae39-47c9e534d695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d715ee95-5c72-42b6-a854-51dfc961a5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af25d29-97d6-42bc-bd5d-685fcf624c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a6754e-64dd-4fad-a626-4b94b7a6cea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3900466d-6413-4379-be14-828a5d1998d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb4f781-c07d-4d49-800d-2d39bb815948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be5172f-35ae-447b-8da3-ce6d840d32d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda046d4-1ed4-4df7-b577-e6ddb9a93bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212b103c-b43b-492d-adc7-b42d4ac268e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ccf28f-a1f8-40e7-832c-13b559ea89ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9439e83-04ad-4ea1-9ece-70022bbbad52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dad0b6d1-97e9-4a3c-a5c2-fa3ed76d9c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dbb1c0b-5525-4a1c-9cc3-efc5bed5f749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa1fc96-c799-4961-a51f-20165d954463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8682ce-0f16-426b-9f0e-9ee6eb7e52d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e0ef3c-8e38-4301-9050-5c5704048275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb71e30-afbf-4c37-961b-1d3a009e1a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02da5c25-ffc0-479e-934a-c31b62bd824d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6760a012-87bc-429c-9cf0-77eaffe67259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17ce2b10-fe18-479e-9b3e-579746dfa5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5cd3a7-84cb-4f30-8918-649b43625759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaaec575-d530-4f43-a867-dcbeb1703413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a84b721-ce0d-439c-a429-b32a61522726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e213d4-512d-4b10-9d40-71d9abe0f588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e5b702-55ac-4294-bfab-9d5cbb78862e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d128afb-63e0-42a1-bea7-21c04876092d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93967df-6071-482d-9c6a-d578f820aace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3186b165-e984-4749-b831-159fd06a4f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc6ed8b4-f1d4-40c0-ba8f-634ef7e684c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd9549d-8ff5-4737-a67c-b5e55cfca957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0181de3b-dd67-4820-9091-d2bedaddcebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c401367-5895-49f4-a3c4-90d782594ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d0ebc7c-dbd2-415b-bf45-81c5b7b4cc18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5566bdfe-eae0-43e5-bb4c-c35483492180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c847cb-5fe8-4abb-8894-db655c6e959e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1391189c-b1d4-479e-9cbb-105ed04e85df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6990f05-d2c5-4d7f-857b-5e434a2b5525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7bfc117-8da3-4540-bfe9-e81f8e44ef95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f9e103-e4f9-47c9-8949-2eed612bbb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b16972-08a5-4f5f-907c-88c037964143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e3a772-3c79-40a9-984e-1996e8f2a525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db805be0-ce9a-45be-9e44-16a32e9ca028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb0365b-fd29-48f4-8eb0-6eaaacb5b864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5f1152-45ae-4baf-be58-066376df9ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3624654-38bd-4215-a6b4-34e4cb81894a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8349f749-4c71-4415-b42f-bc9419a4a2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e18da5-97a7-43d4-a870-03c72711cdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7d0f01-0d1f-4a86-ac32-7b9b08609512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e142072-eefc-4bd1-ae16-823861e94c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e2a8922-5946-47e3-9e63-0a90772a21f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b66abc2-0bfb-421c-bb98-dcd33d1528f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5894d7af-9361-4e8b-9cd8-44c8281f9f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34333fef-3d70-467b-81e1-d1fa47fc22eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ddc22c2-2950-45f8-a81e-3162045d545f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb4100b-923a-4499-910a-21871c35f6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b4bc0e8-9e1c-44f6-b884-f3b4ee27f528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4217a798-67a2-4710-932c-ba6637cd9e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a03881d-6ac3-48be-b745-7aa8492b7f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c102271a-f298-4949-838a-9d24bf367147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e0c1cc-4136-4ba8-85f7-1c12f6b9ee75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8283a90b-f275-4a48-91e1-fde0fe3aadbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101ad7ca-ff8b-4ee8-aeb1-de89b3becb7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a3e333-1c60-41d8-9a83-b3e6659930ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e62c13-6a20-420c-9ba9-6fa4e6ea3b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548917e4-cb31-452f-848d-92e8afd5cce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52a5bdb-3144-42e5-aa9f-92964bc8981e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2949d568-f4ea-409d-aa7b-8fca086c0965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efac77b3-4752-4eb9-ad3c-4257265b9c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c2b65b-ec35-419d-9b32-8f43e59374fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c18a99-cd57-421b-a71d-2f21f16c46c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d12df2-9044-4707-8d50-f63e5cba6241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e56e72-f2bd-48f7-86ae-82366de00cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d39442c-4c93-4a26-9853-22ead24dd8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0942905f-1d35-4be5-a8a8-c8d488c534c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69e9b10b-b9d4-4ac4-9da6-3e124b902d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32c21cfb-4e19-43a5-b5a0-88ab9f7ba1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3eee983-ecb1-41da-8301-441c588349a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 436ed556-d99d-42cd-90f6-9bbd1b622340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a847fb-cef4-4d5d-b9d9-75be5db4517d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843931af-dc6a-4cd0-9578-f0469c061837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 386d3e1c-64c6-42f5-9d4f-f98ea4cfcdc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037633e4-21a3-411c-bafc-1ad3b4574b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d22a707-7424-443e-b84a-9c9444140070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4953e5-f60e-4476-bb46-fcb1f10155c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dea4e8b-dd42-4c1b-a079-ee2ee60f3139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1b2ff4-9890-401e-bb86-875f6d6a167c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40e3cb15-0ef7-458b-877f-26ccf731fc18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e7a14af-d136-42bb-914a-2ac6b22a41b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2273fe8d-b6a9-420b-a98c-655d15a7f5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c593412-ba5f-4820-97d1-be932d393a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 957a309a-0b01-4d15-b49a-a8f18933e376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17de1eb7-841b-4278-bef2-7cf99df4911e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6910e7-b05b-4c85-9acb-7fb54d91767e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd220298-d9a4-4b29-bfe9-b0220679ee1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5279e4fb-bfa0-41fb-8ad3-8fdf646da43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29aa7999-db1d-4a3f-a0c2-1bea7b9f288e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_39
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_labels.txt

📊 Raw data loaded:
   Train: X=(1819, 24), y=(1819,)
   Test:  X=(455, 24), y=(455,)

⚠️  Limiting training data: 1819 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  446 samples, 5 features
✅ Client client_39 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2410, R²: 0.0049

============================================================
🔄 Round 2 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0843 (↓), lr=0.001000
   • Epoch   2/100: train=0.0901, val=0.0846, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0899, val=0.0857, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0895, val=0.0859, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0890, val=0.0856, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0868, val=0.0848, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 2 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0033
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0056
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2395, R²: 0.0208

📊 Round 2 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2392, R²: 0.0247

============================================================
🔄 Round 8 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0785 (↓), lr=0.000250
   • Epoch   2/100: train=0.0882, val=0.0786, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0872, val=0.0790, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0870, val=0.0790, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0865, val=0.0796, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0849, val=0.0800, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 8 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0316
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0045
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2392, R²: 0.0254

📊 Round 8 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2385, R²: 0.0307

============================================================
🔄 Round 12 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0909 (↓), lr=0.000063
   • Epoch   2/100: train=0.0845, val=0.0907, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0843, val=0.0906, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0842, val=0.0905, patience=3/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0841, val=0.0904 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0837, val=0.0901, patience=6/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0834, val=0.0898, patience=4/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0833, val=0.0897, patience=14/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 12 Summary - Client client_39
   Epochs: 32/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0398
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0304
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2383, R²: 0.0319

📊 Round 12 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2383, R²: 0.0320

📊 Round 12 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2383, R²: 0.0323

============================================================
🔄 Round 16 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0821 (↓), lr=0.000004
   • Epoch   2/100: train=0.0868, val=0.0821, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0867, val=0.0821, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0867, val=0.0821, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0867, val=0.0821, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0866, val=0.0821, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 16 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0234
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0333
============================================================


============================================================
🔄 Round 17 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 17 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0271
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0174
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2383, R²: 0.0323

============================================================
🔄 Round 18 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 18 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0216
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0437
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0325

============================================================
🔄 Round 19 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 19 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0267
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0105
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

============================================================
🔄 Round 24 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 24 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0247
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0301
============================================================


============================================================
🔄 Round 25 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 25 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0241
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0300
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

📊 Round 25 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

============================================================
🔄 Round 27 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 27 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0231
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0370
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

============================================================
🔄 Round 34 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 34 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0231
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0339
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

============================================================
🔄 Round 37 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 37 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0240
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0226
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

📊 Round 37 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

📊 Round 37 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

📊 Round 37 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

📊 Round 37 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0326

============================================================
🔄 Round 43 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 43 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0275
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0074
============================================================


============================================================
🔄 Round 44 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 44 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=0.0260
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0249
============================================================


============================================================
🔄 Round 50 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 50 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0257
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0107
============================================================


============================================================
🔄 Round 51 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 51 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0277
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0092
============================================================


============================================================
🔄 Round 52 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 52 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0265
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0244
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

============================================================
🔄 Round 54 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 54 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0242
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0344
============================================================


============================================================
🔄 Round 56 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 56 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0314
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0005
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

📊 Round 56 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

============================================================
🔄 Round 62 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 62 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0254
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0254
============================================================


============================================================
🔄 Round 63 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 63 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0256
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0230
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

📊 Round 63 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

📊 Round 63 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

============================================================
🔄 Round 68 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 68 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0265
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0245
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

============================================================
🔄 Round 69 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 69 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0221
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0370
============================================================


============================================================
🔄 Round 70 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 70 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0241
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0272
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0327

📊 Round 70 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 73 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 73 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0259
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0215
============================================================


============================================================
🔄 Round 74 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 74 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0270
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0126
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 76 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 76 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0222
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0419
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 76 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 78 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 78 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0260
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0141
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 79 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 79 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0276
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0190
============================================================


============================================================
🔄 Round 80 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 80 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0278
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0084
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 80 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 80 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 80 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 86 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 86 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0286
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0146
============================================================


============================================================
🔄 Round 91 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 91 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0267
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0227
============================================================


============================================================
🔄 Round 94 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 94 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0252
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0304
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 94 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 99 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 99 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0275
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0194
============================================================


============================================================
🔄 Round 101 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 101 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0261
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0260
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 101 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 101 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 105 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 105 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0219
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0378
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 105 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 108 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 108 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0265
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0129
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 109 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 109 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0201
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0355
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 109 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 112 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 112 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0191
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0564
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 112 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 112 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 116 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 116 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0321
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0023
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 117 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 117 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0209
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0402
============================================================


============================================================
🔄 Round 118 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 118 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0299
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0077
============================================================


============================================================
🔄 Round 119 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 119 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0228
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0419
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 119 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 126 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 126 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0230
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0379
============================================================


============================================================
🔄 Round 132 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 132 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0214
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0384
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 133 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 133 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0256
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0083
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 135 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 135 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0248
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0277
============================================================


============================================================
🔄 Round 138 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 138 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0311
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0063
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 139 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 139 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0267
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0240
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 141 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 141 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0278
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0144
============================================================


============================================================
🔄 Round 144 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 144 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0220
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0429
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 145 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 145 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0230
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0321
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 147 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 147 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0271
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0214
============================================================


============================================================
🔄 Round 148 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 148 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0253
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0297
============================================================


============================================================
🔄 Round 150 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 150 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0236
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0316
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 152 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 152 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0250
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0285
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 155 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 155 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0267
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0224
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 155 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 158 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 158 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0260
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0270
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 160 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 160 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0234
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0360
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 160 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

📊 Round 160 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 164 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 164 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0247
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0312
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 167 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 167 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0226
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0412
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 170 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 170 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0256
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0287
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 173 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 173 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0238
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0355
============================================================


============================================================
🔄 Round 174 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 174 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0228
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0311
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 175 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 175 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0255
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0291
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 176 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 176 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0294
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0124
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 179 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 179 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0268
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0100
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0328

============================================================
🔄 Round 181 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 181 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0270
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0206
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 184 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 184 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0270
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0232
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

📊 Round 184 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 187 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 187 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0273
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0216
============================================================


============================================================
🔄 Round 189 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 189 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0280
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0162
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

❌ Client client_39 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
