[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3fa6c12-1bf9-43e1-8723-66bd8f3a4f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9966ec89-8289-41ae-9ff5-3fcc53a3d508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1be560-1415-43cc-af14-2d379a393974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54256141-dcc1-4084-973a-34caebd691f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1028ee7f-fb7b-4cd2-800e-f555a59647b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c0fcd1-93fd-4362-9312-68c216f0d556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69763891-346f-4da9-9951-6381f7726630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a0fac4-50cf-451a-be27-60d2e00349a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de3fc611-1064-4852-86f2-6c024f371b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62760ca-d86d-42a8-b9c6-f633acc0d2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e51ea7f-ac15-4fee-828e-cbab48843b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 130b6d89-f12f-4d76-bd6d-19a55b02b79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1182d4-551a-4dc8-b8c2-6670dd634b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e388d3b9-74b2-4431-be7c-1423ab44ad43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea201590-3cfe-4b27-a986-69783bc5d1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9286d79e-b282-4947-8abf-eb866d051c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa9d672-5897-4259-9fcd-2331ea538055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706076fa-f593-4bb4-bc42-73fcd19c4c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ca91ee-82fe-4f2c-8811-72727b2f97ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b72aa1b-e724-47a9-9947-829ec4e226f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0125f0b0-21e4-4607-8acc-46a3f194cbd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3026b33d-0bfd-42f8-a783-da7b4a8551d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd970975-3591-4746-83e8-e7bb3b1ed641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264df997-6090-4a1e-8bce-2d52402ac4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f08243-1598-48d0-a29d-9d249a765877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8128879-8546-4774-a5e9-e2abbe27f629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf26f7b5-a650-4021-a30f-6ab4c1a86e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9a84d5-4e18-4f8e-916b-d8b876c1a5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c09224f2-e6c2-4c59-aa10-c5f79093cba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6303a1-09ed-4a68-8b0a-bcc9aa2ae9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfdf7a06-ff26-42ed-bdcd-35f23936e3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace10be0-aff1-49c9-bf1a-7eb74c95b07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6ebc17-932f-4866-ac77-f0c6e98dffa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c309709-078b-43b1-b1ad-4ea2a4007a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7026aca9-75dc-455b-a2be-5c268a557056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97c1175d-55f6-49a1-b3d8-804599f81008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c74147-ab04-4231-aa9c-4ba7a0c2b247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d31e276-76d7-41f8-b284-1e80eb8f3634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d838baa0-e6f9-45ba-b5ca-6ff9ef8831ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b09046d3-38ee-4b91-ad71-4e1fcab806f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0880ef16-b1a7-41cd-83f6-fcc1580acb25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc70b35e-2693-440e-9adc-b42177cf94c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235fcb5a-9903-4df8-800c-517d0cfaff98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 860f45b5-2fb3-44a1-922b-9777af930bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45b800d7-dbed-4334-88cc-a957fec45b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8149728c-f127-4c12-986f-8a81d819cae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b84dc408-9345-44ae-8d7e-2287fb959db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a39cc54-88a4-4da1-9997-d9e6d113d11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7003cc7f-60f8-4abf-9767-89db9cc46cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6e9c11-d2f0-4998-9b31-9ac44412dc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c48d1ce4-80ab-4b25-b494-65b0353a3706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e818f81-a5ed-41b4-a124-d1bb2c34aa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfeccb15-ab96-4c6e-be83-c4f37224ecbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca20d0eb-eb31-4b6b-b196-c7efbaebc33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9c0000-899a-4b20-a9cf-9f8efa04b081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2ad56a-ea4c-4ce9-a198-7ad2c514e485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0d8e831-1bad-4fd4-bf6e-19ab8bf313d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e41d22-17d6-477e-9314-12af577bb7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de72bd6-7741-4f45-a515-8338b8b56aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d00dd101-ca91-4a23-a3af-e05c196fbe49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265f881c-ac9d-4840-8a55-8affb37fcff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1dfcfd4-6403-4097-9908-1bc1d20e6a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ac4867-ccb0-45a8-86a1-db74f430ec3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88a0c431-be2e-4fa3-8574-de6f50fdbf2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354e308a-33fe-487c-869a-0d14fb82b8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c744926a-b503-4888-a199-e4fc1d0e3eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d601e84d-3bb8-4a10-b16b-a80b9f22897a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4843cc9e-397d-4509-8019-9d7e49f915c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9169a589-fbe6-460b-b34c-c15da8f4fc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3c9027-6b7c-44b9-8e78-98e9df7ebe8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d94784e4-f93f-434e-910c-a3a3b44008ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e444dc-6c8a-47f2-9571-705151344d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce623574-93c0-444e-b305-04c4ce490abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a945ed2e-3ea0-4662-bb2f-060d29e4f395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112886f2-c26e-4fa7-9d01-35b71760c9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a83ae0c8-677b-4fec-bb98-1fc37474bbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eea48c6-7c43-4b30-98b0-36d991e13fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59601ac3-7a71-4523-a12c-57210be36cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9305280e-116e-4a0c-bd7c-bda14450ee1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ee13997-6395-44bf-99bc-22b39865f138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e8d417-26a7-43c8-80a8-106f1f776a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ce3be0-c8ab-40f2-81a0-7e808fca9c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a687ca-e2b6-4d0a-8daf-aad4f224a745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd9b089-20fc-40f9-8cf1-62b8c222779e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf00598-9613-4de2-b3ac-4910406ed5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e7c2483-d9bd-4348-9cff-2ad931644a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb5166a-43a3-4bef-b24c-5875f14a5ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25dcfb78-c140-421e-913b-3651d7c58b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de767de-503f-4fcf-b94e-29e6e74ad9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24264da-1c6c-429d-b9a0-5799279ed7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94a4f02e-5f5f-440a-835e-3936a6868fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 864166fa-ec13-40a3-982c-024caf115f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdfe980f-80ff-4a51-9219-a79c3ad01794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e467d8-e1a3-451d-8ea4-f3f2df28a01b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 984c01c0-0681-44ac-966c-aa42014e53bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eb35198-612d-4f80-8d59-911cab71e59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65036db1-d30b-4135-85ed-3232932683ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26883f3d-a8da-45f5-8552-dd1207eb7ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b443e1-5e78-4bdb-8cbb-4ace14347c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd45537-cf0a-455d-8d6b-4d19491351c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8c9307-d350-41af-ae1a-74974c4a5746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6cf98e1-0d24-43f1-9bc8-060ac961c37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aeb0308-f378-415d-8394-a8ef547e4063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c351609-f1c1-4152-a397-afec7d54c509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8204649-cad3-4428-8eac-8639a3968127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c3973f-1b84-4d23-95b5-687392baf0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bef4e42-da32-4e4b-838d-ce7d6a17ceb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aebd5c49-874e-454d-89a3-cd25fb81bac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 887d433f-3dab-424e-b23d-c626d126abba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a7c885-d4e6-4c26-a10c-ce7660296258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9a62b5-c8ed-422a-90c2-8d982c1147a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa619f4f-36aa-4aac-acbb-9f343fb01479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a478b6-99f8-4dbf-b137-b42e2053cd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e795a5-189a-4532-b990-56547bde4fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d6643d-039a-4249-b5da-0b13d67bd631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa318af-05eb-43ac-a078-9fb4cfba631d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bf74bb-a9c3-43cf-9ece-daa9f7f8d538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38824734-e80a-49ad-ae05-0a5e3da99e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6d26a1-1e33-4934-a92c-f6b0528f7bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c774204-109a-465e-acb4-24b50087ff86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d583be-ddbf-4132-aa27-1a882dafb12d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a824674a-7f7e-44b8-bc4e-da07a173f75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56529219-7054-4463-ade0-38b6a7b06157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9179f1f-04c8-4cc5-bdf0-dd32b5a20e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e1ca56-62d6-4a6b-a8c9-a28c4036a633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dfb2aa4-80d6-46ba-8a3d-f649914399ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58b53dc7-37f1-4eef-ab28-fd3686942982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27fb2a8a-e135-4c8c-ae51-829759a6fec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94283010-2173-4f79-abe9-92fdff80faaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce12511-bd89-42f3-a11e-78b4c9c3ae93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178af0b1-fd97-4358-9687-fd3f22399be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a70e343c-00ab-4815-a4fd-9dd50c83111f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b744f55c-d59f-433d-9304-943b708aeba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b73d80-404e-49b0-8c56-de81a6ea91e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c63bfe5b-7cf3-45eb-a053-656711fd1e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e51adc49-766f-4b0e-96aa-9ecbd024f269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ed0a58-4803-4a87-927e-c3a13d5249fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f024f7-64eb-4303-8671-614ee69bc514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa41f969-3caa-4af4-9335-c394275e7c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a20091f-cc08-45be-b0e5-a6e5b026c946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d654f854-47a8-4185-88b4-13ecc40d5473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae952ce-8b97-44cf-aedb-9a536ca9d4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e75c5b73-5786-4af8-b673-316d5bff0f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7b950c-b44c-419e-abcf-595465f475ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d75caa-fbc7-4140-b344-8c3832490de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fbc3851-3561-40e8-b181-e32124909136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a090e748-bb91-4fe7-9f5a-30d8f2885f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bbcbac6-839e-4fd2-87b7-6e18a9edf13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2d4905d-8c3b-4e1e-b268-103d7c39d919
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_41
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_labels.txt

📊 Raw data loaded:
   Train: X=(527, 24), y=(527,)
   Test:  X=(132, 24), y=(132,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 518 samples, 5 features
   Test:  123 samples, 5 features
✅ Client client_41 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0833 (↓), lr=0.001000
   • Epoch   2/100: train=0.0846, val=0.0837, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0837, val=0.0838, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0836, val=0.0839, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0829, val=0.0837, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 2 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0022
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0144
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2374, R²: -0.0058

============================================================
🔄 Round 6 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.1002 (↓), lr=0.000250
   • Epoch   2/100: train=0.0808, val=0.1004, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0804, val=0.1000, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0802, val=0.1001, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0800, val=0.1003, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0794, val=0.1006, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 6 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0061
   Val:   Loss=0.1002, RMSE=0.3166, R²=-0.0186
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2373, R²: -0.0092

============================================================
🔄 Round 8 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0896 (↓), lr=0.000063
   • Epoch   2/100: train=0.0841, val=0.0893, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0840, val=0.0892, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0839, val=0.0892, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0838, val=0.0891, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0835, val=0.0890, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0833, val=0.0889, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 8 Summary - Client client_41
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0055
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0135
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2375, R²: -0.0119

============================================================
🔄 Round 9 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0860, val=0.0852 (↓), lr=0.000008
   • Epoch   2/100: train=0.0858, val=0.0853, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0857, val=0.0853, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0857, val=0.0854, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0856, val=0.0855, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0852, val=0.0859, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 9 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0198
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0689
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2374, R²: -0.0123

📊 Round 9 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2372, R²: -0.0101

============================================================
🔄 Round 12 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0826, val=0.1000 (↓), lr=0.000002
   • Epoch   2/100: train=0.0826, val=0.1000, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0826, val=0.1000, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0826, val=0.1000, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0826, val=0.1000, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0824, val=0.1000, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1000)

============================================================
📊 Round 12 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0258
   Val:   Loss=0.1000, RMSE=0.3162, R²=-0.0267
============================================================


============================================================
🔄 Round 13 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 13 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0268
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0212
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2373, R²: -0.0119

============================================================
🔄 Round 19 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 19 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0297
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0589
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2373, R²: -0.0118

============================================================
🔄 Round 20 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 20 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0225
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0505
============================================================


============================================================
🔄 Round 23 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 23 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0301
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0459
============================================================


============================================================
🔄 Round 29 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 29 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0279
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0524
============================================================


============================================================
🔄 Round 31 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 31 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0250
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0357
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0115

📊 Round 31 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0115

📊 Round 31 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0115

📊 Round 31 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0115

============================================================
🔄 Round 36 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 36 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0312
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0295
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0115

📊 Round 36 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 36 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 40 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 40 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0345
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0029
============================================================


============================================================
🔄 Round 42 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 42 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0286
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0309
============================================================


============================================================
🔄 Round 43 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 43 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0289
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0325
============================================================


============================================================
🔄 Round 44 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 44 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0242
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0692
============================================================


============================================================
🔄 Round 45 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 45 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0249
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0301
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 47 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 47 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0277
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0206
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 47 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 49 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 49 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0268
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0220
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 51 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 51 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0240
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0350
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 53 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 53 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0219
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0451
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 55 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 55 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0288
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0396
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 56 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 56 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0244
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0468
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 57 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 57 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0242
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0329
============================================================


============================================================
🔄 Round 58 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 58 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0349
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0040
============================================================


============================================================
🔄 Round 59 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 59 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0241
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0424
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 59 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 59 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 59 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 65 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 65 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0278
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0175
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 65 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 68 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 68 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0248
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0710
============================================================


============================================================
🔄 Round 69 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 69 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0309
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0067
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 70 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 70 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0325
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0332
============================================================


============================================================
🔄 Round 71 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 71 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0261
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0291
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 71 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 71 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 74 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 74 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0277
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0198
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 78 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 78 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0263
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0306
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 78 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 82 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 82 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0230
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0390
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 86 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 86 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3006, R²=-0.0303
   Val:   Loss=0.0699, RMSE=0.2645, R²=-0.0305
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 86 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 90 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 90 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0256
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0319
============================================================


============================================================
🔄 Round 91 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 91 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0267
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0260
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 91 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 93 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 93 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0286
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0196
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 94 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 94 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0231
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0417
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 100 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 100 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0246
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0332
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 100 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 102 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 102 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0198
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0516
============================================================


============================================================
🔄 Round 107 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 107 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0200
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0508
============================================================


============================================================
🔄 Round 108 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 108 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0235
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0389
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 108 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 108 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 111 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 111 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0235
   Val:   Loss=0.0958, RMSE=0.3096, R²=-0.0366
============================================================


============================================================
🔄 Round 115 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 115 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0215
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0927
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 118 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 118 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0283
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0750
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 119 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 119 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0215
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0424
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 120 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 120 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0310
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0124
============================================================


============================================================
🔄 Round 122 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 122 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0199
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0633
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 122 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 128 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 128 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0262
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0302
============================================================


============================================================
🔄 Round 129 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 129 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0247
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0318
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 130 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 130 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0320
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0098
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 131 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 131 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0360
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0122
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 133 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 133 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0290
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0213
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 135 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 135 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0225
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0452
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 138 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 138 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0246
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0380
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 138 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 140 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 140 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0338
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0191
============================================================


============================================================
🔄 Round 146 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 146 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0307
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0073
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 148 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 148 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0338
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0087
============================================================


============================================================
🔄 Round 151 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 151 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0325
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0171
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 155 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 155 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0272
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0271
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 156 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 156 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0331
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0370
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

============================================================
🔄 Round 158 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 158 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0225
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0453
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0114

📊 Round 158 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 162 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 162 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0287
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0143
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 162 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 162 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 167 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 167 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0292
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0207
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 170 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 170 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0278
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0200
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 171 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 171 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0295
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0143
============================================================


============================================================
🔄 Round 172 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 172 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0266
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0363
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 176 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 176 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0266
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0241
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 176 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 176 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 176 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

============================================================
🔄 Round 183 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 183 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0307
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0066
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 183 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 183 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

📊 Round 183 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2373, R²: -0.0113

❌ Client client_41 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
