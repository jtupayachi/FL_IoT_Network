[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6abee0-6d76-41bf-98a3-c52dc2ca43c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b61edc-86ea-4220-8c9e-52038e45738a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfadabb5-dfb0-4352-bc13-8a7e0cf0b03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5947a57c-cb29-4ae0-ad0c-4dd3839ff9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f811326-cb2f-4490-a842-d721b226e33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361c43f5-1b9c-4d6e-9dda-7b603c8fd0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec49764a-3bd9-4127-ae59-b5929ef4a9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d80bba-5538-4cdd-9eca-f8065bf9ab72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af2c3e9-f159-42cb-a4f8-e582bc0ea073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c9df7a-f8a1-4068-8307-dda9414a1e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18757c4f-07de-44d9-b2c6-2d42f3980f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175105e5-9e2c-4d96-a6be-d3f5eceb4c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caad30a9-0d31-4010-95d6-320f36b65d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c947ff-9984-4f25-aabd-b9eff042cc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa65f631-dfca-4ba5-a380-c7fb87177675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33183042-8718-4c7a-bb63-dbee4f9ff140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee57be6-e09a-47df-ba5f-49481b7025bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd4c5f1-844e-4ed8-a25f-336dec4c7804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd888414-6811-45b3-8647-da2e8ddc7bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c0ef9f-e13e-425a-b9c4-a8f53a560194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2acc36a-b67d-42e9-b65b-11bc804b5877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4af95af-0932-4c24-bf6c-6dc34c04429b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6fd85b-1b75-425d-a426-6172615014d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdb9c90-ba5c-4bed-ae53-8c583a749e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f68360-0e46-41f6-a335-0939ac6f3ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ac2a9f-938f-4411-a237-03125fda2602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f19a084-27ce-414a-94c5-a8edda23bcdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1ae36b-e237-4bf5-b049-ed3847dbf1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ba68ce-40bd-4b89-bda0-a4e675182c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987811ea-dba1-406b-beae-bf7d50d26eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b19efd1-abee-49ec-af98-85470390b002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cadfd0-dad5-4bd7-8e24-ca0d6cceeee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd095911-f69a-4629-9051-2dd54741b360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d000f599-a849-45f0-b3b2-0646fbfdb6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5639723-c7c5-472d-aef2-d26d81968f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e65ecc-3f4a-442d-887b-0436b3812470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf65c7f4-9631-42e7-b2e8-245e1c52fe84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b124f0-acac-40b4-aabe-f7ccfa34c34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd17509d-f834-4fd4-ad84-bb869446f508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c173c86b-2a39-4c6a-9196-72b1d565374b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d528cee-2e13-4823-b60b-c8487a790051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a938b0-40f4-43ca-98a7-4e5c91779ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac37f08-44e0-4993-839b-74abc16838eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a0b4fd-a5cb-4cde-a792-d3615b2d34fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7267dd5b-a63b-49f8-bfcf-575b48eff6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4aa938e-b736-4d12-8fb2-bf22e6c82c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44c837fe-c112-41df-bfc8-f660e47789f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb07c4bc-24fc-47a7-a4e0-a2d42ae88bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e5cda9-6342-43c8-8151-c8093014c1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7391dd8f-1466-4808-9e5b-0e24f2b00525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6867a648-5ed9-4d18-9855-6ffe53f3e87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66055884-5bf1-4b98-bb61-ba57858a2758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19160d4d-95a2-4230-9e9b-ffb675ece049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b9af4ae-9120-42f5-991f-44965a381abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7207f715-65ce-45c4-baaf-b2958ab0b3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e9d208-6f78-4565-987d-4df9bd2bed94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e7d1b9-8ef7-45dc-902f-bb7301f6942a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9c4d30d-ce2d-4637-8bf6-f3af7f8163da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f8034e-7751-4f02-b65c-be17d1538830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459e9d57-8db7-4241-8ba4-ccaf6686a8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba9d4a03-4426-4f4a-9e80-34f9a84854e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 810f7b93-8df6-4dd9-a6d2-9bcf84b61a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeca05f5-b20e-4f9e-8f35-f0292a82b68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee4bb883-cd20-4aaf-ac85-beef916957b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd8a9bc-eb1b-4521-9b6f-c79f31b7ba3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaec5a9d-7a5d-47c5-b3cd-2ec9098418e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1abbd94-da8b-40ce-a658-e1dbf4e71057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733a0e15-6ec0-476b-a265-6c53c1dc9a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5ea0fb-800e-4cff-91ee-28db1ffa6a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b646c87b-7380-4695-8bfb-f80a71104767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f6775d-9486-4c8e-90aa-635800918d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ddaead5-5d62-4426-8502-c53d08575c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ceda270-b527-4a1d-9311-07b35f337c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e60a5df-c338-4dd1-b9ce-1cf8c377bc45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6532b4b0-24c7-4e8f-85a4-cb41b3896b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e116898-c630-46cf-be34-eaa5f1151de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 878c46af-f0ac-4e87-91ab-3b0e7f125d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4beb67c2-c94c-46ec-abc3-edc0cbc9c6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf073386-8f97-4533-8b8e-26603d44628a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b4aa01-5b74-4b31-9fa1-bf50cccada97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d28d5dd-f11b-4a06-b3b6-3b0a81c5e3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99530c50-cd7d-49c5-9e20-1857978c482c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd530ba-070e-4471-b058-74806a24ceac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ec0be1-f012-48e5-8f75-7e5dcb00c0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7118df8a-a82c-4fcf-a733-b69a638ed452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 078a7f95-7242-480c-a19e-84882d5cc59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43fa3a84-1254-492c-a1c9-9d085ee937df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead63c1a-4238-4535-81dc-48900552fb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f6f4117-ec4b-41ea-b8e4-88848fc6fbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3e26ad-78ab-453c-a642-27aed5221829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b713dd1-660a-4176-82d9-c0eb74cc4593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 898642bb-8c6a-4c4a-8f74-483f25c1884d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816865f4-9379-4321-bb6b-1647f23c0d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa748683-6fa2-4695-b5ca-13ff419f264d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c21aad-404b-4471-a433-861f04f8a46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b00c159-55a7-4ce8-9f78-73497d59593a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd5eb861-6dbb-4666-aeb6-bbfbbf388e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fed108-1930-47dc-a73b-4a7f9a3a8765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03bfbfd2-3c2d-4338-97ac-3f05d2aaeb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1d8c9b3-30bc-4df2-b3c5-cf939873f1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13a1b34-0bbe-4170-af6a-486de4945493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce4116e8-ecea-4c75-a8d0-6bf8f906e567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e49c369-59fd-4a74-bbef-b6aef3ffe6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feec0303-33db-43f9-af91-eac4c9b9ee00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23635a10-d779-443b-9c43-96bd4453d946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2620282d-1cc1-4663-8358-7f5fd71ef479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf63514-7061-4cec-a0a1-437adb526a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7560bfb4-b2a5-4424-b673-e120530d2d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ad8ba6-d2bd-41c1-bd37-0905300794de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd849996-a003-48dd-a2f6-c6b020b5db92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3daa415c-e69a-4d9e-9460-9565298a66a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e518ba35-0846-4111-93e4-a927e9c3ee3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbeb353b-22bc-4220-b121-ab4dafdec7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f9c4f1-4b41-452f-8541-6447f06d81f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa3faff-d2d3-4e39-8ab4-f8cd5b3fcbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7eb1e0f-3549-4eaf-a782-639ba7acf6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e9d705-a9e9-4492-b05d-75c7c1fd4463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b095be-8069-44dd-947c-70517a3e3d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24646f5e-81cd-4eb4-9645-4dd983f6b0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54e58905-4b70-4ed6-ade6-f11de22f0b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42374818-d08b-4d49-91c7-817cec56346f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45798b53-2d81-48f2-89ae-fb5967f4d4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a26af6-3aa9-487a-8940-6be43d5c103f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e77b54a3-f9fc-453c-a598-5b0132a09276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d6deba-2f2f-41ae-8254-a89fc187baf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e919a6e3-5aa6-4495-b1f9-070b381e2318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f45551e-ab78-4689-b015-2987db2f9f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00974ee5-cf7e-4b84-8520-32b12dd6a105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eb156cc-6857-4720-8e2d-2c7080350516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51eb5d3b-5ae4-40cb-bb6e-9e066c2d443f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5c17bf-e8df-4a93-ba21-ed1eb019308f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf8d417-c836-48b5-a8f6-8d7cf8f87846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e61ee6b3-8caa-44d2-a6a7-aba8497ca010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 630774f8-6259-4686-bf29-28413abac38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad959283-9da4-4103-9c13-5d557b57e53f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3b7cdc-7918-4a89-a9a9-d18bbd7b50bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message debc653d-94c5-4cd7-be95-cb39b3c32130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9888a92e-6371-4781-b60a-bc266fe14732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47efd10-a291-4770-9d4a-21e0e410105e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_46
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/test_labels.txt

📊 Raw data loaded:
   Train: X=(1336, 24), y=(1336,)
   Test:  X=(335, 24), y=(335,)

⚠️  Limiting training data: 1336 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  326 samples, 5 features
✅ Client client_46 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0889 (↓), lr=0.001000
   • Epoch   2/100: train=0.0790, val=0.0899, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0801, val=0.0913, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0799, val=0.0927, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0790, val=0.0921, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0766, val=0.0930, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 2 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0060
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0082
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2532, R²: 0.0037

📊 Round 2 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2511, R²: 0.0188

============================================================
🔄 Round 8 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0746 (↓), lr=0.000250
   • Epoch   2/100: train=0.0798, val=0.0748, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0795, val=0.0749, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0793, val=0.0749, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0791, val=0.0750, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0782, val=0.0750, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 8 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0158
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0212
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2500, R²: 0.0251

📊 Round 8 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2486, R²: 0.0345

============================================================
🔄 Round 13 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0776 (↓), lr=0.000063
   • Epoch   2/100: train=0.0788, val=0.0777, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0787, val=0.0779, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0786, val=0.0780, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0786, val=0.0780, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0783, val=0.0782, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 13 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0172
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0198
============================================================


============================================================
🔄 Round 14 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0743 (↓), lr=0.000016
   • Epoch   2/100: train=0.0798, val=0.0744, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0797, val=0.0745, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0797, val=0.0746, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0797, val=0.0746, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0796, val=0.0747, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 14 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0152
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0023
============================================================


============================================================
🔄 Round 15 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0735 (↓), lr=0.000004
   • Epoch   2/100: train=0.0801, val=0.0736, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0800, val=0.0736, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0800, val=0.0736, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0800, val=0.0736, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0800, val=0.0737, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 15 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0188
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0080
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2482, R²: 0.0367

📊 Round 15 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2482, R²: 0.0367

============================================================
🔄 Round 18 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 18 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0097
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0489
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0372

📊 Round 18 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0372

📊 Round 18 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0372

📊 Round 18 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

📊 Round 18 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

📊 Round 18 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

============================================================
🔄 Round 30 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 30 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0194
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0085
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

============================================================
🔄 Round 31 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 31 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0132
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0358
============================================================


============================================================
🔄 Round 32 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 32 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0180
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0139
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

============================================================
🔄 Round 34 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 34 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0165
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0209
============================================================


============================================================
🔄 Round 36 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 36 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0183
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0160
============================================================


============================================================
🔄 Round 39 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 39 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0155
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0273
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

📊 Round 39 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

📊 Round 39 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

📊 Round 39 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0373

============================================================
🔄 Round 44 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 44 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0179
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0150
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 49 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 49 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0164
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0223
============================================================


============================================================
🔄 Round 52 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 52 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0171
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0158
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2480, R²: 0.0374

============================================================
🔄 Round 54 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 54 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0110
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0420
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 55 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 55 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0208
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0039
============================================================


============================================================
🔄 Round 57 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 57 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0206
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0072
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

📊 Round 57 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 62 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 62 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0171
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0179
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 64 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 64 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0110
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0376
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

📊 Round 64 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 66 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 66 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0255
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0122
============================================================


============================================================
🔄 Round 67 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 67 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0176
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0195
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 69 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 69 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0206
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0025
============================================================


============================================================
🔄 Round 74 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 74 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0155
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0280
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 75 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 75 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0180
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0166
============================================================


============================================================
🔄 Round 78 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 78 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0208
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0067
============================================================


============================================================
🔄 Round 79 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 79 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0226
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0011
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

📊 Round 79 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

============================================================
🔄 Round 81 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 81 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0184
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0161
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

============================================================
🔄 Round 83 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 83 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0122
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0407
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

============================================================
🔄 Round 84 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 84 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0221
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0225
============================================================


============================================================
🔄 Round 87 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 87 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0186
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0137
============================================================


============================================================
🔄 Round 89 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 89 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0183
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0070
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

📊 Round 89 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 92 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 92 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0195
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0118
============================================================


============================================================
🔄 Round 95 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 95 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0134
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0346
============================================================


============================================================
🔄 Round 96 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 96 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0256
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0168
============================================================


============================================================
🔄 Round 97 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 97 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0150
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0244
============================================================


============================================================
🔄 Round 100 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 100 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0247
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0067
============================================================


============================================================
🔄 Round 101 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 101 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0185
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0133
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 104 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 104 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0153
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0273
============================================================


============================================================
🔄 Round 107 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 107 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0189
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0109
============================================================


============================================================
🔄 Round 111 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 111 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0181
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0202
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 112 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 112 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0198
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0092
============================================================


============================================================
🔄 Round 114 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 114 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0105
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0136
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

📊 Round 114 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

📊 Round 114 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

📊 Round 114 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 122 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 122 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0192
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0131
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

============================================================
🔄 Round 127 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 127 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0188
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0128
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

============================================================
🔄 Round 129 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 129 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0173
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0157
============================================================


============================================================
🔄 Round 130 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 130 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0115
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0435
============================================================


============================================================
🔄 Round 132 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 132 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0197
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0096
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 135 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 135 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0229
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0107
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2480, R²: 0.0374

============================================================
🔄 Round 136 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 136 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0175
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0199
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0374

============================================================
🔄 Round 139 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 139 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0222
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0026
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 142 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 142 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0154
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0250
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 144 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 144 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0153
   Val:   Loss=0.0737, RMSE=0.2716, R²=-0.0047
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 145 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 145 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0164
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0217
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 146 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 146 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0202
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0095
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 150 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 150 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0189
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0101
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

============================================================
🔄 Round 155 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 155 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0124
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0099
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2481, R²: 0.0374

📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0374

============================================================
🔄 Round 159 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 159 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0110
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0428
============================================================


============================================================
🔄 Round 160 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 160 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0176
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0135
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 162 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 162 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0157
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0265
============================================================


============================================================
🔄 Round 164 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 164 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0172
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0215
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 166 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 166 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0171
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0219
============================================================


============================================================
🔄 Round 168 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 168 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0178
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0184
============================================================


============================================================
🔄 Round 169 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 169 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0113
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0374
============================================================


============================================================
🔄 Round 170 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 170 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0160
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0249
============================================================


============================================================
🔄 Round 171 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 171 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0179
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0183
============================================================


============================================================
🔄 Round 172 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 172 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0194
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0099
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

============================================================
🔄 Round 176 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 176 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0215
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0017
============================================================


============================================================
🔄 Round 178 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 178 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0149
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0159
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

📊 Round 178 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0376

============================================================
🔄 Round 182 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 182 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0156
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0222
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 185 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 185 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0171
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0210
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 188 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 188 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0170
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0195
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2480, R²: 0.0375

============================================================
🔄 Round 190 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 190 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0098
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0534
============================================================


❌ Client client_46 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
