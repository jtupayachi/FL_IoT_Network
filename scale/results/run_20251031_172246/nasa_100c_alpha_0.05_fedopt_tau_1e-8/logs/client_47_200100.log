[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c77e8a0-5eed-4c62-af67-c7410680663b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43e996d-fb36-4c9d-b937-c55446e28549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c395f83-b47d-4104-aade-e88c5987875c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27e1e70c-51b2-4be9-8635-bc3f9f06a365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e1185ea-c470-4181-984a-d4a12e3d6a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9f032b-9958-49aa-9457-4ac37356c5b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bcd4111-36d7-4499-97d5-326b5c57d4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ca5316-e97e-47a2-969e-d83af9478759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c80919e-5413-4730-a7de-0dee007111c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0955338c-5c23-4826-bab9-a64f6e38dbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73cd12a7-f25a-4e77-84a9-6b7fc1eed082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e64765-c65a-4926-9e99-bb9497e6ebc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3685bf0-139a-4bf2-9ad8-3ffe4c2cf5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa755a9-8ec8-44ea-aa1a-c3ef903fab8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d9adbf-4e0f-4cfe-aeb2-13f1fbf02e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b177938-9133-493d-be04-baa7e1dd36f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83aec78a-8fae-40db-b464-47043d847919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ad2a42-cad1-4e0f-8c4d-08c8031fad0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f2316f-46ce-4eef-a6f9-6b8076d6d165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d4be98-c0fb-42b3-a884-d3d443010850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101206d7-8760-4183-96a1-59b3cf4de009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929a80d3-fd2b-4aae-b187-7d188a44a308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2fd63ae-a580-4ecf-97f1-793c1767eb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 106d9991-c9ca-42bf-9449-39903e92d5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eceedfa4-27a5-4c35-a843-cacc86eedaeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4b5c0e-2335-49b8-981c-0210ddd68229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c4f855a-e5c1-4558-bf38-241da2071b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40c5acf7-b256-41f2-9733-54c57c24b2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4d1cd7-6ffe-4f78-9d1d-d40fcee15f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95dfe4ff-baf5-455a-9a27-e1901a8b524d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa42dfb0-8b0c-441a-a1a6-9e5b022735b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e7e0de-3862-400a-89fd-d1bb80340d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2df1f115-1bb5-4610-ae0c-890f61122078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f64e99-6e0f-48cb-a6cf-c1581cb30d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b1678ea-6cff-4fba-ae6f-8b6e30d86da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c396776f-1bb9-473e-819b-69772e7f877b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0396082-4f8c-4e98-aafd-e7872f238276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a5af536-53f2-4a12-b242-38423cb22a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265e69f4-32db-4036-9589-b92c82b5077b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec159af4-5bdb-4778-b1a8-a3ccee0111f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f197ac5-1f03-4e19-b96e-aae72c84eedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e728b6f5-bfd1-4851-8afe-2ebf6f4a06a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d189ef57-e744-4cf3-950f-f710694b215f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4194422b-b88b-4012-af74-4d8dd325d7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f92efb4-d882-459a-be60-4a9a035f8416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c9d676d-f971-478f-a04f-00b16f88f830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78167f9f-d55d-4be8-b0cd-de2e67eb031d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8841cf6-4318-41eb-9489-47b7223ee390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f7c276-20c3-4648-b328-b024140b667c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 983007ce-f24f-49ee-826b-c10134492d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab818fb-db2b-4094-846b-887d6a9e9ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb8bcc4-e19c-4bdc-a9a2-de252ca3d633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f8addf-8330-40b8-9c58-d5030813450c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c71c782-34d4-4474-bbb6-e8c3f853d25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc99792-bb65-4ed0-b3f1-1bb996c70a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b610fe3-ee86-4f9d-8207-d513bd075b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37959d4c-701d-4a2d-bb0a-a62489c30f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cfd9b6e-f12b-4707-9594-d797f742c2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54287755-137d-4642-bc3e-654269d4cce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5b2541-4206-4944-b447-171e9ceb8a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7dae9c7-85b4-40c1-b31c-f25b8145a800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aafc8b8-481d-4a6b-ba15-24a0d4fb75e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2068d015-e7d6-4f5f-819b-3ea8daf612e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eedba9c-a2f2-4b3e-a144-37133a4a510a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403c529f-6b38-4bbc-b849-72c6a29e822c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b225ff4-6b40-410b-babc-22aa93aec88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 377987cc-0d44-4346-b347-218376a0c466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3eebbb-40ec-4b3b-9ef2-796502d7f4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6d60f8-4e2f-4194-ad90-19b3e050d4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59204b6-da50-4b52-9d78-3163bdac53f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a74f72a-591c-4f3c-9264-65735c401cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf120541-aed1-419c-b088-23d94e4269ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff0e56b-edc7-41b9-9525-4d77dd85f661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a91d2b3-78dc-478e-89aa-ebe25415af56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cddd439-86c6-4062-b294-19c5d5074305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de252379-8292-492e-885e-14f8be084487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdda1dd3-e7e8-4039-99e6-391510836d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c3d2e7d-545c-4777-8a21-1856406e8393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d935f25-a957-4792-849d-49bc8c8df6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8607d5ff-88fd-427f-8860-1a607984e18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94d189f-2dc0-461e-9498-c2592f4cffe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20eef3c0-bd30-4516-9f99-d59e6186f421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf8f43e7-4561-4456-a88e-4a607f8b999c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81295082-ea0f-4760-b918-a076e7596f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d0c0146-f670-4b98-bdd6-0389c8986686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f0faab2-a4db-489f-b17e-c706d0dddd97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9ce024-e686-4e1e-b03d-b4c312afafb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c5d1ea-2004-49e7-8ef9-b9a3696a6d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9efd777e-a04f-4605-bfd1-28f1ea235791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cbc6568-d588-45bf-b11c-cf7fed51176d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe7d7f2-664f-4ccc-b177-f30e1282fa78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d014b0a-a640-472c-ae42-b3da5f754c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437c649d-4a37-4cd9-b285-9350ee073623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9837d364-8161-4b29-99e1-cbac132ead2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9cc534-1303-4da2-abae-5259b216b23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99996032-1775-44cb-add1-edfd75fb4083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f5adc1-eacd-4a80-bff1-5e6f7c85aef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49880f87-6958-4603-b106-56e50d71df95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a57b4ac-9e4b-4ea3-8bf8-5a6c810e649d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8321d9f2-b16d-406f-97c9-a19b296f9523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50f538f-f850-45a2-9df5-9f7b4ed4dc1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c34391-16ff-45da-8aa1-02ae1a46829c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b2a78a-abe9-49e1-84e6-d4b24a1088d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa356da2-d5c4-41f2-8e4d-122b8d9b70dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c6365e-9043-4c31-b3b5-9dbf25280242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b93755e-cfc7-45ed-867e-9a259eac5419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c749f7d-6ea6-4c48-b619-26481879ce0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62d6f80b-bf78-4af5-801e-a50ed282747e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf868b2-b1fb-43c0-ab2d-258613d11612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c3aa02f-503f-4550-a4a0-dcc6c81bc8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a70d7164-ecaf-4ccd-9f08-6a8c988e55dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d58c97c-d565-4ade-8891-4d9040c3c44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5077e005-c0f7-45be-8b81-2a61f03a0c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e3404a-25dd-4333-b6b0-802f868197ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6279d9f-d23d-4d54-a580-47270de4edc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cf769a2-60ea-4975-8295-58cfe5d64736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e636ab87-3808-4e7f-bb63-20523b999e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788cc291-4758-4adc-9358-3c4060929d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f49431-e6b6-48a8-ac9d-2095719baa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message febc0bf9-d241-47dd-9e56-661447d31b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e055bc-9225-4e84-ad21-c347ea8f2b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b221579-e19e-4d6e-9c0f-e2aa26b3acd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 809fed27-fb26-45ad-ab39-dbc96ecdfabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61efb23d-e237-469b-83a9-d719f8b1f482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d51a752-77ff-4a47-944b-1880f2f1d512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b347edc-986c-49fe-81ca-8ab5f92a55e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2e94c1-6107-4fdb-a254-73c1aa40ae1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5dabf1e-54e9-48d4-9aa1-381a8e390349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb4462e-1cf0-4edc-80ff-0e9457e8ee97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819030ab-0cb6-4672-bb79-4a631628fde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd50e3e-bff3-4906-93e4-9de841416bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e58e3d-f368-4d05-b826-0487e68abe07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 951f3d54-a3a4-47de-9354-b380795f40dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f96107e8-6431-4a9d-85ca-9516b520e188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 708cddca-7da1-4642-a811-1a4f41222715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5083b224-9ec5-4366-807c-5eab14b2211c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c849be24-9163-45f9-9747-a43f07db3320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1154cee2-ec2c-4700-9957-462416e977f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa18803-504a-44c2-9b85-55798fb8161c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ecfa725-1697-4978-968e-ef975c1315f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33b924a-30b4-4e33-a028-54a48dc52cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b89515-8fdf-42de-b97e-5ee643d253e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452a5efd-0c24-4f38-bacd-749bb42c5cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c067df-c3dd-48b5-a33e-ca69700ae124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db989977-74b9-4acb-95f1-98d3603a252b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a94a3f-fad2-4ef1-a2e0-6c42a489fe83
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_47
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_labels.txt

📊 Raw data loaded:
   Train: X=(1674, 24), y=(1674,)
   Test:  X=(419, 24), y=(419,)

⚠️  Limiting training data: 1674 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  410 samples, 5 features
✅ Client client_47 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2474, R²: -0.0069

============================================================
🔄 Round 2 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0748 (↓), lr=0.001000
   • Epoch   2/100: train=0.0826, val=0.0746, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0826, val=0.0743 (↓), lr=0.001000
   • Epoch   4/100: train=0.0823, val=0.0740, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0821, val=0.0739, patience=2/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0803, val=0.0730 (↓), lr=0.001000
   ✓ Epoch  21/100: train=0.0731, val=0.0687 (↓), lr=0.001000
   📉 Epoch 28: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0626, val=0.0678, patience=2/15, lr=0.000500
   📉 Epoch 36: LR reduced 0.000500 → 0.000250
   • Epoch  41/100: train=0.0566, val=0.0712, patience=12/15, lr=0.000250
   📉 Epoch 44: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 2 Summary - Client client_47
   Epochs: 44/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0626, RMSE=0.2503, R²=0.2352
   Val:   Loss=0.0669, RMSE=0.2586, R²=0.0963
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2462, R²: 0.0034

============================================================
🔄 Round 3 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0782 (↓), lr=0.000125
   • Epoch   2/100: train=0.0802, val=0.0782, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0802, val=0.0781, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0802, val=0.0781, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0801, val=0.0781, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0799, val=0.0781, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 3 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0096
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0044
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2464, R²: 0.0029

============================================================
🔄 Round 6 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0705 (↓), lr=0.000031
   • Epoch   2/100: train=0.0818, val=0.0700, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0816, val=0.0697 (↓), lr=0.000031
   • Epoch   4/100: train=0.0816, val=0.0695, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0816, val=0.0695, patience=2/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0815, val=0.0694, patience=8/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 6 Summary - Client client_47
   Epochs: 18/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0122
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0197
============================================================


============================================================
🔄 Round 7 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0759 (↓), lr=0.000008
   • Epoch   2/100: train=0.0800, val=0.0759, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0799, val=0.0759, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0798, val=0.0759, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0798, val=0.0759, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0796, val=0.0760, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 7 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0145
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0133
============================================================


============================================================
🔄 Round 8 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0799 (↓), lr=0.000002
   • Epoch   2/100: train=0.0787, val=0.0799, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0786, val=0.0799, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0786, val=0.0798, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0786, val=0.0798, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0785, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 8 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0186
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0108
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2447, R²: 0.0175

============================================================
🔄 Round 9 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 9 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0175
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0171
============================================================


============================================================
🔄 Round 11 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 11 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0203
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0049
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2444, R²: 0.0197

📊 Round 11 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2445, R²: 0.0192

============================================================
🔄 Round 14 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 14 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0258
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0108
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 18 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 18 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0239
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0181
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2443, R²: 0.0207

📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 23 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 23 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0246
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0034
============================================================


============================================================
🔄 Round 24 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 24 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0265
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0109
============================================================


============================================================
🔄 Round 27 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 27 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0246
   Val:   Loss=0.0708, RMSE=0.2662, R²=0.0116
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 29 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 29 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0241
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0194
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 35 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 35 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0220
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0294
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 36 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 36 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0206
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0313
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 38 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 38 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0264
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0071
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 39 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 39 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0246
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0094
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 42 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 42 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0148
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0557
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 42 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 50 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 50 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0123
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0188
============================================================


============================================================
🔄 Round 52 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 52 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0266
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0096
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 52 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 52 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 55 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 55 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0214
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0307
============================================================


============================================================
🔄 Round 58 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 58 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0302
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0164
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 59 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 59 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0269
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0210
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 59 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 61 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 61 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0218
   Val:   Loss=0.0661, RMSE=0.2571, R²=0.0278
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 64 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 64 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0227
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0237
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 64 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 71 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 71 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0207
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0262
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 74 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 74 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0222
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0198
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 75 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 75 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0224
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0258
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 78 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 78 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0183
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0453
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 79 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 79 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0234
   Val:   Loss=0.0669, RMSE=0.2587, R²=0.0239
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 81 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 81 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0227
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0262
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 90 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 90 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0194
   Val:   Loss=0.0697, RMSE=0.2639, R²=0.0414
============================================================


============================================================
🔄 Round 91 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 91 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0243
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0180
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 96 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 96 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0239
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0200
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 97 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 97 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0290
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0091
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 98 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 98 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0289
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0135
============================================================


============================================================
🔄 Round 100 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 100 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0202
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0342
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 107 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 107 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0224
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0032
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 107 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 114 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 114 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0125
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0619
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 116 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 116 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0311
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0322
============================================================


============================================================
🔄 Round 118 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 118 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0270
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0091
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 120 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 120 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0272
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0036
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 120 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 127 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 127 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0233
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0211
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 128 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 128 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0216
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0267
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 128 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 131 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 131 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0196
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0371
============================================================


============================================================
🔄 Round 132 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 132 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0259
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0120
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 136 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 136 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0227
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0265
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 138 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 138 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0189
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0237
============================================================


============================================================
🔄 Round 139 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 139 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0213
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0061
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 140 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 140 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0210
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0313
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 146 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 146 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0145
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0307
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 152 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 152 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0271
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0094
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 153 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 153 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0226
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0243
============================================================


============================================================
🔄 Round 154 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 154 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0212
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0266
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 155 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 155 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0236
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0198
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 157 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 157 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0240
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0185
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

📊 Round 157 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 161 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 161 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0240
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0105
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 163 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 163 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0208
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0229
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 166 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 166 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0248
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0088
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 169 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 169 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0210
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0335
============================================================


============================================================
🔄 Round 170 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 170 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0222
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0220
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 171 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 171 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0271
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0096
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 173 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 173 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0250
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0165
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

📊 Round 173 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0205

============================================================
🔄 Round 177 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 177 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0213
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0340
============================================================


============================================================
🔄 Round 179 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 179 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0268
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0104
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 181 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 181 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0227
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.0245
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 183 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 183 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0215
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0306
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

============================================================
🔄 Round 184 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 184 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0324
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0332
============================================================


============================================================
🔄 Round 187 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 187 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0301
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0036
============================================================


============================================================
🔄 Round 189 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 189 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0221
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0290
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2443, R²: 0.0206

❌ Client client_47 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
