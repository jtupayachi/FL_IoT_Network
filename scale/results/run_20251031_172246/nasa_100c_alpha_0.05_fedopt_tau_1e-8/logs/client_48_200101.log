[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af3282c-b266-4ada-89a6-7ed5587b5338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5979649-da01-419c-942d-acdb9d173363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f45aaed-b8eb-41c5-8e88-9c9a8f44703b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb28768-caf0-4068-8ad4-b038c896437c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8024ee-9405-4b26-a76d-fcd46e1531c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5367edb9-438c-4f57-ad06-31cac2622951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3cd712f-2038-4ea4-a6e9-98360f8e1ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 734273f8-6e40-42ed-921c-1751f45519ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15eed46c-befc-466f-a7d9-13d021da75ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c66d705-faa8-4f8b-8649-c5609a7891b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9eea7b5-e9d8-4d8e-ad02-4397435534c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 629de84a-d043-40f4-9870-3a698be4da24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b57c28-e762-4779-a806-13559af932ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1af3b05-2c8f-45fc-b01a-41fb24c46516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16766de1-1170-4eca-bae6-fbcf661b312d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3b45fad-ffb1-4077-b246-5b54522ff770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f817a3a-4c97-45e1-8eca-966307651432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f5f7a17-92af-4939-a29e-624599836fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ffdb14a-bac4-4d79-99aa-d76bd6697340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f6f23d9-d986-45e6-82cc-982323a554d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a4de2d-b8f4-41ec-a0ee-ba3fcacc4e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad397598-c281-400d-8bbb-a30763983739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9cc3497-790c-45ff-a4dc-24d92d82e068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4a4969-6bee-4ea1-aa35-603169fcf5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f55d30-8c39-4f35-b36a-ae3620c7c356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88e78bbc-cf89-45cc-9cdd-901532bf11a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa704cee-184d-46a7-a6fe-b49704173ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 472a30bc-083b-41ec-8e3f-0522a9b864ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf91ff14-c9e5-439e-a740-b7aba678048e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 073110d0-2c10-4dbb-8f10-c6ab1b6e2a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1dc00d9-6af6-41c2-b5f5-9010580b2475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e559accd-42b3-47b5-8567-b9df3b483d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd25be4-a6d0-48b1-ae45-0532e827ecfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12598836-bbad-49d4-985f-e259871f7ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f274dbe-fc47-4c4b-9d88-cc8a17b58bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0093de9-a9e7-46eb-b2fb-2dd1fcfa00e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d697736b-74fe-4009-b23b-2ff994e131fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 421fee69-1d8e-4246-88ed-55db0dfabb01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e107e1f-6e49-4537-8acd-e6ca9c1ac1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e8fd2e-895a-4824-9246-8cc85ff4c76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e417bfc0-0fb9-4de3-b3ec-9ac0ded24f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c8df7e-e316-454e-9111-afc49a2b5656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4809f4-121c-46f3-8490-60e28778f89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e4482ee-25ca-4be1-a31e-1402a050c29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7600cf0-6f21-4951-9635-8b397c58a985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c75c594-fc5b-4f3b-b4ff-18ebe02df9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ad7c08-df8e-4034-9225-b950e47f00c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248da558-ac5b-40f5-abd9-0803af2f592c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b978d43-4bcc-40ef-80ea-c7ec5d7c956e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b4d255-ecc9-44dd-b471-23baa3dead1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f370dd00-c9d4-4e0e-b419-1292e403d1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44c7ccd-8640-404f-9378-452c72ac75c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79d71796-972b-40ef-ae6f-f4e2037609a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e758f4-49f8-40f2-b095-352d66af313e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09aa29c2-1dd7-462a-8f9c-3ea1835629b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812593e0-acd5-4ab9-8ffe-925d830d8511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100e01ce-433f-4df8-82db-a14d080de340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 447eb6ce-e00c-48a8-9a08-a3fbe80c529a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b465e29f-10e0-4d7c-a72f-da28672c8df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db2b6ee-4f89-4174-ab03-d4d773cdc88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb2d3d9-2efc-4958-ad49-5b067d14c375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb094e2c-ed45-4d91-9c78-9e55797f5d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ac4a04-a571-4fc5-9da6-5663ee3db4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc7185a7-9522-45e0-97d4-20f3bcce7cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47722a1-2744-427a-a35b-6bd65b35f3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0285b86-561a-49c2-a7d9-d67902ce317b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f63ed0-1c77-4e21-97e2-c6df2513c57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acd8daed-9e4b-4472-8a07-67c6b5420bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e21ec6e6-e8e0-4ce4-879f-c89473922930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9750daa-d928-4fe3-9479-9b27be0a465d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6196b16d-80c3-40fe-8174-e793ea53540c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e32d4b43-1f42-4251-8e33-0a6dcd5f0c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b6bd4d-6eaa-4d49-8734-208d40c6ae4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8faf1be-edde-45ce-ac3d-7a78ac352aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b272f0b0-0d64-4570-b7cb-13c88a19ac6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9426318c-8ddc-482c-bb95-cbdc8e1e5d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae5cddeb-41b9-4d3e-85ae-192b87c003a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2174d657-e945-4da9-ab9f-70db106fc7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b58bcb-b779-43a9-87e3-1bc20d30fa96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3149f2-3735-4c19-be0f-4296c96af60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3045831d-8cc8-4e14-bc1d-0bd3c0009963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8526641-803b-4b45-b320-3255098f0d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309abfae-ec12-473d-9689-fc0a23c9273d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b8b25c-0c67-400c-a00b-48ce394b8f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e40ae52-52ff-4b6a-b5e8-a95abfe4d64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23528db-5b24-4ad4-a71d-67fbf23404c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078ba05b-43be-41c7-986b-66d2de34ed8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9c7fec-9c04-4f04-a7cd-62a6b5d12f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e896e6d6-ef18-4015-af6e-ccdecd7c2e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3933cc4-7e60-4ede-a88c-9ffac652fe0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f221bb-9888-4421-b8c5-0af9fbf67af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1928742e-e2ad-4a13-924c-8f46e7182553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7bffdb-be60-46f2-b33e-a02635452222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b251497-d424-4b45-b444-d2179c221077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2924429-f22f-4e53-a7ac-3dd4d7e2461c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f625ed3-406c-41e8-8bbe-4b66c9be7035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bddf6e3-532f-49cc-9d58-05bec61e4494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f081b5-94f1-449c-a582-63b86e98f336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16078119-0bab-4efe-84dc-d850d32dc665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd3e2d7a-608a-4af3-88c1-19ceeb466085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef75478-e349-4147-ae5c-9bfed094ce41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5000d7f7-001e-4a00-8680-64699e873602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8535c55b-fe33-4446-ae48-fb13e4afb1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f5076e-3898-4913-96f4-bf49f936100d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d3f96f0-fcaa-47d1-99b9-7c569a9f1714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514484a8-8a51-46f6-b84d-62fba5177bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2b1f96-4082-4e50-9a90-01430ce23aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a8fa5e-186c-4713-9073-960fa83e7d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55cd0d37-cec9-4682-a6b9-40d57e5baad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8ee8b1-2cd7-4ce9-b34c-decefa3b2a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b124da1-193a-4184-9f2c-274cc3da1420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adf61759-8171-479b-966d-eb413808e739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a475418-8347-4ef3-b5af-5c6c113fc9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a6a7e80-7656-4d1e-a30c-29156d508e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2239e8-c5ed-449c-b93e-334941e8c179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e6e557-af3a-4353-90c1-26ad66026b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b4c1bff-f60d-44c5-a9f2-9e81653456b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0dd5b53-8a1e-422c-9d2d-bde4e6796bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ed50da-d370-4d6f-b130-a4a0d0d8815f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f25a4fc-1ad0-49cd-923d-8ef720f8a5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473e996f-fcca-479a-a6be-0627d9cfc6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9736181f-a872-4627-84d3-b4179eeec15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d8c1fe-e558-4e9c-8baf-8b08207009c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03ee9af-9e3a-4485-99a5-d492df4ef904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18b1b177-201d-44d0-8e2c-c29d666c5a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa7e196-033a-48cf-9608-cf179bcbfccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa8ee384-38f3-4ff0-bba2-afdd8086a19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4115399-b5ee-4de5-acba-9bbadd3c097a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da8e349b-b527-4c41-977d-2dcd905edacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa409fdc-a4fb-49ab-9c4d-a3ad36015531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e78e97a7-3912-4391-9c59-b285554ec1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1a0d25-80ab-49bd-b492-f1ab5a49708b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c99e4df-f31c-43d4-8edf-5e0b7691be30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb4be78-c3af-4671-9dcc-02e44c24c755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90eea118-fa99-4eff-8110-0a261e0f16ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5c39a4-61fb-46f2-90a2-5b5207f2553b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccaede86-6303-4280-9864-8d6dd54d1a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9228de74-631a-4d38-a029-d0911e0f6089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 597c4e6c-e9aa-4c4f-bc2c-4e93ae04a7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eb9abb3-e757-4a31-84c7-3480efca2bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4302a15-a91f-4780-8d52-9362f0735863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d23d1b-3b1a-47a5-ba15-134aabd0e204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ed9767-cb7a-43b1-82a6-bab21fadc8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38912191-f2df-47fd-b332-458a3adf329a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d19ac684-b458-4240-8c41-74b443ee4674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a893af2-93e9-40fc-9963-46d69cbb7e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97cb7ba2-0ce5-4eaa-9a7b-f87bfd8e7728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb13a04-0078-4fd8-87ad-7ae8494589a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b95bea14-98d7-4ce0-b7dc-984f89eec39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8538de0b-17e7-41bf-9923-cc186189758c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24527a8-0b42-4ea4-aa39-79d6ee6a95ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 475d89c7-3e52-4e2c-a9fd-a0103261d0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb37af6-8a5f-420f-8ae4-8001c031fd08
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_48
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/test_labels.txt

📊 Raw data loaded:
   Train: X=(1068, 24), y=(1068,)
   Test:  X=(267, 24), y=(267,)

⚠️  Limiting training data: 1068 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  258 samples, 5 features
✅ Client client_48 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2508, R²: 0.0004

============================================================
🔄 Round 2 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0913 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0889, val=0.0875 (↓), lr=0.001000
   • Epoch   3/100: train=0.0877, val=0.0875, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0860, val=0.0876, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0859, val=0.0877, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0844, val=0.0879, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 2 Summary - Client client_48
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0072
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0042
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2523, R²: -0.0059

📊 Round 2 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2520, R²: -0.0045

📊 Round 2 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2526, R²: -0.0079

📊 Round 2 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2526, R²: -0.0082

📊 Round 2 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2528, R²: -0.0094

📊 Round 2 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2532, R²: -0.0134

📊 Round 2 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2530, R²: -0.0114

============================================================
🔄 Round 11 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0848 (↓), lr=0.000250
   • Epoch   2/100: train=0.0853, val=0.0853, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0845, val=0.0847, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0840, val=0.0844, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0829, val=0.0842, patience=4/15, lr=0.000250
   • Epoch  21/100: train=0.0814, val=0.0841, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 11 Summary - Client client_48
   Epochs: 22/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0315
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0016
============================================================


============================================================
🔄 Round 14 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0888 (↓), lr=0.000250
   📉 Epoch 2: LR reduced 0.000250 → 0.000125
   • Epoch   2/100: train=0.0844, val=0.0887, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0840, val=0.0885, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0838, val=0.0885, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0836, val=0.0886, patience=4/15, lr=0.000125
   📉 Epoch 10: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0831, val=0.0885, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 14 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0085
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0006
============================================================


============================================================
🔄 Round 16 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0841 (↓), lr=0.000063
   📉 Epoch 2: LR reduced 0.000063 → 0.000031
   • Epoch   2/100: train=0.0853, val=0.0842, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0852, val=0.0841, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0851, val=0.0841, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0851, val=0.0841, patience=4/15, lr=0.000031
   📉 Epoch 10: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 16 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0046
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0095
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2531, R²: -0.0130

============================================================
🔄 Round 18 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0789 (↓), lr=0.000016
   • Epoch   2/100: train=0.0871, val=0.0789, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0871, val=0.0789, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0870, val=0.0788, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0870, val=0.0788, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0869, val=0.0787, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 18 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0119
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0271
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2531, R²: -0.0129

============================================================
🔄 Round 19 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0858 (↓), lr=0.000016
   • Epoch   2/100: train=0.0848, val=0.0858, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0848, val=0.0858, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0847, val=0.0859, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0847, val=0.0859, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0846, val=0.0858, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 19 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0035
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0117
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2531, R²: -0.0129

============================================================
🔄 Round 21 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0845 (↓), lr=0.000004
   • Epoch   2/100: train=0.0854, val=0.0845, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0854, val=0.0845, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0854, val=0.0845, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0854, val=0.0845, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0853, val=0.0846, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 21 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0024
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0134
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2531, R²: -0.0128

============================================================
🔄 Round 24 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 24 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0024
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0123
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2531, R²: -0.0128

============================================================
🔄 Round 27 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 27 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0005
   Val:   Loss=0.0944, RMSE=0.3073, R²=0.0182
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0127

============================================================
🔄 Round 28 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 28 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0012
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0051
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0127

============================================================
🔄 Round 29 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 29 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0016
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0084
============================================================


============================================================
🔄 Round 32 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 32 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0136
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0344
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0127

============================================================
🔄 Round 33 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 33 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0037
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0010
============================================================


============================================================
🔄 Round 34 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 34 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0075
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0077
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0127

============================================================
🔄 Round 36 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 36 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0058
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0010
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0127

============================================================
🔄 Round 38 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 38 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0039
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0063
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0127

============================================================
🔄 Round 40 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 40 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0005
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0227
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

============================================================
🔄 Round 43 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 43 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0001
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0198
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

📊 Round 43 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

📊 Round 43 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

============================================================
🔄 Round 48 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 48 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0108
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0262
============================================================


============================================================
🔄 Round 49 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 49 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0054
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0012
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

📊 Round 49 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

📊 Round 49 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

============================================================
🔄 Round 55 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 55 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0044
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0046
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 57 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 57 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0108
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0315
============================================================


============================================================
🔄 Round 59 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 59 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0051
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0015
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 62 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 62 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0049
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0054
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 62 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0126

============================================================
🔄 Round 64 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 64 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0148
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0336
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 67 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 67 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0050
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0015
============================================================


============================================================
🔄 Round 68 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 68 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0016
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0073
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 68 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 68 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 72 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 72 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0000
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0250
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 73 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 73 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0030
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0103
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 76 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 76 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0048
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0024
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 76 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 76 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 76 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 83 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 83 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0045
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0030
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 83 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 88 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 88 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0075
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0069
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 90 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 90 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0021
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0134
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 90 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 95 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 95 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0020
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0148
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 96 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 96 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0065
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0055
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 97 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 97 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0051
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0002
============================================================


============================================================
🔄 Round 99 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 99 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0113
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0255
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 99 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 99 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 99 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 99 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 109 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 109 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0041
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0347
============================================================


============================================================
🔄 Round 110 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 110 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0046
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0026
============================================================


============================================================
🔄 Round 111 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 111 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0013
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0190
============================================================


============================================================
🔄 Round 112 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 112 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0005
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0219
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 112 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 115 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 115 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0006
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0101
============================================================


============================================================
🔄 Round 116 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 116 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0029
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0120
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 118 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 118 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0053
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0003
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 121 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 121 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0082
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0101
============================================================


============================================================
🔄 Round 122 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 122 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0013
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0197
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

📊 Round 122 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 126 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 126 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0094
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0147
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 129 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 129 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0064
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0044
============================================================


============================================================
🔄 Round 132 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 132 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0035
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0086
============================================================


============================================================
🔄 Round 133 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 133 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0090
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0221
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 134 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 134 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0042
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0012
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0125

============================================================
🔄 Round 136 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 136 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0046
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0145
============================================================


============================================================
🔄 Round 137 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 137 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0057
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0003
============================================================


============================================================
🔄 Round 138 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 138 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0003
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0152
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

============================================================
🔄 Round 142 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 142 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0009
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0042
============================================================


============================================================
🔄 Round 143 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 143 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0010
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0025
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

============================================================
🔄 Round 149 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 149 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0056
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0007
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

📊 Round 149 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

📊 Round 149 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

📊 Round 149 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

============================================================
🔄 Round 155 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 155 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0253
============================================================


============================================================
🔄 Round 156 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 156 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0034
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0089
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

📊 Round 156 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

============================================================
🔄 Round 162 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 162 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0019
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0154
============================================================


============================================================
🔄 Round 164 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 164 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0076
   Val:   Loss=0.1002, RMSE=0.3166, R²=-0.0053
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0124

============================================================
🔄 Round 166 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 166 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0071
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0074
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 169 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 169 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0076
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0103
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 172 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 172 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0037
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0057
============================================================


============================================================
🔄 Round 173 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 173 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0098
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0248
============================================================


============================================================
🔄 Round 174 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 174 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0043
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0127
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 176 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 176 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0065
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0394
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 177 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 177 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0031
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0102
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

📊 Round 177 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 183 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 183 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0063
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0028
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 184 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 184 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0064
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0068
============================================================


============================================================
🔄 Round 185 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 185 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0032
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0095
============================================================


============================================================
🔄 Round 186 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 186 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0018
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0140
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 188 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 188 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0032
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0101
============================================================


============================================================
🔄 Round 189 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 189 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0018
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0326
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

❌ Client client_48 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
