[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f165f985-496e-46fd-8c33-96d0387baa4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 334a17b6-72b0-4eb5-8de4-4ebfae7893af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e8cea8-a541-4b8c-89f0-9d70a38bf253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21accb51-e1c7-4321-9be4-ccce5fdafb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa3131a-28a6-4c07-82a4-0a3430668884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415a8912-8cdf-4609-8121-498da6b91c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f96fc82-4777-4f2f-890b-7ed267df4741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878d8ac1-3b77-4e7e-aea6-dc1a1082df48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6630b90f-63d0-4c47-b016-c075caf108ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d67f8bb1-8527-4c9c-b368-9b9c76744c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd71667-4cbc-4fca-80e4-8b6e6d33ea4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb88b285-e42f-47d7-bd94-c4e99f1440ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e672fd44-be7d-4d03-805f-8156b9a73628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4e12e0-9d61-4472-ae19-acb9aa204481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bd0a3a5-55e9-41f3-bae4-94ab9817f376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbc9c840-7eb2-4866-8fb5-5b83c6389b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d3dc03-f1e5-40d5-aeb3-339f00d8bd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4f8d15-8da3-43bb-a7af-2c7320b9b46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b889d494-8a05-4901-963d-3adc53d7c672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e04198e-0409-4468-91aa-24b8ed7f975e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e0c5656-8866-478d-984e-65b18de6cde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caca91bc-f646-4523-be09-ecb9bc5b5a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4043f8ea-7f04-420b-8b04-ca749a29bfc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f5d38b8-37ba-485a-a438-671d1c1cc421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10f9272-da89-422e-b802-812ddc191207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35eccea6-8f7a-4806-a07a-382f571e32f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919434ec-469d-4dde-afba-718130d42362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a57eebe-238b-428b-bcde-daae871a04c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906351d8-4c8f-4690-8ed0-f47df90c1de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a505f38-7ccc-4116-86a0-55746c68887e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c981a7f-a061-4d7d-af71-396c3ab70e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f10253-20a5-4672-a25f-e7d2dc3dde66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3479676d-edf9-4af7-94df-7b6163a9c437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc08638-fd1b-494e-ae3d-657e3fbb474a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 356dc74e-0f19-4617-8aee-324c72dea2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87651d8-ae62-4f89-b892-e7d34fd4cf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c891722-5227-426d-ae33-671f11fb8548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e56583-e1a3-473d-9dfc-2e476edb982f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fd8873-0d82-43a6-941a-2d0f6162beb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714e7597-0e19-4da1-9d86-d8cfbd913e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662f5c93-0c10-4b21-9424-012e0dd68606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2d7298-5507-4426-a828-795f0432205c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da4c610b-8407-4c24-93a7-3117cef0025e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d129cc-76cd-407c-9fd8-b870bceda203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ec3923b-7d1c-4c6c-b207-d6aa7d6a92a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498ab78e-ae28-46e3-a2dc-f7717625dec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca73635-cb53-4691-9f5a-d3725cfc8221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b69f9e59-f7a7-46e7-8d2d-5738ad67fa86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf2f52fc-7b40-42dc-9f6c-b59daae63aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db1e541-d9d4-4462-8c0b-d8bc9677cce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19ef044-f5be-49f0-9475-08f32ab9d587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02e5c70-cef3-48f3-921a-71df740cfaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c351cb-cbb7-4de9-a84d-b462c5911c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1179b3b8-5aea-487d-9e31-e87fb3a8bd6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0fee30-e781-45dd-b253-302b530fb5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53019f89-f2aa-4c91-b5c3-a5924bf84259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da0ac06c-0465-413a-90f5-9b5511333ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0085067f-495f-4e06-9d2c-1b274ae987f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c69cedd-b0b8-4806-a601-7baedbc1cc87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acdb2d0a-6649-4c07-b0f8-5a806a01c6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c40896c-1eb2-4524-9e7c-86c3ce9e2fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a122047d-b8be-4044-9975-01836f9b4609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab9e128-a8c2-48b4-9756-7a9a046a4b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10045eea-0e4d-46de-ae73-62165285c282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4edbde3f-baf8-41ad-a20a-b5a8bcce6e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837254e2-f188-46f6-b135-2794c51f4be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2ea8ec-e328-4e78-b8c3-a1906e57bfef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 256fc73e-0a97-491b-8b2e-b4de88dfef7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858d1565-15f4-44ee-8b00-386b8c486979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d2d1057-dbfe-43b7-806a-a4d7ae65680c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message becae806-7340-41a7-a57f-56c381527512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92dfbde1-46de-4220-9ee5-fbd3334e5125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9350070e-75fe-4f70-910b-494c753585be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8749de29-0255-4cb6-969b-850016b36c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 359e08bc-1fed-4c75-8828-56eb396c4d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc3b116-a96b-4862-b6c2-22585bc171f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e38dba38-ead7-4706-842a-b37d6f388d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27023df1-4124-4279-9d31-754590081411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b338357d-3f46-4324-87d2-0391597b71e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b95966c7-f32e-4ea9-a4ac-5a5950238ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8104478e-1ad3-463e-8feb-548cddb8a788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b8d972-5eb8-435b-bbe1-a5364ea6e162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 358cf0e5-dec6-4be1-8971-da63707262be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a3b82f-6550-4e97-a587-491370a388ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be800e75-a239-4123-ac0e-98f7eb45fa7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0ca44d-4f80-469a-b77a-16a82dc40e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f102fb2-816e-4912-8fd8-72826d109495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d83576a6-b730-4206-b901-b745afc6e5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2bf0fb1-9289-4270-976f-0505191e558e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee383cf9-7c76-4474-8c4e-07e1c9aac94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090116fb-8590-495f-a887-a97a6b5eae38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29fb18ea-491c-48ac-bd4b-02351f3d0226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ea5a2e-db3d-4aa3-a965-8669e3ee69ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14d07b2-2ef8-4764-a102-8d009eaa5268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc4d3f5-66e6-4899-baa7-18d0ec0b08ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40421d3-5954-4cc8-bc14-270cbdb06169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967baf1d-47c4-46df-8350-ef1990cf7ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d90b96-9766-461c-a7c2-f9877e8191de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45349f56-a266-461b-8f24-c132db6f9e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 449fd28e-dd33-4975-a5d6-150255ff8eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162856b8-edc7-4f3d-b925-000581832163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdbcac33-eadb-45ce-879b-bc5b26c33507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eb40eaa-66c1-47dc-b787-5166de393142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e09c04-adb5-4e2c-9113-a56877284cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7adf1bfa-fad9-46d6-b38b-4893201d9fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081c9fec-c1ca-4db5-9be6-5044b654feef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2af9ed-abf4-4b1c-92ab-05c25dc9eb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1acf6c-8450-442d-bc75-3ddbbf46a6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b18885-bf27-41ed-bd0e-8b03ea2503f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2109d85a-7b18-4065-bda5-7afef4595572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494f16cc-9747-4e6a-b1b9-e8d17441dedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08843e02-0c6e-4da7-b295-932d36456dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 360ec251-7643-4710-bee6-9a1230bfc79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5dd483d-7124-4c5a-b679-bd9888139b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a95380e-abb4-42b5-986a-d37ccbfdc7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb94478-a12e-4d5a-9ad8-e7ab248e808c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beb7e75a-fd70-4db3-b66e-fc819e64dc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ef6387-fe26-40de-9ee1-5fa6352c7914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40408749-7e12-4c50-9e98-8fc610922d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e5cb5b-397b-432c-b5b5-83a90bbbacfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96fcf383-b412-4b4b-9256-cefc4564408c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b60d1f-f89c-497b-ad15-f824cd11ac65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7728552-8233-4f7a-93be-7133fb47480a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4236e9d6-753b-4de5-b08e-8c7795d71586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f30c930-c926-4133-9718-c7695d6e6677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e48617a8-8427-4e08-9952-31e53db66f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 997a7b09-0609-4dc0-810a-37e00c450b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 269485aa-d74e-4eb3-96ff-998e864adc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc23191-cab9-4d6a-ab20-76cd946ac64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0067041e-2106-418e-9fbf-40b876163322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb3b8d7-43f0-4fc4-8aef-d09b244f0637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54820a02-2c0e-455f-983f-0c778363080a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c539287-01e7-461c-9e73-7160909f1998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dafe77d-1ac8-40e8-b767-481d9447dd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9826eb0b-a685-4051-b231-ffa66d87b6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b91ee0-6e2a-483e-b7da-16250ac0d7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c68496f-35bf-42d7-a81a-ef2b2465de85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d891a2-8d9b-40da-939d-b4af2e54b530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9741e274-62e1-44d2-b609-653e37acfd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d78da1-0ef9-40bf-a4f0-beab181924e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa88a89-3846-420c-9a5a-828e65b25de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1cf94be-230a-4fa4-a76a-a1dac2e966a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a050be9-a1a6-4935-a665-039bf2f72981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a628bc7-db60-41b1-a3e1-a3a0e399da92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b764c7c-77e7-45f5-b113-a7f1a02bd0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fe3c1a-359f-4e66-83d1-430a7478b9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf1624e3-ba63-4e74-bfb1-1d35369d7d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2baf13-d662-46cb-a7be-041ee9894199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca62f0d-0630-40b3-b10b-8ef4549d3d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f33d442-a58a-476c-9d90-c39be2da5e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a77e34a7-3b23-4559-9568-20981a620a5f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_49
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_labels.txt

📊 Raw data loaded:
   Train: X=(2404, 24), y=(2404,)
   Test:  X=(601, 24), y=(601,)

⚠️  Limiting training data: 2404 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  592 samples, 5 features
✅ Client client_49 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3326, val=0.1011 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1021, val=0.0869 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0919, val=0.0756 (↓), lr=0.001000
   • Epoch   4/100: train=0.0869, val=0.0751, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0871, val=0.0751, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0869, val=0.0753, patience=5/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0853, val=0.0746, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 1 Summary - Client client_49
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0062
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0017
============================================================


============================================================
🔄 Round 2 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0889 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0846, val=0.0876 (↓), lr=0.000500
   • Epoch   3/100: train=0.0840, val=0.0882, patience=1/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0838, val=0.0883, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0835, val=0.0881, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0831, val=0.0885, patience=9/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 2 Summary - Client client_49
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0077
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0295
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2419, R²: 0.0004

============================================================
🔄 Round 5 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0882 (↓), lr=0.000125
   • Epoch   2/100: train=0.0847, val=0.0881, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0846, val=0.0881, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0881, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0845, val=0.0881, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0843, val=0.0881, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 5 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0044
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0142
============================================================


============================================================
🔄 Round 7 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0837 (↓), lr=0.000031
   • Epoch   2/100: train=0.0865, val=0.0838, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0864, val=0.0839, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0863, val=0.0839, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0863, val=0.0840, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0862, val=0.0840, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 7 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0112
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0292
============================================================


============================================================
🔄 Round 9 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0838 (↓), lr=0.000008
   • Epoch   2/100: train=0.0869, val=0.0839, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0868, val=0.0839, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0867, val=0.0840, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0867, val=0.0840, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0865, val=0.0843, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 9 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0214
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0183
============================================================


============================================================
🔄 Round 10 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0780 (↓), lr=0.000002
   • Epoch   2/100: train=0.0886, val=0.0780, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0886, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 10 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0229
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0522
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2425, R²: -0.0082

============================================================
🔄 Round 12 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 12 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0232
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0142
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2425, R²: -0.0085

📊 Round 12 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 18 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 18 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0287
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0165
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 19 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 19 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0277
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0101
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 21 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 21 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0241
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0218
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 22 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 22 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0218
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0330
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 24 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 24 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0268
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0060
============================================================


============================================================
🔄 Round 26 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.1032 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.1032, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.1032, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.1032, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.1032, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.1032, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1032)

============================================================
📊 Round 26 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0253
   Val:   Loss=0.1032, RMSE=0.3213, R²=-0.0200
============================================================


============================================================
🔄 Round 29 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 29 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0212
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0335
============================================================


============================================================
🔄 Round 30 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 30 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0243
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0307
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 35 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 35 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0230
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0270
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 37 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 37 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0204
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0425
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 38 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 38 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0273
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0070
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 39 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 39 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0240
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0197
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 40 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 40 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0212
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0318
============================================================


============================================================
🔄 Round 41 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 41 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0277
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0084
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 41 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 46 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 46 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0190
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0444
============================================================


============================================================
🔄 Round 47 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 47 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0194
   Val:   Loss=0.0994, RMSE=0.3152, R²=-0.0350
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 50 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 50 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=-0.0226
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0249
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 50 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 53 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 53 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0209
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0560
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 54 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 54 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0236
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0209
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 55 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 55 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0201
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0385
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 56 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 56 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0247
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0175
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 61 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 61 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0204
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0466
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 61 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 63 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 63 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0220
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0276
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 63 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 66 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 66 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0226
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0250
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 68 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 68 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0253
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0129
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 71 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 71 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0298
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0138
============================================================


============================================================
🔄 Round 72 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 72 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0225
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0256
============================================================


============================================================
🔄 Round 73 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 73 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0222
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0262
============================================================


============================================================
🔄 Round 75 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 75 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0243
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0179
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 77 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 77 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0257
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0130
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 77 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 81 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 81 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0241
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0199
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 88 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 88 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0242
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0291
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 88 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 91 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 91 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0183
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0469
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 92 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 92 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0220
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0287
============================================================


============================================================
🔄 Round 93 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 93 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0185
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0435
============================================================


============================================================
🔄 Round 94 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 94 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0229
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0280
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 94 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 96 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 96 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0219
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0295
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0095

============================================================
🔄 Round 97 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 97 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0248
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0150
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 99 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 99 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0200
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0418
============================================================


============================================================
🔄 Round 100 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 100 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0217
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0308
============================================================


============================================================
🔄 Round 101 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 101 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0234
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0222
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 102 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 102 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0220
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0421
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 102 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 102 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 113 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 113 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0221
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0285
============================================================


============================================================
🔄 Round 116 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 116 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0226
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0391
============================================================


============================================================
🔄 Round 117 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 117 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0214
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0369
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 117 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 122 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 122 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0269
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0145
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 123 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 123 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0195
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0579
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 123 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 123 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 123 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 123 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 131 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 131 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0272
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0073
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 131 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 131 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 131 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 131 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 141 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 141 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0274
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0124
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 144 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 144 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0216
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0363
============================================================


============================================================
🔄 Round 145 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 145 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0220
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0272
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 146 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 146 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0226
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0254
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 146 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 146 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 151 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 151 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0216
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0296
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2426, R²: -0.0096

📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 151 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 163 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 163 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0212
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0482
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 165 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 165 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0195
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0380
============================================================


============================================================
🔄 Round 166 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 166 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0228
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0253
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 174 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 174 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0289
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0028
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 176 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 176 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0218
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0283
============================================================


============================================================
🔄 Round 177 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 177 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0234
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0297
============================================================


============================================================
🔄 Round 178 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 178 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0253
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0209
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

📊 Round 178 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 183 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 183 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0325
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0174
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 187 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 187 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0226
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0288
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

============================================================
🔄 Round 188 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 188 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0200
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0356
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: -0.0096

❌ Client client_49 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
