[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a9dbd5-be28-40b9-8418-0748fc538777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd99d20d-6960-4996-9ea4-76560cedf589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37c7253-1117-4faf-b5f9-867da8e764fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc269492-06f3-4190-aea6-581dd0275496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db3de47-c213-4206-a056-ed8965787fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783254f4-8bb9-4048-b4f2-8de7ea8ff52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a87084d-521b-43bf-9b32-de9e9ad71cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e4ae125-6852-4466-ae88-37a82db37418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a8c77c-511c-4b52-bef5-93ef15f15b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eecfc3a-dee1-45c0-a135-7adfe3cc015c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a64c69-98f4-453b-9800-3a99e1b46830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7884b191-0ecc-4f1f-ae10-5238cac061ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5844883-252f-4971-b520-c0166b410cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d07f913-d78f-45e7-ab27-f367733d9dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e537811-517f-45cd-a23e-a8db29fbafa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff23b3c4-9409-4636-b8c0-f026aca17c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ef42a4-49c5-4fb5-b2ee-ef91556757a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0902d9c0-4936-43dc-9686-15686088cd4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572bff2b-9a74-434c-bf48-f3df93c904ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8cba3a-3f99-43d5-aecd-70b825b57c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb98e2c5-8aa1-4a40-87ca-bf6b98e4d8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6621fa23-1e96-4b25-97ce-dd770ac02de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b747a948-fa9f-424d-a268-d123431534c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf6cc9d-c1c6-4a19-b9f0-6bd3b80e9f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2459d316-c6ea-45bb-94a7-bc0a6fe7655d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3e6d35-1d2f-4f75-8e91-fb889510cbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cda00e3-2114-4c2f-9aaf-a0619ad91afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d878fd-2387-43fe-b132-a079bcfa3de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e76bf3-c208-42d5-9d6b-1c8fb889656c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04265e51-037e-4995-8fd7-a224a9601525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903c6432-f080-4de9-8ae8-f5f2b21485f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6f29b8-dd8c-4157-be40-e18e06ee0035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ab4d8d-d4d9-4b61-ad31-aa591a004c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae2e396-b193-4009-ab86-315572f1d235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b376ebe-808b-4a5f-bcc8-18fd8a377465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c573b1-e719-44fe-ba98-c2b2b258cb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e05b352d-d9a6-4fdd-b053-d94d3856d8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79905650-66ea-4719-86ca-dd9147d177f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f46420-18bb-4437-9e04-d4e668003bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1796d7c-2ecf-4716-ba87-989053920110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e4b60f-e89a-49e5-b352-ed172361e1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20501a2f-66ce-4dcc-b303-94c77811b584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6ccb384-ede5-455c-a879-d814189af9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f308aa9d-e4f8-40df-8cee-407195489ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf9f588d-c55f-4a99-a03b-11e7047d5483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5818c7-6464-465e-8b43-6ae91d1a9bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb04e124-9b14-44d4-9fd6-7fcccc498051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e159f5-95b1-4a11-be40-8c185905c7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3755187-adff-4e5b-8eca-a8ed154beaa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f85ed5-815d-400e-a0c9-5fef6c52c290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ffaaf4-00ac-405e-898e-e0161a9a755b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a862686-0cee-435d-b7da-b13346750847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6fa9b51-6e77-4034-8e6f-7aa7e1381962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f18753-2d74-4eaa-8682-b19fed99a3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f4942e-c30f-4b8a-9928-fb9a4437682a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29cd8af-ca72-4d3d-afd7-76f2ccd302f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5989f9-7562-4a6f-a365-efee9500dd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60155a9f-3d35-4788-8c1a-7906ef36ad1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a107d7-7777-4385-a07f-1ba36fdac304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e144e6b-1cc6-452c-821e-d7351862537b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc68783-13bf-440b-aa07-4d807543cfd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669ad5b1-6597-42ef-82a2-ae59d0cb9508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ed737a-dc2a-46b3-8d39-e71763d9beb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8812c0-45ec-45e1-a3a5-c3ea1fbde7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6a93f25-8f20-43b2-838d-95bb9076b542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbde898d-1714-4478-8454-07315fc015d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ab1a54-5b6f-40b2-be12-9cdcdc6d10c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6656e6a-0d22-4c44-bb52-8adbea74ffc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea0fafb0-02f8-4cb2-b901-309ff8667ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c610ff4f-21e5-46cd-a8aa-0cc3f6910fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76718140-2e7e-4e46-a03b-29261af1fabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59510dc8-edc7-41c4-a980-97bfee3c86e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27d0a952-332c-42d7-8e8e-67dd1a2b14c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c12b079a-d338-45f8-854b-73959d9c9b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc9349d-d8f5-4ee0-9deb-925b19f027f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4438cefa-4d0b-44d6-bd7d-252491041285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a5c58ad-0b05-434a-a295-e63a011198cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942738db-22d8-4a1e-bf15-cf7dbd688564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8db89f-ceb9-4bec-be8d-b97c3afc20f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e1bac33-42e1-4cbb-a31d-d686d46c5575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 738d1890-a0e8-4e11-8cd7-c37192e87019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19643e7e-4657-4ce0-8940-7822f5b8bb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e68efe-4144-44c9-8f37-42babb9944f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5e9d58a-2b9a-4b9a-b307-c128046f39a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f516c5-1488-4730-ba89-0c1cdffc3d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5471df9-d26f-4954-b4a1-350a0cb419a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475708fa-23a9-49fc-9f13-8f6c5a5e13ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de690d32-90eb-46dd-aa55-97ba4021e4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f016a0-bcdb-4fbb-a2a2-6db91bcb191c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf62676-c0e7-423c-88c6-595ab3c9d020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0017dd57-dff8-4130-b869-c527ac1ea364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 124cc90f-f5cf-4bd1-a44c-a2780ac83d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2852cb5c-fecd-4df7-a336-4a39fcb67a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759fdf60-8432-4aa5-9557-1382813b07d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fcb2da2-bf2c-4aef-b35f-6969f965abbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab153c78-34ab-4d22-8a54-d75c7900a3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 950d4d89-6473-4521-bfa6-66e2377a3220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4b4b285-fbc3-4eb8-988e-60ae164ae5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb8915b-ea2d-4161-a595-2bec38af1fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7caed50d-8056-40e9-ad1e-14eaf529fd59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68939bb1-cb94-405b-b1dc-19fac7051134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d1a1121-2f99-4275-accd-32b76b2257e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68dc3d6-fd44-4cdc-8202-d4f95b80e9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceaac794-3363-4884-a3a2-cca27fc4cd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9523e171-102a-43af-9354-fe988aafa0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a248d410-1158-48eb-ae48-53dc6fbcb3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac564020-0479-4880-9f48-ddf7600113aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c20ee8-f903-4c3d-908b-dd9c6711dbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96ab5ecb-283f-499b-8c21-5cb4ff337222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebf979a1-cba1-43e0-a6ea-aab254348376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415c7357-03dc-494c-b46c-9c3f23e08d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad2d927-2416-4716-b43c-80ee52f6c6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e46b673-62b9-401b-b4da-4e43e72a3c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e2916bc-47a1-4e67-8a44-895bc7362a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5011f74d-a713-4c75-a8b3-89c357ef07d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8639d069-b79a-43a4-9ca3-232307cb461f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c7dd61-da6b-4db2-8d38-73ad80243b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e2f2e1-359b-4f2f-b9dc-5f8d28d8df9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240db8f1-453f-4938-968c-eeb1facf0893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c621ab-b575-484f-afd7-171b5ef49a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ae10f48-eed8-4d92-bd22-92671eb882fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8141e54a-18cd-4c05-9e3a-470e61264c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db5642ad-0064-498f-ace5-a4c81328fa57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b19e371-6374-4a85-ad3b-b1b9d4253c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf4589b-e6cc-4434-ae54-5a096ee10497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58398104-3bf5-46a2-99d1-bdfb8521a2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be02781e-d0f1-4d1c-b916-f738f5e462b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef9f489c-3533-464e-9ec7-c531d5e3ecd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 442bf7f2-cc97-4e23-a4c2-906a0e0172a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b40d1d-0a92-4f48-9146-a7e87920c7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e378f1-fc91-4d6d-975f-823f07e3f9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1154c43-d0d4-48a4-8462-f663ce5c4f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 692b1a96-bdf8-42c1-9e18-02be216541d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61039322-fdec-4dd6-95eb-2011685f84d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37eed63-01e2-4af3-be6e-0c574754ca10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01fa8bea-8641-4b66-ae9f-fdfb96b21735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf9028a-1b72-4860-8c63-07fa67348f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f53168-12e6-4e1f-8c64-fff7e7909c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80908cf7-8708-4101-9cfa-2fc6a5c70783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e76eb08a-167a-47bc-9b77-35ec22c13646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae85ca7-34d5-48be-a31e-4a87d0cb9b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528868dc-ee59-47a0-8f0d-923d182eea01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c7ed1f1-ab27-4799-be25-2046f83c482e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104d3e9c-2ddc-4bfd-a006-8f90adf696e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b514d1-35ed-4326-9afe-555b9f90e33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56824fac-0fb1-4835-bf5e-747a306e91cc
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(724, 24), y=(724,)
   Test:  X=(181, 24), y=(181,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 715 samples, 5 features
   Test:  172 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0819 (↓), lr=0.001000
   • Epoch   2/100: train=0.0848, val=0.0817, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0843, val=0.0816, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0817, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0835, val=0.0817, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0811, val=0.0829, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 2 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0025
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0003
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2482, R²: 0.0009

📊 Round 2 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2482, R²: 0.0002

📊 Round 2 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2480, R²: 0.0005

📊 Round 2 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2480, R²: 0.0012

============================================================
🔄 Round 9 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0803 (↓), lr=0.000500
   • Epoch   2/100: train=0.0815, val=0.0810, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0810, val=0.0810, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0804, val=0.0811, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0779, val=0.0814, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 9 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0337
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0060
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2483, R²: 0.0002

📊 Round 9 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0026

============================================================
🔄 Round 13 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0828 (↓), lr=0.000125
   • Epoch   2/100: train=0.0808, val=0.0828, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0796, val=0.0831, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 13 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0295
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0227
============================================================


============================================================
🔄 Round 16 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0843 (↓), lr=0.000031
   • Epoch   2/100: train=0.0805, val=0.0844, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0804, val=0.0845, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 16 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0241
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0322
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 16 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 16 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 21 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0691 (↓), lr=0.000008
   • Epoch   2/100: train=0.0844, val=0.0691, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0843, val=0.0692, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0843, val=0.0693, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0842, val=0.0694, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0841, val=0.0696, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 21 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0243
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0209
============================================================


============================================================
🔄 Round 22 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0832 (↓), lr=0.000002
   • Epoch   2/100: train=0.0810, val=0.0832, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0810, val=0.0832, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0810, val=0.0832, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0810, val=0.0832, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 22 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0247
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0346
============================================================


============================================================
🔄 Round 24 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 24 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0339
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0139
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 27 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 27 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0275
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0140
============================================================


============================================================
🔄 Round 28 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 28 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0234
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0403
============================================================


============================================================
🔄 Round 31 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 31 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0313
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0084
============================================================


============================================================
🔄 Round 32 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 32 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0239
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0359
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 34 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 34 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0203
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0504
============================================================


============================================================
🔄 Round 36 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 36 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0257
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0103
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 39 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 39 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0247
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0257
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 40 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 40 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0277
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0213
============================================================


============================================================
🔄 Round 44 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 44 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0313
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0027
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 44 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 46 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 46 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0288
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0128
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 47 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 47 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0245
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0338
============================================================


============================================================
🔄 Round 48 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 48 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0308
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0117
============================================================


============================================================
🔄 Round 49 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 49 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0272
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0150
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 52 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 52 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0270
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0271
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 56 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 56 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0265
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0290
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 56 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 58 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 58 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0290
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0071
============================================================


============================================================
🔄 Round 59 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 59 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0227
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0372
============================================================


============================================================
🔄 Round 60 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 60 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0295
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0165
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 62 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 62 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0293
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0173
============================================================


============================================================
🔄 Round 66 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 66 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0254
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0325
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 66 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 71 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 71 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0201
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0160
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 71 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 73 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 73 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0281
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0229
============================================================


============================================================
🔄 Round 75 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 75 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0226
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0447
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 75 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 77 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 77 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0249
   Val:   Loss=0.0959, RMSE=0.3097, R²=0.0213
============================================================


============================================================
🔄 Round 78 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 78 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0278
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0036
============================================================


============================================================
🔄 Round 79 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 79 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0254
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0342
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 83 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 83 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0247
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0148
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 85 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 85 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0282
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0206
============================================================


============================================================
🔄 Round 86 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 86 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0275
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0246
============================================================


============================================================
🔄 Round 87 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 87 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0298
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0114
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 87 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 89 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 89 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0250
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0276
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 91 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 91 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0317
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0039
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 91 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

📊 Round 91 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 97 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 97 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0244
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0369
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 100 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 100 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0297
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0109
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 101 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 101 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0288
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0199
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0028

============================================================
🔄 Round 103 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 103 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0242
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0334
============================================================


============================================================
🔄 Round 105 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 105 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0261
   Val:   Loss=0.0666, RMSE=0.2580, R²=0.0256
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 105 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 110 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 110 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0275
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0225
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 110 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 121 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 121 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0273
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0243
============================================================


============================================================
🔄 Round 123 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 123 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0239
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0397
============================================================


============================================================
🔄 Round 125 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 125 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0287
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0102
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 125 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 127 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 127 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0228
   Val:   Loss=0.0674, RMSE=0.2596, R²=0.0473
============================================================


============================================================
🔄 Round 128 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 128 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0210
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0386
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 130 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 130 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0294
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0072
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 133 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 133 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0217
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0018
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 134 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 134 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0263
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0268
============================================================


============================================================
🔄 Round 135 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 135 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0306
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0067
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 136 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 136 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0279
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0202
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 140 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 140 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0282
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0055
============================================================


============================================================
🔄 Round 141 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 141 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0274
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0219
============================================================


============================================================
🔄 Round 143 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 143 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0294
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0158
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 146 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 146 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0269
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0264
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 147 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 147 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0280
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0036
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 149 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 149 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0270
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0058
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 149 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 155 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 155 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0239
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0412
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 156 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 156 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0232
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0387
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 156 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 156 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 163 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 163 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0257
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0338
============================================================


============================================================
🔄 Round 166 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 166 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0274
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0209
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 166 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 169 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 169 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0282
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0192
============================================================


============================================================
🔄 Round 174 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 174 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0259
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0238
============================================================


============================================================
🔄 Round 177 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 177 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0230
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0436
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 178 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 178 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0298
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0069
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 178 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 178 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 178 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 183 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 183 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0280
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0213
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

============================================================
🔄 Round 185 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 185 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0273
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0224
============================================================


============================================================
🔄 Round 186 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 186 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0257
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0286
============================================================


============================================================
🔄 Round 187 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 187 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0269
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0247
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

📊 Round 187 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2479, R²: 0.0029

❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
