[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51b2fd6-5793-4e69-88c8-152681ae05b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a5fb5d-28f4-49a0-a552-e0f0d4983180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805c8eab-4d7b-4f9d-919c-a15bf0260db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc666d9-d533-4d41-8580-fe07b3b8a812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cddd5d8-ecc6-4e6c-9964-d9ec2d9afaab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40f07845-30d7-4d26-a9bd-576b53abafc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee92523-999d-46e7-acc7-e7997eb84229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb98e613-a5ed-4a9d-b23e-ed09946ae66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eba6ccd-da56-4184-912e-392b9bcc5482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63aee236-e503-4765-87a4-130fcb8043b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c0568e-01ac-4d34-ba94-7007133c12e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a30fc4-68fd-4629-9a2f-791356a7c4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a856b315-8c89-4614-8a75-6657eaaa6361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f1d1da-8531-4689-b30a-5258bbacc85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3c88a1-e066-4267-825e-0edc86bf2858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c67e82c-8b0c-4cfd-abc5-49bdd1f39db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c53b86-b3b7-4ccd-8399-104ac239881a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ec479a-d920-41d9-92d4-48dec92c242b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbfde7a-709d-4560-a4a2-37ee4d0515b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc93e685-6172-4d00-8ca5-2610a41b6917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8ee7a56-95e0-490f-8079-1783f9ce9c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0509860b-d9b8-4587-bf69-13834ad6666d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 429ad9ce-e30c-49ac-b8b2-015c9c2f2d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad407f29-7665-44da-8d02-04c151bdc97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ace5b5d1-4730-44cd-a79b-1f73208c99bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef689f21-5314-4701-bb07-86d6cf3ad36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a1a2b6-70c3-44ba-a70d-00f6a835cb4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efd0116a-670e-4ea1-aae0-d74f33cfe76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8118debc-1072-4e85-b9d8-48e08a40f998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39666949-0a4d-4d3e-ac91-baa8ebba068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f595047-123d-4b85-80d2-fe1df04c2935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9591b1a-732c-4a4b-89bf-c43f9b0351c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b36356a-36df-46bf-b2a2-8cd24b3c220a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6694a16-25e6-47d7-b513-56a2f2e60407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2085890-7398-4479-b982-061754432f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43a6e123-0e6a-444b-9235-e040bb93c410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078789d8-4da3-4e43-b287-2405ac6c60e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f02d7ef9-b12d-4f40-ae96-64e5d38ff5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 019a0b26-2e9e-47ac-92b9-c6cc807b458e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2e6563-5274-4926-802f-d07a183abb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf7c6822-5822-4ac9-b55a-dedf7afa704d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa522399-20b9-41e1-88c9-f6049a0b0980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a326bc3f-08ee-4a8a-a8ad-25cc076b71e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f942d896-dc94-4bf9-8194-dd68867c2914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ae6c0b-1acc-4d84-a787-93fd0cf621d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602068a0-17c3-4907-833f-0da16f3e5aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f297b5d-9f00-4643-89cb-a71a631435c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4237fa-5517-49ef-a43b-46864248b397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9d3cc0-48d3-4a47-ada2-3670d871175c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d59d2c6-e6f6-4ded-9c7f-4cc5755be542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c244fa18-5bed-4805-8574-b027232c6e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d89d93-bc4b-4f04-9e32-8b0c822f7ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d90d807-797f-4b0b-b9c1-2e1ee17d98dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f07729-1178-4b8a-88fc-fee4ae2ce4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd49b52-d6a7-4d0e-a981-927df8d9d099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f06484a-1854-410b-82ff-53f7daa13512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69557ba2-7820-4368-8974-fe867223a908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abaf617-b40d-4768-85fb-6af7857fcda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcefbd51-46ec-45e8-86eb-aacdbdf3a2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e03279-a679-43a5-9caa-77c21705d1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3088519-457b-430f-a77d-e3ca72464a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f3f77f-923e-47e0-a1a6-d5b97a0e8cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9d0297-d5dd-41bb-8ba1-9c0e330d3405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44baa5a9-56f6-46cd-93db-3bcb31c8ff2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14cea39-7574-432e-91cb-3eb4fdb6a9f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83df9982-a03f-4dfd-9992-28c2fccd6bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d50bff07-096c-4cfb-9533-b9c9360a0b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc2ce70c-c264-4671-a681-0752272d7196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3125e43-aef7-4348-a4c6-dc55fdd6604f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a53771-d576-4ebe-9253-cca832286b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8f8d14-1958-462e-80f9-d848e7a295ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d4d802-5afb-4bee-894d-7308f931a7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70fe4938-6bb4-4e7b-9a6f-a287d5a021ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5866252-ce99-4808-99af-1e1e67e68312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105b530a-0090-4264-a8ac-2ca4bae09d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8b80ba-60ed-4f6d-95cb-6e9edea51378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b220a0-0752-4d90-8444-ea90613ee59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d42ee70b-c734-4087-acec-395d75b0527f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a668ad3e-d000-4b9e-b436-8068c37638cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02993aa-de04-4713-963b-cf970ef54533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19f63e8-1b67-42ed-8fd4-9ae50024f532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb1e99d-931f-413b-9481-3890dccea3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7284b020-e559-47c1-bb4f-0987613f282d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c469b47-c728-4bff-9ef8-29f29c77be34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 997a8fa6-ecea-4a1a-9dd2-4e0ed6a2913b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91565bc-cf24-45df-9dd1-2769179143f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858802bc-bf11-4523-8bb3-b34a7c7300ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e163a738-9d74-4967-9247-91744d3c0438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e9ce36-b0e8-4789-aac7-88765a174e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88523fb-f915-4a27-8d2c-2d49ad844c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e209149c-d322-48d3-a14a-9b295abc7f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee4448f5-e1c8-4107-af1f-0256565c8c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f62ce1-4ecf-46dc-8650-62db9f706e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff4e32d-ad66-496c-a1a8-801baa5d47b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b504d6b-462a-4f4c-8e74-e2cc8e7b4952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ea36ea-9af2-429a-be35-f3e730f2b4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d594a3-f50e-4a21-ad2e-420d66946971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac5538d-e1eb-43f7-82e4-0a3de9d54c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d46416-2952-4b71-818a-997517bc94cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94bf1bc-c960-4e7d-abc8-37690925eeff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ed835e-1a3e-4f47-b73d-b4c088f3a689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b2ea94-aa07-4d46-9095-121f82ed298d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c80357-b30b-4ca7-bce1-91b01a29de14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cb78c7f-0ae9-4454-a74a-944e75ff3ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b4c2ad5-f19f-43cd-825b-a46feb5cff4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa03a09-ccb0-4f3a-9e1a-e4fee3e27912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e16f427-ca01-4c54-b07f-3b56a6819ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f4a6215-1e50-462d-941d-bf1cb6fd1d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a063f8d0-0390-4c3a-8491-9a580a62b941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b89b489-52d8-4dd5-b000-6ef1d5957438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2d1511b-2535-415b-a79b-d734755598ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8690761d-443e-4c8e-91e2-21b441eeb4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b73c66-b611-4069-a788-07eb6dc2a7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52dd9b55-eb0b-4860-88ae-8261160dab2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb8ca12-c9be-4eb0-babf-7063e85ef615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81dc9981-6385-4a90-b17a-dac07de8248e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1ba6d2-e73d-4a87-a2ab-d5922d0a14e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba00aef-5ba4-4750-b750-7d415f053f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c55b34e7-f2fe-4b00-b4ea-5bf54cf3a46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab36220-f86f-4e52-8936-8e5da0953cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02983f90-4745-49f4-9058-a8ab50704c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8815060-747e-411a-b7c1-f1d3a82b4be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf663bf-1848-443a-a4f0-1ad6fc39b5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57ed0e57-7196-4a0d-ada0-6dd8ed569d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2ebff3-c8ec-4b8d-b5f0-201a9d13dfcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf311218-be61-438d-ba77-d51230c8c1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed87c76-4d2a-441f-8b44-b73c5b8c5dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a318cb-c8a8-4f71-b95e-948ccc11d85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86dba2b6-3094-4751-9006-181816246428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71737637-1afa-4909-97ec-5f8c3439ca7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9261ba59-06f7-4d2b-8858-2be91b78b43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f309ef-6ddb-43bb-9a31-77533a9f1685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6205a8cb-c73c-4ea3-b527-a9a7d1602983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e56532f-478e-4e25-b7ba-653adec81e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42521982-7cf6-409c-a78a-949854ea1635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a407cf-d278-4c35-b69d-f33d8134d9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff17e29-806e-4f8b-bd74-d629c41e94fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc640d20-09d3-4951-9aba-6c8d25be2242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fcbfb26-4713-4412-8409-6bcabf9c6dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d491aa4-bd4c-4eee-87e2-6a8024e590f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67fca39b-0f86-436c-a9d9-d310cb021cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e70f0e0-27b7-4efe-83c9-0aaa62134e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52fe7d06-bc05-4560-b042-409394d156e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee36bb65-2a18-4fdd-b420-fb9742b37bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e1546c-8ab3-4491-bab8-5c8795c87f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb63c5c-20fc-4fe2-bc85-76bfbef137fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b86cf122-14c9-4ba8-8cb7-f8d46020e314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e46f89d-b2b0-45e7-9a65-aa2366d90514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4aa6ea3-ccb6-4888-a392-2c6b5c975a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea1660d-dcc7-4519-9331-746179ecfa77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d921550c-d706-4449-805b-8c6dcb2eb584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5215c9b1-6398-4480-9fe1-ceaa09ee586a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5df7c73-ccf2-4b70-bc0c-ffc9e6dc965b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 997a92d2-35a6-45e4-a61e-0d2bff39a38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9259f16-2bdd-40d9-9eb2-a34dae7e02be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfbba6fb-bd9e-420b-be8e-a94074a0fa17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f204e502-9045-4faf-ba9a-d687ce137e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5db58e3-8398-4783-83ee-4593969a569e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_52
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/test_labels.txt

📊 Raw data loaded:
   Train: X=(1116, 24), y=(1116,)
   Test:  X=(280, 24), y=(280,)

⚠️  Limiting training data: 1116 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  271 samples, 5 features
✅ Client client_52 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3281, val=0.1003 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1009, val=0.0875 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0911, val=0.0728 (↓), lr=0.001000
   • Epoch   4/100: train=0.0864, val=0.0736, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0865, val=0.0739, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0856, val=0.0736, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 1 Summary - Client client_52
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0016
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0023
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2420, R²: 0.0003

============================================================
🔄 Round 2 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0744 (↓), lr=0.000250
   • Epoch   2/100: train=0.0861, val=0.0743, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0861, val=0.0743, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0860, val=0.0742, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0860, val=0.0742, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0856, val=0.0740, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0853, val=0.0738, patience=7/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 2 Summary - Client client_52
   Epochs: 29/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0099
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0065
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2411, R²: 0.0064

============================================================
🔄 Round 3 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0897 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0820, val=0.0896, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0819, val=0.0896, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0819, val=0.0896, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0819, val=0.0896, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0818, val=0.0896, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 3 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0066
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0090
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2412, R²: 0.0092

============================================================
🔄 Round 5 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0865 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0822, val=0.0865, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0821, val=0.0865, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0821, val=0.0864, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0821, val=0.0864, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 5 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0181
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0058
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2400, R²: 0.0207

📊 Round 5 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2394, R²: 0.0253

📊 Round 5 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2393, R²: 0.0266

============================================================
🔄 Round 9 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0922 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0795, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 9 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0234
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0023
============================================================


============================================================
🔄 Round 10 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 10 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0323
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0285
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0756, RMSE: 0.2749, MAE: 0.2389, R²: 0.0311

============================================================
🔄 Round 11 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 11 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0355
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0043
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0755, RMSE: 0.2748, MAE: 0.2388, R²: 0.0323

============================================================
🔄 Round 12 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 12 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0253
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0394
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0755, RMSE: 0.2747, MAE: 0.2388, R²: 0.0327

============================================================
🔄 Round 13 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 13 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0318
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0149
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0755, RMSE: 0.2747, MAE: 0.2388, R²: 0.0326

📊 Round 13 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0340

============================================================
🔄 Round 17 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 17 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0297
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0236
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

📊 Round 17 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

📊 Round 17 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 24 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 24 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0367
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0030
============================================================


============================================================
🔄 Round 25 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 25 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0286
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0277
============================================================


============================================================
🔄 Round 27 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 27 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0323
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0020
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 29 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 29 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0364
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0009
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 30 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 30 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0297
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0305
============================================================


============================================================
🔄 Round 33 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 33 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0246
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0501
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

📊 Round 33 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 36 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 36 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0244
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0461
============================================================


============================================================
🔄 Round 38 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 38 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0307
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0170
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 42 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 42 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0348
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0091
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

📊 Round 42 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 44 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 44 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0283
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0346
============================================================


============================================================
🔄 Round 45 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 45 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0346
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0095
============================================================


============================================================
🔄 Round 49 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 49 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0228
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0213
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 50 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 50 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0265
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0316
============================================================


============================================================
🔄 Round 52 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 52 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0266
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0312
============================================================


============================================================
🔄 Round 53 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 53 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0266
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0447
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 55 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 55 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0319
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0216
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

📊 Round 55 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

📊 Round 55 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

📊 Round 55 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 63 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 63 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0293
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0310
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 66 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 66 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0227
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0529
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 68 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 68 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0259
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0340
============================================================


============================================================
🔄 Round 69 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 69 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0307
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0267
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 70 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 70 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0337
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0128
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 74 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 74 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0266
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0392
============================================================


============================================================
🔄 Round 76 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 76 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0266
   Val:   Loss=0.0686, RMSE=0.2620, R²=0.0413
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0341

============================================================
🔄 Round 77 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 77 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0335
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0134
============================================================


============================================================
🔄 Round 78 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 78 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0297
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0308
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 80 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 80 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0208
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0647
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 84 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 84 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0325
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0178
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

📊 Round 84 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 87 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 87 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0279
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0363
============================================================


============================================================
🔄 Round 88 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 88 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0356
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0060
============================================================


============================================================
🔄 Round 90 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 90 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0315
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0239
============================================================


============================================================
🔄 Round 94 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 94 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0285
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0321
============================================================


============================================================
🔄 Round 95 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 95 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0354
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0066
============================================================


============================================================
🔄 Round 97 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 97 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0264
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0408
============================================================


============================================================
🔄 Round 99 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 99 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0308
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0248
============================================================


============================================================
🔄 Round 101 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 101 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0268
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0422
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 102 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 102 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0335
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0083
============================================================


============================================================
🔄 Round 104 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 104 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0324
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0193
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 105 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 105 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0310
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0210
============================================================


============================================================
🔄 Round 108 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 108 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0265
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0445
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 113 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 113 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0255
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0499
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

📊 Round 113 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 116 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 116 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0314
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0248
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 118 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 118 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0303
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0270
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 119 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 119 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0300
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0288
============================================================


============================================================
🔄 Round 120 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 120 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0328
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0158
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 124 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 124 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0277
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0380
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 126 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 126 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0298
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0291
============================================================


============================================================
🔄 Round 127 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 127 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0342
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0136
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 128 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 128 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0230
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0432
============================================================


============================================================
🔄 Round 129 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 129 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0306
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0266
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 130 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 130 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0260
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0383
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 131 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 131 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0317
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0227
============================================================


============================================================
🔄 Round 132 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 132 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0336
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0113
============================================================


============================================================
🔄 Round 133 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 133 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0212
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0538
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

📊 Round 133 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 137 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 137 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0339
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0131
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 139 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 139 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0315
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0248
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 140 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 140 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0311
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0245
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

📊 Round 140 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 142 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 142 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0281
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0178
============================================================


============================================================
🔄 Round 143 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 143 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0343
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0121
============================================================


============================================================
🔄 Round 144 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 144 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0309
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0266
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 151 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 151 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0295
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0273
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 152 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 152 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0297
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0256
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

============================================================
🔄 Round 153 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 153 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0272
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0431
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 154 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 154 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0300
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0298
============================================================


============================================================
🔄 Round 156 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 156 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0322
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0079
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0342

📊 Round 156 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 160 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 160 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0286
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0039
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 161 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 161 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0290
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0340
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

📊 Round 161 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

📊 Round 161 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 165 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 165 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0329
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0197
============================================================


============================================================
🔄 Round 166 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 166 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0322
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0195
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 172 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 172 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0271
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0391
============================================================


============================================================
🔄 Round 174 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 174 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0342
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0150
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 177 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 177 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0294
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0319
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 180 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 180 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0302
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0299
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 181 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 181 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0340
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0142
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

📊 Round 181 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

📊 Round 181 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

============================================================
🔄 Round 185 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 185 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0336
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0165
============================================================


============================================================
🔄 Round 186 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 186 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0296
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0327
============================================================


============================================================
🔄 Round 187 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 187 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0253
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0385
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2386, R²: 0.0343

❌ Client client_52 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
