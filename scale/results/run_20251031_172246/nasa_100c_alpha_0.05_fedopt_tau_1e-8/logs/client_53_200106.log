[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc62c1f-affe-42d6-a58e-411bcd3f20b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c5b6bc-2e50-4ab6-a06b-c00a919dfa58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8c773a-f648-4bf9-b30c-0f76299c2ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1975051b-561b-4ccd-82c3-f3705e58437f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65105529-3a45-4d9b-9d58-4f1ff3d6fd9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5014b520-3c64-47c7-b58c-8847bc89adf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a659586f-47e3-404b-8f04-f4acbd9b647d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e867479-74da-4878-be7e-915b3ca0bc6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 596053c0-ea46-456b-a1f7-45350ba795bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b9f1dd-cc60-4256-9655-6bdf2d485b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a4a8dc-26d8-4ebd-8556-a5ad423a9e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95458f9e-0bbd-411a-93d8-773708d19cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598f832e-3c14-47e5-bd01-b041be75bbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff92d385-d5d5-4648-b87b-9b9481c6727e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c87c480-a207-42ec-940d-5cb93f674b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f23744-6009-4446-9202-6ab617402ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db6ab026-e3bc-429f-a237-4f7481f86f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145ce249-67b4-451d-b9da-c7340a14af13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31e7511-094b-4e39-91e1-b6e4d05432f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad8a092f-4f2a-48b0-9d07-e9d8bff5fbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39998f3-e562-418b-a1f9-1aeb3e27bf6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa9f0c1a-4540-4730-991c-041f4e8f8c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 548f2013-2d33-40f8-8b32-ee46d325021b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1d2f97-07d4-4de6-b3f6-3c3a016efd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b55d8f-5389-41e9-9302-b523780fdf42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed3aa2ff-9f28-41d2-ba5f-c338901a1ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 004bebdb-561b-4615-b8a4-47acaebd1239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127c4a18-3718-4e5c-bf10-89e55653581d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c98120-cd09-4b7a-bfff-5e6ca04cdece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6441e7bb-1818-42ad-931c-e5b607890dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5eb237f-96d6-4ee1-bd00-ec85d65abc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68deb813-6987-4b18-88c6-9b8183ff3aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 515939ed-a24b-40d5-8288-d15834d2ae23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81daf31-0b58-440c-b272-9859e7801f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a1c4b67-0471-43b9-ae83-babb434cb2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0dd7df-6170-4437-aa0e-4343d1a2ace7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd710c48-c300-4f3f-b632-d280916cd19d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8913244-f249-4cee-b96b-0ed3884aa845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4bbd460-6910-435c-b9e5-343959e5c99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c3bc81-9740-4e5f-a005-582c58b58667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6759a7fa-7f2b-47a2-9d69-5233418480e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cdd71b4-5fe2-46f9-9452-e5fcf7d243a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ddc69ac-fc34-4477-ade8-2172b124e407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6423fd-44e8-4f8d-9bff-02d41d468cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da57de9-f9a4-4f4c-ba79-55aff6464b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 447b0ff7-1c81-4bee-84ba-f70a56e09023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ccc587-0513-40b7-8a5a-898d5582448f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ffd1a6-fe00-4e30-ae8d-194db3397982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ddaea6-1ddb-4122-b318-1ab318813644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3555bbbc-2a46-483d-808e-c7d9de90398a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6f469b-4bd8-4e1c-abf5-e74685c926a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5b9e26-4fab-4a78-ad20-ccaf302dfa3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d142a80-b398-4884-90ce-920bc2a3f703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e60a29-68b7-496d-aa54-facd8a69bbe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc8a859-0d72-411b-887b-6fb243e5f67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4306243e-b18b-4d1c-a663-25edeb0cd3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4daa1bb9-6b10-4131-a629-c49ea695e87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba5367a0-8685-47c9-aa92-535898da6f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9136bd8-1b5b-4741-8fff-a038e47ed181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc73108-0621-4047-95b3-7d665b097144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498a8ec5-c42b-4414-b115-a52733c75af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afca6197-c16f-4267-bf4c-1741bb0c366c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 892f5a60-217c-4062-870a-bbc6e1794fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8b0022-4ec0-4216-bbc5-ef52fe66da05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a48554-9003-4e50-a5d6-3fe6373d6f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c72958e-0632-491a-b1c5-96f5f72ad0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 640a3048-6342-4a76-a282-c92cc60d6d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185b17b3-f29d-46f8-88ca-40f06f8f3adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7917154-1220-40ab-bd1f-04671e0dde95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f23ff97-6e09-4dc5-b0f8-2ff86bf19b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26da89c-293c-48c1-a8ec-f706d0ad09d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d333f861-f453-4fdb-a233-f8438903cf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b532072-f0fe-4443-9f92-6f4d57b5fbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c98ca3-8d3e-4636-b485-ab2eedaf99cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ac9b11-6a57-45dc-90d1-312d4d8e7a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2667abe1-5be9-4bcb-b358-e21cce570544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ba6e0f-3cb0-4ce8-afea-439589b1cc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8886095-d5e1-4e54-89b9-295b0c365ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d774e06c-2fb1-48b1-b7f1-a93a36549c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2c655d-54dd-4eff-b00a-3ed4ffae443e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41813668-a5d9-4807-9e87-5b632a6fdf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e972df6-ee9c-4920-8169-89d096b0a13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcbdad75-e9a6-4824-9628-c44c155e0afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15174c5-8c2a-4532-8acf-3ec5fc4c5963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26270f52-5270-4d3e-800f-a7a6e9c759c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e559ca27-7092-462e-a963-302b682335aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56147543-301a-41f4-876b-27ed078fe8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db47fd01-4689-40f6-8a55-c6a1f19e153b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ca8447-0418-4053-8d95-128cfb6fbf5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e731bca-d71c-4a54-9217-e2d7c248c9cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dcbc04b-78e9-476c-bb24-bf560c7d30d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b39b08-b725-464f-a663-e11095ce13fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 582e8667-ac25-4600-9123-f9a5ff565dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4550a9d2-9cdd-4ba7-812a-b37189e30697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f1c7e22-b2f3-4d1b-803f-a74b37b98d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a9f950-44d1-4625-b435-2c322453e0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a19334c-54ca-4a16-a137-69ec24b55b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf600293-1921-465a-b812-7d6508dbf636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca4128d-39c3-440d-8ad7-9bc0d1f5dc2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee6587f-ca12-48e3-98de-e2919862a4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b04d40-d886-4eb5-83d8-aa48e49a574b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c22f66-a2b8-4299-8256-2f8b1355c817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf0ea60-ac85-4877-a39b-c5365b54c767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 660ab2af-40d0-4422-ba52-26ceb6d24c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39242e8e-c9a3-462d-98ad-26130fb41e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d80260f-ecea-42a0-a6c5-ad85f5abfb73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919fdaa2-fbd3-4d78-bb31-7454e7a95818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35805a5-5ea3-44b5-9e89-c7f1cf2bcbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d7ea87c-e2f0-469f-81db-4e97ec9ec44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ea58ce-f2e3-4591-9b23-872c6997de02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15642a7f-32b1-4bf1-98ef-f4cb1f3eca6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843acde6-305c-4571-8ecd-c5444c7eaf68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f026db-5b3b-4329-93ab-ec3ff237de58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d773abe0-2409-4a61-9ee2-d54448148030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f75d863-4b0c-4275-bcb5-680e63b856cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a765871-8ef5-4eb6-9ddc-dab222a933c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 848282e0-8bb4-46b5-af61-8ef4c7fd520a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56313cd9-bdf7-4cd8-bb69-09e188637170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd36b35d-bfc9-4ac7-9fba-3ffd0723cd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab80721-61e8-415a-8296-71182c144a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1a41ce-bf06-4c0d-a74c-d6d1393fcc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da964df9-e64d-4492-8547-22e2d7e01b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3c2cfa-1972-465b-94a8-8461bc8b17c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d358b6-a9f4-4d21-9bcc-c48ca4c7a1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196e86b4-d852-4820-8af1-d16533986eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f55547-c585-46c5-a1a2-e1bcfad58057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38fbd8e-341f-43cc-9cbe-050e9c544e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e82d7d05-c95f-494e-a940-7b7cea20cee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618df7ba-64bc-429b-a1da-edc0325447f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4dce54b-dd43-4baa-9220-47633f94ca3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 097cb933-8327-4db2-ad4a-aa08f2b1adc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6032a8f-7ced-4a8f-9920-bb7cbffdfd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dff38eb-8677-4c77-8f62-1b938c637791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b00266-e6af-438e-acc7-62a0b664903d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c79fb3-e7aa-4b19-8b5e-10bad76341b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e693c8df-2dd8-47ed-a4be-2027e163be52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35db2ff8-5768-43fc-8fbd-a9d12615477b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3a9e0d-7150-47cb-bb1e-ba7c00db7c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3ea55e-77f5-4409-9c56-e77c89d8555f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d13e2d-334f-47b9-bf2a-23a14b1f7b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04017ff3-6eee-4e0c-a343-701033ad61c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34fde315-161d-4f67-a837-a9d6a4d7b05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301b0581-ac09-4ca3-8b05-397e94fc8b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 183c4e5d-e6c2-40f4-9ec5-6572850fea4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2ec112-e906-4c67-b4d1-7b0eb23298c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2cb7a00-eeca-4169-b9ee-eba4d39ec166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd47633-e373-4a68-8405-44dc0ea5b4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4753d9f-fa34-45c3-ab20-50e2f29fb92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd7af97-1d21-48b2-98a4-d8d2eac69dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc85e098-8977-4f21-8e60-38a2adca25e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a80e65f-1421-4167-b72c-fceaeada3703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7bf266-4b22-41f4-8dec-78297e738f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4950c866-c40f-423a-94e2-6c3345732177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b2f38e-469f-411d-b053-67985ce747f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5d31c6-b55e-4a66-8ee8-d51ed8275bd8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_53
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_labels.txt

📊 Raw data loaded:
   Train: X=(1126, 24), y=(1126,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1126 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_53 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0929 (↓), lr=0.001000
   • Epoch   2/100: train=0.0823, val=0.0938, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0819, val=0.0956, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0808, val=0.0955, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0806, val=0.0953, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0788, val=0.0979, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 2 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0363
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0044
============================================================


============================================================
🔄 Round 3 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000250
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0856, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0829, val=0.0857, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0825, val=0.0859, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 3 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0033
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0024
============================================================


============================================================
🔄 Round 4 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0781 (↓), lr=0.000063
   • Epoch   2/100: train=0.0849, val=0.0782, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0849, val=0.0782, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0849, val=0.0782, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0849, val=0.0782, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0847, val=0.0781, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 4 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0043
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0057
============================================================


============================================================
🔄 Round 5 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0808 (↓), lr=0.000016
   • Epoch   2/100: train=0.0847, val=0.0809, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0847, val=0.0809, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0847, val=0.0809, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0846, val=0.0809, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0846, val=0.0809, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 5 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0062
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0124
============================================================


============================================================
🔄 Round 6 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0787 (↓), lr=0.000004
   • Epoch   2/100: train=0.0853, val=0.0786, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0853, val=0.0786, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0853, val=0.0786, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0853, val=0.0786, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0852, val=0.0786, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 6 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0075
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0069
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2541, R²: -0.0115

📊 Round 6 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2547, R²: -0.0159

📊 Round 6 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2552, R²: -0.0211

============================================================
🔄 Round 11 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 11 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0144
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0211
============================================================


============================================================
🔄 Round 12 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 12 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0180
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0094
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2556, R²: -0.0238

============================================================
🔄 Round 14 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 14 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0152
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0289
============================================================


============================================================
🔄 Round 15 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 15 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0125
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0386
============================================================


============================================================
🔄 Round 17 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 17 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0161
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0312
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0251

📊 Round 17 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 22 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 22 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0162
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0376
============================================================


============================================================
🔄 Round 23 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 23 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0159
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0247
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0254

============================================================
🔄 Round 25 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 25 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0201
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0088
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0254

📊 Round 25 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 25 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 34 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 34 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0157
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0279
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2557, R²: -0.0254

============================================================
🔄 Round 36 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 36 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0130
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0365
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2557, R²: -0.0254

📊 Round 36 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2557, R²: -0.0254

============================================================
🔄 Round 40 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 40 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0198
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0069
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 40 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 40 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 45 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 45 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0158
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0238
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 46 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 46 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0186
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0211
============================================================


============================================================
🔄 Round 48 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 48 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0191
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0108
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 53 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 53 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0208
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0043
============================================================


============================================================
🔄 Round 56 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 56 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0250
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0024
============================================================


============================================================
🔄 Round 57 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 57 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0236
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0052
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 57 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 62 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 62 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0151
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0268
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 63 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 63 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0200
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0128
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 65 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 65 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0164
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0240
============================================================


============================================================
🔄 Round 71 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 71 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0187
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0173
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 72 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 72 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0216
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0442
============================================================


============================================================
🔄 Round 73 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 73 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0237
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0081
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 75 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 75 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0263
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0045
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 78 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 78 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0258
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0134
============================================================


============================================================
🔄 Round 80 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 80 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0218
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0049
============================================================


============================================================
🔄 Round 81 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 81 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0190
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0217
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 81 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 83 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 83 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0185
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0176
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 84 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 84 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0231
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0037
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 87 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 87 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0137
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0399
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 89 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 89 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0182
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0153
============================================================


============================================================
🔄 Round 90 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 90 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0194
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0103
============================================================


============================================================
🔄 Round 91 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 91 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0161
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0224
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 91 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 97 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 97 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0220
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0135
============================================================


============================================================
🔄 Round 98 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 98 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0164
   Val:   Loss=0.0781, RMSE=0.2796, R²=-0.0309
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 98 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 104 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 104 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0138
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0313
============================================================


============================================================
🔄 Round 106 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 106 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0193
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0257
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 107 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 107 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0153
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0258
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 107 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 113 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 113 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0202
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0090
============================================================


============================================================
🔄 Round 114 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 114 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0158
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0309
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 115 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 115 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0145
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0333
============================================================


============================================================
🔄 Round 116 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 116 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0113
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0411
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 116 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 116 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 121 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 121 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0188
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0351
============================================================


============================================================
🔄 Round 122 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 122 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0181
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0252
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 123 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 123 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0211
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0227
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 125 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 125 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0160
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0228
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2558, R²: -0.0257

============================================================
🔄 Round 128 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 128 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0202
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0071
============================================================


============================================================
🔄 Round 129 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 129 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0168
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0199
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2558, R²: -0.0257

📊 Round 129 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2558, R²: -0.0257

📊 Round 129 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 129 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 129 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 137 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 137 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0185
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0191
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 139 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 139 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0180
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0228
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 140 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 140 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0164
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0223
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 141 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 141 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0167
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0241
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 141 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 144 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 144 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0200
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0121
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 146 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 146 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0138
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0610
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 149 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 149 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0133
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0434
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 151 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 151 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0181
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0299
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 152 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 152 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0144
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0357
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 153 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 153 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0185
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0134
============================================================


============================================================
🔄 Round 154 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 154 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0119
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0461
============================================================


============================================================
🔄 Round 155 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 155 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0199
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0103
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 159 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 159 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0204
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0140
============================================================


============================================================
🔄 Round 160 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 160 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0231
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0253
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 162 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 162 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0188
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0126
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 164 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 164 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0193
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0228
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 166 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 166 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0248
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0063
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 167 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 167 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0223
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0036
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 167 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 170 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 170 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0167
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0212
============================================================


============================================================
🔄 Round 173 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 173 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0224
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0039
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 173 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

📊 Round 173 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 176 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 176 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0149
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0308
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 178 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 178 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0194
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0082
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2558, R²: -0.0256

============================================================
🔄 Round 180 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 180 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0177
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0163
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 183 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 183 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0223
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0002
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 183 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 183 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

📊 Round 183 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2558, R²: -0.0255

============================================================
🔄 Round 188 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 188 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0170
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0193
============================================================


============================================================
🔄 Round 190 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 190 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0224
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0276
============================================================


❌ Client client_53 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
