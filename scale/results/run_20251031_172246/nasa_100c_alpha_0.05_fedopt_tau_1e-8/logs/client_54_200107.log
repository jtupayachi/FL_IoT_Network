[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 610515c2-2dad-45a3-a2b1-551c2a495797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 846bd8c6-83de-423b-b140-f7909453b54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdef37ed-1a22-4d8c-b0a0-5efaa23c7390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee119d73-d9f0-4744-b686-832bc3064fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e416eb2-5deb-4bbd-b80d-057b9defd563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec72270e-fcdd-4002-bfa7-9d0c61630a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388cd436-6e63-4c7c-bec0-1aaa273de746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca996cb1-dfd1-4921-9382-186fe806f3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7f664ee-ab9b-4b56-b6f7-22864f3a6139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 449a859b-3f1d-49ca-8227-1182ac5c5ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce85ada-6929-4e8e-9de3-f53011e5329b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02802b8a-8997-4c9a-8d5e-0932838a6ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd678d3-94ca-4d3a-ad7f-05dcec418101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0cd8212-d66e-4d7f-8ae6-b289b90143bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8f71a8b-f0fa-48e1-96c7-a732ab44ecd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47e83c6-4635-4421-b97f-53f868e2ba43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da2a306-5a2c-477b-afc8-ada44bb61a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb416cf0-a0ad-422e-85d2-5165ad854cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790753f2-7a33-449c-ab25-7e2680d3b59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00ac9fd-8447-4a67-a198-77264b7542d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be3d233-9107-4b06-925b-61e5383a8c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0627de7b-5bfa-4865-931c-d1e95cca8fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19cef96f-df2b-4af0-bbb9-c84aadeb7b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97881525-8132-438d-9e5a-0aefd07c681e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0f45d2-f694-4f21-a088-04606f3eb826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78791dee-e075-42bb-aaaf-386020b6d861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb684b0f-ea47-4278-b6ec-391df2542fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48507ae4-004a-4266-91be-e8bc4710c6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f05468-e992-42a8-8263-cfb8ec498866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f83022-735d-42ca-a02a-d56523cc1a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a4601b-d89f-4fc0-9cd0-cb281c0f97be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbaa55d3-5856-4cb2-a7bc-2b554e39561a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cd9142-b592-4f6e-8275-525de660f195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24cc5b60-7d21-40a0-b0bb-692bd6f5cd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8efc7f-53d1-4699-9042-77113b001a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ae2eaf-b04c-4480-b0b3-c31b52568ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adbdaea1-cdb9-4489-b592-42573958691c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d8ab20-df5c-4e49-a512-8c14ca093c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ddb56d-5339-44ca-9d2f-dce895671772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d662c6a1-f97b-4a87-aaeb-99a628a8c34d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5976806-abdf-4bbe-968b-2b8dceeb00fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a757c4-da7d-469f-8de8-63e3e8d0f99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34b05ecc-8d94-4c9a-a253-3b4f65eb499d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8119cd-bee3-4964-8348-e6bf98819d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc38a40-6811-4dd5-9175-672e6b885040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a150494-2b63-4fdf-b9ff-63ae6a153a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df36747-8a1e-4293-b408-db8d5f3187e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf2cc54-66dc-4a44-864f-4ffa6d12fcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39e0019-2bdb-4112-acaf-9b624c09d3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e00fcd0-95ee-4d9a-955d-00ad6f60a96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d57dde-9a18-40ac-84d8-5e18d4edbdcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c9756fc-0e02-4a34-a537-86118b280879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fceb510c-7a4b-4cb3-a89a-53b48c25dde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35e2735-4f6d-4b75-9650-24900d2c2a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d93428-b1e2-4276-acf8-5099bca934b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c54c0d68-ff65-4ea0-95c8-a3dfc76eed73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489c52f8-1480-4af4-8582-8facf83b3a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e450e6-04c1-4a8d-b80f-2db60a3f3751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b4b7510-0b8a-4589-9194-edcd019271c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dd91406-d80e-4142-ab27-7f5aa813ff6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eaba9a3-b3da-4281-a1ab-db115c261ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 252eed7a-dcb5-4970-94dd-91b5a3171f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eaf32b5-d087-4f98-80f9-79b40e13d9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f42e4978-09c1-413c-8187-4216885afd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56708f58-b770-4c0b-8a79-a07974c6c08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ced565-2daa-4daf-a784-8af8c96973e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f42a7876-a10d-4f8e-86c8-8e866af15d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52d2e64-b2e1-4895-80a0-6b56a7984466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be83218-1417-4bf7-89e0-2292d2c50986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d89fb0d0-4c2c-43f4-9ee3-e9f3a6d1df39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b7bbd8-bb75-40f9-adbf-fbd75cffcd24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66131274-7de8-4c40-982a-0d26ceb02a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27c39997-cd51-4221-a985-a754966049c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67e78778-63f8-4b9c-bb1d-492cab53728b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd62b07-f930-4823-aaa5-8945ec53930a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9be4c112-7dd4-466c-bf46-3ddf8ef6b809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea527060-c716-4182-bc52-fef2b7e54f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c50dda-2573-42d4-86b4-0a69004e201a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c685180e-3540-4abe-994a-bba27e0a60fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bb6e946-b451-42db-844b-12b5f2d016d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a2d539d-dc96-4fd8-966e-e2bc32ee37d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b66284-1cfe-484b-9d12-3d02f752406c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24dbbce2-3c34-47d9-b35c-c74005ad021e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56955c0c-a2bb-463a-ab8f-880635ebddd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d79f625-152b-4682-b52a-bd638015a48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 846b13c5-5bf1-42d9-b38e-f836f0f4a823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a531743-d00d-4b1c-a1ab-5e13da417a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c893be7a-6280-49a9-a5db-20ac5a3743e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc9228d-fec5-4af5-8f2d-0cc04da5a235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c825cdc-4a14-41f3-b2e3-730cca922037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5952c8b0-e3ea-49cd-a647-42746f31a1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94bec75-3ce4-492b-af5a-0279ccca8109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 445e07ff-9340-4f20-bb3e-4bcf52c08652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37110171-f501-4f5a-99aa-3ca62538a405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246f09ae-6354-4a9d-931c-a2494d23cedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f420794-97b4-420c-b9e6-ee1541f8313b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b36a5a-7426-4f1e-b5ec-2f8ad89b79e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe0a1028-e70e-4f3a-b016-94ce4fd4b921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f9381d-a478-482d-b80e-d4e06e37ce86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56d4734-3650-4035-8e59-dab225fa18b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a83925d1-140c-46ef-a8d3-b335c233cad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38eaea56-7e9b-4423-876c-bd95e4685a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ba3bde-2534-4f1d-a10a-05e5465bc2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de7afe2-4cdc-4553-821b-5e2540f354bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4260af6b-2346-47c1-a485-044ad580c74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8113a6-9ada-4adc-9d34-c0414158ad35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38e1d2bf-9a13-4298-ac5c-e1b357abd41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6fd9e5f-2e53-4fc9-8cbc-6a32af0e93eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491a51e4-31f0-4218-ae80-17dc8de4197e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36426d70-f8ab-4044-a6bb-65c863ec44db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be84072-3452-427d-9722-5ae8f5dc3e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 221a12e0-b383-4853-89b8-e9969c696246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64065c4a-41e3-4295-8271-eefbc8317f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b7c3ae-daa2-4bc2-816b-438c48857895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6995e3e1-6fe5-412e-a333-01d3121acb82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6ec93d-95c8-4f5e-b877-e29c71017977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ae90ff-a9c4-4717-9872-d23a83b00a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38352471-e949-49d7-a775-f41e3bc62386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 647b23db-b93c-4ec4-ae6c-43b5c9a6aaf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b29185-6351-4371-86d9-a470cd5e17f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d5052b1-6529-4161-8462-5a7ec16d1629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a728a6-946c-4153-9a34-7661a130e55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987540db-3082-454a-be8b-e59dcbc3757d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14365591-4c88-4965-83a5-3373a6abebfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87cffb01-d440-402c-8c25-d7bbd3c8c9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e45f029-fe4b-477d-9834-957a7f769046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7effbc0a-12b0-44d5-8924-6d002e7a4fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aeb58dd-0ef1-42b5-8fe3-f58f9eacc969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6e2a82-de3a-493c-9af0-eea30805e16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f73dab6a-6010-49be-8645-4be616cd9fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff1ad50-7470-40ab-b212-c9c229834c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9897d7-4fac-448e-8670-6548ac03f495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b1f04dc-01e0-49c8-8213-5c5219d4afa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23462b17-572d-411c-9332-f34c57bf0daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc81043-0820-4c59-9462-a420a145b866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4731d715-76f6-40a0-a948-a0c310cda673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 494ca844-d99b-43e1-b593-e5ddc6940e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc3b2dcb-cf3a-42d4-b724-00740cc9249f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71857a78-5e26-4be5-a289-00f7bc4988b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c485d8f-fd91-47d7-9675-b995604c5e18
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_54
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_labels.txt

📊 Raw data loaded:
   Train: X=(3010, 24), y=(3010,)
   Test:  X=(753, 24), y=(753,)

⚠️  Limiting training data: 3010 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  744 samples, 5 features
✅ Client client_54 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2595, R²: 0.0028

============================================================
🔄 Round 3 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0870 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0866, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0816, val=0.0868, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0815, val=0.0868, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0813, val=0.0868, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0790, val=0.0868, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 3 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0041
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0002
============================================================


============================================================
🔄 Round 5 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0745 (↓), lr=0.000250
   • Epoch   2/100: train=0.0840, val=0.0742, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0837, val=0.0745, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0835, val=0.0746, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0833, val=0.0747, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0824, val=0.0747, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 5 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0120
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0138
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2583, R²: 0.0100

============================================================
🔄 Round 8 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0890 (↓), lr=0.000063
   • Epoch   2/100: train=0.0796, val=0.0889, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0794, val=0.0889, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0793, val=0.0889, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0792, val=0.0888, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0788, val=0.0885, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0786, val=0.0884, patience=5/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0785, val=0.0883, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 8 Summary - Client client_54
   Epochs: 31/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0334
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0064
============================================================


============================================================
🔄 Round 9 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0817, val=0.0802 (↓), lr=0.000004
   • Epoch   2/100: train=0.0816, val=0.0802, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0816, val=0.0802, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 9 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0186
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0275
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0122

📊 Round 9 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0124

============================================================
🔄 Round 12 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 12 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0295
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0057
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2578, R²: 0.0127

📊 Round 12 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2578, R²: 0.0127

============================================================
🔄 Round 17 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 17 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0281
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0108
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2578, R²: 0.0127

============================================================
🔄 Round 18 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 18 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0273
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0047
============================================================


============================================================
🔄 Round 19 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 19 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0219
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0423
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 20 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 20 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0292
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0028
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 21 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 21 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0262
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0246
============================================================


============================================================
🔄 Round 22 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 22 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0200
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0463
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 26 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 26 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0251
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0261
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 29 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 29 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0327
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0181
============================================================


============================================================
🔄 Round 30 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 30 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0238
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0349
============================================================


============================================================
🔄 Round 31 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 31 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0252
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0172
============================================================


============================================================
🔄 Round 32 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 32 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0289
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0128
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 34 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 34 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0207
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0499
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 35 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 35 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0306
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0035
============================================================


============================================================
🔄 Round 36 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 36 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0257
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0192
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 38 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 38 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0237
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0334
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 38 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 43 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 43 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0267
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0131
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 43 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 48 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 48 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0289
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0139
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 50 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 50 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0312
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0041
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 51 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 51 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0232
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0328
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 51 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 51 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 57 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 57 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0239
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0329
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 57 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 63 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 63 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0187
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0527
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 63 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 67 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 67 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0271
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0203
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 67 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 70 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 70 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0266
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0231
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 71 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 71 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0216
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0404
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 74 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 74 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0257
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0191
============================================================


============================================================
🔄 Round 75 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 75 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0266
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0194
============================================================


============================================================
🔄 Round 77 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 77 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0262
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0254
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 80 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 80 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0200
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0409
============================================================


============================================================
🔄 Round 82 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 82 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0257
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0254
============================================================


============================================================
🔄 Round 86 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 86 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0249
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0312
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 88 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 88 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0243
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0261
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 93 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 93 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0227
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0385
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 93 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 97 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 97 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0271
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0090
============================================================


============================================================
🔄 Round 99 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 99 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0281
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0152
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 100 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 100 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0277
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0176
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 102 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 102 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0259
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0254
============================================================


============================================================
🔄 Round 105 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 105 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0256
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0265
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 108 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 108 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0261
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0203
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 110 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 110 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0262
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0194
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 113 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 113 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0233
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0326
============================================================


============================================================
🔄 Round 114 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 114 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0244
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0334
============================================================


============================================================
🔄 Round 116 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 116 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0217
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0337
============================================================


============================================================
🔄 Round 118 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 118 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0245
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0319
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 119 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 119 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0241
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0299
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 119 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 122 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 122 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0272
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0202
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 122 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 122 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 122 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 128 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 128 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0200
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0405
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 128 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 128 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

📊 Round 128 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0127

============================================================
🔄 Round 139 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 139 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0246
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0309
============================================================


============================================================
🔄 Round 140 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 140 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0287
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0173
============================================================


============================================================
🔄 Round 142 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 142 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0252
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0290
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0128

📊 Round 142 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 144 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 144 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0256
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0196
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 150 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 150 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0277
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0164
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 150 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 154 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 154 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0295
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0129
============================================================


============================================================
🔄 Round 156 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 156 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0249
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0307
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 157 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 157 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0257
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0253
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 158 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 158 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0258
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0264
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 159 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 159 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0268
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0233
============================================================


============================================================
🔄 Round 160 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 160 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0274
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0085
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 160 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 160 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 165 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 165 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0247
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0217
============================================================


============================================================
🔄 Round 166 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 166 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0287
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0114
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 167 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 167 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0288
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0061
============================================================


============================================================
🔄 Round 169 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 169 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0233
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0135
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 175 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 175 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0269
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0137
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 175 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 175 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

============================================================
🔄 Round 181 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 181 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0278
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0199
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 181 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 181 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

📊 Round 181 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2579, R²: 0.0128

❌ Client client_54 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
