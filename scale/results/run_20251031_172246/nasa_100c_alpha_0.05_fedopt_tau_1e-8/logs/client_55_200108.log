[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4496e942-f9ee-477e-838e-86c8f514acce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7faa1d2-8596-482c-b96d-e5370becf66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4230c83-2413-4eb6-8103-1fc29b85c99d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94602c46-cae8-4770-9229-440c19d5925d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1b6b6e-4c80-4512-93ca-c183c5c095fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02b3553-34e2-4809-8304-5937e09a7b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901a0b66-a918-40f6-8a7b-be870a7c9ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3671b40a-ff39-4431-9c10-db0f5aa892c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1809ba-3e5a-41a0-828d-e80d18128516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf0f51e-37c5-4044-b26c-1232b3df24df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e413b6-d6f4-495d-8b92-324a47efbbae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61905d4-7645-4342-a5c4-98872aac057f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b89b20fd-bf1c-409c-8b33-1be7d04d10f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14161e3-6552-4749-a134-2593db30313a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 406ecdee-9ab9-4948-a2bb-b4f7e888928e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3728ab47-a589-46e1-bd60-6afe435534db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3bda560-1eb9-4997-9881-424e761182f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc5f930-de28-4fff-82b0-73ec4b9f55d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 298da478-4b8c-4efa-b9c2-f79b27e8186f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7755b528-06aa-45ec-84b7-e44353a8d0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a0d6a1-7780-45f7-80cc-773c46f8bb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d887f6-3857-46a4-9864-305250b55f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d75c14db-1cc5-439f-b5c1-0fbc2002efdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a813dd57-582a-4b2e-8d50-3e8529ae7faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeed5394-dbb9-4052-aa33-a5ccf385584e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e3c3fb-d79b-4a7d-8c64-c512c1beb13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28e7c33-02db-4959-8643-b5646ab3f542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e375858-0fab-46e4-8eef-dece63c63f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942cd0d8-2fae-4440-8c20-4c42f3639225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84233705-32e7-4626-a83d-aa65da7cd045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50fb58d-3c89-4ce4-bc4c-883b6dd67e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1063b8c7-39f5-4a46-bcfa-1385c741ca54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b2f81b-5ec1-441a-a97e-7411186c9c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89cdea09-b317-45ae-817b-ee74093bd21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bb2e48-7fb0-4ea1-b260-7b898718015d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47591b0b-5ff7-4667-8675-3a23f37a6005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef44ab8-ef52-4220-835f-1d84119e3b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21da9cf-df35-4666-bd1f-55b64e76f7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6069d93-b0d3-463e-abe1-65109212cee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec2ad53-831f-43dd-98b4-3475c4163d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab01d63f-b7ea-4d71-a2aa-baf231b352b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01bc29e9-6b13-4887-b193-a7d8035846c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5caad836-068d-4bed-a8b0-4a90deb642b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace46f28-c43d-4d8a-96cf-a1bcd68eec88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 923869b1-656f-44cb-ac9c-bcc5949b4f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2bfb123-854b-4e6f-bd49-f2be7e497d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77467d52-7dbb-47e9-8546-cb70a5ac1f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f73e235-a700-492c-9440-fb19d209a85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dea0103-a5bc-4366-8f68-6578e7db9ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f459ea-c61b-4898-a396-a6cff64357b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a7c407d-0bd4-48d2-8611-9d3e348ebfdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791c0a20-c5fa-4139-8751-a65d81bedd20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea37098a-2613-45f4-8b4e-9aa6e368d08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a82f478-32d4-4d4b-b1d1-d7a3c53418b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1152ea9-dc1e-4936-8a75-8d90066cae11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58519f6-9b27-42bd-8c7c-f133752f6a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82eb44b9-14aa-40a8-8d61-8ac6236b2d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f42996-4a4c-4ac2-bf4d-24ad326eade5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857b10cb-52ce-423c-910a-5bcb6f5bd3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a953209b-c5b9-40f4-a6eb-d654f706381b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad996da8-6bdf-4b18-ab9a-7e958fc406ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d779b7-a170-491a-b857-c88b6ab4c847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3fa506f-c58b-4c54-9a6f-a7de1f3eb5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c27d62c7-2b53-4064-ab01-f3f1cf842f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68695f04-de7a-4988-ad43-1d0f78b8b254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c0cc1b-3e3d-41c6-b053-1246ccaad5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf4b80a8-5103-4a27-ac32-ad8a236b5873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d723fba4-5246-42d6-bc4f-aaa834a47cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4d939e-f592-45c0-92e7-fa1aa5215906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f433370-c6e0-46dc-a78a-c948263e6c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34df5713-e64b-4054-ac36-548e87396a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca7beeb-9ce6-489d-bf62-7363de256a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c2536e-332b-4239-b763-cf641d37f028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4826c50-1b86-484a-8ce6-302861f4904c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94eeeef3-1132-4090-9450-65d531ada122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e554630-e17d-4912-aa96-1890095bed0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 586f8aee-5d4f-4da2-9ec0-3e0e704a5ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45279470-c34e-4a41-a9ac-e99e87492319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dae36f4-f115-4274-9e23-3488dd51c5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead7fdd0-17ec-46a5-8b1e-9f407a5700ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e5b940-44d8-47d2-a245-d7e815c3c9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3119ecd9-4433-4e08-8ff6-56cd58d27795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681d39af-394d-4f0c-824a-ef2412db66ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2eb23ba-746e-4533-b574-484485d9f1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d5c942-6156-41f3-86c1-1c54feef48f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1895064a-d168-4901-a633-f1c99f9a2d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b19919-d5e9-467e-a907-a6913a4790d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2adea2-b023-453b-9458-9e534798c27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86019c6b-1caa-443f-9944-35820d25db2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029bc841-66f8-470a-b382-36851f0de1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29b6adc-f4b5-49ec-a189-ceaf365271d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ed27c9-1c53-4faa-8c72-83e9b7036a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da57593d-75c9-405c-b67e-19eaac783314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e64848bb-3558-4d35-a83a-3b7f544d171c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e34fd6-4de5-4e6e-9dec-157c8594457f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec4315f8-a85f-46fa-8ad2-937756349fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56977284-b081-4c6b-8ad6-440dd1181a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0f2454d-09d2-4ff9-9ec7-28e4828ee96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a27d7042-82de-4811-bc73-4efa6e758c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65821a8d-58e0-4805-b3db-b96ad00d17b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de10538-286d-423f-8056-7aa9fefd54ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf84174-754b-427c-a4f5-f3c1664d521e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a84dac9-377d-45a7-b83e-a444e572ebed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df5b4b5-b532-456f-b850-217ffec69185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e93af4b-f95d-4773-b2cf-5cf67557fad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362aace4-1679-4a48-bb29-0cb91720cf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d6827b-9378-44d3-b56d-985bac37ba70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6df032-d39e-4f80-b016-4c5cbc519181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bf4964-856a-4abe-a6e2-67147f3c3075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda4cb5e-4bc8-40b0-abd6-b9301b0612a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7da80317-dde0-4b37-9199-4f8adfcb507a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21ff1cb4-de92-4c16-8f8f-bd8880c9e71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2743a1a-d412-4c6d-8529-238e3270acef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4678ec36-b621-413d-b8c9-e440f97a9c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab387fd2-fb0e-45a1-8ae4-c476dd0abc8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2367b15-7925-4e8c-962b-8de341c1c76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d410232-5514-4dff-818d-8d32a09c58e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49574d1-daf5-4fd0-9a6f-dbb71f650999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac655a59-192b-44d3-ade8-e82a33706aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef2e4d3-003f-4fea-8727-75e52cb7349e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf4eda9-f458-414b-a403-b9aa9e0f7ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f07b9a-cb42-4b56-8291-575bfcd041a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089c8f95-0ae4-4021-a666-f5ee5f2675cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 298d14fc-e14c-4c22-a7ee-bb9a9c6055b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 620edc45-8e0c-45e9-80cc-5a96dd92e9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad1c149-81bb-49c1-8757-1da09cd5098a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d872034d-43ec-4205-a39c-6ef57706e2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378ebe62-41e7-4266-a84b-52eb3224cdb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f992936-c2e3-47d4-a4f9-91eb6f3e10bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba3c062-20df-4fa2-aae5-9ac25c37f864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9d32e8-ce36-4762-b213-20d0a78bd4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d087319-e3c0-402d-b1cd-770ce623eaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea4ea29-9cd1-423b-a1e5-d0e3e82f9559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a2d699-b29d-47bd-b886-7000fff998ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6be4fa3c-b924-4a29-a28e-0910456fd54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 717d38c9-d476-41d3-991e-18b3f9afd63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6edccd0-df4d-44e9-9afe-b03ac8444ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91638313-201a-49fa-bc09-95364d75112a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f5dc1e-f364-438b-b625-c210a16cb3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed236f6-11d7-46de-92c4-db1836e0cef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8483d1b-0ffb-424d-8e7a-7f3780472707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e70f45-2adf-4f53-b311-3e6a34613087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38121bb-2b4f-4ff3-88dc-46cf978c6ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82996d37-25d1-453d-afb4-2c96aeacba30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad71718-5d55-488b-bd42-83b06026d30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d10ed8-555f-4dd0-b84e-5bff5a35c24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab2f46e-9927-481d-90e8-6f81d7ec80d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36acae6a-5d26-4136-adb1-1fb59c526bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf165135-537a-4fe5-b08c-47e6bc4b16f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c4bbbc-035a-4b86-bef8-28fdaf2a6549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a177dfa5-7c6c-4f9a-a6fa-f2c9a3141d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 032ab687-4a8f-4223-8260-f0d3032fa448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f07a17-c2c9-483c-a827-767e95e43f35
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_55
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/test_labels.txt

📊 Raw data loaded:
   Train: X=(1940, 24), y=(1940,)
   Test:  X=(486, 24), y=(486,)

⚠️  Limiting training data: 1940 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  477 samples, 5 features
✅ Client client_55 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0825 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0836, val=0.0816 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0847, val=0.0784 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0847, val=0.0773 (↓), lr=0.001000
   • Epoch   5/100: train=0.0839, val=0.0773, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0821, val=0.0787, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 2 Summary - Client client_55
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0033
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0057
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2551, R²: 0.0008

📊 Round 2 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2552, R²: 0.0005

============================================================
🔄 Round 6 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0781 (↓), lr=0.000250
   • Epoch   2/100: train=0.0824, val=0.0783, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0820, val=0.0787, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0792, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0808, val=0.0796, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 6 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0077
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0145
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2549, R²: 0.0021

📊 Round 6 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0027

📊 Round 6 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 14 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0789 (↓), lr=0.000063
   • Epoch   2/100: train=0.0824, val=0.0789, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0822, val=0.0789, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0820, val=0.0788, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 14 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0017
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0139
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2549, R²: 0.0025

============================================================
🔄 Round 16 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0827 (↓), lr=0.000016
   • Epoch   2/100: train=0.0812, val=0.0827, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0812, val=0.0827, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0811, val=0.0826, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 16 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0055
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0081
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0027

📊 Round 16 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0027

📊 Round 16 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 16 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 16 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 22 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0865 (↓), lr=0.000004
   • Epoch   2/100: train=0.0805, val=0.0865, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0804, val=0.0865, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0804, val=0.0865, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0804, val=0.0865, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0804, val=0.0865, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 22 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0040
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0039
============================================================


============================================================
🔄 Round 23 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 23 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0036
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0063
============================================================


============================================================
🔄 Round 24 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 24 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0037
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0081
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 27 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 27 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0018
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0040
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 27 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 27 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 31 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 31 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0045
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0384
============================================================


============================================================
🔄 Round 32 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 32 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0049
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0343
============================================================


============================================================
🔄 Round 35 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 35 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0062
   Val:   Loss=0.0987, RMSE=0.3141, R²=-0.0106
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 35 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 35 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 39 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 39 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0097
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0311
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 42 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 42 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0001
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0020
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 43 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 43 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0056
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0175
============================================================


============================================================
🔄 Round 46 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 46 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0034
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0045
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 50 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 50 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0044
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0116
============================================================


============================================================
🔄 Round 52 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 52 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0004
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0098
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 53 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 53 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0048
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0125
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 53 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 57 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 57 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0016
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0044
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 58 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 58 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0029
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0199
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 59 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 59 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0057
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0204
============================================================


============================================================
🔄 Round 60 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 60 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0002
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0123
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 61 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 61 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0035
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0051
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 62 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 62 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0006
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0091
============================================================


============================================================
🔄 Round 63 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 63 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0075
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0183
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 64 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 64 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0017
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0359
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 65 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 65 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0079
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0186
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 70 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 70 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0048
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0130
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 72 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 72 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0084
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0356
============================================================


============================================================
🔄 Round 73 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 73 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0077
   Val:   Loss=0.0969, RMSE=0.3112, R²=-0.0166
============================================================


============================================================
🔄 Round 74 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 74 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0032
   Val:   Loss=0.0678, RMSE=0.2603, R²=-0.0086
============================================================


============================================================
🔄 Round 75 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 75 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0008
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0672
============================================================


============================================================
🔄 Round 78 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 78 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0051
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0099
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0030

============================================================
🔄 Round 80 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 80 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0113
   Val:   Loss=0.0984, RMSE=0.3136, R²=-0.0275
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0030

============================================================
🔄 Round 81 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 81 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0015
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0081
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0030

============================================================
🔄 Round 84 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 84 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0027
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0000
============================================================


============================================================
🔄 Round 85 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 85 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0061
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0130
============================================================


============================================================
🔄 Round 86 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 86 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0028
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0003
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 87 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 87 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0049
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0277
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 92 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 92 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0038
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0040
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 92 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 92 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 95 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 95 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0058
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0413
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 97 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 97 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0037
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0073
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 97 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 97 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 97 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 102 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 102 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0031
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0044
============================================================


============================================================
🔄 Round 105 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 105 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0007
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0070
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 105 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 108 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 108 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0011
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0069
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 112 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 112 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0007
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0118
============================================================


============================================================
🔄 Round 113 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 113 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0111
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0418
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 116 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 116 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0033
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0047
============================================================


============================================================
🔄 Round 117 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 117 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0011
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0148
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 119 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 119 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0042
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0127
============================================================


============================================================
🔄 Round 120 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 120 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0018
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0066
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 121 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 121 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0009
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0090
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 121 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 125 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 125 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0055
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0173
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 129 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 129 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0028
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0196
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0030

📊 Round 129 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 129 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 129 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 135 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 135 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0005
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0046
============================================================


============================================================
🔄 Round 136 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 136 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0004
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0091
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 136 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 140 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 140 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0075
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0310
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 140 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 142 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 142 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0003
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0058
============================================================


============================================================
🔄 Round 143 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 143 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0027
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0003
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0028

============================================================
🔄 Round 146 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 146 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0055
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0164
============================================================


============================================================
🔄 Round 149 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 149 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0011
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0077
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 150 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 150 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0004
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0085
============================================================


============================================================
🔄 Round 152 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 152 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0022
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0090
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 153 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 153 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0002
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0098
============================================================


============================================================
🔄 Round 154 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 154 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0087
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0337
============================================================


============================================================
🔄 Round 155 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 155 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0073
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0206
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0028

============================================================
🔄 Round 163 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 163 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0002
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0105
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 163 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

📊 Round 163 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 168 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 168 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0051
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0254
============================================================


============================================================
🔄 Round 169 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 169 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0059
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0437
============================================================


============================================================
🔄 Round 170 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 170 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0049
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0124
============================================================


============================================================
🔄 Round 171 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 171 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0031
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0019
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 174 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 174 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0055
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0532
============================================================


============================================================
🔄 Round 179 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 179 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0001
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0087
============================================================


============================================================
🔄 Round 180 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 180 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0013
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0168
============================================================


============================================================
🔄 Round 182 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 182 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0067
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0179
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0028

============================================================
🔄 Round 183 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 183 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0023
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0133
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 184 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 184 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0018
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0040
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2548, R²: 0.0029

============================================================
🔄 Round 185 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 185 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0151
============================================================


============================================================
🔄 Round 188 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 188 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0015
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0068
============================================================


============================================================
🔄 Round 189 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 189 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0017
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0032
============================================================


❌ Client client_55 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
