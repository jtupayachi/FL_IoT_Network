[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718c5f1f-68a0-4361-bab3-8d4a84900f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d423ba-2307-42df-b7d6-eb0df18e34ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 332276a7-9084-4c24-8a17-e559b80b4b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7d26bc-9870-44a3-8aad-4d94aab292b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9336a96-1f4b-47ee-8a69-b9b9f895bf8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 226d083b-92bd-4f09-a9d0-f96871416e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285bad75-1453-48bf-b06c-ee727406c28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5021d9df-8278-48c5-a1a7-db21bf8ac926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e45767-eb47-41b5-8410-6a634ba98a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81b2e95-a7cf-4bab-be26-69c434002b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message badb856f-55fb-4817-9fe3-d0edfd1f463b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417377e6-ce09-49c4-beb3-9f1c39f78ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a68a94-ed9e-46bb-a207-d2c7fd5cf590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ae54655-8b8f-4170-8da6-872c737b9d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d88d55cc-4862-4af4-a70d-7e94a5cd2ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3fa884c-a136-4b34-9538-27c4ad08360d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ad16710-4704-4b9c-9d96-f891e014f5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715bf895-c685-4039-a55c-c4870e6f18e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8946f4d-edf9-4804-aad4-4494b39e8859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afccaa18-20af-4922-96e8-16faa2d3b717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b20f8e3-253d-43fe-b875-358535f28f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33541960-8855-452b-a532-96f1bcb9ccd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f90e719d-43ea-45e7-b9c0-7e1914f853d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c09c3f2-d7e5-477f-8ab9-5087d262d5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4573bf-d67c-4eba-b178-e2a607c4fdfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8b511a-31ae-45eb-b400-f817a25e2dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a93182e1-53ed-4054-8cf4-e4c46c10d3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b333ec59-19ae-4bf7-84d5-e1ccd24b1140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ba9bc0-3271-4eb1-a92e-80ccd3016eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 394cf635-ffe7-4820-a0eb-1b94bc0d4a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59ebf45-5a43-4bd3-8723-2095dbdf704e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94db971a-1b0d-4b7c-878d-632cea5b5387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ade9d4d-8999-49ec-b390-b3e3dd05d459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03b0024-8ed3-4496-8135-f156ebfadafe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a753924-114f-4b12-acb4-906cfdb92132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4ee1e1-31d7-4d5d-8d6b-8478657e224e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5af6c2-df88-4a3e-a68e-edb0d9f521da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68e9766-8744-4c92-9675-b77f330b42f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95bd4510-71d0-48de-aac4-186d0a0e0c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 769425f5-9dc2-4059-9e82-487dff85565f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a65ad4b1-6543-4286-bf97-bd968d928784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec18b86b-ad04-4f8a-8d19-f60a9bc30c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6620e7c8-8484-4902-95b8-c8a3d8b3d5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f15b3a-30d8-46f6-8551-2f3f8b243a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd80f4a-d146-4ba2-a328-af2a27d08b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d12c5ac-aa4d-45aa-a290-e657bf4e2578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b4791a-6a06-439a-820d-305e494e3720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b24ada4-1f3a-4a6f-8dd8-35c44a22cd42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad08fd0f-42ca-4f64-9f3a-fbbc7dd465f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f260a2b1-fcae-42d9-8fd2-552895687376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a02142b-51db-4ca8-b325-159247af939e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d5abea-c24d-46bd-85d4-91e1c2beca68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e034d800-e22e-4219-ba01-36f9d9512bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cfc7c20-bb90-4430-9de6-7c578e586773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90b722f-bd32-4202-8f16-3b11b6c2a867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d224e05-20ac-4a26-96d5-fc93dbc0ea00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73808dd3-eef8-4877-972a-1b91638d6ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9238dddc-d66e-44f8-b7b1-5240700b0b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19973836-d161-4853-bd20-b2714f77c7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fba3af8-2447-491a-975e-14f303214e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8d93e88-e7a8-4f18-9d46-6d286d652549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce03d088-24dc-4049-920c-16a9ee4a2d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18fd8244-b4e7-42d0-be34-5c653a2f55d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7bd1d1-aa5e-4678-8d24-402a7e6dde7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e89d962-0dbb-49e1-9150-d99d7a986861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8754b73-23fb-4322-a790-4e70e9db452d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ea3804-b948-42d7-b474-1e2b5ac962bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff25d470-dd9d-4cb8-9dac-172defdb3af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feff6652-0dcb-4b2e-be72-1560dc49d874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f123d314-44ec-413d-a912-000b79258143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd823205-3970-48fe-b43e-20b641043956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a0c2b6-f68d-4532-88a4-8bb197dac3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d6f70d3-3c1d-4ccc-a20d-eb1166e5928d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3dc6800-db40-4970-85c7-964a8c7413c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda00208-05f3-4632-9d37-10a2428bde0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f02f78-e867-4dab-a8dc-25cd78eba10d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40e5829-8cdb-433c-bc9d-d82a47b27f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce702f2e-aa2a-4bda-bccc-24bd0f98e976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2ecfac-42bd-4fc8-aeee-268a6141d314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e84527fd-c689-4289-ba9a-80ef0d041317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ab12c0-1a13-4c73-9283-15cfaf11180f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf4e1b25-6f85-4f6a-930e-f9c3b985dd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32328387-0fe8-45e3-addf-afcb4deaaf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a7f8af-41a2-4e6b-a0a7-8f9547b5ab19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cfe06e1-9f84-40a2-b771-2f900fc971c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03917cf4-246d-4c49-a414-e454eaf542bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67aa954-b4db-4d58-bd50-38db7d1c63d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9d5989-1b2f-4b34-ad61-622c480a9e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea706fab-95d0-4a4f-95c3-12eac9a2253f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0943c16-78aa-4ee7-9aa3-33cc9c759e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3725ad8-97a3-4e9d-8ec6-6c52df8af93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52aba77d-9901-4ed8-b976-359dfe6fa3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ed86cc-26b6-4a28-b6e2-8d74ace3e61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ee32a1-784f-4ded-9df0-f33646f0e5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af834a0-30da-4dea-925d-82bfac9f3526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d62bc503-c9c9-43bb-986a-855809346935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f8fa29-ef42-48bf-ba3b-8bb590b05d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78f48ace-c8b2-4e52-82c0-88f7a2de53cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39828998-0ad8-421e-8638-224e984d0156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4aac3f-ddfd-4769-ae5a-e15db3600bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4706038c-afda-4e33-92c7-d074ca444022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80b1b9cb-25e1-42c5-a35d-f8c60d51c4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ea17722-b4c6-4ec4-8d39-12c4d7f7e7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1864dd56-bfaa-472e-a064-0577be685314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a9a15db-4e23-495d-8948-4a1732156dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b172f13-74be-4987-b0e0-72b7ec28850d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49352c01-6841-4350-9bc2-cde5b2ae561a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03fd3290-2277-4b01-b1f7-37a805149a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a594fb93-d034-4126-b5a9-af47a00e328e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af7b1b1-642e-4590-9e4b-75b123822713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68608670-6463-4738-8c4b-c1689dd7e6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8f16b8e-0c2b-41d3-8306-9c12ca60ab66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26031e34-aa65-4841-a9a9-b71adbe2dedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1214c282-d948-401c-af86-d28f68c8cbae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f315f5e9-3e51-4598-8e2d-0cc6ca99b374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1877901-203f-45e2-9274-df9e955287b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d9458f-7123-419a-aa9c-85a387e28855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc800219-2670-4506-80e9-22b3fbc2f2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8afc1f4c-629a-4f74-bde8-56d2f89b2edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206a7f7c-103b-498a-94ed-baa1058db382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 135eea83-2587-4819-b29a-2e737a9b630e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d02044-e00e-4441-8c37-dba2e79f38b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded409e6-af87-478c-8f7b-d376be178e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89781579-0a0a-43a9-9cb9-0a37d21b661e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 723d44de-9fa0-4500-9239-de82e60485c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f5f58d-b4f0-4000-9805-52bae60c8cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c36373-01d0-4e65-82cc-193fbdea3175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158ddca6-cb2b-4f3b-a494-df4b5907182c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd27c70-212c-4db9-ab68-70b25207fff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c3a6b3-069d-4d5c-8dbe-5bf862762aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4710b0-df0e-46dc-8f68-2a3e91f09c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da489e27-38b9-409c-8330-3f208535bbb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95104261-52af-4daa-bf53-d24321f4f4c6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_56
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_labels.txt

📊 Raw data loaded:
   Train: X=(1226, 24), y=(1226,)
   Test:  X=(307, 24), y=(307,)

⚠️  Limiting training data: 1226 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  298 samples, 5 features
✅ Client client_56 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2549, R²: 0.0023

📊 Round 0 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2529, R²: 0.0165

📊 Round 0 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2516, R²: 0.0263

📊 Round 0 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2508, R²: 0.0321

============================================================
🔄 Round 6 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0743 (↓), lr=0.001000
   • Epoch   2/100: train=0.0789, val=0.0738, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0782, val=0.0733 (↓), lr=0.001000
   • Epoch   4/100: train=0.0773, val=0.0731, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0765, val=0.0729, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0710, val=0.0717, patience=3/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0637, val=0.0739, patience=9/15, lr=0.000500
   📉 Epoch 26: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 6 Summary - Client client_56
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0695, RMSE=0.2637, R²=0.1436
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0722
============================================================


============================================================
🔄 Round 9 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0702 (↓), lr=0.000250
   • Epoch   2/100: train=0.0793, val=0.0702, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0791, val=0.0701, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0789, val=0.0702, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0787, val=0.0701, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0775, val=0.0699, patience=10/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 9 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0403
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0167
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2471, R²: 0.0583

============================================================
🔄 Round 11 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0862 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0747, val=0.0853 (↓), lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   • Epoch   3/100: train=0.0745, val=0.0852, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0742, val=0.0850, patience=2/15, lr=0.000125
   • Epoch   5/100: train=0.0741, val=0.0849, patience=3/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   ✓ Epoch  11/100: train=0.0735, val=0.0842 (↓), lr=0.000063
   📉 Epoch 19: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0730, val=0.0836, patience=2/15, lr=0.000031
   📉 Epoch 27: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0728, val=0.0833, patience=12/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 11 Summary - Client client_56
   Epochs: 34/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0729, RMSE=0.2699, R²=0.0657
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0588
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2469, R²: 0.0606

============================================================
🔄 Round 14 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0779, val=0.0734 (↓), lr=0.000008
   • Epoch   2/100: train=0.0778, val=0.0734, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0778, val=0.0734, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0777, val=0.0734, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0777, val=0.0734, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0775, val=0.0734, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 14 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0439
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0382
============================================================


============================================================
🔄 Round 15 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0761, val=0.0807 (↓), lr=0.000002
   • Epoch   2/100: train=0.0761, val=0.0807, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0761, val=0.0807, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0761, val=0.0807, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0761, val=0.0807, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0760, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 15 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0422
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0463
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

============================================================
🔄 Round 17 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 17 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0404
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0558
============================================================


============================================================
🔄 Round 18 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 18 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0366
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0306
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 18 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 18 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

📊 Round 18 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

📊 Round 18 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 24 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 24 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0443
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0365
============================================================


============================================================
🔄 Round 28 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 28 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0452
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0375
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

📊 Round 28 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 36 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 36 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0393
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0553
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 37 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 37 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0472
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0296
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 42 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 42 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0422
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0434
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 43 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 43 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0472
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0267
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2467, R²: 0.0621

📊 Round 43 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2467, R²: 0.0621

📊 Round 43 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 47 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 47 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0430
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0433
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

📊 Round 47 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 51 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 51 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0468
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0305
============================================================


============================================================
🔄 Round 52 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 52 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0466
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0275
============================================================


============================================================
🔄 Round 53 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 53 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0462
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0026
============================================================


============================================================
🔄 Round 54 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 54 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0478
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0044
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

📊 Round 54 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 56 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 56 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0400
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0148
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 61 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 61 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0440
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0421
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 64 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 64 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0425
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0371
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 65 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 65 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0466
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0234
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

============================================================
🔄 Round 67 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 67 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0463
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0314
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

📊 Round 67 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0621

📊 Round 67 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

============================================================
🔄 Round 74 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 74 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0421
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0500
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

============================================================
🔄 Round 80 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 80 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0415
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0498
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 80 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 80 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

============================================================
🔄 Round 85 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 85 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0378
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0284
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

============================================================
🔄 Round 86 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 86 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0409
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0540
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0622

📊 Round 86 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0623

📊 Round 86 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0623

📊 Round 86 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0623

📊 Round 86 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0623

============================================================
🔄 Round 98 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 98 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0394
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0537
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0623

============================================================
🔄 Round 99 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 99 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0431
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0418
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2467, R²: 0.0623

============================================================
🔄 Round 100 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 100 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0456
   Val:   Loss=0.0684, RMSE=0.2616, R²=0.0341
============================================================


============================================================
🔄 Round 102 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 102 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0468
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0202
============================================================


============================================================
🔄 Round 107 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 107 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0387
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0621
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0624

============================================================
🔄 Round 109 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 109 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0360
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0633
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0624

📊 Round 109 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0624

============================================================
🔄 Round 113 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 113 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0420
   Val:   Loss=0.0674, RMSE=0.2595, R²=0.0506
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0624

📊 Round 113 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0624

============================================================
🔄 Round 122 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 122 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0414
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0479
============================================================


============================================================
🔄 Round 123 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 123 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0427
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0377
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0625

============================================================
🔄 Round 124 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 124 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0442
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0397
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0625

============================================================
🔄 Round 125 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 125 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0420
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0430
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0625

📊 Round 125 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0625

============================================================
🔄 Round 128 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 128 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0411
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0407
============================================================


============================================================
🔄 Round 131 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 131 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0478
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0283
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0625

============================================================
🔄 Round 139 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 139 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0408
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0571
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0625

============================================================
🔄 Round 140 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 140 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0412
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0405
============================================================


============================================================
🔄 Round 141 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 141 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0444
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0330
============================================================


============================================================
🔄 Round 142 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 142 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0442
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0412
============================================================


============================================================
🔄 Round 143 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 143 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0409
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0544
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0625

============================================================
🔄 Round 146 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 146 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0441
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0426
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

📊 Round 146 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 149 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 149 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0436
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0394
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

📊 Round 149 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 157 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 157 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0476
   Val:   Loss=0.0654, RMSE=0.2558, R²=0.0244
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 160 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 160 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0445
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0293
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 161 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 161 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0426
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0458
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

📊 Round 161 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 164 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 164 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0414
   Val:   Loss=0.0695, RMSE=0.2635, R²=0.0495
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 170 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 170 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0450
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0161
============================================================


============================================================
🔄 Round 171 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 171 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0433
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0370
============================================================


============================================================
🔄 Round 172 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 172 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0436
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0223
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

📊 Round 172 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

📊 Round 172 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 178 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 178 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0388
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0291
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0626

============================================================
🔄 Round 180 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 180 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0461
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0342
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0627

============================================================
🔄 Round 184 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 184 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0392
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0613
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0627

📊 Round 184 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0627

============================================================
🔄 Round 187 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 187 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0409
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0375
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2466, R²: 0.0627

❌ Client client_56 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
