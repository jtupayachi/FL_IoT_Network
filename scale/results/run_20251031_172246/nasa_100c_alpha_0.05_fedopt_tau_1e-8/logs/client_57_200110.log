[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b445cfe-ab4e-4406-b758-168b97a21c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33563dea-3478-46b9-8347-440907220484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23cd2cb4-82ba-4313-bfcc-b221347fa4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae9e520b-3281-4438-aa9f-c6b359b3965b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6405965b-1790-4056-9bd8-dc6f8ee0b70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe7aa36-73eb-4e4d-b5d7-1db57a8f4dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de71433-8007-4f31-8df7-80b68f7c1357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c803a9fd-09c0-4fff-9238-697181a4b91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 807517e2-b710-49a1-aecc-f7bd58bc809c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c839cd6-c63b-4610-ad76-1010739d0996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9522d017-9bb6-4875-b91a-8a9f206f46b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e45365-e884-4181-9bc7-a640b03480a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6740969a-d62f-4dbf-815e-c3ee76d49107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f2b62a9-9b9a-4d09-9ca2-f49e8e6eb98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409ed6a4-4f53-45a4-8c3a-239b2bcfe718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8b619c-4efa-421d-a244-94ed21ffc3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2225b0a2-6593-41f7-9d58-246f9d156f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9058aca4-8d38-4a78-a949-0465a6d9a75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b111442-fea7-4dcf-a4ad-69700b42a50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299e3a3f-d2cc-4693-a7af-33aa27923dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb0bd4e3-68b1-4827-b8f3-a0b3951e4da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46adfefa-9206-4cab-9e79-2930f31a2b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df9465b2-8c2a-4a14-98a1-a56927af48d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5eedc3-939c-408a-ab0b-f919c766450a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5aaceab-139f-4f3a-9555-25d843fa7eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d799cf-8303-4cf1-9847-dc1683037887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7448c9db-ccaf-4949-91bf-f20803a36e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 657cbcfa-3e66-4148-bf4b-894cf6d4ec2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5548cd2b-b0ba-44ca-bcd6-816c95df9cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715e4f22-65c1-42d9-ba8e-445aafaaff1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc4882e-cd64-40c6-8b3e-a658f6ab4d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d632ea2-fb80-4974-888c-e8809e9ccfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68e1530-4551-4f6a-9767-01cf60161e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 262aa006-2bbc-494c-9e7e-c31c39257f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c99ccbd-ccdd-437e-ba1f-a99206745ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7c8fc8a-aa75-46eb-994b-48ea0f040dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1db652-8f78-4aa8-90d0-dee48aa45582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ef4725-fdf3-4b96-86bd-f0fd1528447c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe9c86c-ccb5-44f0-9259-28dfdbd806fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d19d5a1-eeeb-4972-b437-65eaca4a5a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 270e259e-d4f1-4786-bbcf-3c6c9cbb2c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf9af8a-0343-4d8d-8b22-7b82502b44d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e75c1425-9990-418f-9878-e5ff11a537c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafde9a7-8da3-433f-951e-039515208998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50d88f14-663e-47b8-a72f-886ac89dd721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e13ee192-2347-49d8-8039-261a950627f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1b4300-3c1d-4258-81d3-b32f126e23ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeeac010-dc38-488f-b235-fb32bdce9715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 548ff3cb-d812-4394-ab7f-39e7c3678f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 431f72f0-e814-4ef0-becc-5b47a9cd1ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cba7aab7-bbda-4ae5-9231-6a27ae82e36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db70bec-c8d0-4ea6-b2f5-0d05c7ca41cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f94d63f-c6f3-47f0-ac7b-c39d1fb76c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076b4015-693d-444c-8750-1cb47f8f46bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ab0beb-4ad5-4c9d-acd3-966ec1d7f752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfdc0745-8f6a-45cf-a3af-15f99e15a531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d5407c-5d93-4a81-84b6-339a1a2dee53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf18a52-9207-4b8d-be45-7caa71ecee7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2280e7-5763-45e0-bc18-16ca8df3314b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5e534f-1faa-482b-a983-87949022b4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e16948-b52c-4d06-9c34-2a99e12dc9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb5a259-8d60-4a87-b0dd-75c9f2dc0e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7dca55-83b8-4a23-9112-3b445f4fbb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090fb347-3690-4f11-9d02-91004954c3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29dbc05b-345c-49c0-aa62-7bc4b1b2e5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32cf81a3-eaa3-4a44-8f4c-873b43b795bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb058f0-8631-4e73-94ba-d07a2505c973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ecfc553-b32d-4170-9cea-3536e2cf6ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde01f25-308c-401a-a10c-593384e2f306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5704d5-1169-455d-aaef-f84a6e6af604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a53022-5256-4af2-ac19-c9e374f94990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d85bdd5-6935-4308-98f7-fabc7150c847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7411d2-1a77-4932-accd-8f3f4683507e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b3ed233-1759-4771-94d7-c055b34f6f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7743e61-f84a-4994-a01f-15d910b8d43a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfeec4d-0658-4757-9c19-3bccf2132aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1064793b-1820-43fe-ad51-085c21aac3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3d1c8e-225f-4b65-b43f-a21d254c309e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c2cb6b-7a45-4322-9f73-c51d43ed9ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb08e3f-45e9-448b-b59a-e817fd971f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4032603c-7d3d-480b-a163-cb3d9730ee6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de3c15eb-6e71-40f7-bcfc-2cab640b167a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28cfd064-2d0e-4dbc-b349-155b1ca566a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d77b5f6-a824-4aa4-9be6-78afb607413f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a659600-1198-4488-91c6-fd6f80b86848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd237ca1-211c-4d6a-bca9-277d7ac1141a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9defe220-6383-4a9e-b64b-2ab234e3ed12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ccc9a00-3d0e-4c56-99e9-4749f6d43cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 643649f9-3d3f-4086-afad-6d74816eb86d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 540d71e8-21ce-4700-ab73-252ee2e6ac11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f679f2-c700-4bf3-8829-e1a000d4cd94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2ab6cf5-0c12-47af-b4d4-5deab51f3f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 129a988a-104e-4231-af8e-6fe5fed8aec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8788510-5b6d-4343-b1e7-ae12a7f4e431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03057eef-d6a3-4a13-a6fa-fc8c5bbffe2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d5a3d6f-118b-43fe-b70e-a76efeb15d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34e3421c-ac19-41d2-b846-8320aa1d8624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea3a2d6-ab6b-40cc-a542-9806630a4037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a595ca3-2c8d-46e3-ba89-e5c441a84e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44cc472-c681-4cbd-8396-0437a1869cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de352e3d-2d58-49f2-8b41-139ea19d9082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 379670ba-fc33-4856-b97b-16e30fd4690d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443ded1a-a527-41ce-bc68-59bdb69a7166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62bf23cd-33a0-46bb-b78d-e574698e2883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884cbc7e-8bef-4bf3-beae-6bf085edb978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46031c4a-019b-4295-a274-db5ecb8a62a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a073626e-3f06-4792-9822-e4ae6e81e3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1161b3ab-3a0f-4ada-acb8-6a96a0cad980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82cf5484-a425-433e-a138-957d0aeec3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11df1266-cef3-414c-a97d-5ba9c05b94e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2917a42d-0518-4869-9e25-c3fec80ea90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b8a30fb-f607-48c3-b2ed-c2653cc3d9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2736f11-8c03-4704-b9c6-c384593b5404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e80c3bc-dc14-4d99-ba9b-1d11e8c48526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47302013-9456-4dfd-adfc-7f72efc104ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eb09576-d55d-443a-9549-bb146b493053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f01dfd-6b73-43b6-93d0-e2c1b2bcfa8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe72ee60-aeee-45d9-97a9-1f0a8783ea50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d4e5c4-5280-401b-a96f-b234161ef71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b580b9f7-6907-4eb2-8e1e-cf8a823dac5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fcc50dc-b04d-43ae-b9e0-f99e6abb42cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d31a2d-7620-42de-bcc6-8f96673a0fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3e44be-7c17-4e95-9139-38b7a21ecb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea3a38d-a903-4867-811f-a8410ca2e9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c58703-f7f2-497d-be5c-fd9eafa6a3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04be98c-364c-42c9-aaca-45f1d7dfc5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f184a4b-0815-45b0-b8c2-ddfee9134bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7739ffd4-a74b-4d88-b1a8-a72de16871fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6083d3-0757-4c94-b696-aa29adcd7c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068e5a74-291a-4150-abf0-0ef670f7ed24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e0821e-7aee-42cc-a184-647239415f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a98055-fb6b-4f0f-b44b-72b158c43e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9332669a-3c31-41f5-b071-45600c98b42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b35e0ad-344c-43e3-a710-5085e2072202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd9530cc-8f5c-445e-a6cb-83ea91c515a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003021be-37bc-48c2-8ae2-b81f3f4be8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 397824ff-467d-4eb3-b107-cb8451d8cc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c7c602-88cd-4236-b900-7c59f2af2245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a24cff3e-2804-449d-90e8-1b1dd2c7b11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466fca6c-f022-4391-9f8e-48dff66c3d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d8cd7f-4ae2-4c4a-b864-db8dc182d80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b5cb6a8-3926-47c5-a006-3cb5ca83f8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8049e2c9-21a5-4e66-9a8f-bb9ef1e08e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada8ad7b-229c-46ec-bd55-aef418cd1d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec895755-7621-4c99-bd06-3150e2bdd927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca5c294-4cd1-4d6b-a537-75c6c640d7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d37f4f10-fcdc-4f15-ad78-94f440a19b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46129aee-dd4b-439b-84f3-0a0f87ef0f69
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_57
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_labels.txt

📊 Raw data loaded:
   Train: X=(1626, 24), y=(1626,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1626 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_57 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0754 (↓), lr=0.001000
   • Epoch   2/100: train=0.0860, val=0.0761, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0861, val=0.0765, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0861, val=0.0765, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0860, val=0.0764, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0847, val=0.0765, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 2 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0040
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0008
============================================================


============================================================
🔄 Round 3 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0848 (↓), lr=0.000250
   • Epoch   2/100: train=0.0844, val=0.0852, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0841, val=0.0856, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0859, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0838, val=0.0862, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0830, val=0.0873, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 3 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0020
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0106
============================================================


============================================================
🔄 Round 5 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0771 (↓), lr=0.000063
   • Epoch   2/100: train=0.0856, val=0.0772, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0855, val=0.0773, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0855, val=0.0773, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0854, val=0.0774, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0852, val=0.0777, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 5 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0008
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0175
============================================================


============================================================
🔄 Round 6 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000016
   • Epoch   2/100: train=0.0844, val=0.0820, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0844, val=0.0822, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0843, val=0.0822, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 6 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0037
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0217
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2488, R²: -0.0006

📊 Round 6 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2490, R²: -0.0024

============================================================
🔄 Round 11 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0794 (↓), lr=0.000004
   • Epoch   2/100: train=0.0859, val=0.0794, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0859, val=0.0794, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0859, val=0.0794, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0859, val=0.0794, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0858, val=0.0794, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 11 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0140
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0008
============================================================


============================================================
🔄 Round 12 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 12 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0231
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0503
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2490, R²: -0.0027

📊 Round 12 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 15 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 15 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0127
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0135
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 18 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 18 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0151
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0313
============================================================


============================================================
🔄 Round 19 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 19 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0194
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0088
============================================================


============================================================
🔄 Round 20 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 20 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0122
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0179
============================================================


============================================================
🔄 Round 21 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 21 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0208
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0067
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 21 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 23 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 23 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0185
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0059
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 23 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 26 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 26 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0146
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0316
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 27 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 27 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0087
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0419
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 29 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 29 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0160
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0091
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 29 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 34 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 34 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0111
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0237
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 35 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 35 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0184
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0037
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 36 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 36 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0138
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0107
============================================================


============================================================
🔄 Round 37 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.1001 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.1001, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.1001, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.1001, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.1001, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.1001, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1001)

============================================================
📊 Round 37 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0077
   Val:   Loss=0.1001, RMSE=0.3164, R²=-0.0444
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 37 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 41 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 41 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0109
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0272
============================================================


============================================================
🔄 Round 45 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 45 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0142
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0119
============================================================


============================================================
🔄 Round 48 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 48 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0105
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0365
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 48 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 58 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 58 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0119
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0198
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 60 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 60 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0105
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0247
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 64 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 64 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0152
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0169
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 64 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 64 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 70 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 70 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0088
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0298
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 70 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

📊 Round 70 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 79 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 79 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0132
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0168
============================================================


============================================================
🔄 Round 80 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 80 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0181
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0009
============================================================


============================================================
🔄 Round 81 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 81 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0168
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0102
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 82 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 82 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0121
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0177
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 85 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 85 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0118
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0553
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 87 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 87 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0160
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0036
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 87 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 91 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 91 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0161
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0023
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 91 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 93 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 93 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0145
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0080
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

📊 Round 93 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 96 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 96 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0097
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0268
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 98 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 98 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0152
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0066
============================================================


============================================================
🔄 Round 99 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 99 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0090
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0371
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 101 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 101 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0090
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0403
============================================================


============================================================
🔄 Round 102 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 102 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0219
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0188
============================================================


============================================================
🔄 Round 104 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 104 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0272
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0198
============================================================


============================================================
🔄 Round 105 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 105 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0111
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0215
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 106 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 106 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0161
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0018
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 107 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 107 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0086
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0322
============================================================


============================================================
🔄 Round 108 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 108 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0098
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0448
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 110 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 110 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0158
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0031
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 115 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 115 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0104
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0259
============================================================


============================================================
🔄 Round 116 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 116 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0164
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0003
============================================================


============================================================
🔄 Round 117 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 117 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0164
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0295
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 117 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 117 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 129 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 129 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0097
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0288
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

📊 Round 129 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 134 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 134 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0148
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0168
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

📊 Round 134 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

📊 Round 134 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 140 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 140 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0148
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0097
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 142 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 142 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0092
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0357
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 143 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 143 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0153
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0052
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

📊 Round 143 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

📊 Round 143 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 146 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 146 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0151
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0092
============================================================


============================================================
🔄 Round 147 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 147 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0119
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0189
============================================================


============================================================
🔄 Round 148 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 148 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0120
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0272
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

📊 Round 148 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 154 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.1000 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.1000, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.1001, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.1001, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.1001, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.1001, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1000)

============================================================
📊 Round 154 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0144
   Val:   Loss=0.1000, RMSE=0.3163, R²=-0.0224
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 157 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 157 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0156
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0040
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 160 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 160 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0142
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0133
============================================================


============================================================
🔄 Round 161 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 161 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0089
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0453
============================================================


============================================================
🔄 Round 162 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 162 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0148
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0106
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 168 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 168 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0123
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0177
============================================================


============================================================
🔄 Round 170 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 170 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0183
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0054
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 172 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 172 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0064
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0546
============================================================


============================================================
🔄 Round 174 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 174 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0133
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0343
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 175 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 175 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0115
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0247
============================================================


============================================================
🔄 Round 176 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 176 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0160
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0041
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

📊 Round 176 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 179 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 179 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0177
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0025
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 180 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 180 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0083
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0319
============================================================


============================================================
🔄 Round 181 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 181 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0078
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0571
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

📊 Round 181 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 184 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 184 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0136
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0322
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

📊 Round 184 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 186 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 186 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0178
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0010
============================================================


============================================================
🔄 Round 187 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 187 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0161
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0021
============================================================


============================================================
🔄 Round 188 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 188 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0153
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0057
============================================================


============================================================
🔄 Round 189 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 189 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0140
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0108
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 190 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 190 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0149
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0088
============================================================


❌ Client client_57 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
