[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c54cf6-889f-4dee-94b3-5c328792b558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca955e79-4428-4fba-b1e2-8f4bb12c9dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5dc4a24-3c14-4bb5-a3c3-a23a1d3bbdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b7c289e-98bc-471e-80df-2716da555091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751b0db0-c127-43ec-a796-e1ca2925a856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aa59052-b03f-406c-b18c-dcc6c6d9aa3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3e44bc-4fac-4fa9-a988-ae6721e802d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf85264-eec1-4442-bb30-f78ce78ce3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01866b4b-d560-4aff-b253-8cf4f94d8494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48690458-61e7-4803-8cb7-f35ef7d56032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd9a68b-ff9c-4f6b-ad3b-41d24ae21e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b952af21-c97f-4a0d-990e-6efc7a076a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f96de0f6-fef6-4c1d-8b4a-9f9affe0a667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e53b6b5-d3b7-4c5a-90e6-313747c4995a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e428d60-c195-40f6-b01a-45b4dae7a8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2582f55a-2798-4e70-b35e-3fe90fe8c379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d60036-0dc4-49db-8d32-0dc70bdc0d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506c9809-8ea8-4d15-9108-7aebcdd088d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b004fc58-f48b-4c8a-866a-013b1c5f2f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2224849c-5f0f-4ca9-8f17-f9b956eeaabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7632785c-1112-474c-83f4-ce6eaecaa029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a0195a-6f34-4251-9fef-d9aace799594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9b9001-9db3-4f00-8a58-64b1b7e3741a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84659800-fac9-45a9-bf8f-676426f6242b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10284ce-f1d3-42a5-8e99-f4461b225213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3f7566-4676-4bae-af8b-1e10dacd2ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b8e5d90-212f-49e6-96eb-b2f6b99a15a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8789155c-91a2-4a55-af54-892e7a3d8831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c10a9241-d1b9-4720-a435-bed90b1c7050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb8a2907-13f0-4edd-ba66-3847a32e3aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41075c5b-1b31-4780-8bfe-f92ea1bd85f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e219c11f-2aca-4b65-8f4d-078d992bb861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de22b73-0968-4f51-bbc7-45184bb3063e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16efd050-4c21-43fb-8594-77b384543cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd51b7a-c77b-4e28-bd38-995dae4a627b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ccbf8b-c576-4a41-86a2-1a4ff67fa377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d4a289-6b74-4077-8e7a-1f8da7c35c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a024f1a-b003-4f57-baef-4196713339d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e2a044-141e-4f2a-9309-c8e26d3232e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 632b49ef-c20e-4a38-89db-8f07d9a107c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07fd82cb-3191-4f19-b4ff-e42a84c7542d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00e1bc56-9f6a-4e79-ba35-0a3cce673fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aa214ce-6bcb-4ecf-8062-e73d21d3b273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3cccde0-ae75-4756-912d-7ff81bec5b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc43281-ce4c-473f-abe2-a0e5b47537d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d80cdac-cdb0-4e8d-9827-5b97db7671a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1a4392-1ffd-465e-b1d6-042a8ebc0f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c1edcd-6e17-4fbc-b9f5-b6ebc408a5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db01d930-ee18-4b86-9ac7-48b7b52e7ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c71533-c3a3-41aa-8d6b-b6a1845e16a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb7b756b-a023-46c7-a5a3-5569c702701e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe4088b-d52f-4fcd-bed2-98e4760c0d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abed7219-3ead-4b40-94e8-a3cb630d2a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbc25b8-ad4c-40f8-8744-86235aeb56ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e0415c-9488-422d-aa98-58cdef01f639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89061634-f4dd-4f2f-b49c-3c438682e3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bacc18dc-0c9a-4885-b02b-a6f28e58b3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1a9d24-8447-4012-9acf-e00cd628a79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d95ff12-ac7d-4527-83de-e4e3a1aa4f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f1f26d-c76a-47da-85b2-1d9ab3bc1a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4fca17f-54e8-4db7-a6c9-eb2f93ff990d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cc9f492-02af-4f87-bd2b-7544ca32076f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa17c98d-a023-45b6-bff1-9442bf9c0e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e50afb2-3a31-4745-8529-6b9cb496443a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e3e8880-cd39-449b-8505-d7d3633222e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438a48bc-f465-4341-b66a-8e6184f97b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6aec07b-58ae-460f-8fdb-bd7668390b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f88470f-938a-410e-86dd-717fdf43f6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341c7a08-820c-4a47-84fe-898d5e1806de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b3bd96-288e-48ca-a6bc-212c9c0f5ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35955bc3-acdb-4841-925b-c7c8db020269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611c5f8e-374a-415b-aeb4-f210311b529b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b57607ef-2700-4289-9992-f84ea5792f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe6a4cc-ca12-4568-a431-9e191a0325a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efbfe736-ac86-467b-83eb-36fc857f11b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92044e73-6cf0-42cd-8915-5104658438a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2372f76f-3813-42a8-8daa-9c64bdf6c6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c91d979-4e91-4f42-9184-d96b920b6b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36999449-ab66-4dc3-bf45-70498ddb9e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537ab605-ab82-4c8e-9267-fc7ce6490698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d945ef0b-22f9-4b18-92ff-0ef2051364f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be078358-1e97-4c63-b6c0-200ac0acd148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7c87fe-882c-4362-8a55-c4e7923f0e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be862583-bfae-4e35-b51e-b70afa7a9ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414f549b-5c30-42e3-8585-e0c73f9e2357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08207883-a5a0-46aa-a4d0-23d1be5ca438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbcdf6e5-a985-4727-9f05-feec5e276521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96475fb6-d7c7-4a35-866c-70df4a2554d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a43dd0-87c2-4070-ac27-1f1f61eecf9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf94745-1a4a-450b-b1df-c3589e4a6b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e499b4-e34c-42ca-b0d1-32b82250dd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec89da1b-20c6-4917-ab0a-e894f62e7e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d24b9d22-fdf6-44e5-8db4-ad23643198fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 981a4c78-c6e3-46ff-8683-02fe45d0c98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e82d417-a1f6-4147-9b9d-965fe3dc989a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5163da7-b58a-4999-bb6f-f996137f3a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78464e5e-70a8-4998-80c1-4b8646c2c1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bab02b6-d60e-4fd0-941a-6f9adbdae0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05eb3c78-9ff9-4c93-9e37-2d8cff8199e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2439b5fb-f5fc-4c84-994c-dba6258a827d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fad6b3b-a06c-4be1-a4ef-e6d388740662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c96f03-5db8-49ca-a010-001c92786089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb9805b-db78-4c18-a634-9625acbb0237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6884846f-d4b6-48e7-9aff-27a8f86b4517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8208ab8-f269-42f6-b762-3c633640b988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146eebc6-2e20-4f09-82dc-9d7d6abfa28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27d5a053-942e-410d-95be-5a60ec2fd0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5454525c-1e13-4e4d-9f68-298e61f9a251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c8f736-2b0d-4b0d-b0e5-ddcc6d8ee5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db53c227-eca6-49be-bfd0-20f2d23dd8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166d68f7-bd86-4652-b58b-904c396a06cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee452310-f6b7-4e25-97b9-1f07d230b0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abd0749-5776-4ab8-ae76-82ce1d5cd853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1b23fe-d32c-4630-b417-0eb9a3153571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e261c0f8-f82a-4905-8d54-45aa7676c89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0bedea0-c598-4c49-82fc-2415ae971ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87338d2-038e-48af-998c-46b547bf3821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cebd8d3e-0029-4ae0-88ea-2d4561d0bf09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 312ab161-26e1-40fe-afe6-23017241193b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2410be3a-5a8b-4d8e-a4fe-0fc589dec91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b189bfe-465c-4334-a18e-aec0ef6f36ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38d6cf48-5418-487f-b12e-44916aa8857d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c58c1b66-b00f-4a4a-b9b2-4ba8cecf18e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc6364ef-039c-49c7-bc55-0c105f53ab0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada27773-6dbf-46cb-9b95-12db83b117ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac538025-6dfe-401c-b36c-485b62dc54bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a476fe4-7056-4930-a9d9-04afaaecc7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cd5740-6a72-4730-bf3d-6b3f4e6d0168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc5d7862-fdf0-4505-95b2-01bccfaea3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33f057cd-3a36-40a5-abe3-adc200d8dc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffad44f9-b631-4226-89da-65a47b6d7dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb4936fe-6376-4f8b-b17c-52507c881611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35af62d2-d74e-4b39-9840-4a7c3a38bfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80405285-4b73-4347-ac28-d249f9472fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6adaed-ecb2-480d-a0be-86a907fae76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70847084-ffae-4827-9f55-52338a1c7c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e479a88-3db5-4dd2-8ce9-72c21559b9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f061423-05d2-47f1-8403-cff0593d1a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6fef3e5-7d1b-4331-88d6-467fc282b86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2c21db-b65b-46a1-8d42-06e760028c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8b209e-77b4-4899-94be-4a48c15d2101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5851758-e709-477d-9d0a-5b15f615cf40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0adf0831-d4eb-4321-8ede-d2e696f4a2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d06b0a56-7618-4c47-a038-fa22b87ec630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4f135f-4802-4dbc-a879-936364542191
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_58
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_labels.txt

📊 Raw data loaded:
   Train: X=(864, 24), y=(864,)
   Test:  X=(217, 24), y=(217,)

⚠️  Limiting training data: 864 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  208 samples, 5 features
✅ Client client_58 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2534, R²: 0.0000

============================================================
🔄 Round 2 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0924 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0836, val=0.0896 (↓), lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0896, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0813, val=0.0896, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0896, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0791, val=0.0894, patience=9/15, lr=0.001000
   • Epoch  21/100: train=0.0748, val=0.0882, patience=5/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0665, val=0.0926, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 2 Summary - Client client_58
   Epochs: 31/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0694
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0089
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2521, R²: 0.0090

============================================================
🔄 Round 3 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0884 (↓), lr=0.000500
   • Epoch   2/100: train=0.0811, val=0.0884, patience=1/15, lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0809, val=0.0885, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0804, val=0.0887, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0886, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0802, val=0.0885, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 3 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0031
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0038
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2510, R²: 0.0170

============================================================
🔄 Round 8 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0837 (↓), lr=0.000125
   • Epoch   2/100: train=0.0809, val=0.0837, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0806, val=0.0839, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0805, val=0.0840, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 8 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0118
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0133
============================================================


============================================================
🔄 Round 9 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0871 (↓), lr=0.000031
   • Epoch   2/100: train=0.0799, val=0.0873, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0798, val=0.0874, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0798, val=0.0875, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0798, val=0.0875, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0796, val=0.0876, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 9 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0140
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0029
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2484, R²: 0.0348

============================================================
🔄 Round 12 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0794 (↓), lr=0.000008
   • Epoch   2/100: train=0.0817, val=0.0794, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0817, val=0.0794, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0817, val=0.0794, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0816, val=0.0794, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0815, val=0.0795, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 12 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0118
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0106
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2482, R²: 0.0367

📊 Round 12 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0380

📊 Round 12 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0379

============================================================
🔄 Round 25 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0914 (↓), lr=0.000002
   • Epoch   2/100: train=0.0788, val=0.0914, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0788, val=0.0914, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0788, val=0.0914, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0788, val=0.0914, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0788, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 25 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0128
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0071
============================================================


============================================================
🔄 Round 26 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 26 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0104
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0009
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 29 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 29 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0088
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0233
============================================================


============================================================
🔄 Round 30 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 30 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0092
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0185
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

📊 Round 30 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

📊 Round 30 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0379

============================================================
🔄 Round 37 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 37 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0113
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0079
============================================================


============================================================
🔄 Round 38 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 38 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0091
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0078
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0379

📊 Round 38 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2480, R²: 0.0379

============================================================
🔄 Round 42 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 42 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0094
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0216
============================================================


============================================================
🔄 Round 43 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 43 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0130
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0071
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 44 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 44 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0097
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0111
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 46 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 46 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0110
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0089
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0379

============================================================
🔄 Round 47 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 47 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0074
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0294
============================================================


============================================================
🔄 Round 48 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 48 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0123
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0077
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 49 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 49 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0123
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0097
============================================================


============================================================
🔄 Round 51 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 51 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0171
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0118
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 54 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 54 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0076
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0120
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 56 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 56 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0111
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0117
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

📊 Round 56 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

📊 Round 56 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 59 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 59 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0077
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0273
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 61 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 61 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0092
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0223
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 64 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 64 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0151
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0032
============================================================


============================================================
🔄 Round 66 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 66 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0136
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0163
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

📊 Round 66 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 69 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 69 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0154
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0015
============================================================


============================================================
🔄 Round 70 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 70 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0133
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0004
============================================================


============================================================
🔄 Round 72 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 72 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0130
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0065
============================================================


============================================================
🔄 Round 76 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 76 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0106
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0157
============================================================


============================================================
🔄 Round 78 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 78 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0137
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0069
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 81 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 81 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0081
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0289
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0381

📊 Round 81 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2480, R²: 0.0380

============================================================
🔄 Round 90 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 90 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0093
   Val:   Loss=0.0988, RMSE=0.3143, R²=-0.0185
============================================================


============================================================
🔄 Round 91 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 91 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0048
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0224
============================================================


============================================================
🔄 Round 92 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 92 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0154
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0056
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

============================================================
🔄 Round 93 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 93 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0144
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0044
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

============================================================
🔄 Round 94 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 94 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0129
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0052
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

============================================================
🔄 Round 95 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 95 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0144
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0003
============================================================


============================================================
🔄 Round 96 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 96 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0164
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0217
============================================================


============================================================
🔄 Round 99 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 99 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0116
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0130
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

📊 Round 99 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

📊 Round 99 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

============================================================
🔄 Round 102 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 102 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0071
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0165
============================================================


============================================================
🔄 Round 103 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 103 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0091
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0176
============================================================


============================================================
🔄 Round 106 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 106 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0144
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0016
============================================================


============================================================
🔄 Round 107 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 107 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0079
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0155
============================================================


============================================================
🔄 Round 108 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 108 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0159
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0224
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

============================================================
🔄 Round 109 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 109 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0065
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0297
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

============================================================
🔄 Round 111 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 111 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0153
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0077
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0381

📊 Round 111 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 113 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 113 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0056
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0348
============================================================


============================================================
🔄 Round 114 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 114 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0121
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0114
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 118 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 118 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0166
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0164
============================================================


============================================================
🔄 Round 119 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 119 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0146
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0090
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 120 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 120 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0128
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0070
============================================================


============================================================
🔄 Round 121 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 121 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0074
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0286
============================================================


============================================================
🔄 Round 124 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 124 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0099
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0103
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 124 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 126 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 126 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0111
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0150
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 126 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 126 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 126 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 135 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 135 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0196
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0362
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 136 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 136 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0074
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0290
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 137 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 137 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0128
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0075
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 138 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 138 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0125
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0081
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 138 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 138 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 143 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 143 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0132
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0067
============================================================


============================================================
🔄 Round 144 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 144 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0143
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0024
============================================================


============================================================
🔄 Round 145 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 145 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0127
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0029
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 145 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 145 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 145 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 154 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 154 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0000
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0440
============================================================


============================================================
🔄 Round 156 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 156 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0089
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0029
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 156 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 156 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 160 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 160 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0061
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0322
============================================================


============================================================
🔄 Round 163 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 163 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0068
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0314
============================================================


============================================================
🔄 Round 164 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 164 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0073
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0276
============================================================


============================================================
🔄 Round 165 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 165 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0080
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0279
============================================================


============================================================
🔄 Round 167 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 167 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0096
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0211
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

📊 Round 167 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 169 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 169 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0093
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0195
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0382

============================================================
🔄 Round 170 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 170 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0155
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0037
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0383

📊 Round 170 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0383

============================================================
🔄 Round 175 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 175 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0076
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0111
============================================================


============================================================
🔄 Round 176 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 176 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0146
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0017
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0383

📊 Round 176 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0383

============================================================
🔄 Round 179 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 179 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0094
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0158
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0383

============================================================
🔄 Round 182 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 182 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0054
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0313
============================================================


============================================================
🔄 Round 185 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 185 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0085
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0233
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2479, R²: 0.0383

============================================================
🔄 Round 190 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 190 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0126
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0097
============================================================


❌ Client client_58 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
