[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88893934-869f-46f5-a473-9462d89ef0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62517c9b-148d-483c-bec4-13c1eeeed492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa25d50f-34b9-428c-b7aa-b99f27a39a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61e66a7-91f9-4234-9550-503fbfa620d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4bd8bf4-d7be-46cf-92b4-6dd2657f88e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493bcd81-9cdb-4f23-97f5-376242011566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8074c9f9-ad23-4bcd-8637-4fddde74670d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6365edf1-9a3e-4327-a1aa-6df020c9d959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ec0fe8-344f-43b9-bc50-088c5222cd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023b5969-6c89-4bc8-b3b1-3b5ff5137f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a93d34-1c31-41e5-97e1-92cd4dfb57fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f30c8d4-0b44-4f2a-858e-b034ef0fee80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e246772-d3d5-4bb4-ac43-4fadcfee7245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d436e4-7d64-4540-99d1-e5ffbd15b8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 187c470e-baae-4025-9bbe-b015ca26be75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33ce8069-4a06-439d-a464-18439aa36f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4271d1-8c11-4c86-8fa3-34a7a69265b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3984f0ad-2cf8-40fd-9018-7782a401e45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa542c6e-e08f-47ab-8684-662bb372f2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c658fd85-cebc-4740-a153-8442beb24365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dfea355-36c2-4c44-aa1f-262c5b2cd813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d087bfa5-fcc9-4da0-b1de-90c562e45f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd503306-b58e-4a3a-8c07-3754b315df07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message badffe88-7662-48db-b728-305c66a0631d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e341e7a-28a0-42cf-9bbe-ceb665cc2585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068ffba4-9f53-4d3b-b12e-0c06e5d26396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad11f30-6baa-41f1-954c-14ee8dfd981d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf2eca5-d986-4bcd-b822-000c490d66d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1102bcb2-68f7-4c6e-a927-b52fa3c5ed1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 532b092b-3c80-47af-9640-63dee35a4f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da336e2-bbcb-47c3-9733-a4d93e0d2bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8057f7f-668e-4f70-9459-b64249d36fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0936dd-b107-4477-9b5c-163d0866099b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9623738-ccaf-49b8-93a8-7ca92ff53416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b8b4319-1547-4dc9-a8b2-40c960affa0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 241d6322-b094-44a0-b1f1-ae88a11cd0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab679e01-ce11-48a8-857c-2f9af42a9817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a11508-b681-41cd-92e3-815edcd0963e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967dcbee-0b79-49c1-b73f-f5f117e1b59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393670eb-f1d7-4d69-8982-baaf9ccfab0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8b168b-f506-4ed4-bce8-09b0b2b39f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1314de4-9fb8-44f1-a4ec-938c6c71d47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b7bfd5-15f5-4d03-a7af-a4522000d0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2040cce8-45f9-4b3d-90fd-c5cb7f2e4565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2871e4-7f72-4d81-88c1-afec934e91fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5079c20d-e232-46d2-b236-3466b81671a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a7b51f-91b1-48b4-980c-a59212017ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f0dd0d-d3d7-4d50-8756-51385a09417e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926d7235-c874-4577-b939-9d1ebc4cd1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967ad4e5-11b5-46a2-835c-f765210c8742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ade4c3a-aa36-41ec-a004-018c05ac0728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c70f56ee-6c01-4998-a378-d26eddde879f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acbf0203-5173-417b-917c-3f4b8bc14c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec03e4f-bc18-41ff-98d0-bb33896615ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a88a6bf-36ef-4d57-b687-f3757fbc8299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe92f6f5-6e13-4155-bf7e-660f3635434b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d152f9e-b896-4c77-8dd8-ca4cc98f827d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4d0590-84f1-495f-acbe-a059718bf126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31bac0c7-1ebb-44fb-94ee-d43a5222197e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f07ab88-69ef-43cd-b745-7a1eb74f87e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a4ce9e-8bfe-4421-b711-f1af7e6e0cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a10458b-22bf-41ba-84be-b4fe24fb31bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cfaa419-688e-4cb7-a9e2-ada41b6fc55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2b3920-4ef2-46e0-a7ee-27d955beb639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e2a655e-5da3-450c-8f72-304e745da597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a38a3a-049f-4e64-a452-e47359c15a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac6055d-d29a-4316-9c4e-7bdc0e2523fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53c4126-bae5-45d6-ba46-af929b978eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3454af-c82e-4397-8ada-7d93be6e3cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aab9903-fc96-4a16-b746-6f656aea3bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de752ac-c312-453f-ba87-5c145c0edd67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327507ad-e674-4ab1-9b8f-d93fa646ac8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 541ffc23-7767-4dbf-b3e6-27599f1b4754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b01654b-eff0-4d87-8db3-e00983629b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa83ef88-3e5d-42ff-8798-94af10b50c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10c74bc2-d089-4233-89ef-b11d69c6222c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adf9191a-77b6-4656-b758-bece87fd87ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3e24f7-be0b-46d4-b381-7a37e09405d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45596fc9-bf25-49cb-b358-c36d0a8698cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2d872c-c965-4816-af71-d9dab12dd8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ff12ea-a7ff-463d-90ec-c71fbd31de2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b07343-e0e5-4be3-9bce-158021472868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38030234-5b3e-44ad-9c45-1626c09626f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50f6f89-b844-4de2-acf9-776a235af91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b29a0a6-7207-4654-9649-0c8c48e8fc79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bac2fceb-206e-41e8-927c-e828d606d675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b53aaa-c940-4df8-8d9b-9b94970e1fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7517da-e496-4f63-93fd-24bfd2589fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cbd0d79-4d2f-49c0-8308-964d3bd071b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4885b2c3-4810-4e4b-ac9b-fe7ef15e96bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b6a22ff-ce51-4f56-9a2d-a28132b0e270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5237281-40fb-438c-b629-4739bcfc8c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd87a390-cfb2-4053-ae97-67df987022b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e5c165-c9ba-497c-ae17-13293cd9526a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e94041c4-3ec0-470d-9c6f-77689478b161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ac8947-795f-4a2d-bee7-f498825be0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1415220f-8b41-48dc-b223-e029c1a2d0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47ca8a2-6362-4201-9ecd-730205915b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b126cf00-71e3-4baa-8a0f-0dfaacc6f291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4661e49-2b8f-4ca0-b8ac-2efd85d2d657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db408cd5-2752-4fe4-a528-eee053d3c54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2e4eb1-a725-4cb0-9588-6fd22aa32187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e2fe83-cbce-4d9a-ab34-15d4cf3054cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9af125e-d4db-46e8-9026-b99e95de5add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d16a5a86-0bdd-43c0-9398-c4ace51379fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173941c7-f1f3-4700-a2e1-d7a8dd906bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f91454-3b82-4c66-a371-cf42d6290794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba2a5832-48f1-4fd0-ba75-70c4bb4c1b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f0b996-082b-4150-8568-18efaf14c3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942e8d6f-7165-49bc-b6a5-f16803392772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed3d636-7cbe-4364-8b1b-e8c47efc1c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562cced7-57bd-4a0f-beb9-63a79ede7edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ebf8f4c-96d0-4d8d-8749-b6a04b2f0f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec347cd-b907-49eb-9a21-aff29f1c0901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22e7a2c9-a3bf-4790-aca8-0f6e610be7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f302a1aa-f0c5-4bce-9a27-b7e11b94a648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51169b9d-cf86-4a94-9072-1a047340d897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71101edc-a4ea-49c4-acf5-ec31a64ffbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecef402-b189-4bf5-91d5-d271fc09c44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc0a0a57-977c-423e-a688-c32590008c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50294b85-4be6-4d7f-a262-fd107871e5af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754f0590-f7b5-470e-88d8-a2026757aa49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71d144e8-b5f3-4d1d-b65e-670cd620bf35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950419ab-681e-475d-b6c0-556e62e09e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e5e175-306c-45c2-8f16-725b23c72b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b15ad4c-6931-46bb-8b01-7ee9dd60454f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8404eb6-f824-42ac-af0a-63ecc1a05889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a29118-1a7a-4404-b0d5-606a38e46dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a21455ff-eeec-4c13-912b-41ae0f4f494a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c7b527b-0555-4f89-b08e-f5c5f692c6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 934e3798-8308-4d4b-bc97-e3fdca8f1198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c8ec07-2511-427f-8232-6cd0e5468083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a04616-c338-460e-9757-d42e63b1b329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7a410d-8b26-4a28-adcd-ca5da0a81bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3627a4cd-f353-4f72-b764-d1d4e2d3a328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194efd43-8c19-4fd5-a9ee-c0edd72470a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef45f54-7d9d-43d4-900d-405eb90e7f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f564a6-100c-463a-8d77-8b184fd577c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d4d3157-8b22-4881-8fdf-33c40bccfdd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03470cd5-8440-4d5e-b90b-84681eab139c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18272a83-8b2b-4b3f-ae60-4aa699c5b425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57313cd1-5273-4c6c-bf7f-04f981b26b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a372f927-6ed5-4e38-918f-4f45c1cb579b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6f39f7-1a88-4ba8-9498-0cfab8741a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b469a44c-6f56-4498-aa32-ce6c11e98e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92763083-e6f8-4542-a97a-1d6ed939fa84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df48d31-bb77-48cd-953c-e1dd4d80b324
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_59
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_labels.txt

📊 Raw data loaded:
   Train: X=(1113, 24), y=(1113,)
   Test:  X=(279, 24), y=(279,)

⚠️  Limiting training data: 1113 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  270 samples, 5 features
✅ Client client_59 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2520, R²: -0.0168

============================================================
🔄 Round 4 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0709 (↓), lr=0.001000
   • Epoch   2/100: train=0.0843, val=0.0708, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0842, val=0.0708, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0839, val=0.0707, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0837, val=0.0707, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0831, val=0.0705, patience=10/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0797, val=0.0710, patience=9/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 4 Summary - Client client_59
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0169
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0152
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2535, R²: -0.0296

📊 Round 4 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2538, R²: -0.0319

============================================================
🔄 Round 8 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000250
   • Epoch   2/100: train=0.0816, val=0.0809, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 8 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0090
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0109
============================================================


============================================================
🔄 Round 10 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0786 (↓), lr=0.000063
   • Epoch   2/100: train=0.0828, val=0.0785, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0827, val=0.0785, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0784, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0825, val=0.0782, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0821, val=0.0780, patience=5/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0820, val=0.0781, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 10 Summary - Client client_59
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0063
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0168
============================================================


============================================================
🔄 Round 11 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0852 (↓), lr=0.000016
   • Epoch   2/100: train=0.0810, val=0.0852, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0809, val=0.0851, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0809, val=0.0851, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0809, val=0.0851, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0808, val=0.0851, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 11 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0188
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0089
============================================================


============================================================
🔄 Round 12 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0803 (↓), lr=0.000004
   • Epoch   2/100: train=0.0824, val=0.0803, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0824, val=0.0803, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0824, val=0.0803, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0824, val=0.0803, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0823, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 12 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0182
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0179
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2554, R²: -0.0462

============================================================
🔄 Round 13 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 13 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0229
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0027
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2554, R²: -0.0459

📊 Round 13 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2556, R²: -0.0480

📊 Round 13 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2556, R²: -0.0481

============================================================
🔄 Round 18 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 18 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0177
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0292
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2556, R²: -0.0477

============================================================
🔄 Round 22 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 22 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0224
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0140
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 22 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 22 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 27 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 27 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0149
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0503
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 28 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 28 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0142
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0455
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 31 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 31 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0267
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0055
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

📊 Round 31 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 35 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 35 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0208
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0284
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 38 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 38 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0261
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0044
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

📊 Round 38 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 42 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 42 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0203
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0225
============================================================


============================================================
🔄 Round 43 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 43 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0243
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0021
============================================================


============================================================
🔄 Round 44 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 44 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0146
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0412
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 46 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 46 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0267
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0013
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 47 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 47 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0241
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0340
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

📊 Round 47 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

📊 Round 47 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

📊 Round 47 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 53 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 53 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0154
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0396
============================================================


============================================================
🔄 Round 54 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 54 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0221
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0130
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 57 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 57 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0230
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0232
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 58 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 58 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0135
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0580
============================================================


============================================================
🔄 Round 60 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 60 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0222
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0101
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 62 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 62 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0242
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0085
============================================================


============================================================
🔄 Round 66 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 66 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0206
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0204
============================================================


============================================================
🔄 Round 68 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 68 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0198
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0214
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 69 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 69 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0180
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0467
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 71 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 71 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0199
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0319
============================================================


============================================================
🔄 Round 72 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 72 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0283
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0074
============================================================


============================================================
🔄 Round 73 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 73 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0219
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0141
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

📊 Round 73 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 77 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 77 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0220
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0177
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

📊 Round 77 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 85 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 85 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0164
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0339
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 87 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 87 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0241
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0131
============================================================


============================================================
🔄 Round 88 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 88 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0112
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0599
============================================================


============================================================
🔄 Round 89 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 89 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0182
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0308
============================================================


============================================================
🔄 Round 91 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 91 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0184
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0340
============================================================


============================================================
🔄 Round 92 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 92 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0232
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0093
============================================================


============================================================
🔄 Round 93 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 93 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0176
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0319
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

📊 Round 93 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

📊 Round 93 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 96 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 96 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0213
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0204
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 97 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 97 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0263
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0127
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 98 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 98 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0195
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0224
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0473

============================================================
🔄 Round 99 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 99 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0140
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0465
============================================================


============================================================
🔄 Round 100 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 100 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0196
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0378
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

📊 Round 100 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 103 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 103 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0270
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0005
============================================================


============================================================
🔄 Round 104 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 104 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0205
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0192
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 108 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 108 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0253
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0063
============================================================


============================================================
🔄 Round 109 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 109 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0242
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0113
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 110 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 110 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0173
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0349
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

📊 Round 110 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 116 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 116 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0261
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0023
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 117 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 117 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0270
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0083
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 117 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 122 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 122 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0255
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0047
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 122 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 122 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 122 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 127 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 127 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0212
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0194
============================================================


============================================================
🔄 Round 128 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 128 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0189
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0266
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 130 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 130 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0164
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0381
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 130 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 130 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2556, R²: -0.0475

📊 Round 130 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 130 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 142 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 142 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0223
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0119
============================================================


============================================================
🔄 Round 143 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 143 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0181
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0280
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 144 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 144 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0211
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0161
============================================================


============================================================
🔄 Round 147 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 147 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0191
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0243
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2556, R²: -0.0475

📊 Round 147 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 150 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 150 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0130
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0728
============================================================


============================================================
🔄 Round 151 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 151 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0212
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0158
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2556, R²: -0.0476

============================================================
🔄 Round 158 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 158 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0208
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0286
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 158 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 161 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 161 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0252
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0197
============================================================


============================================================
🔄 Round 162 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 162 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0214
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0302
============================================================


============================================================
🔄 Round 163 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 163 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0147
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0436
============================================================


============================================================
🔄 Round 164 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 164 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0235
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0060
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 166 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 166 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0222
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0146
============================================================


============================================================
🔄 Round 168 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 168 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0163
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0363
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 169 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 169 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0288
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0006
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 170 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 170 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0098
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0682
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

📊 Round 170 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0474

============================================================
🔄 Round 174 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 174 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0231
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0081
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

📊 Round 174 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 183 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 183 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0245
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0309
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 187 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 187 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0157
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0577
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2556, R²: -0.0475

============================================================
🔄 Round 189 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 189 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0168
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0375
============================================================


❌ Client client_59 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
