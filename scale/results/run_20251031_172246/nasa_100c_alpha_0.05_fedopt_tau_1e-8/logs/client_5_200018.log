[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255823ba-1f7f-448f-9acf-61205f4b2bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c61a4a-9e8e-44e7-8e79-5193f8cb0d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9740d47-6fab-4705-9134-6ca500abbdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6805eec-68bc-43c2-95a9-72f6f3034dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77b7004-7899-4701-9a42-7146aed2f0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2493a40e-fa29-4ba6-a9df-f418345d6da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d617ca05-5431-4519-9d9d-3d23edfde05b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39fab432-bfbc-4b87-9e38-0fcd9aad0ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8b6cab-75fa-466d-a63f-553fc3c9143f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 566688f1-91ee-4dba-8b0c-b0206b10c934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39e18380-554e-4c36-a3e4-a2fdb61be03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94fae8ca-72a2-454a-95ec-255b6e2c7724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6063c818-0521-4a2a-a7ae-266468a01a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ac72b0-3f75-45c3-ad86-5dd6193a6bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a04781-4e15-467f-b0a6-1912700e6a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18e7639-7f81-4343-83ee-5bbdc876f914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 505d6583-dac8-4858-8510-f91ac75a7c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327c1c8a-cdf3-4918-8880-1703a9dd6bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba500f81-124f-448b-949d-ad7d79b776da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea1e71d-e84d-4f9a-9bce-17438782bd05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56451c82-dc00-4e19-a586-dc9b566e240b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f2a2f9-ac91-4cd3-8722-84c61ea8bc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c642d26-86f7-431b-b258-45c6b99f7dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea746d19-3b15-4cb6-9db0-a606b619b1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a02d951b-6ea5-4dad-a89e-4ae852df16ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274ed509-bea4-40b9-98e1-3089a2b93ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a6a816b-113b-4762-8bd1-c677700ec9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea71f3f6-196b-4167-bfad-7e8bf1494d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f5ae491-a5ee-4685-b7a9-092ba05a104f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe7cbb7-0d93-4439-9ecb-0ee19fb5c9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e4e7d30-70ef-4848-ba3e-20ac4e2a3aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53bf0282-37fa-4201-b359-34470cc34957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76df0af1-280f-4297-b167-84f9d9f657c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d7cdc5-7bbe-448c-848b-94fe6c9df2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b335587-3b3a-487f-866d-b4af4b612cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b59574c3-6004-4a75-8cb0-fadbc5414dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8859591c-1700-4a45-80ef-853dc68ea762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b0102c6-b7d5-4b33-9885-32b2143081df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a7d861-61cc-4ad3-8d75-0570572af0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9c4cf0-d4a2-40e9-9874-0c54ce4b13f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e99f7a3-afb5-4e81-811c-0935316d20ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c58f4a1-338a-4d60-a29b-4389c0e0fb5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bd4370-81c7-434d-8db3-1b936633170c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33236db-2a25-4a39-828f-29019aaa7ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83dc16c4-293d-41ca-bac1-d32d864afc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb8153c-5146-4c41-af40-fb44d2e91915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd9ad0b-3cb1-4cee-9bf5-03c199f61d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b038455-bfcb-4ea3-a914-841990ba4c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe9cee6d-4e98-4dbd-86b1-0d4bda82dac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92c9c4e1-ac6a-458a-b81b-48cd52327307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc80bad-d01c-4f12-97fd-a6221e3a310e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35c87fc-8cc6-4f03-b5e7-66aa133e41ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a758f05d-76b6-413f-8f2e-d63e20f93794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3132eef-9fbc-4bf1-8654-d18e9aeb766a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7eb1e2f-a9ed-4000-861a-37b07b519e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2affbf0a-605d-4163-9077-f8967e3bb1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56230cf4-2ef9-4be6-a6fb-09a9ba2c8da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a649f2f0-26c0-4692-89a4-3972c7d1a15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713e7c9e-f916-4267-a46d-54bb021a6d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a29865-1892-4599-bd07-b8660f9bd17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66dfc235-0d37-435e-8089-9baba169c3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07dfe796-c561-4520-a436-afcd454dee52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a2b92b-a869-4230-be99-f9ea8e303de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a7df9d5-1d84-4a4b-ae09-963c6a1e2c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aeeb0ca-88d9-4e8d-8c10-e8f4efd9b040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aadbc1d2-9ce2-43b5-b214-5da0757b05fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d34c62f0-4cb7-4858-9ac9-0b0e2e53dfcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4cdbf74-e24c-4f3d-9010-f85c1340e77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d012b3b7-73fc-4e71-b2d9-c4f69bb281aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6356a88-b653-49a5-bd59-986225889931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b10c55-e27e-4fe9-aadb-f4fb28b6d085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9569c2e-4ed5-4a3f-af47-1cff11744cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e869e874-db11-440d-a888-953fe2d228a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff93c717-1808-4425-9274-3870bab3f566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0398a83-5a55-4bcd-a920-85e1f5f690f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64f5e883-bc50-460e-aac9-192d3b72fcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a415d628-c400-4472-a9ac-291225bc216f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adeaa3d-aa2a-4b03-ac87-d77fb8e0fee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bb65e7-79eb-4f20-9e12-48d35524ad14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6b8a7d-edd8-4958-90fe-f9ce8bf897ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ed3c2d2-451c-4058-b978-e50598fb723d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676ee8a8-3cb2-4a6a-9ef9-bb22a2795a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0706c5b-7fe5-4f5b-85b9-bbbbe9228614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a684074-d198-477f-8f04-8242aa81e496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c943e435-b4f0-4eaa-ba0a-d4de8083b4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e0e051-4252-443f-ae29-3e5daf4550f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96665df4-11ea-41e6-a24d-ddc9afccf5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1389aec-c393-4edb-af85-e555f2926020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b385cc-f679-4ad3-869c-9193ff737ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f920b07d-f76e-4e73-983c-72d04f9e9e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a681eac5-ad60-47c4-a704-dd7a8168ba64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5052e974-f8d8-463e-acaf-cd7b27beb389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac0edd3b-0628-41f4-a1a8-9db68c5af97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2aaedf3-41c4-4f8b-9087-94ff328c70ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78bb3189-e103-4a43-9709-958845450d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18edc3a5-89b2-4e43-8e49-4d7e4a950f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7b3262-b7dc-4da7-aa00-343b0b752dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c06120c-1190-42f0-94ab-6b62564ac237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db98178e-b9ac-4f47-b8ee-f3cefac9986a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c600dbf9-9fe5-4255-98e0-bf858a6bf049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b10c16c-1a0a-4e79-b0af-732a87fb41c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22721079-463b-476f-8fe7-6bc5aa9ddfa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d3698f5-deec-4c8f-b441-4a423c59e7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c21e20-aad5-4964-848e-722e179109f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af03bf1f-4fd8-4221-a587-77ce65f9e2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a15bd7-2c5f-4f45-a7e5-cb1f518c91d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 269b2526-c57e-41a0-8581-63b103cb6dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4122ff19-159e-4405-94b5-698269859d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca601d3-0114-4ece-b503-a80b352e4e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94b9857-d92e-410a-b16c-55ee8a42cbff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389dac56-5aab-4ea8-a9d0-fc6d50464485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36cfefef-bb1a-49c6-85d3-73984533a8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ec11a4-8f6a-48a8-a95d-4f4d8fac6c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3ea7a6-0c9d-434f-9ba0-4fc2ca15f180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d42900-eee5-4b81-ad63-e821d3cc656b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f231277-cde7-4a04-87cc-01cf64cab666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f6553f-517c-4550-b5d2-b06955ed38a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2384b3c-febf-4499-926d-7ac492ec8e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e44298ff-9194-4583-bb57-f403f25ee99d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63e43d7e-b5e5-4573-bc4e-a1c5afac87e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db452d86-d9e0-443d-880e-211a97fbfaf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fb1b79-3ae7-471b-bc0f-f53b9a836342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eadd700-7a5e-467f-82d5-e9c6e41a19c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1782fbc4-12e3-4801-b705-569cb6b353ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5124c6e9-a5c9-4905-a845-fa7f4290f8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5182035f-6d00-4345-ad75-ebaa965aa56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ec48a3-7a09-4cee-9a6e-4f4a7fd5ea18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bb38a44-6a3e-4bae-9d5d-f1d45a32eedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e408353e-540d-40fc-9092-94badc96b5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0715d24-fc52-4dbd-8674-c1c23bdb7a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ebd1ee9-ec78-4154-b86a-42810891d557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e76c167-3479-4c30-9597-bad88de56b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e67d6cb-057b-4068-98a5-007ea62de231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 825fbd69-f680-44fd-b569-54342047b869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 105fe34c-0d62-4f07-9457-4188b6a485fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30bfaca4-addf-4a1a-88e4-307a85a9b03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ae2f33-3867-4de8-9b82-ee3421812af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5fa29b5-b29a-4c0e-bc73-3f4835d54aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3872e0d4-fddb-4486-95ff-b00dbd9444f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199c0c57-b93e-4653-bd72-bc80cbb7e41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b06dbb-034a-426c-a13f-80984c5e18f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818c6084-531c-460f-81ef-38729af27e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb812b0-9cde-4104-96bd-338909d2fe12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847226d3-c143-4d9a-a0ed-36032d8be30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cc1778-8b6b-45b2-8522-ad38a9954e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e920034-54e5-47d4-bfe6-2e55f5f0758d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7982d2ef-f22c-4aed-8cbb-f2cb32a4c433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb5289b-c93b-4b4b-89f8-f7c467491fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9eb1d92-1d08-4358-9e29-2f2771d3673e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0497b5-c813-4ba1-9f1a-c54d3dffaabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93659357-caec-4151-a258-dfbb31c4d984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195aef80-1c49-40e0-8d6f-b0631a3e90a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 478f15fb-4f85-4a5b-ad66-52b87fe80a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3e83b3-952e-4dc9-a4ec-732b5ce0b73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b11d34ff-bf6e-48d9-b8e2-8a61b0592a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d023e918-109d-436a-8d8f-fbccc56abb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c36158-a23e-4eea-b4c5-9f15269832a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff57b69-95af-4911-b797-fa8adbc04506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19826e4c-4d2f-42f0-95e0-3576e17fdd0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d8e136-2988-41c0-b483-ffb4f22a8a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10a89c8-2df5-484d-92c1-a54890b6d006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 762fc2ad-fd40-4296-b782-3d749035c638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03aac688-881e-430a-a185-36ccd675130b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(660, 24), y=(660,)
   Test:  X=(166, 24), y=(166,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 651 samples, 5 features
   Test:  157 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2443, R²: -0.0100

============================================================
🔄 Round 3 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0921 (↓), lr=0.001000
   • Epoch   2/100: train=0.0853, val=0.0947, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0835, val=0.0912 (↓), lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0923, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0827, val=0.0919, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0807, val=0.0916, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 3 Summary - Client client_5
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0019
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0159
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2452, R²: -0.0143

📊 Round 3 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2449, R²: -0.0137

============================================================
🔄 Round 5 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0859 (↓), lr=0.000250
   • Epoch   2/100: train=0.0839, val=0.0860, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0837, val=0.0861, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0836, val=0.0861, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0830, val=0.0862, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 5 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0082
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0138
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2448, R²: -0.0138

📊 Round 5 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2456, R²: -0.0180

📊 Round 5 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2459, R²: -0.0207

📊 Round 5 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2467, R²: -0.0261

📊 Round 5 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2465, R²: -0.0252

============================================================
🔄 Round 11 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0865 (↓), lr=0.000063
   • Epoch   2/100: train=0.0876, val=0.0863, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0873, val=0.0863, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0872, val=0.0863, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0871, val=0.0863, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0868, val=0.0863, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 11 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0211
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0285
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2468, R²: -0.0270

📊 Round 11 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2468, R²: -0.0269

============================================================
🔄 Round 15 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0822 (↓), lr=0.000016
   • Epoch   2/100: train=0.0870, val=0.0822, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0868, val=0.0823, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0867, val=0.0822, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0866, val=0.0822, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0862, val=0.0821, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 15 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0293
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0242
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2468, R²: -0.0274

📊 Round 15 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2468, R²: -0.0275

============================================================
🔄 Round 18 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0770 (↓), lr=0.000016
   • Epoch   2/100: train=0.0892, val=0.0770, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0890, val=0.0770, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0889, val=0.0769, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0888, val=0.0769, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0883, val=0.0770, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 18 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0318
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0089
============================================================


============================================================
🔄 Round 19 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0930 (↓), lr=0.000008
   • Epoch   2/100: train=0.0868, val=0.0930, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0868, val=0.0930, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0867, val=0.0930, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0867, val=0.0930, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0865, val=0.0930, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 19 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0306
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0267
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0279

============================================================
🔄 Round 21 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0947 (↓), lr=0.000002
   • Epoch   2/100: train=0.0851, val=0.0947, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0851, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 21 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0230
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0470
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0279

============================================================
🔄 Round 22 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 22 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0308
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0230
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 25 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 25 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0293
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0256
============================================================


============================================================
🔄 Round 26 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 26 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0223
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0559
============================================================


============================================================
🔄 Round 27 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 27 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0339
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0171
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 28 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 28 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0271
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0370
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 32 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 32 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0298
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0603
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 33 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 33 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0295
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0350
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 34 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 34 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0270
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0423
============================================================


============================================================
🔄 Round 35 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 35 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0281
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0369
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0279

📊 Round 35 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0279

============================================================
🔄 Round 37 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 37 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0324
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0209
============================================================


============================================================
🔄 Round 38 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 38 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0286
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0609
============================================================


============================================================
🔄 Round 39 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 39 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0350
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0040
============================================================


============================================================
🔄 Round 40 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 40 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0385
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0214
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

📊 Round 40 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

📊 Round 40 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

📊 Round 40 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 46 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 46 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0253
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0750
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 49 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 49 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0310
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0221
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 50 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 50 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0328
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0140
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 52 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 52 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0264
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0483
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 54 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 54 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0295
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0247
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 56 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 56 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0255
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0390
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

📊 Round 56 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 59 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 59 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0332
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0100
============================================================


============================================================
🔄 Round 61 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 61 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0324
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0835
============================================================


============================================================
🔄 Round 62 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 62 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0269
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0336
============================================================


============================================================
🔄 Round 63 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 63 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0251
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0425
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

📊 Round 63 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 67 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 67 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0342
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0098
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

📊 Round 67 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 71 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 71 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0328
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0223
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 71 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 74 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 74 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0280
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0355
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 77 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 77 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0218
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0546
============================================================


============================================================
🔄 Round 80 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 80 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0226
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0572
============================================================


============================================================
🔄 Round 81 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 81 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0326
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0200
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0283

============================================================
🔄 Round 85 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 85 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0210
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0733
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 89 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 89 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0283
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0288
============================================================


============================================================
🔄 Round 90 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 90 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0269
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0340
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 92 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.1042 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.1042, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.1042, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.1042, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.1042, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.1042, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1042)

============================================================
📊 Round 92 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0301
   Val:   Loss=0.1042, RMSE=0.3229, R²=-0.0320
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 93 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 93 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0311
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0177
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 94 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 94 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0322
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0254
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 94 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 98 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 98 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0268
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0343
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 98 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 101 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 101 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0295
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0312
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 104 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 104 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0260
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0380
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 105 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 105 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0256
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0490
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 108 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 108 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0309
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0214
============================================================


============================================================
🔄 Round 109 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 109 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0338
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0186
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 111 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 111 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0278
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0309
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 112 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 112 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0360
   Val:   Loss=0.0893, RMSE=0.2987, R²=-0.0000
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 112 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 112 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 112 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 121 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 121 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0265
   Val:   Loss=0.0991, RMSE=0.3148, R²=-0.0358
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 125 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 125 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0304
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0286
============================================================


============================================================
🔄 Round 126 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 126 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=-0.0306
   Val:   Loss=0.0698, RMSE=0.2641, R²=-0.0198
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0283

============================================================
🔄 Round 130 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 130 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0315
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0330
============================================================


============================================================
🔄 Round 131 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 131 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0250
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0415
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 131 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 133 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 133 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0269
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0368
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 133 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 139 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 139 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0201
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0624
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 139 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 142 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 142 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0346
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0045
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 146 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 146 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0233
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0486
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 147 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 147 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0337
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0039
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 149 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 149 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0392
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0155
============================================================


============================================================
🔄 Round 151 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 151 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0293
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0272
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 153 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 153 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0248
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0432
============================================================


============================================================
🔄 Round 154 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 154 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0315
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0286
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0280

============================================================
🔄 Round 157 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 157 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0286
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0309
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 162 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 162 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0296
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0532
============================================================


============================================================
🔄 Round 166 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 166 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0271
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0388
============================================================


============================================================
🔄 Round 167 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 167 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0316
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0183
============================================================


============================================================
🔄 Round 168 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 168 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0298
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0266
============================================================


============================================================
🔄 Round 169 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 169 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0313
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0174
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 169 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 172 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 172 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0228
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0534
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 172 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 174 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 174 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0306
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0417
============================================================


============================================================
🔄 Round 175 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 175 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0329
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0115
============================================================


============================================================
🔄 Round 176 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 176 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0291
   Val:   Loss=0.0987, RMSE=0.3141, R²=-0.0784
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 176 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

============================================================
🔄 Round 180 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 180 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0242
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0470
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

📊 Round 180 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 184 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 184 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0303
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0403
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0281

============================================================
🔄 Round 185 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 185 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0305
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0258
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

📊 Round 185 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2469, R²: -0.0282

❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
