[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6374133b-9a6c-4baf-a992-41716eba9ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce18b5cd-5e85-41b9-a8de-49a8f926366d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0dc675c-eef1-4d12-9501-bacb2d484eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563c5f95-36d1-434b-a4e6-f462e5e01322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48736688-107c-4ba6-8a86-740d6dc4b3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 883f6f86-394a-4b4e-8ec7-91b677d4059e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917b27fe-1fa8-4c44-81a4-c3369efd78c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aef8978-4fab-49ef-9493-b3770d20b3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde57188-c4f1-4f46-b647-590c7c10c2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8eb8fb1-281e-479d-a12a-a2851ad18d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77eeb8c0-0a24-4072-b803-22aa662c9109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad9bf0c-0684-4765-90e1-ab1f6c9bbf99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f5bb0ca-5623-4a70-9b71-d02bd0fa14e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e95bd19-3005-4080-a651-82fa801a4b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9622bb8-3687-4c49-aec4-4edc1d20535b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ef380b-79ed-43a7-b927-fe5529f3be5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dcaa8df-6162-4b94-b380-60adbf5e2356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9a1b06f-9041-4ab0-8439-d4263d51a007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f11e83-f162-417f-8378-f53287a0ea77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc3aebf8-61c6-41fe-98e4-5594b1b22f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c851b015-2a4b-4473-af11-47b4d16e5296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e0842f7-4df1-41a1-81ce-c54992fe33a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98900e7-076c-4df4-97bf-4ab1d3b8945d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f20311-5095-443e-b5c1-95f18fdedcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58719c8e-191e-4ec8-ab95-06cbbe55d59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4bbd86b-2c92-467a-84b1-9c4d4df8f0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4329c0-489d-4975-90e4-326cc05b82e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309ec28a-3644-43bf-aa0f-a73e4de0c623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d238cf-99c2-470a-ad25-d90bce6c9eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d150ef06-8f98-44b9-8986-10736e648343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee81edb-e810-4cb1-9c10-a1bef30b9819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff877a8-f31a-4d76-9203-af9909a4f9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 753f24c5-fcf0-4ca5-9c65-3cb90a3f9986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea07ee1b-2f3a-4f81-9537-ef36a1055eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a04558a-b203-4ee8-b2e5-133ba09d4963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3967c009-e784-44f8-b6fd-069da39d841a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33fbf67b-2b25-432f-9263-2bf7a5e4aeb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8fbd1a6-6459-492d-bb88-46ffdee304d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d230120-48b3-467d-a625-86e820ee67bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61f4d55b-c0e9-42f2-8c2c-e72b4514103b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb31add-8553-49c7-bc90-c072f38cf70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062d498f-e4d0-4c23-903e-9e6e8f91a672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc07827b-7ef5-43e9-bbad-df15df620d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6a6ba2-c204-4546-93e6-c34c0c20a281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915f0ee0-64c1-4bb0-a868-28a695ecada9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 652cdee6-2af4-4bf3-9752-58345ef59383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4f48d7-6fa2-4ed5-81e7-c99053d3562a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 750d4c9c-cbe2-45ab-bcb4-701b0c14f2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488df978-0d6e-4f56-9bc6-2050baff6974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b8ef0cc-8a49-4397-8cf6-f9650dda6dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65596f0c-1d70-42ee-8dfa-db9deca6f3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d78d03-6246-4fa7-8e48-71486ef72a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c142401-8d66-4161-9f47-a50e974145c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf709c4-2157-45fb-849d-5bf3664fafea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d4c3e2-80ef-4bfd-80a9-c5b5ea46b767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d036e40-6b07-43c4-8a69-cb5d08ec2b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 207f6cfc-f8d2-45ca-8ffc-a7908ee9f508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9df23f1e-446e-4f44-9da2-ef7bdefb1dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769ae767-84ca-4e62-b6cb-a8d7490f762b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe56dbb-ccdc-41e0-8ea2-d8ca542f0f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de21667-5ac4-4c5f-9bed-70e7ae7d7bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b7a883-71ce-4558-8e93-a0a8484eaffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297cdd45-f2f6-4853-98f6-4a0dcfe90072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04002eb-40b2-4aa4-9af0-7fe1847696cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e292df18-0bf7-4363-912f-c296b030c475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a8f9e5-60ca-4d12-a8d9-04b89ca49231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f84d99-bd3d-471c-a0d3-cb625047befb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afcc70fa-b23b-49eb-8475-41d94818d52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e1f512-ca40-439f-a952-c20a6a264ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 232e35e7-598e-46fe-8d80-8e10198f16ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 293d20eb-9c1a-45e4-b726-9ac9bd5fb39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d49837a9-3255-481d-8a8a-0770e875b8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20e2f471-d599-4bcf-b052-5325ceb04e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b92969c-3889-4969-92b3-0a340accb878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b360aa1-b6db-4246-88f9-e5509f77c4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2683dcd9-60c5-45e7-b871-cf3664ea9a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f25fce-ea1f-4bc0-aee6-cb2f266792cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7fd719d-ec03-4e8a-9071-d122da3040d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef135c4-143a-42f1-a002-24b6a9365f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a5f373-4190-4be2-afc6-3a4110175c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c88c6b-a831-4fc5-896d-2d52c02916cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e22b07c-171e-4281-bfb6-8b7a690e5da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925a52b5-271f-4ed7-9523-7609677331bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe83b71-81e3-4bc7-8304-e1ce61173c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8256d17e-7c14-4e4a-8a90-722d94e62853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3df43e-3b4e-4f10-81d9-8cb1d2197942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ebbcb1c-1af9-465a-a107-9ff5331e0917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22d97037-f184-48f1-8d77-88ce385736df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92420095-f480-4fef-b507-5b40f9d64c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3527a5-0aec-4fc9-a189-dba0efd1945f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a7add09-c2c4-4f5b-bc8c-6d4f9e09980d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f040cc39-1fa1-4c39-a0fe-b74331bfd5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3d6ff5-0c7c-447e-88ac-90dd81ca9f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f673e7-951d-4060-925d-94476be6e6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd49cfe-19ce-4111-8e5b-8bae529e38ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 581eeb95-2d33-4876-b180-b1131c3dd1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09e5512-d4de-4bd0-973b-5616c851fdbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145802ea-f775-421f-948b-d795b30ab5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f84482f6-3835-481e-b48f-ebc26e55aaa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a8c16eb-d8e6-4467-90c5-20d31b0eab54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d76acc5-fde8-4992-bfad-f657bb9aa97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d52f5a8-86db-443b-9a26-e2daf373c518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d899a4-d0f1-42f1-bbbd-91cf693938d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45d7d72-f79c-4cd3-a261-c59bb4976963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d36c9d-587f-4220-ae5f-aa94624f1c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac33b10-2373-4b37-952a-36be9733efac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037e163a-2e17-46a3-bd82-4cb6c2de3216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a0ed27-5550-4689-8134-517b4e32425f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f24c96e1-1fae-4b96-854c-e8b32f1020af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440c12cd-aa1e-498b-844c-4717cf7bd213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0011f848-09e4-4e1e-9557-91994bf5ac2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e5cd3b-88b7-4b12-911e-620e6197121b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2206059-0bb4-4fdc-a27b-f1e8841de9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d276aaca-ac7b-4771-9646-291651bb4d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49947083-5e98-4753-9045-9c04504e5e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8473ba-7569-480d-b6af-df1aa9048c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05fac241-608a-405d-b2d7-aca78e8841b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82899c07-19fb-47ea-b9ee-1ab2e8eceaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14bdfd9-79d3-4e6c-8a9c-b50f8d5be68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e3cc04-5a5e-4195-b3d7-e80b5ef2f820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f430346b-df16-4414-9e3b-394164c6d4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e557321b-2660-486e-b468-1a79c03ce096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce301406-4a7c-4882-999b-b9e31a75d61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f751b1-cf00-4c54-975d-508fe3493ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb00f775-e529-4c06-955e-fe4d4cc29d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72c21527-9659-4868-9f42-2c8990e571fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a72256-94d1-4a30-a4e5-c28630b0322b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f94ed04-fc6e-4355-85a8-3d6edb1b724e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8455784-1434-4fe7-9e1f-554d74060f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc63ed2-c324-4812-9953-cda1c4c12cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c306e482-8fdb-4cd3-9101-03b254ee0594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 454a9f99-690a-40c7-a3f5-ce592d0cd305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa10127a-ac7c-4f84-8513-632b15405369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de5f22c-15c1-4720-8bd9-28bf6fb0351e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a65e80aa-74e7-4851-b13e-4164879fe1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d8bcea-c68c-4083-807a-1c070d9e10ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1309c3b-d93f-4ca1-9558-83dd579a143c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f0ad123-d864-48c3-ae59-415a3fcb3b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddd0a4e2-fe24-40e0-bdce-1ac726141d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a880192-d29d-4a43-a0a7-2553ecfa5336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 168cf423-7932-4c6c-98e4-ac1b5ac900e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b4b2a5-4bf6-4d12-89f2-ec846352995b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84ab627-af33-44d3-94e8-2258370b8a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 727049e7-12b2-4097-8790-881a74d97b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a03746f-9bb0-4779-8ab8-7063eecb6049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33af1c6a-c685-4807-96c6-58de6c5161e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41888cd1-2b1b-49ad-a296-798f6836f355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b9da9d-1876-4628-b3db-0dd311ca6093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01bdc1cb-4f6f-4e61-877e-ae403d00b3a7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_61
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_labels.txt

📊 Raw data loaded:
   Train: X=(1000, 24), y=(1000,)
   Test:  X=(251, 24), y=(251,)

⚠️  Limiting training data: 1000 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  242 samples, 5 features
✅ Client client_61 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0913 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0884, val=0.0897 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0888, val=0.0872 (↓), lr=0.001000
   • Epoch   4/100: train=0.0867, val=0.0871, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0863, val=0.0873, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0852, val=0.0872, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 2 Summary - Client client_61
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0036
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0195
============================================================


============================================================
🔄 Round 4 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0988 (↓), lr=0.000250
   • Epoch   2/100: train=0.0826, val=0.0989, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0824, val=0.0990, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0822, val=0.0992, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0821, val=0.0993, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0814, val=0.0998, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 4 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0021
   Val:   Loss=0.0988, RMSE=0.3144, R²=-0.0072
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2427, R²: -0.0047

📊 Round 4 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2430, R²: -0.0072

============================================================
🔄 Round 7 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0845 (↓), lr=0.000063
   • Epoch   2/100: train=0.0865, val=0.0846, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0864, val=0.0846, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0864, val=0.0846, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0863, val=0.0846, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0860, val=0.0845, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 7 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0075
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0059
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2436, R²: -0.0127

📊 Round 7 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2435, R²: -0.0123

📊 Round 7 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2435, R²: -0.0116

============================================================
🔄 Round 13 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0886 (↓), lr=0.000016
   • Epoch   2/100: train=0.0861, val=0.0886, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0860, val=0.0886, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0860, val=0.0886, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0859, val=0.0886, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0857, val=0.0885, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 13 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0123
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0117
============================================================


============================================================
🔄 Round 14 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0884 (↓), lr=0.000004
   • Epoch   2/100: train=0.0865, val=0.0884, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0864, val=0.0884, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0864, val=0.0884, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0864, val=0.0885, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0863, val=0.0885, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 14 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0139
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0111
============================================================


============================================================
🔄 Round 15 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 15 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0137
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0494
============================================================


============================================================
🔄 Round 16 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 16 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0131
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0205
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2436, R²: -0.0125

📊 Round 16 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2436, R²: -0.0125

📊 Round 16 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0124

📊 Round 16 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0124

📊 Round 16 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 21 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 21 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0122
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0223
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 21 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 23 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 23 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0174
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0005
============================================================


============================================================
🔄 Round 27 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 27 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0135
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0214
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 29 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 29 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0151
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0063
============================================================


============================================================
🔄 Round 35 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 35 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0157
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0393
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 35 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 37 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 37 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0155
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0192
============================================================


============================================================
🔄 Round 38 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 38 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0186
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0089
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 39 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 39 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0182
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0370
============================================================


============================================================
🔄 Round 41 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 41 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0114
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0313
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 46 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 46 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0173
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0330
============================================================


============================================================
🔄 Round 47 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 47 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0087
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0344
============================================================


============================================================
🔄 Round 48 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 48 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0093
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0344
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 49 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 49 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0142
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0263
============================================================


============================================================
🔄 Round 50 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 50 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0141
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0098
============================================================


============================================================
🔄 Round 51 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 51 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0130
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0173
============================================================


============================================================
🔄 Round 52 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 52 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0097
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0381
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 53 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.1078 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.1079, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.1079, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.1079, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.1079, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.1079, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1078)

============================================================
📊 Round 53 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0130
   Val:   Loss=0.1078, RMSE=0.3284, R²=-0.0289
============================================================


============================================================
🔄 Round 54 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 54 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0117
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0246
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 55 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 55 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0094
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0414
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 57 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 57 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0103
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0383
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 58 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 58 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0082
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0355
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

📊 Round 58 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 62 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 62 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0114
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0208
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 63 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 63 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0147
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0116
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 69 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 69 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0134
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0135
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

📊 Round 69 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 73 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 73 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0134
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0140
============================================================


============================================================
🔄 Round 76 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 76 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0117
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0254
============================================================


============================================================
🔄 Round 78 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 78 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0141
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0130
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 79 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 79 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0161
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0116
============================================================


============================================================
🔄 Round 82 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 82 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0100
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0326
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0122

============================================================
🔄 Round 86 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 86 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0121
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0363
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 88 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 88 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0059
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0427
============================================================


============================================================
🔄 Round 90 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 90 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0185
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0102
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 92 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 92 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0155
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0199
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 92 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 97 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 97 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0169
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0143
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 98 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 98 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0212
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0132
============================================================


============================================================
🔄 Round 100 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 100 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0107
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0337
============================================================


============================================================
🔄 Round 101 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 101 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0105
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0324
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 101 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 105 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 105 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0148
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0093
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 106 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 106 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0159
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0032
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 107 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 107 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0129
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0192
============================================================


============================================================
🔄 Round 108 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 108 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0134
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0137
============================================================


============================================================
🔄 Round 111 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 111 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0121
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0268
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 111 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 113 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 113 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0140
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0117
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 119 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 119 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0068
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0413
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 119 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 122 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 122 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0115
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0230
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 122 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 125 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 125 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0149
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0089
============================================================


============================================================
🔄 Round 126 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 126 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0154
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0057
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 126 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 129 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 129 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0158
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0077
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 131 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 131 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0051
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0496
============================================================


============================================================
🔄 Round 133 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 133 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0139
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0279
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 133 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 135 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 135 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0130
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0164
============================================================


============================================================
🔄 Round 137 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 137 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0098
   Val:   Loss=0.0813, RMSE=0.2850, R²=-0.0341
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 137 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 137 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 140 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 140 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0184
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0001
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 140 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 143 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 143 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0139
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0214
============================================================


============================================================
🔄 Round 144 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 144 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0125
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0187
============================================================


============================================================
🔄 Round 146 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 146 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0101
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0279
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 153 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 153 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0110
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0288
============================================================


============================================================
🔄 Round 154 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 154 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0148
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0097
============================================================


============================================================
🔄 Round 156 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 156 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0106
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0240
============================================================


============================================================
🔄 Round 157 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 157 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0085
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0345
============================================================


============================================================
🔄 Round 162 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 162 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0149
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0062
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 163 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 163 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0164
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0383
============================================================


============================================================
🔄 Round 164 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 164 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0119
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0229
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 164 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 164 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 164 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 164 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 171 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 171 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0118
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0220
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 171 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 171 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 177 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 177 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0151
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0088
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 177 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 181 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 181 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0142
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0098
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 182 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 182 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0140
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0128
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 183 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 183 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0126
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0337
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

📊 Round 183 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2436, R²: -0.0123

============================================================
🔄 Round 188 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 188 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0101
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0289
============================================================


============================================================
🔄 Round 190 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 190 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0132
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0207
============================================================


❌ Client client_61 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
