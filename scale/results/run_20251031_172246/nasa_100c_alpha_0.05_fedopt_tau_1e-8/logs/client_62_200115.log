[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2a83d3-4e34-4d75-a903-426961cd6849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ad5f27c-dfa6-4148-b879-520e9b29cb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc8cda4b-2365-4359-a1e1-77925fc163a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ddfbcce-5c5c-4b10-b6b2-8d5ef3671efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4f7726-76b5-40bf-ad95-cf7866efc813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2fe1599-a597-452d-a407-7111a73e5236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eeab82b-08e5-4dde-a6d5-138a36c95209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c660d0d-3b77-4a11-9af0-6643db747f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b8a3df-95e2-49ef-b501-199a9a9f6e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e51bdd0a-4bb2-489e-9f1d-1bc3f9fafe16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e459cc63-90cd-411a-be05-4cb1cfef0cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e30cc9-c7c9-41f7-936a-74a101b94831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed50c1d-cba1-46f4-a199-694ac5c9dd0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c8e4a2b-dd51-4fc4-a24a-e88337a7e233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 719a0512-ac67-4f6c-9703-ea19668badd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7080aca5-94c6-43f1-bdb1-f8f9c9f812bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12965380-2cfb-41cb-83b1-41f113849506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab25384c-fe7f-4d12-906e-cc2357ef19bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65421756-4a86-41fc-b0f1-d8d474d5b829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841e9b24-040e-4d94-9f84-e63564f47774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6905f869-1009-46b1-b877-22f74bb44680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2fe5e3-c2cb-4466-b561-7d7b0d96dc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424fab87-b6a8-4ffa-b5be-1bf8ba249856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361e68bd-9e12-42c3-b7ff-810a48d60913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef1bad6-b2f1-4e92-884c-f4364d05f66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c92214-bcba-4281-9d86-7cde584fdaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f241b79-1cd9-4ce1-b034-f65f60cd0c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 734235b7-c48d-4e18-9347-43b943c8fa06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f663cec6-ae00-46df-9a12-9a5df15b43ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2f8895-7791-4d50-9c6b-2e1950c23ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb9e42f-d5c6-47ef-9b59-f8e0b1f60070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe09d54-7426-4ac3-bfd8-3a4fc2f0cc75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a4b258-4f0f-4ba0-a478-c1bc4f445613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4658f710-dcde-49f6-a183-c4d5b683b294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab8b9ec-0f08-4bcf-9443-7eec2cd0f883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd16c2e-fada-4dfa-a3ac-8a97fe68a3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142c7877-b77f-4056-8b62-8846b78b273d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22ac8446-3588-48bc-83ff-e9283f4be16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc02f18f-a77e-4fc3-b79c-8a5eea55aecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42cce7a0-0b51-4504-bb04-2e6236dd0367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b6345b-f759-475a-b09f-698a12cb151e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef6237a3-fa42-4eb6-8bd4-9c862f9fa9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 103ca720-7da9-4f63-b3e9-8a0e1ae9a453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b3d8d18-4ade-4133-8750-68075aa33cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1af832c-36ea-4493-b14f-95d2b8ecb135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35298f0-ce03-4d87-a85c-66e94e3c792f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee3dacac-c56d-43bf-9505-e364ddf5aa64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b53b998-8a4c-4ebd-b69f-82120ca19b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fab826-7200-464b-8b5d-f9a044a11a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1411cca8-9e7a-4e9a-8634-f5c770fef2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5c6e4b-c02a-48d0-a671-6e6820ae181d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31f9824-f074-4800-95d3-927e8c6527e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdaa128b-d79e-4430-b873-2ee5bd59e330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c73703-8e63-4baa-9939-5fb006a4a57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d54ea0-2cbd-442c-bca3-e4ad5a02c757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647dfda8-d26b-4848-9f2f-84112dc258a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60891f1-1c58-4bc7-b1f7-7f6c20f69da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c1bc25-cc6e-4587-bc0e-5c37b25c9100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19d86ef-d0db-4f09-bc17-0416955ac50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20744b0c-e19d-437a-a0f1-11b6bacc9ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf26400-00d2-46e6-8e0c-173b31b25fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7f553b-a767-4da8-8366-17945600f7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c329b296-ed16-4f82-89dc-c54eb38d8c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b1c0fe-56f7-484c-b94c-f41f88c0f2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e09b5276-9e67-4157-bad4-6479e6b4185a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e92cab-8a2e-4933-96c4-f554a83aa744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05f8f1a0-2251-4600-8f1b-8aed1755c2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69eadbd9-bd33-41cb-8205-7750e73a2d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca91e64-2c80-463f-b114-2c5a3ed3fd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16418774-17a2-48e6-8e8f-d8b6722863c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b92ce1e6-4c7c-4467-be88-78af2f863047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf2e361-bd6a-4cb3-a8d2-c0e75e06bdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b77628d5-c1f1-406c-b93f-27f6a0e246ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0014fae4-07c7-4b0b-9412-04f2f6ad551d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c19fad2-f6b0-416d-9e7c-1e92d4d8876b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2edbee-588c-4bc7-a35d-c02df13fb38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d1f65a-1e62-4ff2-bd83-5a49d03cef40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e95461ab-4531-4561-9280-dbf99205a514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1728efc7-f634-4e7a-b6da-2ef50497ef25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715b7d8c-1d29-490d-b883-53f6bd29f4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285df5db-efd0-4f7e-94ce-70217b0fb6c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 156a646f-4303-4dd6-8d3f-98cb87f56175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d70cf02-e998-449b-b774-3226749aa36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359ac433-742d-459a-bd5b-cc29a9e61117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c94b8c-c66d-44b8-8240-e1e65338863c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a95e1acd-665e-43a0-9c43-69356f22563d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e52d926-e200-43a0-bc39-889510818ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7ea86c-99c1-4edf-9fae-5b9af4533576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e73ce7e0-4737-4ee4-a05c-7138e3cbb398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33d635e-61d7-49e3-82bc-eeaef5540b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197af25b-2c09-4210-8c30-ad094945b646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40058a76-bc9d-43ea-b2bd-f5a0172908ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87dc5deb-7164-4aa8-8262-bb2e6ad59413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74c34c1-740d-40e4-a14f-3128defbbd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2db96c-1f68-4d59-9bf3-46e18604316a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c68460-8ba2-49bd-8fd7-f1928e9c41e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a529f25d-c673-481f-84be-f3577bb631cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef42cc83-62ed-4916-bd0b-b4ae32c46f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cd78db2-8f31-4549-9e43-6a0b149f22ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6285474-1eb1-44a9-adc5-40994fc75253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62313a7d-c9ae-494c-864c-6f588773e93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71104caa-9283-4284-bb3f-f20f7668a46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4967a169-ca90-4927-9f0e-28557c927d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6327d2e2-5da2-4bf5-918b-eb7599efa25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2404728-bb3f-4e63-afe8-014f134e574f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce2a772-af5f-45f1-95f2-a21bb6d8e73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee7e54a-1b75-4448-bd5c-b5619de89050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c18b91-171c-4d9b-904b-1fa575de8310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0811ed7-7b27-49b2-8fa7-aaeb02d0f461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3e843d-1ade-4670-be02-83f5598e22a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746b3372-302c-4afa-8e40-472f4b5924d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 121ed86e-756f-41af-83c4-c6a1b6d97f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b821395c-c797-467a-a801-8d32984f1d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8731eb10-4b59-48de-a4d5-9951f74a80db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23a5faa-74d4-40a1-ab41-6f9b1913f3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d40a55-dc99-4156-a756-d848091a31f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a6e35fe-886f-4929-8c5e-fa86b7d926bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c14698e-9190-4444-9220-ac34906ea294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac2875ea-d53e-4d14-9625-660511a1252f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32c51b9e-6d25-4b24-ad80-a1007e937a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e75fcd5-de3b-4ef5-8a16-e50f6e6113d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18dc44b8-157d-41e4-97ea-1fe546398a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b666e4c-36b3-4f7c-9826-72daef6dc387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7703504-7eb3-4445-a4c7-0e779c756035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de26c910-c81d-4ba1-aab7-14fb5fb30735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4434e657-a2d9-42dd-91df-eb08ca3e54e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92bc2d3-e0a8-4e8f-83f0-cde43b712aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d2d2e4-4032-480e-998a-92288b47826f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262732e5-0a3d-4b68-bb92-ca3d8858158c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b3942a4-4206-4df7-8473-ebed789874e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569a4441-ba90-42f4-ba54-258e36f7d23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcd74507-3b4c-483a-9900-32aff4ab4bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909017eb-11c4-49d6-9e7e-50b8bd37d8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22386f85-2600-452c-ac62-3006041907d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a162527a-872b-41e5-84b4-ae6cb2e9db6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b84b4a84-9047-4b5e-a191-9479e545e67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6893efc0-1e2b-442f-a8cb-19e624c4edc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5cd3375-b227-4c19-be2a-28b630365c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a816e21f-ad57-4368-ba4f-19ba9413cd47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9891a2-d1a3-441f-9059-007c91e7244a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb63108-f770-43d0-979c-831d08096013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5f8664-f731-4501-8010-264b06d75f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca2acc5-c809-41e9-a9d4-6508d8de0ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6850dffd-d508-4432-ad62-6f4190941990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e247744-bdde-47dc-84d0-c8b691dbd393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9640e5fc-c042-4cb3-b9e5-bc4d50d3a655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf139c91-ad43-484b-adc9-fd669115d3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48835d3d-d8e2-40ce-92ae-2241eede1e8a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_62
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_labels.txt

📊 Raw data loaded:
   Train: X=(1464, 24), y=(1464,)
   Test:  X=(367, 24), y=(367,)

⚠️  Limiting training data: 1464 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  358 samples, 5 features
✅ Client client_62 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2514, R²: -0.0026

============================================================
🔄 Round 3 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0838 (↓), lr=0.001000
   • Epoch   2/100: train=0.0859, val=0.0840, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0847, val=0.0847, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0841, val=0.0840, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0840, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0832, val=0.0843, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 3 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0411
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0016
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2536, R²: -0.0185

📊 Round 3 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: -0.0213

📊 Round 3 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2548, R²: -0.0268

📊 Round 3 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2558, R²: -0.0344

📊 Round 3 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2568, R²: -0.0429

============================================================
🔄 Round 10 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0882 (↓), lr=0.000250
   • Epoch   2/100: train=0.0836, val=0.0878, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0829, val=0.0879, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0824, val=0.0885, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0815, val=0.0885, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 10 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0100
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0126
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2567, R²: -0.0425

📊 Round 10 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2568, R²: -0.0432

📊 Round 10 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2569, R²: -0.0440

============================================================
🔄 Round 13 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0850 (↓), lr=0.000063
   • Epoch   2/100: train=0.0848, val=0.0849, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0846, val=0.0849, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0848, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0843, val=0.0847, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0835, val=0.0843, patience=12/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 13 Summary - Client client_62
   Epochs: 24/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0047
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0002
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2568, R²: -0.0437

============================================================
🔄 Round 14 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0894 (↓), lr=0.000008
   • Epoch   2/100: train=0.0842, val=0.0893, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0841, val=0.0893, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0841, val=0.0893, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0841, val=0.0893, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0839, val=0.0892, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 14 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0187
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0069
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0866, RMSE: 0.2944, MAE: 0.2571, R²: -0.0457

============================================================
🔄 Round 20 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0933 (↓), lr=0.000002
   • Epoch   2/100: train=0.0830, val=0.0933, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0830, val=0.0934, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0830, val=0.0935, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0829, val=0.0936, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0828, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 20 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0255
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0409
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 20 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 24 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 24 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0168
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0213
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 26 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 26 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0208
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0256
============================================================


============================================================
🔄 Round 28 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 28 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0162
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0253
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 34 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 34 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0250
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0093
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 34 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 39 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 39 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0207
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0094
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 42 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 42 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0180
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0163
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 43 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 43 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0236
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0063
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 45 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 45 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0206
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0067
============================================================


============================================================
🔄 Round 46 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 46 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0267
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0170
============================================================


============================================================
🔄 Round 49 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 49 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0126
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0554
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 49 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 51 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 51 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0117
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0657
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 51 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 51 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 57 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 57 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0169
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0284
============================================================


============================================================
🔄 Round 58 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 58 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0179
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0168
============================================================


============================================================
🔄 Round 64 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 64 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0197
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0101
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 64 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 64 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 71 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 71 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0182
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0223
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 72 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 72 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0127
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0584
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 72 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 76 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 76 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0125
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.0415
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 78 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 78 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0237
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0020
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 78 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 78 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 78 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 78 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 85 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 85 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0203
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0097
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 85 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

============================================================
🔄 Round 87 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 87 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0236
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0014
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0454

📊 Round 87 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 93 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 93 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0195
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0272
============================================================


============================================================
🔄 Round 94 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 94 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0162
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0767
============================================================


============================================================
🔄 Round 95 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 95 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0205
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0071
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 97 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 97 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0179
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0170
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 98 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 98 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0168
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0215
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 101 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 101 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0116
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0401
============================================================


============================================================
🔄 Round 102 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 102 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0136
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0412
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 104 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 104 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0168
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0219
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 104 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 107 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 107 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0154
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0265
============================================================


============================================================
🔄 Round 109 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 109 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0274
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0189
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 110 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 110 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0245
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0070
============================================================


============================================================
🔄 Round 113 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 113 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0126
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0425
============================================================


============================================================
🔄 Round 114 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 114 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0240
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0069
============================================================


============================================================
🔄 Round 115 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 115 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0185
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0144
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 115 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 118 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 118 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0124
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0387
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 118 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 123 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 123 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0174
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0242
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 123 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0456

============================================================
🔄 Round 125 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 125 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0243
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0084
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0456

============================================================
🔄 Round 127 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 127 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0173
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0263
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 128 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 128 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0145
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0384
============================================================


============================================================
🔄 Round 129 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 129 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0190
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0162
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 131 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 131 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0142
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0312
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 133 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 133 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0214
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0172
============================================================


============================================================
🔄 Round 134 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 134 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0174
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0230
============================================================


============================================================
🔄 Round 136 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 136 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0164
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0226
============================================================


============================================================
🔄 Round 138 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 138 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0169
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0230
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 141 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 141 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0249
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0091
============================================================


============================================================
🔄 Round 142 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 142 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0254
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0074
============================================================


============================================================
🔄 Round 146 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 146 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0162
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0236
============================================================


============================================================
🔄 Round 147 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 147 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0172
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0289
============================================================


============================================================
🔄 Round 148 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 148 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0162
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0306
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 148 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 152 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 152 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0140
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0388
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 153 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 153 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0164
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0229
============================================================


============================================================
🔄 Round 154 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 154 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0210
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0101
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 157 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 157 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0171
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0202
============================================================


============================================================
🔄 Round 158 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 158 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0148
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0285
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 159 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 159 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0194
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0112
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 159 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 159 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 159 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 166 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 166 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0289
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0238
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 168 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 168 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0228
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0026
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 168 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 172 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 172 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0200
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0181
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 173 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 173 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0216
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0106
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 173 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 179 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 179 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0199
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0257
============================================================


============================================================
🔄 Round 182 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 182 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0215
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0055
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 183 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 183 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0175
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0196
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

📊 Round 183 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 186 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 186 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0172
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.0195
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2570, R²: -0.0455

============================================================
🔄 Round 189 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 189 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0163
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0268
============================================================


❌ Client client_62 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
