[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a48dbe3-455d-40d3-94ee-a3b83cc773c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18fb8abe-b618-4cd6-9aeb-be699957cad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6d633b-36b4-420a-b197-68b4f11fd8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3deb5882-ad95-4a6e-a53d-650c13b40eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b973dad5-239f-483e-b336-e3b67725b386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9acd731-c0ab-4c06-a0eb-510eb4221289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1d79fc4-83bf-4850-947d-ed81f8175fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0568377-f2b3-4651-af42-6eb0080ef3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 465e8f44-9427-4787-a433-da53fa67b658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2567ac9-56a5-463e-97c7-28aa7b0e4005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f61b02-314a-42c9-98ff-5d5bdb389485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48338aa4-348b-4025-9087-538b849d3cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae643496-bcf3-450b-818b-161f1dbc6bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784594c3-bd4c-4faf-87f5-ebfbc004beb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2e60fa-64ea-43cc-9c8a-796eccae2027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0ec8d8-7382-4c25-a796-18fa5735c2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ce007d-8d7b-46a0-ba9f-13b25a911433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378f9987-dfe1-4b02-b742-8619e02315e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61fc8f42-6050-459d-ba64-453cb11d102c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6d5a12-c12e-494b-a3d9-a6df279175b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54f046e-f8dd-4112-82a1-ca9a95c7d8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf21dfd-984f-4e80-871a-288168256a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57349498-59f0-418c-9f78-98f26beef72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c8e4f6-de78-469b-854e-cdf036bdde6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ee2909-8a07-4fd8-a2f3-3277dbf786bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab8ac16-5e35-4915-bd71-008e333add94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ace141-dcf7-4af7-ab35-a627feac5ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea309d67-2ba5-4406-ae3d-3becbf8c7672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196c6fe6-7e56-4f1d-b618-433dea9bb0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aa902f5-08eb-4a8b-910f-2e0b59278f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4602d7f0-d127-4b1b-abad-534db9b37036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca27f7d-1dc7-4d7b-b1aa-0c97c387ad8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51766e0-a460-4f2a-87dc-0f254d34823e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded0f545-37f3-425d-a0c8-0d37eace1d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e6bc19-361f-48c1-8cfe-b0a7c358d145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bd04c09-a6a0-462b-b556-8fe1ae96abee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb85c92f-10e7-4423-9703-51aee0a87461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df46a270-790d-4bdd-adc6-69d098db2337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62cca0d0-bc87-42ed-b26a-6d73d2d24c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56491c95-4095-4976-a7d8-ff3fd618e9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aec368ca-12b7-4167-97c4-2f6e0f78c2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ecbe45-5972-46be-bddc-c2854dd792b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be02cd21-4cca-40d3-af3a-e71427695e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c559144d-3821-4353-9291-b5eac565bcdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5fd2b1-e1b6-4803-b011-1b51015d7e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f152e77-7149-460d-9015-4a251bafb632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4170e6ae-f80a-429d-a6ea-5ff052fb29c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17eda13e-8a8a-49eb-a53f-70b3ad173786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f274794-2db4-404b-9535-c8d27cf7ae2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4fda31-b052-47ff-94fa-f6f6a9f01a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8097b797-6e90-402a-8355-14ccd8f86d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f04b8ce-97ef-4d08-8aa2-63f4935d8d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf317e9-d62c-44a9-96ed-77cc844721ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078cda68-3909-4d7d-97f8-22f41cd13756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b2c0be7-8197-4d20-a117-0dee27b42b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a77ad32-54a1-4320-9aa1-66a987534c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2598e1de-2341-4ffd-bf56-fff334e9d8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f147095-48c8-40e9-8c18-a4e7b65877e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c04759f-e9b8-46af-8e25-4c3cb6a65e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9f632af-4816-4fe1-8b96-9c5cba92ac9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5892c8-15a6-497b-aedc-2448801d6904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661f234e-4a16-4fa1-b07b-6facf88d0d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6296e4c6-81e2-4855-985d-f2de12266f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e26e0b-c26b-48a3-975e-b44f6624ae89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 047c197a-cbcd-45d6-920f-f04bb6b15c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fddc877b-8d2d-4c22-bc03-d35213e98555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18fe188d-df50-45dc-a958-e057f6f1f8b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb24e70d-fef2-44ce-b2b1-f20b370a9a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4066a3dd-2f60-4a9a-aea4-d5457028045b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986ab5e9-f046-4195-b6e9-de2e10033852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce4ddef-b773-4bf6-ae18-a5311dd59239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130c6e33-9837-4b06-8c81-577d024575de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcad61da-80ce-491b-a4a8-a5457283c12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859abc12-5834-4308-9110-0fb49b981003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a503f06e-8959-4265-8536-2585baa7dc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170ef746-c4a1-44b9-a528-1e9899409fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3960a150-df14-4a85-9c66-3b91ca970408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488baa2c-ee64-41d8-80ae-a9bda74c18b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8def002f-5a8f-42f2-b90e-420bc9f9308d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8e6341-e2f1-4bdf-88a0-c32b4761eaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3279bd3b-53e7-4856-8ee5-a053a40f349e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 093123c7-38ec-42a9-8647-a3ecac0d01c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60780fd3-a841-47c9-95fa-764ec3fa10d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9190fb13-e0c2-4762-b7f5-17dd51b1e209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7e654d-15e5-4c65-a7b7-d60739444307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9e96a9d-eec9-4510-a951-d117c86e8686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7351f1-bc7e-430f-a1f4-ce97fe59666c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78026f0-0d66-416c-98b1-441537e88fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7e3a0b-4baf-4e20-9093-6633380e9fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa63c99-4047-4ecb-a292-cf035e8ad25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4abe9ef-a233-4545-a188-8d68dd544da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1b750b-da48-4136-9876-43dde8a16323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e85d5d-5883-4cfb-b64e-9767ad99b05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ad16a6-ef5f-49e4-ae0a-03f6509a5a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb61746-92ed-4259-bc65-0efebb77f5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd939459-53aa-4bdd-af2b-0b94a6cb296c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb072f5-bd61-48cf-96ad-aaddcb821308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9207a8-1cbc-4b27-bfdb-3612cc5611bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325e52de-8eb3-472f-bde7-a0432f0e172a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ad1f9e-dec5-496b-9f89-e7f48ad97fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708f6098-6591-4bd9-adb5-08c43aca469f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb230fa0-6b8d-4269-ac6a-d4cd8115a2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e4d50a-93af-4111-a958-ec30f61a5a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa58049a-3b16-4c20-a59f-aecef852d984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c657811-8721-4579-99a5-6894b8fa2edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddbebbf2-a206-411c-87bb-31bf1cd4ff9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b82c1f6-6f03-4167-8571-18c8343ac73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016064b2-0c97-4404-a74f-9358d0fd5efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c3915c-335c-4ea5-ae22-56fb1ce0cfd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a63ab7f-5950-40de-86c6-a1b0f04879be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5604a1f6-fecc-40dd-82f7-d947ffbd42aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8998d4-514a-41d6-98b1-1dc6a4c7b8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e936bf41-809f-4aaa-aabc-a1a0cf356270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a4a247-05d0-4332-95f1-359288d545c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b767dabf-8eb5-47b7-aca4-3964cd3adc57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451a1cd8-f244-47ef-8c18-6b4e37e60e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9820e7-6669-41ef-b977-4c7dfd01dfc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83165d17-0d65-4857-8fff-67894dd1dfde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9982f8d-0db9-4f7b-bb00-d71ed772fa3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec83735-8d67-4e3a-9cbd-4771f8ae8f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 217cab41-e652-424b-8a0a-906eea7da8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9beb20a-d84a-41be-b4bb-93c725f7bce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bf275f-759b-4d25-b0a5-20ae06ab9c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff68892-b76a-450e-9fcf-2db02ae11c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a20956e-0dda-4294-8555-fb3e58457dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66c3e13-8593-4007-8e1f-1c369962414b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf6dd684-ba7c-4e43-a428-ba8c991698a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69ad54c-3080-41a7-a02b-b96709e9e011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df827fe-3be2-4faa-805d-08c019f71f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d0d09c-e5a3-4640-9bce-461632a0197a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c80e178-d8f7-46c8-bc02-637c56fd2c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7893f257-1508-4030-b5c4-dce007c0da39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6514329e-b00f-4fcc-bc74-2b9ce26f4612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4ff43d-aa12-44e2-bd85-510ff984f9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a20956-6057-4537-8f89-6f283971ac8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2193175c-5ea1-4160-bbcf-b345c26e9d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 280416b7-7a86-4060-8dcb-ad41a06042b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a11c8e-2a8b-44c6-a389-70139e1f466f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6b098e2-3ff6-4dcd-9e70-af247c3ec064
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_63
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/test_labels.txt

📊 Raw data loaded:
   Train: X=(1341, 24), y=(1341,)
   Test:  X=(336, 24), y=(336,)

⚠️  Limiting training data: 1341 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  327 samples, 5 features
✅ Client client_63 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2369, R²: 0.0031

============================================================
🔄 Round 7 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0802, val=0.0806 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0784, val=0.0796 (↓), lr=0.001000
   • Epoch   4/100: train=0.0773, val=0.0798, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0762, val=0.0794, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0715, val=0.0808, patience=8/15, lr=0.001000
   📉 Epoch 13: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 7 Summary - Client client_63
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0510
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0263
============================================================


============================================================
🔄 Round 8 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0842 (↓), lr=0.000500
   • Epoch   2/100: train=0.0771, val=0.0840, patience=1/15, lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0764, val=0.0842, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0759, val=0.0841, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0757, val=0.0840, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0746, val=0.0832, patience=3/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0734, val=0.0823, patience=3/15, lr=0.000063
   📉 Epoch 27: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0729, val=0.0819, patience=4/15, lr=0.000031
   📉 Epoch 35: LR reduced 0.000031 → 0.000016
   • Epoch  41/100: train=0.0728, val=0.0817, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 8 Summary - Client client_63
   Epochs: 42/100 (early stopped)
   LR: 0.000500 → 0.000016 (5 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.0747
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0486
============================================================


============================================================
🔄 Round 9 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0764, val=0.0896 (↓), lr=0.000008
   • Epoch   2/100: train=0.0763, val=0.0895, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0763, val=0.0895, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0762, val=0.0894, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0762, val=0.0893, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0761, val=0.0891, patience=10/15, lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0760, val=0.0890, patience=8/15, lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 9 Summary - Client client_63
   Epochs: 28/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0236
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0147
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2352, R²: 0.0136

============================================================
🔄 Round 10 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 10 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0189
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0128
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2352, R²: 0.0136

============================================================
🔄 Round 16 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 16 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0228
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0119
============================================================


============================================================
🔄 Round 18 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 18 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0213
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0178
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2348, R²: 0.0153

============================================================
🔄 Round 20 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 20 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0248
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0219
============================================================


============================================================
🔄 Round 23 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 23 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0260
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0021
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 27 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 27 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0215
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0145
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 37 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 37 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0172
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0258
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0149

📊 Round 37 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

📊 Round 37 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 48 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 48 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0181
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0280
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

📊 Round 48 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 53 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 53 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0170
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0313
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0147

============================================================
🔄 Round 60 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 60 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0253
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0012
============================================================


============================================================
🔄 Round 61 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 61 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0210
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0161
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0147

📊 Round 61 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

📊 Round 61 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

📊 Round 61 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0147

============================================================
🔄 Round 70 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 70 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0189
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0224
============================================================


============================================================
🔄 Round 71 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 71 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0254
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0265
============================================================


============================================================
🔄 Round 75 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 75 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0226
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0065
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0147

📊 Round 75 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0147

============================================================
🔄 Round 78 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 78 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0245
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0019
============================================================


============================================================
🔄 Round 81 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 81 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0188
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0247
============================================================


============================================================
🔄 Round 83 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 83 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0137
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0145
============================================================


============================================================
🔄 Round 84 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 84 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0230
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0081
============================================================


============================================================
🔄 Round 86 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 86 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0174
   Val:   Loss=0.0674, RMSE=0.2597, R²=0.0254
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 89 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 89 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0195
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0224
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 90 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 90 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0220
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0050
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 91 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 91 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0135
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0271
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 92 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 92 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0187
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0248
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

📊 Round 92 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 95 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 95 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0188
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0203
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 97 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0656, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0656, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0656, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0656, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 97 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0160
   Val:   Loss=0.0656, RMSE=0.2561, R²=0.0215
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

📊 Round 97 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 100 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 100 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0231
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0223
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 103 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 103 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0174
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0304
============================================================


============================================================
🔄 Round 105 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 105 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0231
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0034
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 107 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 107 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0149
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0273
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2349, R²: 0.0148

============================================================
🔄 Round 108 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 108 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0218
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0149
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 109 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 109 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0161
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0321
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

📊 Round 109 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 112 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 112 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0228
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0083
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 113 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 113 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0234
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0039
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 114 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 114 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0238
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0033
============================================================


============================================================
🔄 Round 115 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 115 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0191
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0212
============================================================


============================================================
🔄 Round 116 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 116 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0177
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0295
============================================================


============================================================
🔄 Round 117 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 117 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0225
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0119
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 121 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 121 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0187
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0262
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

📊 Round 121 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 124 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 124 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0114
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0326
============================================================


============================================================
🔄 Round 125 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 125 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0201
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0200
============================================================


============================================================
🔄 Round 126 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 126 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0204
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0052
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 127 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 127 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0110
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0461
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 129 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 129 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0209
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0147
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

📊 Round 129 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 131 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 131 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0151
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0322
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

📊 Round 131 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

📊 Round 131 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 137 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 137 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0206
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0064
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

📊 Round 137 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 142 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 142 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0163
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0372
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 143 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 143 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0218
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0040
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

📊 Round 143 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 145 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 145 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0158
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0253
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0151

============================================================
🔄 Round 146 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 146 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0207
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0194
============================================================


============================================================
🔄 Round 148 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 148 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0234
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0061
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0151

============================================================
🔄 Round 149 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 149 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0194
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0242
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 150 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 150 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0162
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0224
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0151

============================================================
🔄 Round 152 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 152 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0251
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0059
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0151

============================================================
🔄 Round 153 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 153 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0135
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0386
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 156 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 156 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0175
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0282
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

📊 Round 156 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

📊 Round 156 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 162 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 162 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0223
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0019
============================================================


============================================================
🔄 Round 163 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 163 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0207
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0180
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 165 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 165 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0216
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0147
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

📊 Round 165 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 170 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 170 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0208
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0182
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

📊 Round 170 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 172 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 172 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0204
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0204
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

============================================================
🔄 Round 174 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 174 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0247
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0012
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 176 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 176 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0199
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0048
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0148

============================================================
🔄 Round 177 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 177 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0192
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0231
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

============================================================
🔄 Round 182 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 182 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0126
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0275
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

📊 Round 182 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0150

📊 Round 182 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

📊 Round 182 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2348, R²: 0.0149

❌ Client client_63 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
