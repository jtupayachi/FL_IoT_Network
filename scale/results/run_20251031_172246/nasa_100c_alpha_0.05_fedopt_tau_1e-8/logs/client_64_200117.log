[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264dfe05-fb4e-4d44-a880-15c118c82cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7187bd0-68f6-42d1-95b5-c84e4e29510c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a2b1b4-ac42-4c7f-9190-56c816b782be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41065a3b-58d1-4461-ad93-476fc020b7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aac4bc4-4f7b-44e9-b64e-52a871a224f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1d5c17-a166-401c-9f46-f921984abe08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd6a476-4f13-4618-a9c0-2fa7eaa345b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f43361-0722-4bdc-9d07-f4bbadf4619f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9eac406-8e5a-4f73-a071-cf24d9ef7115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b2da6b-04a6-46a2-9941-67910270990c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0485486c-c36a-40b2-af46-e6047d00223d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c392df9-3518-4f67-94c6-fa1b347567c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642f3b00-1f06-4e44-944f-e5cfdddd0ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115aef24-5a9f-4f8c-b367-0d8d848d6c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13602f56-2849-4227-8742-4b6779aac40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de8ae634-9129-4df8-9457-0f65a262ef77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add4166c-ee16-4e8d-afcb-e195aa6da866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 373f18e9-6c0b-4d43-976a-c51823746980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2742c9d-714f-4e5a-ac34-294ce6c05759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df76ead4-0c29-4ef3-a389-312dd968802c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b572c41-c182-4fd6-807b-db3436dea1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5840e192-dc90-4d05-b9cc-6184ac968146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd611471-fe8b-4ad0-9e40-d56e89986137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a88a84-134b-4bf4-91bb-159be95e6e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09aca996-dd2d-48b0-869e-bd5e49a753cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922f00e2-cf27-4b3c-9d2c-ee230ac201d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34bbb0b3-b1fd-433f-b900-748b2d656698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7025327-9acb-4580-8f59-b118a18c396b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54919882-5165-4c59-823f-4646dbd54a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efb6f6c5-3b6d-431c-b624-575d5c8bd688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45bc2271-0acb-44df-8e1f-4e5cbddf9099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e33ddb61-791d-42fe-a9f6-116270b380da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbca00e-5d0d-4207-947e-44c4eaa0fc81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93dceeef-b7af-4228-a2c5-48adf6b52cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb334b3-4a7a-413e-91ca-1d813a291e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e846dd8-f79b-4bf2-91fb-d4da8c88f58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a9c324-1f52-482c-a89d-366b12d93c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5011e562-b37a-4e12-90cc-31015607df9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dba9ed0-8fd1-4cfa-8ca1-d1babaa06835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd50845-adc4-436f-ade6-ab649b8812b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9c6e8c-878f-44df-b480-819d3c82982f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597fc201-deb2-4d8d-ad6b-bd535d6d5597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1214b9c5-4d71-4984-a072-5053ad3cd568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11203446-3160-4041-a11e-3f8f5025caa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da262da1-951b-44e4-b733-32b4ab3d834d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd3c7b40-af1b-402a-8276-ef06209b4828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55bfe8ee-7a91-4ff1-85fe-57d75cbae488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37004ef6-3a82-4eb5-9a60-05c4251e5478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44a0580d-9690-4b91-b6d8-465e2906ffb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cebaa47-631e-4a26-a93c-b0f73adfbf47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d78b3825-7dc1-4637-bf22-605c84755360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a54143-9e9c-43de-987a-677eda79431f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f575a7f-7f93-4285-9290-5e73440f665a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4caeb6a-ee7e-48fa-892e-5641be7e362d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b56f3f9b-9dbb-4500-9acb-8cf40ac12fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85301ebe-6238-4203-96b5-de399f515d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cd6d25b-7b00-412b-9cc2-2f5ccd4798cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6588e7d-c341-4b93-a4f2-680b7116454f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9989925f-b253-4eb0-af22-493c85460bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ffa4f70-90c5-4a1c-8a48-a140fa412e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2558b7a7-d43f-4c35-8781-cb3c7abefdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d0b5a36-4b24-4a80-92b6-0e2404d5966b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be022c2c-2a8f-48be-96eb-9ddbeab3c0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b17edb-f327-4791-89da-e2720a3a9a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 702d01d1-a1de-43c6-a6e5-99ee72338bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50112b1-4aef-4fc5-9367-9dc89d9d1712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f765b41b-feab-4a05-9a02-b6ef839fa91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 312de584-f52e-494b-95c5-7945bfba6086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39b55ce-0422-4eb2-ad6d-fb13bdfc1cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0838e399-4dd3-4051-af8c-060bd8970d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a1d126-2898-4e87-b69f-d9c253a2c89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36486e6d-3bbc-4cef-a15e-f1d3cfeaaf0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd155ab9-c257-4ec3-bf45-025a25960f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b01299e-fb09-4181-9b0b-9ef385505d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d93cba-c438-4fc1-bebd-1df390ba9053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc21ac0-4df0-4485-9c4c-4d4efd2362ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df29cd7-9d49-4458-89df-bcb0752b2d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f1d8d63-0934-4557-9842-189bc669a07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62805dee-3a09-498c-9392-96bdccd15e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 815e552e-2896-4130-8379-1d434d718cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea51d232-3c02-409e-8aa2-b39f6c7f0a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad698e02-631a-4ef7-a144-ea283c1f0d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438e1ecd-d2e7-42f2-bbd0-82a72b3ddf50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b2076e-4435-4472-a0a2-bbd41721976b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcd64849-64f1-4218-b63f-d3d84f14d569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0859397-ae71-4a46-b3dc-91e503e8d033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac4725ff-ff99-4b49-b5f0-6a8f07c2d63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcbcc3c0-9740-467e-8ed2-3e8c79a79b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6bd720e-cc5b-4f87-ab86-c57ce284339d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5a7283-8fce-436e-9f35-91920a9157e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6885f17d-5412-4a09-8d7d-5ef73c26f554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eeb506a-d40a-4be5-a62f-a34a54032e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae8e024d-7a47-4754-bda5-572c773987d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7611e132-af04-4e06-9dd1-f9a3e9ad0f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6bc830-d412-465b-bc28-c02fb05bc92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fffd697-a856-4269-a03b-6cb6a4dd3689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc233637-97ef-4e15-be49-794a9ea4687b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08284661-6ec3-4665-908c-ec2fa5157f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cbd102e-8307-40f5-bcfe-a01be2ccf3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32d0401-bae3-4bbd-bcea-cb6a4dc1e725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a118a3-2e93-4e9a-8066-e968fe144a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15d538b-53d1-43a8-bf84-b9d37d002754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e4322b-4792-49a0-89e9-990ab1b8b0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 116d7b05-1775-47fb-babe-9c753e36c00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3836b6a4-e40c-49e6-9798-9ae0727f8149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d7f887-a338-4b96-b661-58ab5a61999f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcec77c-363f-4e7c-a437-76c17c988c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96637c5c-1a6e-45c7-a798-ea76f2f5a7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4325bad6-f506-41e5-a689-02bd6916e412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd274114-e320-44fd-88d1-d7f11593eddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1547f0c6-35a8-413b-b41e-689755b33396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16bdafa0-f5e2-4537-b125-016aaba7f2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0f7490-d801-4f32-b887-fea917d2b7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19ce0a1-a831-4444-954a-6dfdfd189e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e4c0ca1-d94f-4781-893c-30c35666955e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b5bc38-bb92-42e5-ad00-40a32768f54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d130e0f-fb0e-45d7-9056-c5fb9a44135d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cbc4bc1-6716-475a-a979-82ecb748a316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf333a2d-a228-48a8-aacb-d9a05deb7090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22b972d-65a3-41c8-b6ea-7c490f423134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85cfd889-1c18-4db2-87dd-1a91de436f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7555ff65-b32c-4dd5-84ad-69472ea7cad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a70dcab-5322-4954-ad82-6665e286986a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f21ce1f-0687-41c2-88ef-6442182b70c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce155007-5150-440a-a229-4ff665a08e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8635bcc9-bbf4-4d91-9614-820193709375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab6c453-0c63-4c83-8c0b-0ca6921d4c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0d72ba-02d5-466c-88a1-f95bc9257732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee67eef-79e5-43a9-9df2-bd58e215c7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b6f230-c809-46d2-9917-d4bcc4333431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ad37e5-0d80-4b1d-a4fd-5daa70b8b81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e62251e7-77e6-4f5e-9281-30ae411ea8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0976c3e2-fe93-40eb-8c66-71e9e4fba34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110bea14-ad30-4c26-ae18-78630442b3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad924ea9-8a5e-4584-9f65-2ea5714bef2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1552aafb-4e0c-454c-b30a-7b6858488f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ca05e5-4465-4303-8ef9-2d8ef300bf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2828e51-718c-46d1-8954-726ee7b709ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 918e10c1-ee4b-4709-956c-c884e7d9055b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e297c7a2-9f94-4056-94d4-b1762484ff2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce9f130-b270-4778-b713-0710605c3fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c335c1f2-e154-40cf-af86-7a8e5b129833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77ee13f3-b205-49cb-b4ba-6eee66ff7f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a348285-dbad-4676-bc29-04be150e5290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f057a85a-fff7-4f28-9ee9-81b30d1c11c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6945c3df-d77c-49aa-843f-f3d687587743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f922ca3-fa16-4716-ad36-d0d800740b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f522e6a0-18b9-45a9-b763-bf5cc22bfa0d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_64
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_labels.txt

📊 Raw data loaded:
   Train: X=(1040, 24), y=(1040,)
   Test:  X=(261, 24), y=(261,)

⚠️  Limiting training data: 1040 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  252 samples, 5 features
✅ Client client_64 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2535, R²: 0.0053

📊 Round 0 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2532, R²: 0.0109

============================================================
🔄 Round 6 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0724 (↓), lr=0.001000
   • Epoch   2/100: train=0.0807, val=0.0726, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0801, val=0.0741, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0795, val=0.0723, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0784, val=0.0723, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0710, val=0.0669, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0591, val=0.0695, patience=9/15, lr=0.001000
   📉 Epoch 23: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 6 Summary - Client client_64
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0677, RMSE=0.2602, R²=0.1729
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.1293
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2520, R²: 0.0232

============================================================
🔄 Round 9 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0738 (↓), lr=0.000500
   • Epoch   2/100: train=0.0792, val=0.0737, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0784, val=0.0733, patience=2/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   ✓ Epoch   4/100: train=0.0777, val=0.0732 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0767, val=0.0727 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0750, val=0.0721 (↓), lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125
   📉 Epoch 20: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0729, val=0.0712, patience=5/15, lr=0.000063
   📉 Epoch 28: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0721, val=0.0709, patience=6/15, lr=0.000031
   📉 Epoch 36: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 9 Summary - Client client_64
   Epochs: 40/100 (early stopped)
   LR: 0.000500 → 0.000016 (5 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1194
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0463
============================================================


============================================================
🔄 Round 11 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0817 (↓), lr=0.000016
   • Epoch   2/100: train=0.0770, val=0.0816, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0769, val=0.0816, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0768, val=0.0815, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0768, val=0.0815, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0766, val=0.0814, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 11 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0306
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0595
============================================================


============================================================
🔄 Round 12 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0806 (↓), lr=0.000004
   • Epoch   2/100: train=0.0769, val=0.0807, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0768, val=0.0807, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0768, val=0.0808, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0767, val=0.0808, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0766, val=0.0810, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 12 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0363
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0231
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2517, R²: 0.0271

============================================================
🔄 Round 15 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 15 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0381
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0369
============================================================


============================================================
🔄 Round 17 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 17 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0358
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0461
============================================================


============================================================
🔄 Round 18 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 18 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0320
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0541
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 18 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 20 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 20 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0457
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0083
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 21 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 21 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0368
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0457
============================================================


============================================================
🔄 Round 22 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 22 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0416
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0147
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 23 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 23 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0345
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0549
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 23 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 23 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 27 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 27 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0371
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0206
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 28 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 28 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0458
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0077
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 28 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 31 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 31 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0238
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0935
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 31 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 34 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 34 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0391
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0355
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 35 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 35 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0407
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0292
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 39 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 39 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0441
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0089
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 41 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 41 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0396
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0338
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 44 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 44 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0404
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.0185
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 44 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 47 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 47 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0452
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0030
============================================================


============================================================
🔄 Round 48 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 48 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0377
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0361
============================================================


============================================================
🔄 Round 51 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 51 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0415
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0252
============================================================


============================================================
🔄 Round 54 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 54 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0390
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0375
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 58 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 58 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0346
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0552
============================================================


============================================================
🔄 Round 60 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 60 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0405
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0247
============================================================


============================================================
🔄 Round 61 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0656, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0656, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 61 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0361
   Val:   Loss=0.0656, RMSE=0.2561, R²=0.0409
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 64 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 64 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0417
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0279
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 66 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 66 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0376
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0431
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 66 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 66 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 71 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 71 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0391
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0306
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 76 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 76 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0465
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0057
============================================================


============================================================
🔄 Round 77 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 77 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0421
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0249
============================================================


============================================================
🔄 Round 78 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 78 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0367
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0461
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 82 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 82 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0424
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0235
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 84 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 84 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0403
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0289
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 85 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 85 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=0.0340
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0590
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

============================================================
🔄 Round 86 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 86 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0392
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0371
============================================================


============================================================
🔄 Round 87 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 87 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0386
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0021
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 89 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 89 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0423
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0049
============================================================


============================================================
🔄 Round 90 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 90 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0373
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0210
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0279

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 105 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 105 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0329
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0493
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 105 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 105 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 110 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 110 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0343
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0505
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 113 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 113 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0387
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0333
============================================================


============================================================
🔄 Round 116 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 116 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0330
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.0572
============================================================


============================================================
🔄 Round 117 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 117 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0316
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0649
============================================================


============================================================
🔄 Round 119 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 119 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0359
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0489
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 120 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 120 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0409
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0277
============================================================


============================================================
🔄 Round 121 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 121 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0488
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0043
============================================================


============================================================
🔄 Round 122 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 122 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0327
   Val:   Loss=0.0672, RMSE=0.2593, R²=0.0386
============================================================


============================================================
🔄 Round 124 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 124 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0336
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0568
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 125 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 125 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0347
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0506
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 132 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 132 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0426
   Val:   Loss=0.0749, RMSE=0.2738, R²=0.0198
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 132 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 132 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 135 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 135 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0407
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0212
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 135 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 135 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 135 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 140 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 140 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0432
   Val:   Loss=0.0771, RMSE=0.2778, R²=0.0168
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 141 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 141 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0392
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0247
============================================================


============================================================
🔄 Round 144 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 144 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0420
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0163
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0281

============================================================
🔄 Round 148 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 148 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0287
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0753
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0281

============================================================
🔄 Round 149 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 149 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0388
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0374
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0281

📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0281

📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0281

📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 154 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 154 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0366
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0420
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0281

============================================================
🔄 Round 158 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 158 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0414
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0219
============================================================


============================================================
🔄 Round 159 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 159 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0327
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0508
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 162 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 162 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0334
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0612
============================================================


============================================================
🔄 Round 164 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 164 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0350
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0318
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 168 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 168 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0343
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0556
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 169 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 169 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0396
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0318
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 169 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

📊 Round 169 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 175 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 175 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0330
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0516
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 177 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 177 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0397
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0348
============================================================


============================================================
🔄 Round 178 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 178 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0431
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0203
============================================================


============================================================
🔄 Round 179 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 179 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0380
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0197
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0280

============================================================
🔄 Round 180 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 180 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0393
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0274
============================================================


============================================================
🔄 Round 181 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 181 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0367
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0223
============================================================


============================================================
🔄 Round 182 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 182 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0382
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0321
============================================================


============================================================
🔄 Round 183 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 183 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0415
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.0268
============================================================


============================================================
🔄 Round 184 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 184 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0419
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0084
============================================================


============================================================
🔄 Round 186 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 186 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0383
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0379
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2516, R²: 0.0281

============================================================
🔄 Round 189 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 189 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0348
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0402
============================================================


❌ Client client_64 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
