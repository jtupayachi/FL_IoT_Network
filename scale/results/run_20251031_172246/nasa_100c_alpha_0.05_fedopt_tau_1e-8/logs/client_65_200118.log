[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 215ccd69-dc9e-4561-a8d8-1af54bdabd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb3f210a-51ac-4ef8-bb21-d8d66e2a964e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf6c26e-941a-45e3-91fa-db97b70ba1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd601e2-cb62-4fc7-aef2-8b7c1b1eaa9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc679037-7973-496b-b928-d64100722aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 174654c4-f59a-4f1d-aeed-9ef8a25f48e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4857bf-29b6-4973-8f94-14a280027c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666f68e0-9f21-405e-9240-3caeca23b162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c77478-b425-42f6-b1f8-796a31f799aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0514ee67-a2f2-4a57-b45f-363fe7d9c789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 405b33b8-a4ce-42e3-8065-d7ea39de0826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521d9df0-6062-46b4-bed5-7d71f864ff14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82caed28-eadd-492f-8306-f3bfeb73616e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38acea8-4514-4043-b3c4-6c305e2095b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ecb1d4-d1df-4195-a8ff-2bc808ebd0cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f3de19b-ae50-4ebb-b1a7-5e2fe1931902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad82bc9-5109-4efb-986c-f5e017c66654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fdd1677-9672-4eab-9b3b-354081fedd78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc08d335-38ca-4ba0-a71d-1361f04ca2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838229f6-a236-4161-a6ee-5bb8cc6ea7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51c43c7-a16b-4f21-bcd4-97e5643d72ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message becf5077-9327-4761-96fd-1b66c7cc8fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70bac4a6-2186-4220-98a7-fcd607b49b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61154a3d-c078-4418-aa17-696db70caadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4f6a3f-1f41-4510-bf07-e6768794c918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc5c99c-acc6-4d40-b13c-5b59d703bab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d23525e-192c-403f-a81e-4c2953cf7e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de67e8d-d6c9-491e-9769-bf66cbb3eefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ee9c9bf-d05d-4a26-aff6-ed06fa8fd628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86c9e34-1018-4df6-b117-6d4885b4f32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ad69d8b-3753-40e9-8a79-ff687f4cf0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c6220b-a2a9-4d6d-bbaa-8cdfc1a9bb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d3e5b9b-298c-47cd-b2bf-96cf84de0645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01a854a-cec3-4116-8ce5-5f557fd8d098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7592569b-b9cd-4f1d-a970-6b0a95f96623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a96487c-9d5d-4cf6-9a70-b8b9ce568c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33b01ee4-f510-4335-b27c-d228c932535d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638653c8-72c9-4c02-811d-f47fde4a9177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ced39b3-e38a-4dc3-a64c-093f35e439ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51f4342-127b-49ea-83fc-a87649f90b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a42440-fb0f-4761-89ea-a2d0517af4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0ca3513-8c16-4fc7-aab9-bf6a044001eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ba2873-7f69-47fa-8a42-e24375e5fa17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d2bcf2-7355-4c09-b197-a83894528760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d87ad1d1-f092-44f1-ad40-3c5bdb0c884f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9d13f84-2f31-4185-a3d0-a842e96872b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351bacfb-72d9-4c25-9e61-0884e7f4e392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7579703a-6516-44f0-a077-bc419bba20db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd2daf0-86ca-4751-8854-65845646ff37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67bb1a7b-5d26-4396-bf7e-fa1044a88a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fc232f-ab05-4d93-ac22-69f70c1bfa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75455ac7-2f2a-48c9-8005-9a02a2a5fcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb955521-e1b4-4d57-bacb-8cdd5f14fc3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a527051-4ebe-4c10-8964-70d8e7de0887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536e40e9-3100-403a-aedc-e1d90e7639fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d445f0-d88a-49e3-93fc-b65f5ed8a6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac514f53-5a71-4852-b96f-14b7842dbfe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e33e78b2-2c87-4426-8c77-ee61bc81a8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d71be5-1925-4342-9844-c9c5c06d5cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ca8b5a2-8ef5-4ea0-ad35-1423a81c908a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683a1255-d8eb-4fd2-bdaf-141697b72a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cdc6ee-a627-4dc5-b07d-302f476e802b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac2f32e-b773-4040-8c7c-b6a335b7f9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b60ce3-9fba-4352-b47b-941ab8923c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff011f6f-6348-45e5-9351-c5f5114fc17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db64295b-401b-4b66-b9fd-e47c34fe8d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a6679b-fca4-44cf-b226-77ac5048232a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11dca259-a245-4aa1-840c-d4a6dd165bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7866c7-cac0-4813-85cd-63e46ac31577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e888c0f-fdc9-45c7-89e3-609514010133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8176cf98-47db-47e5-9c0a-ba0f720cb271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5efd2a-f269-4ee1-9fa5-c66a18ca1554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 224f1cc8-5709-4fe6-92f6-69b3c8e081cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01929861-bb26-41e1-9c89-4f45c0f57169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ecbb650-6031-45ac-a710-b9754d3d4e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4380990-d2e4-4e6f-a969-44ab3ff70e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99903819-45d1-4809-9bd4-a174577247f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c607e2-22b2-4faa-8b80-01b8d961c9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 144aae6a-0514-4b84-946d-d6ebd408bee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1fa62e1-786c-4209-a049-f104854a5da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a5056c2-ab7f-4a19-8902-6857cc731182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d84dca9e-8479-429e-ad14-787ed45c5658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88266b35-b341-4abb-8132-32e8becf3e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b0ace1-9214-42e9-bf34-4daaa9753cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2da2a1d-0810-4614-81b7-7c2ce49efeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50b4225-bf16-4a74-a7f3-cf64275dd9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68a5f5f-ca08-42d8-9851-e968e84891f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695b1a9b-061a-4aac-a251-2fe330db61ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42eb022d-ebd1-4504-a52c-f3d1b81f40b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f56bd4c9-6a47-42d2-84f4-1b5ac9a23647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 125d3b7d-8ab1-4968-989a-cbfcb072269c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ffdea4-b5e4-401b-997c-97f5d27e98a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3729c67-5472-4be3-bc6c-e8c3dd3000c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0caf77b-83fe-4332-b261-5bf39213db60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message badd2421-e9f7-479f-b8c9-4c8e526d9284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ccc091-dc8c-4c50-bbc5-30d2914bc70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a11fa05-d333-45d7-a34e-74c8448f659d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6420db6d-0cb6-4b62-bc22-faa7d62e940d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 540b9688-4b4b-46ba-b364-a1a2920425c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab29d7e-6bb8-4562-8d42-5ec0ffee4736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 017a71ce-c579-45e2-b0ae-c94ec2dc9a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297b977a-9f6b-4e49-9cb6-e3ee7bc0e356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce75594-203a-4ab0-aefc-35439c67cf30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d09c411-e134-4b55-b20d-20e6e27f3021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad2fd6a5-f0ff-45b3-a224-c9ab3e0deca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55661851-b2b9-4012-9089-d22e46245a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3cabb3f-8967-4295-971f-079b093bf13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d2353f-82af-4002-8be9-9cbb6c4ffb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94902758-a037-452a-a034-d170da91f789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d2f9b0-1e6b-4482-81b4-a637f211a029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e3bd135-7409-4f68-88d1-914a7f908025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7835e15-6139-4ff9-ab91-651065f3c2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34f605d-ff9c-401f-8a0d-5d8dfc4582ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c83384-1983-42be-a290-7de2e34d4cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d4c611-d5d7-40e7-8766-78c85d59a69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe6cd5f-c1be-4a90-a936-8fc8b42ddbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ade57a-7f79-4d3b-b864-863bc8ad328a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b754e66-415a-4c50-ae69-3de88ed5ae64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4d616b-2157-4e38-b004-af5382bbd0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed60b5a-f5aa-4d52-97e2-c482e87c7ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a59c8e-8134-47fd-9c95-908af1c17459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc85253-b718-423a-a809-d9aa53a5b482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0848f4-40e3-405b-8582-7f5a152b70b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43596775-555a-490d-867a-a07fc21c0fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b8afdf8-1f64-425d-aed5-ad7fd6af627a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93611d5-4622-4277-a915-08dd80a85aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4a2076-2617-4cd5-ac40-5669e2b6d139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d972939-a06d-491e-b593-49a2c7c5ce60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51271331-9caa-47de-81a1-2394d663f5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0313f696-75ac-4a25-b3c2-f2e5d92d47df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16faa34-32ae-42e6-899f-9848ca72a303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d415502-a1cc-4fdb-907e-a50a716e7e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 653baf83-1d4e-4e36-95cc-7c9b4af69b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7eaab7-d92d-4afc-8452-4246b84bcf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d2c823-15f7-4f0b-bf5b-172b0e92b775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61d85cfb-7d22-480a-ab32-f55201d79cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252a1f57-f244-4ebf-99ac-5dad94138552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 056ca0a0-4fc3-4574-b1a5-a53bfbd6741a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433e8ea3-0de4-47b7-89f1-9155ed830d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28242601-99f8-491a-ac4b-b941fdeb7bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a25f5798-5283-4b1f-a93e-10020779ce63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18aacf39-1cc1-47ca-aa10-b76d993b9c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 653ffe46-10e4-4240-91fd-72a016a4f68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403e355b-ca48-4662-8967-fa562862b8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68975459-38f6-4b63-b366-69fd604d154c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9680a487-4a1f-4452-8539-f2ebef98276f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a340a04e-2d60-4458-b5f8-f2ebde1350ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb6cf33-5fd2-4368-a476-ff1386e1edc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc23dea-9c2e-4f14-8c7a-3e4a9bd72085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 431c7d96-1016-4571-aa12-7c288e378273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1906a612-76a0-4bde-8161-7dd30b6a86db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19c8a782-29b9-4625-8680-a0462ab038b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dbe15c5-38b1-40d6-8def-82f88a5e82ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4504c8f-e80c-4c46-8dc9-d0bd83ee6019
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_65
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_labels.txt

📊 Raw data loaded:
   Train: X=(1919, 24), y=(1919,)
   Test:  X=(480, 24), y=(480,)

⚠️  Limiting training data: 1919 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  471 samples, 5 features
✅ Client client_65 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2440, R²: -0.0033

📊 Round 0 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2435, R²: -0.0024

============================================================
🔄 Round 3 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0840 (↓), lr=0.001000
   • Epoch   2/100: train=0.0882, val=0.0874, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0857, val=0.0836, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0844, val=0.0841, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0846, val=0.0844, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0816, val=0.0851, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 3 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0016
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0071
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2430, R²: 0.0007

============================================================
🔄 Round 5 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0825, val=0.0912 (↓), lr=0.000250
   • Epoch   2/100: train=0.0816, val=0.0912, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0813, val=0.0913, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0811, val=0.0915, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0811, val=0.0915, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0805, val=0.0916, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 5 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0116
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0028
============================================================


============================================================
🔄 Round 7 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0838, val=0.0843 (↓), lr=0.000063
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0834, val=0.0840, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0833, val=0.0841, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0831, val=0.0842, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 7 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0122
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0303
============================================================


============================================================
🔄 Round 8 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0774 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0848, val=0.0769 (↓), lr=0.000031
   • Epoch   3/100: train=0.0847, val=0.0766, patience=1/15, lr=0.000031
   • Epoch   4/100: train=0.0846, val=0.0764, patience=2/15, lr=0.000031
   ✓ Epoch   5/100: train=0.0846, val=0.0764 (↓), lr=0.000031
   • Epoch  11/100: train=0.0845, val=0.0763, patience=6/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 8 Summary - Client client_65
   Epochs: 20/100 (early stopped)
   LR: 0.000031 → 0.000016 (1 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0113
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0071
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2425, R²: 0.0030

============================================================
🔄 Round 9 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0827, val=0.0862 (↓), lr=0.000008
   • Epoch   2/100: train=0.0825, val=0.0861, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0824, val=0.0861, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0824, val=0.0860, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0823, val=0.0860, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0822, val=0.0859, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 9 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0050
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0178
============================================================


============================================================
🔄 Round 11 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0827, val=0.0853 (↓), lr=0.000002
   • Epoch   2/100: train=0.0827, val=0.0853, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0826, val=0.0852, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0826, val=0.0852, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0825, val=0.0852, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 11 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0054
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0065
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2426, R²: 0.0017

============================================================
🔄 Round 14 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 14 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0018
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0119
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2426, R²: 0.0010

============================================================
🔄 Round 16 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 16 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0061
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0275
============================================================


============================================================
🔄 Round 18 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 18 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0022
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0136
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 19 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 19 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0054
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0086
============================================================


============================================================
🔄 Round 20 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 20 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0131
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0724
============================================================


============================================================
🔄 Round 23 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 23 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0070
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0124
============================================================


============================================================
🔄 Round 24 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 24 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0140
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0461
============================================================


============================================================
🔄 Round 26 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 26 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0057
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0044
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 26 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 26 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 30 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 30 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0007
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0211
============================================================


============================================================
🔄 Round 32 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 32 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0106
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0243
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 33 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 33 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0075
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0126
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 33 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 35 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 35 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0010
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0187
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 37 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 37 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0112
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0347
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 37 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 43 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 43 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0057
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0112
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

📊 Round 43 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

📊 Round 43 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 48 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 48 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0026
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0230
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 49 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 49 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0079
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0123
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 50 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 50 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0059
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0049
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 53 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 53 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0035
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0033
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 54 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 54 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0094
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0193
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 58 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 58 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0035
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0046
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 66 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 66 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0305
============================================================


============================================================
🔄 Round 70 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 70 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0016
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0188
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 70 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

📊 Round 70 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 73 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 73 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0116
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0286
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 77 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 77 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0012
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0242
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

📊 Round 77 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

📊 Round 77 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 81 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 81 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0055
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0040
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 84 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 84 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0014
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0238
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

📊 Round 84 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 86 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 86 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0026
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0077
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 89 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 89 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0018
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0115
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 92 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 92 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0002
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0178
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 92 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 96 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 96 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0049
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0312
============================================================


============================================================
🔄 Round 97 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 97 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0066
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0096
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0006

============================================================
🔄 Round 99 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 99 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0102
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0264
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 101 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 101 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0037
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0036
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 102 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 102 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0120
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0352
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 103 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 103 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0055
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0153
============================================================


============================================================
🔄 Round 104 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 104 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0054
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0049
============================================================


============================================================
🔄 Round 106 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 106 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0020
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0100
============================================================


============================================================
🔄 Round 108 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 108 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0094
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0171
============================================================


============================================================
🔄 Round 110 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 110 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0098
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0468
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 112 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 112 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0018
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0211
============================================================


============================================================
🔄 Round 114 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 114 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0010
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0211
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 116 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 116 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0070
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0290
============================================================


============================================================
🔄 Round 117 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 117 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0039
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0348
============================================================


============================================================
🔄 Round 118 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 118 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0062
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0133
============================================================


============================================================
🔄 Round 121 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 121 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0008
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0012
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 121 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 126 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 126 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0003
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0139
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 126 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 126 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 130 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 130 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0005
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0099
============================================================


============================================================
🔄 Round 131 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 131 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0116
============================================================


============================================================
🔄 Round 132 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 132 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0068
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0131
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 138 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 138 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0065
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0085
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 139 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 139 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0054
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0085
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 141 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 141 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0049
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0106
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 141 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 143 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 143 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0026
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0183
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

📊 Round 143 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

📊 Round 143 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 148 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 148 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0011
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0088
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 150 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 150 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0089
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0231
============================================================


============================================================
🔄 Round 151 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 151 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0041
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0022
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 152 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 152 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0125
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 154 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 154 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0005
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0150
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 157 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 157 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0019
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0041
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 160 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 160 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0024
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0096
============================================================


============================================================
🔄 Round 161 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 161 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0029
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0075
============================================================


============================================================
🔄 Round 162 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 162 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0000
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0196
============================================================


============================================================
🔄 Round 164 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 164 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0071
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0140
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

📊 Round 164 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 164 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 169 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 169 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0036
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0027
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 171 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 171 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0025
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0081
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

============================================================
🔄 Round 172 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 172 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0079
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0215
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0007

📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 180 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 180 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0026
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0293
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

📊 Round 180 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 185 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 185 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0041
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0029
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

📊 Round 185 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

📊 Round 185 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2427, R²: 0.0008

============================================================
🔄 Round 190 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 190 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0082
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0152
============================================================


❌ Client client_65 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
