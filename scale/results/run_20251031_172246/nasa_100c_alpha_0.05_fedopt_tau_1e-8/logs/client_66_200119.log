[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04df7834-2f15-4b7f-9d85-2a85e38de2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 677fe716-6e9e-42a4-bfa5-d026172db7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e372d3-a5d5-4834-8042-5f59204a4c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0eea67-6178-4e68-8f41-6f1b33590bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda07f51-4f71-45e8-89f1-eac3e04b3e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a99c842-dcd8-436e-80cd-2dc8ec620d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07122b04-4b0e-4cc8-9c9e-587ffade9710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18bcfca0-1b89-46ac-8eb0-89201ca11f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77fb202-34c3-4d48-8391-bafef96b4b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14a12a5e-ec2f-4ea3-896e-a3352433476f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfe6469-8367-405f-965c-96886bf4521e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abfb5326-7499-4ba2-a2bc-48333ab301c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e3127b-7b9a-4ed1-a622-12868d0d0077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 875ad1f7-8f67-4859-8680-15143e1c218b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9759b1ac-9d93-43d6-872b-d2673b4febd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f82392d-8d75-4c13-94b6-1a5a82e245c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce785e1-da5d-4b9b-8c8c-dbefc7bfe1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd59b761-1bea-4fb0-9ab1-a918056bad09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e089b55-975b-4f80-a399-1f9589442ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a98918-9fae-4dfa-9409-51e2408c8c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5824ff7-f6ef-429e-8201-5ecdb695de00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 749d2f6d-f04f-426d-99cf-f459b124efa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af25ea8-cd4c-4efd-ac62-f5b85ab061c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e08fad-97f1-49af-8f70-d207306f3d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 378197ed-0e4f-4aec-ae90-b66043621d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d4a00b-bec6-4b50-b051-525a5643d554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fb1165-b3d7-4738-8fdb-f1eca2fc4078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f10ea2d-265f-4bc4-8ba6-bf5426572bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec7d48e0-2677-4c6a-910f-94fe3fffd995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 968094fd-821a-4399-86b6-50799ccaac8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5a9281-f4ec-4107-ab08-6ba67f3d9c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad60fccf-764e-4758-8a62-f86dc0e5999f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02af8cf4-43b5-4fdb-9c23-cb5e29e0a62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 278aa185-0640-4904-8a03-aada5731a962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55ca778d-7ea2-49a8-97d1-f1d848ab30f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c28fbc9b-602e-46dd-bfe9-72a2397b08e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ab5ee0-dc99-45ae-9bf1-88c5a06b953c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8931da60-4d67-4904-9f6a-ccb4e87cb761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3324aced-603b-41fd-a3f2-50af872908ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aff90288-0367-4d94-abe2-a26b09708e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1540db7-67b7-4688-a071-3470f6c82c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1b69e43-64aa-4b25-a74c-2eb86a584f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7632083-e20e-4257-a07a-b79dd9bc64da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218a84e8-97de-4c5b-8c81-3d5f8e23bcd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c81dfb4-d000-4232-bb66-06d65f3f046c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d745145-9feb-4fbf-950e-83d8108131e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60bba55-664a-4e2b-b9a6-76acbf97d168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1945789d-ace3-4643-974a-484e2ddda890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6346df12-abdd-426f-8312-566be990d1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7e8754-7cbc-45d6-b8f0-cfff38c51b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56ec4925-130a-43ed-9368-a301949bbb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc92fc1-9264-4bd4-81a8-7e208d5eab1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 508ab085-a19d-4a33-90b1-a768044f5ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da58522f-2f50-4c52-a8e1-f83c353fa29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3a4afc-d92d-4669-986b-3cfa2b3ef5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6059703a-68a5-46a7-81cc-853c4da6561a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c5809b-8094-475c-87a7-5d563528af1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615d5bce-18a9-4c7d-968f-fa2c1ddf78ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31f1040b-8304-4eb5-9351-797563d7d99e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b35ba70f-d7cb-41a4-83d1-29e417d44b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6849b966-f187-42d5-8b67-2be840019a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4636539f-4652-47a8-9df7-82767d5fa63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19cc4e0b-7c95-473e-a078-9e97b27b01ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa366874-5bcf-4a68-9b56-8566d4fa986e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0a015fe-2e91-49ce-a9f6-1d5fede3e822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80ca762-15b7-4c73-a738-2ad191a97b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44646a47-6e13-40a9-a85d-0ba637fd4ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a57454-0fa4-490e-adac-e83d0db069b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b337e6b7-0c0b-4303-b62f-8dddd4fe82e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7385ee40-fab0-4025-8717-144895845aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2de7dd2-2501-4d4e-bf78-8204e7dae68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edf3952-dfb9-416b-92cd-ca21f9967afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65c7acc-de8c-49a2-8c64-38b4472b3f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc587cf-9ae9-4159-b227-fb6fd00b6c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b3d067-7a92-45a6-8a4c-b425e1d11be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3694da-8295-4d67-a40e-e4753bc17620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25641c85-c1c4-4871-a614-656f0f4deb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad562da-f263-4b91-a07b-05af8af7c8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a43cc0e-f553-405b-876d-c41072226d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7242f38-b3d7-4337-8ca9-aabdd9a83918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d4c7af3-b8e6-4e13-90c0-024df3082fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e780b8f-f2b3-4928-9d8c-8d7564832965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74c1879-ecbb-4a59-9021-500a51cd3f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89de361e-7d2a-4a89-94b7-c66423f0e250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ae996b-2d5a-4bb5-b8fb-bd0ff65c9d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6831b3b4-98c5-453a-9879-2ffa3476f5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07022bc-e322-4e56-bc3c-6fe334d29d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d7ea86-62dd-45dd-ba8e-82a21469d265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e48a9c-4f2f-43ad-8082-95f78dfd9b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff624dbb-86ce-4e71-9425-c61cff6f82c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be43568c-7431-437c-b8c4-69c21cb9b981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f02bcf-6632-4a9e-99ad-2a97a296ff5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325ea4c2-aad2-42e9-bd3b-d672d3539a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98052f93-de13-4fd2-95e4-a731fae0d608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e30521-f908-42ce-9d16-7f7eb38e7429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6342994-e143-49be-8440-027531cf9d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9f11cb-06e2-4981-a90c-f794bd85d390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf0160d-3f88-407f-b1c3-3d4ca0f51701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebedc1b6-e755-4774-9ab1-8dd9244ba527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bc3694b-b93f-45aa-aedb-0b2856b31111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961c9ac2-1096-4035-ba41-1486106bf161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9bf95f-2cfd-4913-8560-e66f3d9bf01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dded5e0f-458d-40d4-a137-58843e3226ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e0fe39-8f6c-4cf5-af86-d7c95524a4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ff7b3a-a49f-4c01-925c-8c55a24fe5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e06e6c-cf38-4ff6-918d-60d55befa791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 103494de-23c4-4b41-91de-2dc79d1a7e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8460a9-d41f-4e34-9ab3-89bcf78b7b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ddfa32-19c0-4417-b99a-5ab2067ca5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b22c316-27d3-4c4c-9b6c-4759cb6097c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00345056-4508-40c1-8760-009eff1c2a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3301c0a-9683-4d50-88d2-9e4b0517967f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63954b2c-cd88-4a2e-a422-92446db93ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210db88e-fb33-46a1-8625-9750563bde4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c4630ad-3f11-45bc-9565-b4b55d8def89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfa3fd0b-c4ba-4248-8db5-0aa0b5649c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4f4ff3-424b-450d-9626-46062d46b88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dbd9d7b-3c45-4918-b9a0-a840c3e50929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082fd22f-db88-4a4b-b568-379c79b0c106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36d28ec-1d9d-4dcf-b765-e251d85c1ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2522d336-9f33-4e6a-be2b-fa8f2d731383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65c7d50-6eb3-4da3-952a-9ab2a5b91357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd98da5-84d9-45df-ac53-11bb6a946e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a2b941-f498-44eb-9f60-ef303a396f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9acc3447-a773-4b66-883f-e301c15a11b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e0d286-cd1f-425a-9e43-d950e302c2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de6727a-33e9-47aa-b3d9-49e140481b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07d1f1e-d27f-4da4-867a-7f36a2f89c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b45a1f-d84a-4bd2-a83f-b50a5b794f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15df91f0-b297-40d0-b82d-d5f9e682f03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b370f8ac-a26a-405f-8200-c682e37cdab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea54bd6-97ea-4232-b05b-c58e4044c4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414538b8-f1f0-48a2-b66f-73da83e7ca7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ee1936a-ebbd-4017-b7c2-a3edd3091fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f16d9cee-261d-4534-89a5-76891f1b1f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 001d6039-2c2d-4006-97f0-34d06e6978ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4634d3da-6d45-40f8-8d4a-af7ee975b6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2afb5707-b36d-47b8-ac47-60e50bf4beca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96547ceb-6998-461e-ab9c-e306326a31ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1cfc42a-b413-4fbf-b44f-6e72ae705e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2777f52-f4f5-41b5-b908-3bf4934f2e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f693127-29af-4d28-ae60-fcf5c4baf746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e4fc01-79ac-4042-9f42-5b91879002a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e93debea-8696-4c7e-af4a-78ab1e7101ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e455b5e7-4b26-4c23-9ce1-314df97af469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbde11b2-c244-4e8d-88b5-14ae92a4bf29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96201b78-740e-41a7-a480-3c2bf2efa903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c4fc91-9a4b-4d23-809b-b2736dbec860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f1f8373-031f-4018-8e10-64b676520060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95289ed9-88f0-469b-8d87-4039a23e2fb2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_66
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_labels.txt

📊 Raw data loaded:
   Train: X=(1796, 24), y=(1796,)
   Test:  X=(450, 24), y=(450,)

⚠️  Limiting training data: 1796 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  441 samples, 5 features
✅ Client client_66 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2513, R²: -0.0045

============================================================
🔄 Round 3 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0847 (↓), lr=0.001000
   • Epoch   2/100: train=0.0819, val=0.0848, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0821, val=0.0848, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0821, val=0.0848, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0847, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0809, val=0.0852, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 3 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0005
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0033
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2513, R²: -0.0039

============================================================
🔄 Round 4 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0910 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0812, val=0.0901 (↓), lr=0.000250
   • Epoch   3/100: train=0.0809, val=0.0907, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0808, val=0.0908, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0807, val=0.0910, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0802, val=0.0913, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 4 Summary - Client client_66
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0023
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0218
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2528, R²: -0.0181

📊 Round 4 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2534, R²: -0.0241

============================================================
🔄 Round 10 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0844, val=0.0826 (↓), lr=0.000063
   • Epoch   3/100: train=0.0843, val=0.0825, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000063
   • Epoch  11/100: train=0.0838, val=0.0823, patience=9/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 10 Summary - Client client_66
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0144
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0309
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2535, R²: -0.0244

============================================================
🔄 Round 12 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0874 (↓), lr=0.000063
   • Epoch   2/100: train=0.0830, val=0.0874, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0829, val=0.0874, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0828, val=0.0874, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0827, val=0.0873, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0823, val=0.0872, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 12 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0197
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0243
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2538, R²: -0.0265

============================================================
🔄 Round 13 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0845 (↓), lr=0.000016
   • Epoch   2/100: train=0.0840, val=0.0847, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0839, val=0.0848, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0838, val=0.0850, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 13 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0243
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0350
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2538, R²: -0.0264

============================================================
🔄 Round 14 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0880 (↓), lr=0.000004
   • Epoch   2/100: train=0.0832, val=0.0880, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0832, val=0.0881, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0831, val=0.0882, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0831, val=0.0882, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0829, val=0.0884, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 14 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0126
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0900
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2539, R²: -0.0280

============================================================
🔄 Round 16 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 16 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0294
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0132
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2539, R²: -0.0280

============================================================
🔄 Round 17 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 17 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0305
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0152
============================================================


============================================================
🔄 Round 19 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 19 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0278
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0216
============================================================


============================================================
🔄 Round 20 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 20 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0215
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0516
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2539, R²: -0.0281

============================================================
🔄 Round 21 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 21 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0197
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0781
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2539, R²: -0.0280

============================================================
🔄 Round 22 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 22 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0273
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0183
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2539, R²: -0.0281

============================================================
🔄 Round 24 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 24 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0249
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0383
============================================================


============================================================
🔄 Round 26 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 26 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0243
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0323
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 29 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 29 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0265
   Val:   Loss=0.0665, RMSE=0.2579, R²=-0.0205
============================================================


============================================================
🔄 Round 30 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 30 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0199
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0466
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

📊 Round 30 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

📊 Round 30 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 33 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 33 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0278
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0286
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2539, R²: -0.0280

============================================================
🔄 Round 38 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 38 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0305
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0039
============================================================


============================================================
🔄 Round 39 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 39 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0257
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0251
============================================================


============================================================
🔄 Round 41 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 41 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0284
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0145
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0280

============================================================
🔄 Round 45 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 45 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0287
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0125
============================================================


============================================================
🔄 Round 46 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 46 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0246
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0497
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

📊 Round 46 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

📊 Round 46 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 49 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 49 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0300
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0061
============================================================


============================================================
🔄 Round 50 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 50 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0267
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0415
============================================================


============================================================
🔄 Round 51 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 51 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0221
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0402
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 54 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 54 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0277
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0233
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 59 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 59 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0223
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0480
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 61 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 61 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0242
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0299
============================================================


============================================================
🔄 Round 62 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 62 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0260
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0309
============================================================


============================================================
🔄 Round 64 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 64 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0308
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0230
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 65 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 65 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0312
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0030
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

📊 Round 65 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 70 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 70 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0222
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0566
============================================================


============================================================
🔄 Round 72 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 72 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0178
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0552
============================================================


============================================================
🔄 Round 75 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 75 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0269
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0198
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 76 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 76 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0283
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0183
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 78 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 78 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0252
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0264
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 79 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 79 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0285
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0132
============================================================


============================================================
🔄 Round 81 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 81 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0257
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0245
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 83 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 83 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0280
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0555
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 87 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 87 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0274
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0166
============================================================


============================================================
🔄 Round 88 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 88 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0254
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0366
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 91 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 91 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0252
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0379
============================================================


============================================================
🔄 Round 92 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 92 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0181
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0556
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 93 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 93 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0194
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0501
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

📊 Round 93 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0281

============================================================
🔄 Round 99 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 99 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0214
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0417
============================================================


============================================================
🔄 Round 102 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 102 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0246
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0286
============================================================


============================================================
🔄 Round 103 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 103 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0181
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0626
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 104 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 104 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0287
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0203
============================================================


============================================================
🔄 Round 106 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 106 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0283
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0157
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 109 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 109 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0247
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0449
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 109 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 113 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 113 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0270
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0185
============================================================


============================================================
🔄 Round 114 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 114 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0305
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0072
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 114 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 117 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 117 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0304
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0044
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 122 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 122 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0222
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0412
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 122 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 124 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 124 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0242
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0315
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

📊 Round 124 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 126 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 126 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0239
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0309
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

📊 Round 126 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 129 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 129 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0255
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0267
============================================================


============================================================
🔄 Round 130 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 130 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0300
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0145
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 132 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 132 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0277
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0223
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 134 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 134 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0298
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0177
============================================================


============================================================
🔄 Round 135 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 135 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0261
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0277
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 136 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 136 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0256
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0268
============================================================


============================================================
🔄 Round 138 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 138 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0232
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0374
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 138 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 138 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 138 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 143 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 143 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0289
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0105
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 143 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 143 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 149 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 149 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0264
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0259
============================================================


============================================================
🔄 Round 150 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 150 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0269
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0206
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 154 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 154 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0255
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0253
============================================================


============================================================
🔄 Round 155 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 155 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0231
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0352
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 159 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 159 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0230
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0375
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 164 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 164 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0279
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0276
============================================================


============================================================
🔄 Round 168 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 168 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0255
   Val:   Loss=0.0984, RMSE=0.3137, R²=-0.0258
============================================================


============================================================
🔄 Round 170 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 170 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0288
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0153
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 170 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

📊 Round 170 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2540, R²: -0.0282

📊 Round 170 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 176 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 176 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0354
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0060
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 176 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

📊 Round 176 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 180 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 180 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0350
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0006
============================================================


============================================================
🔄 Round 181 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 181 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0256
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0253
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 183 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 183 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0228
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0506
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

============================================================
🔄 Round 186 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 186 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0308
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0304
============================================================


============================================================
🔄 Round 188 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 188 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0257
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0237
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2540, R²: -0.0282

❌ Client client_66 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
