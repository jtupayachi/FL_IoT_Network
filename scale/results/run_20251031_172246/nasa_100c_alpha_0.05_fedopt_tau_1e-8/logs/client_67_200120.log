[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39bb6e1c-92d5-4ac7-9e03-484b8c589de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88070357-6f2c-413e-82cd-d48b6d509fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e759796-2caa-4c68-8ab5-5c6816c8895e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf9e065c-e71d-4f5b-9826-ba1f79485d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b98728d4-4c19-4aa4-a23a-1fd57f0cf2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be61548d-dcd6-4f13-b629-a1a4e7c7d747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ee8395-49e5-4cbe-915d-81d1091966a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac0d24d4-1140-461c-80db-64a652d19dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1150441-52f6-4903-8d26-626a92e2aa60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e197281-6a8a-4c82-9a45-9baa7d60c03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f290142-0e76-4ccf-8d29-ed704e4bf031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ef66e6-7cd1-48ee-84f2-c6f6c8179369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1075ed-8bb2-4c9f-83b2-b2da2a12fe54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f891f9-d299-4035-baca-18e3ec93d17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4e020a-a60b-44c2-ba6e-ab75b0cb322f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abc3ba27-9fc3-44b9-8dc0-87abd5da48ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eabfe4f-f17a-470c-bc6d-39e9b0fe188e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad533e16-494b-4cd2-a6f2-95ae2992e604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943b214f-8da0-4db8-b9e5-75378da5b4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc342802-20b6-4d9b-82a2-18f80ff9942b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b15785a-479e-4260-8698-c4fc95b59e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de61fab2-d8fc-4c8b-99d6-e4164b879b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9dafbef-7a27-4b01-9ba3-11ebc5177e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d69efb-30d2-4389-98fe-502f9446cac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65223bce-952a-4558-b9e8-7c6154e9188c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450e6a8e-93fc-4b8f-a001-98df31556c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e35a1b6-1932-43c2-9e77-443a78868913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348ec104-91f1-4703-9b7b-8868cb5868a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7acb820e-f639-429f-9eaa-9704b1fd0495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb23a6e-12d4-4c49-8b43-51194c5add89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b53bda85-ce28-403c-8555-c225ca5f5729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52a2ec1-66fb-4ec9-b8e2-de7d809fb322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd22e2c6-39be-478f-a6e1-6a168f35f0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81efbc27-8a9d-44dc-bfad-070a77b00463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24149f01-aff5-44dd-8757-299b24ee9b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ef225d-3ce9-474b-a507-e50a3c6c941a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb71ce30-89ca-448c-93d9-fd409fed00a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac29980e-5187-4d79-9438-396286a6bb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fcdbf0f-69c1-4e25-85c5-d47750e2cf21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b7080f4-6c88-4752-86d9-37d62e5c3516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f217fd-2e30-4fe1-9816-3ffc2c60a7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd335af5-82c7-4dd8-af79-5965514157d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8478808f-82bb-4b1c-8d3c-8ade5ba9d506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3e4eaa6-a403-4263-b6bd-1182ab9e5f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7f4e62-1ffa-4209-be8b-d02ff07e4521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8201af1f-68cc-4381-b2fc-8a43591d6288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ccf92f8-125c-40f3-8000-e69d89dbff7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88871e63-8701-4da8-96b8-78b23229e1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d0d218f-762e-43ac-9aa4-25739cff2293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18551dfb-5beb-4be4-ae70-25eb669fe9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0099e2d-6734-456f-afce-8e08296eb86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507158ed-847c-48e7-94fc-4ce5c9d992b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd24681d-6e00-4b71-ad94-10f042316661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399f2214-383c-4419-9bc6-b31c0c9b0e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da25603b-6a2f-4475-b5f0-fb7845fa71ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d88467d0-f5db-48c0-a8eb-53665f0b2c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7acb285f-008f-4ae8-872c-fff7a0786847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1422216e-3d13-4c52-9d36-bcff83837596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7406e418-9a89-4351-a969-e348637b4a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f209a4-c02e-44ad-a2b9-4dd932561a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8c4f12-c259-4c3e-9e77-a63b0e85eb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee4baff-14b2-4f3d-967e-0d04aaab74c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab779b3-5a2a-4ee6-9ae4-3f73a640c10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f31a3d-7942-41ae-a031-3442e7797a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c01ee5c8-dde5-419f-8e60-64b0101c47ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e4c2d7-8a49-4a6a-901f-f7781377e89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fdd9535-8388-477d-8d4b-7165b8f08da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1204b861-11fa-4f0f-9aa0-1a1bc893c681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 915f4f59-e4bf-4c8a-be82-55bd8314ea50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7976f3f-e6e3-4a8e-b4c7-3d083b9e71bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d50f70-fe0e-4625-839c-911fb62e2a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0a2d63-460d-49c1-895a-56670c753f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 143b558b-5b83-4c72-9793-bb92476eaaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e321b875-4cb8-4769-8587-861d495a8dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e391b7ba-a2e6-406c-826d-c9f9a84d0b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4cb80e-58f6-404f-a978-927eea350a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0673e87c-2a2c-4dff-9940-8c94b4dff068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80968198-a525-4484-b40b-a00405db977d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d30c8e-edb6-4900-bda5-735e0d9e2326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554da811-b636-4f2e-a9ac-47e6d2c25694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c9c30a6-1f61-4b82-8d7a-090450eae644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24164c20-d547-49b0-bdc2-0f7f5b27408c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7abddf7f-cb9c-49b1-a588-6738d18e7028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667d16ca-20e8-408a-8923-ccf8654b7239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6cb1b80-d383-4ba3-b8da-4d3ab05237cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d115d8d-770d-4570-ad32-50e4d2b70eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d26caf0-6183-4394-80b7-2bb8268bfcd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a2e1338-31d8-49e8-85ee-d0b00a8a4596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2bb623d-eef3-4966-80c0-2864337025fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20d78355-1258-4ef0-b28a-74115cc12b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37760380-57b6-4fa1-a7ac-acdc20a90c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a26208-fb95-461a-930b-ce22df6afaec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 660c01fa-0f82-435b-941d-4d3c1ee8f3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c973cc-8c19-4a84-8bdf-159e7c3ea1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f483180-972c-4129-b199-08913924268f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf75209-a5c3-44d0-a827-a0c6f361b1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d75e54-a49a-4f2c-a5a3-c88fd4583960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8a0900-f2aa-4f9f-890a-a0f74bbc2211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac07f66-3902-4e84-be34-ef68b2ce67bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073d73a0-d07e-4895-af54-e93fc24b3327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a98394-b722-486c-bed2-3fbe95cf4b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da033ea3-c93d-4765-b0f7-2ff9cc3385d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01844c3-9631-4f9c-9bc6-4e514ef117a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc8777c1-4cdd-45b4-9a21-9fcfcbb77b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73baaa13-f7cb-4bdd-ace0-c2e892a8bfe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5254457-c3cb-4c2b-8971-adedc3f637ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c5692c8-ecd5-458a-a666-57183226d7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f7fd00-d9af-40e5-9b14-6e9f4e4bf595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45cc3c29-070f-4749-8659-ba9af2457c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d2169e-38a5-4e14-a09f-36bc005797d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff727dd-f80e-44b3-94d9-ee735070b3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3b8f95-15f0-4a4e-bc9e-b12da20a8e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ccca436-d9e3-4eb0-b2c5-1cf7337b2c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34b43813-5575-423e-a615-8790180bb9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5480d881-34e5-4ad7-b77f-c822ce349c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e021af-9454-4bd8-9183-da5320833ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc7a5ae3-05d9-4a13-9c0b-1cfa9f574c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89d6ef0-9889-4fe6-b118-e91dd6b4478c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 730011b0-a2ea-4cd8-b5f3-3504e0fe34ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989ad4a1-c75d-425d-aa44-70d85598ae70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a2ce98-e0f5-4782-a219-f3f72fc779e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c7f308d-f3eb-4127-8165-2adc6ae18597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a0fc48-d94c-4d9e-827c-54f3039fe850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9343b199-7196-48d9-a713-2e653d9d53d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cd3c3d4-141a-4733-8146-17c493035ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd20c34d-ec8b-417c-a66a-eba0918bf2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838f93de-24e5-4057-8c31-0dab809bcdde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf275fe-1967-409e-92d4-5cdc02c33bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc616ec-8519-426b-85e1-ce13507dd613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f92b2e-8d6f-4b6a-954a-7d1068a415da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb090a7-0f5b-4794-9dc6-4e94460dfb9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c0cec0-10d6-48f5-85e4-b99fca41ed52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5606eda-744a-4b6e-8ce6-dc83b13302d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45dceccc-a9fd-48e2-ae74-ae50c4ba6c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9215060-1275-4dbf-8a90-459a4f4147bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e175e04d-8824-42ad-a1ae-4601d64e0320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebcd442-449f-4ee9-9605-a6f84ce1d542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451058f9-05b9-408b-9845-5ea8f0f2ccd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d97fd3-514f-4747-b2a4-915599bbc6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0bbb171-c918-4257-9501-cf0efe9f6349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eda72ab-87df-4aaa-bc30-41e1965ec550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fdc6039-ff75-4624-bae0-8e9a6ff19291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 443112da-756c-47ca-b86f-a8cc9afd7ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3916c5-3756-4707-bf2e-610200c3041c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad1ab7df-fbde-4418-87be-069734a2dc38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bee95f6-7868-42a6-9cba-de9ca188f53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71fcc77-9a91-4d0f-b835-e46e2d03d41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd591aa8-08bc-465f-8c43-a4a6076aefd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0684afda-0454-42de-8f77-5d79a96e7f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142acbd2-773b-4baf-9e07-a5cc6389e90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df206f84-1e7b-4132-9139-4025236e98ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1098c32c-27cd-41b0-b7ac-9ee2f8a44e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80276625-0c65-4edb-a85d-22d51916eaa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90bb00a-f7e3-4ab4-b959-71eacb442589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db6f67d-501e-46c0-a9cd-b1274403c4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb6e8d41-d4b7-40a6-be83-da800c780fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3048eef9-7104-4e10-b59f-a32642d73231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb966095-65bb-4a5a-a80a-3861ea7bacf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7317a0-2f97-46dc-b013-21ebd942cd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74fc68b-235e-47d2-a118-ac80a75d4c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376e4f9f-85dc-4b73-a7ce-8e5d68e17992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c40ed71-ffa6-4266-b5f1-67e09fa3a9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783ab770-1b07-40b3-b41f-2438c39d4b9e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_67
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/test_labels.txt

📊 Raw data loaded:
   Train: X=(1552, 24), y=(1552,)
   Test:  X=(389, 24), y=(389,)

⚠️  Limiting training data: 1552 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  380 samples, 5 features
✅ Client client_67 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2419, R²: -0.0032

============================================================
🔄 Round 2 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0828 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0831, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0821, val=0.0833, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0822, val=0.0833, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0821, val=0.0831, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0814, val=0.0827, patience=10/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 2 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0036
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0053
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2418, R²: -0.0003

============================================================
🔄 Round 4 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0850 (↓), lr=0.001000
   • Epoch   2/100: train=0.0838, val=0.0868, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0832, val=0.0856, patience=3/15, lr=0.001000
   📉 Epoch 5: LR reduced 0.001000 → 0.000500
   • Epoch   5/100: train=0.0826, val=0.0859, patience=4/15, lr=0.000500
   • Epoch  11/100: train=0.0811, val=0.0872, patience=5/15, lr=0.000500
   📉 Epoch 13: LR reduced 0.000500 → 0.000250
   📉 Epoch 21: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0794, val=0.0904, patience=15/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 4 Summary - Client client_67
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0169
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0554
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2423, R²: -0.0044

📊 Round 4 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2425, R²: -0.0059

============================================================
🔄 Round 6 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0764 (↓), lr=0.000125
   • Epoch   2/100: train=0.0846, val=0.0764, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0845, val=0.0764, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0844, val=0.0764, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0844, val=0.0765, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0839, val=0.0766, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 6 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0057
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0151
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2436, R²: -0.0163

============================================================
🔄 Round 11 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000031
   • Epoch   2/100: train=0.0850, val=0.0798, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0847, val=0.0798, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0844, val=0.0798, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0841, val=0.0799, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 11 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0285
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0088
============================================================


============================================================
🔄 Round 13 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0910 (↓), lr=0.000008
   • Epoch   2/100: train=0.0826, val=0.0910, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0825, val=0.0909, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0824, val=0.0909, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0823, val=0.0908, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0820, val=0.0908, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 13 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0219
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0494
============================================================


============================================================
🔄 Round 16 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0793 (↓), lr=0.000002
   • Epoch   2/100: train=0.0858, val=0.0793, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0857, val=0.0793, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0857, val=0.0794, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0857, val=0.0794, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0855, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 16 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0365
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0093
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 16 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 16 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 22 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 22 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0299
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0282
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 27 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 27 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0281
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0380
============================================================


============================================================
🔄 Round 28 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 28 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0324
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0409
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 29 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 29 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0261
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0447
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 30 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 30 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0321
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0228
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 30 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 35 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 35 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0293
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0338
============================================================


============================================================
🔄 Round 36 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 36 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0315
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0272
============================================================


============================================================
🔄 Round 37 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 37 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0324
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0213
============================================================


============================================================
🔄 Round 40 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 40 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0254
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0493
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 41 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 41 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0328
   Val:   Loss=0.0727, RMSE=0.2695, R²=-0.0141
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 43 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 43 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0282
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0366
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 45 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 45 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0270
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0444
============================================================


============================================================
🔄 Round 46 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 46 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0248
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0705
============================================================


============================================================
🔄 Round 47 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 47 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0324
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0193
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 47 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 49 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 49 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0319
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0323
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 51 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 51 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0284
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0528
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 51 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 51 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 59 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 59 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0330
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0165
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 59 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 59 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 63 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 63 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0282
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0350
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 65 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 65 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0287
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0351
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 66 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 66 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0331
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0235
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 68 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 68 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0304
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0266
============================================================


============================================================
🔄 Round 69 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 69 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0297
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0414
============================================================


============================================================
🔄 Round 70 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 70 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0247
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0484
============================================================


============================================================
🔄 Round 71 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 71 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0287
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0654
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 72 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 72 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0309
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0449
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 72 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 78 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 78 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0271
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0397
============================================================


============================================================
🔄 Round 79 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 79 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0334
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0276
============================================================


============================================================
🔄 Round 80 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 80 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0346
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0136
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 81 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 81 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0310
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0288
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 85 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.1009, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.1008, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1009)

============================================================
📊 Round 85 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0335
   Val:   Loss=0.1009, RMSE=0.3176, R²=-0.0214
============================================================


============================================================
🔄 Round 86 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 86 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0340
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0180
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 87 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 87 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0273
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0397
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 90 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 90 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0292
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0388
============================================================


============================================================
🔄 Round 91 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 91 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0243
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0538
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 91 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 95 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 95 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0282
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0361
============================================================


============================================================
🔄 Round 96 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 96 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0328
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0165
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

📊 Round 96 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0183

============================================================
🔄 Round 101 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 101 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0312
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0731
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 102 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 102 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0289
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0333
============================================================


============================================================
🔄 Round 103 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 103 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0289
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0365
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 103 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 106 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 106 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0300
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0290
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 106 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 110 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 110 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0313
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0229
============================================================


============================================================
🔄 Round 112 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 112 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0300
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0290
============================================================


============================================================
🔄 Round 115 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 115 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0259
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0453
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 115 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 115 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 120 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 120 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0288
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0333
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 120 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 120 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 124 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 124 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0226
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0591
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

📊 Round 124 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

📊 Round 124 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 128 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 128 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0307
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0396
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

📊 Round 128 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

📊 Round 128 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 132 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 132 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0355
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0093
============================================================


============================================================
🔄 Round 135 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 135 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0317
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0516
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 136 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 136 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0299
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0317
============================================================


============================================================
🔄 Round 137 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 137 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0272
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0396
============================================================


============================================================
🔄 Round 138 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 138 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0275
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0388
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 141 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 141 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0314
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0238
============================================================


============================================================
🔄 Round 142 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 142 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0295
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0402
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 143 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 143 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0277
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0387
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 143 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 146 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 146 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0278
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0609
============================================================


============================================================
🔄 Round 147 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 147 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0226
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.1094
============================================================


============================================================
🔄 Round 148 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 148 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0286
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0409
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 150 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 150 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0283
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0449
============================================================


============================================================
🔄 Round 151 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 151 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0330
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0195
============================================================


============================================================
🔄 Round 153 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 153 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0326
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0184
============================================================


============================================================
🔄 Round 154 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 154 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0351
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0200
============================================================


============================================================
🔄 Round 156 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 156 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0320
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0401
============================================================


============================================================
🔄 Round 157 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 157 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0251
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0494
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 159 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 159 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0309
   Val:   Loss=0.0688, RMSE=0.2623, R²=-0.0339
============================================================


============================================================
🔄 Round 161 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 161 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0312
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0231
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 161 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 166 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 166 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0314
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0225
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 167 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 167 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0328
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0165
============================================================


============================================================
🔄 Round 168 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 168 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0291
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0549
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 169 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 169 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0266
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0505
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 169 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 171 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 171 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0331
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0152
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 172 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 172 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0346
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0094
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 173 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 173 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0282
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0390
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

📊 Round 173 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 177 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 177 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0371
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0026
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

📊 Round 177 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 179 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 179 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0279
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0361
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0184

📊 Round 179 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2437, R²: -0.0184

============================================================
🔄 Round 181 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 181 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0299
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0290
============================================================


============================================================
🔄 Round 183 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 183 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0320
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0332
============================================================


============================================================
🔄 Round 186 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 186 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0362
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0288
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0185

📊 Round 186 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2437, R²: -0.0185

============================================================
🔄 Round 189 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 189 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0346
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0102
============================================================


❌ Client client_67 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
