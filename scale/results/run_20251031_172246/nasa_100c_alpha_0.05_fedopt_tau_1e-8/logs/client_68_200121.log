[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccaa1c91-8707-4351-8d0c-141a12bf8d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eee6616-54a4-4a9d-9ffd-3ccc3e4b77f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9188cbc6-27ec-4721-899b-4c7c973bb7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818de985-6082-458f-a515-be52b2201eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3474142-3c15-4131-b9ba-0070a32344d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5578f469-e7aa-4a13-bb0c-43147f279b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759f425f-31db-4b58-b389-b8db517c15ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c06ec6d0-af72-4bbd-bb5e-9058d9c5e5b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dfe9e59-0528-40e4-8ef3-6e65d4e54618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f733e84-bdd7-48bd-9055-cfc144732aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faecb96d-6323-4d40-8da3-09ca4b0befe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee007d5-e689-4dad-b377-435f3e5a4de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b694ab8-367b-4b3d-9b23-e21c29b4a4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eda2dfa-845d-4419-893b-2c6e812df415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a95b10-cdb8-4a8b-b7b3-d2541cfab02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349d3c8d-1c3a-48d1-bf16-bbd9a9b9afe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab17518-9a24-43f5-8a00-0f890e512f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb3d3f6-69e5-4bfb-aa41-67c646d191ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e06d673-0b2e-4bf2-b537-e8bb012deae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ce8e0b-60f4-4caa-aed0-66e321e02bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162193af-47f7-47db-8f4f-8bda98692d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62594aa-1a77-46cd-9d26-812a5411250d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16e6689b-89dd-471c-9cab-d1fa73570847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f922e0-6467-49d5-bb2d-5c26c9e3f935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3034a189-41fe-481d-99aa-bd3082c3581e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c484043c-142b-4137-a7e1-cc647ff74cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ceed3c-67df-4bd7-bbe6-41ac5487ecc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06899ce-dc2f-479b-9045-1c0bcb7e3d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641e153e-cb8c-4d8c-bfd0-8b2228ef7c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bfcf68c-4478-417f-b73e-49cb314e2dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f33651c2-4523-4749-a9c7-0826df7f8b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74171546-f3bd-4ab4-aa42-adfe1539e2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569258cc-38c1-4108-815c-0a672f2310c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 402dea5b-7fe6-4c1d-abc6-b89a2c966fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2f009c-53af-4b87-97cd-1c78fcbf70c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0406497d-bfbd-4b49-83e4-81d7a3616b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f843310e-e5b2-4777-8e2a-7bfe8c01e06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 188cc827-23e2-4152-9f3d-62e926bcbdb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3001b798-3ec9-4328-ae7c-66c330a62b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581e96bb-0406-4cdd-ab1e-28d4e7e962f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb33fc7-ca4c-44db-b155-58c409988b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8080e0d0-611a-437b-8b47-f36ee0521a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 761da959-90d4-47bf-8bf0-4870b30216ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073fc2fe-c3c5-4979-abf1-42fba5cd3f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee0e6f4-68c8-4180-b4d6-60e5b543070d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d42e7731-e2ea-40d4-b0fe-e2e2fc0407b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d16f08-e641-4aaf-b568-e8eebe71ad2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7362f13-fc54-43cc-91ed-e5175bbd75e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e87966-90f7-4462-bc4b-c7df92429bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7607fa63-2ae5-4949-bc07-bf2b7f92fe9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b351c3f-47aa-4ddd-a9f5-5dcadd1ced68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c65cde05-77e8-4282-9833-e4d1da4f057f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e63fabd9-b002-4f79-a995-6c5543dda90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798b4dd4-9b60-4ab6-8a7a-012d3cbb3bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd33bc7-121e-4eec-8057-18220bf590ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a26501e5-c868-44ba-a6b1-a45e76092d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d98aecb-e0b7-4696-b387-72b1a01da4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d302ee5c-94f5-4e4a-bc8e-06371909e463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d51ebf67-59b7-4ded-a415-886615b5a1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0d28a9-dd60-4b36-9109-be6da55f90ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ccce03c-09d6-41d1-82da-e7c35b3faded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8f43df-b9ad-436e-a3ae-5772f7bd8330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1016404f-72dd-4eaf-8492-fe78d78b1897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74eec468-cb27-4042-98de-99e2c06be457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440339c6-8c0a-4ed9-8120-931011a06622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56364e8f-f453-44c9-b692-7fceb0655710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b36adb-74dd-465e-9b8a-e56bbea8afe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c6b56c-3c27-4e04-947d-d6f4b84a929c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1e1238-1d2a-4754-8245-fa30b74c5d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61dff84d-7008-45db-b9a6-5dcda8b6f102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e93bd0f-ed0c-4e7d-bfe5-80692257e65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13c33384-aae3-4043-8aaa-7813b7167edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d97171-a8cf-4b7b-bc20-ce589e85c1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f767984-113b-41e0-9a10-84b045ccafcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5735f8e4-5ad5-4d6c-a2c5-16f38abba97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a7fd40-43bc-4c0a-a05a-027adebcd601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5973fa7-c089-48e6-a0ef-33648fa0132e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c956ebf8-7fcc-4d38-860d-5748cc4da206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ad0c0f-c642-46dc-a9e8-3789531d62cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd2deb9a-8f2b-499f-b882-5ce45fce4517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb6856b-29bf-4807-9ea8-dd876dcb760e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e272c7-0733-4051-8525-0d9116098023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69ef8eb7-c084-4845-b127-de8fa538ede5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aff1599-b5d9-4dea-8d71-b0483998d8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2704b863-8fdd-4ad8-ba5e-a9d489a3a79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d7a4ed-e7a1-49d1-a0ae-c9ece34a15ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14da49ed-ce55-4dce-a50e-f3d32a6c64f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf974f8-2612-4b0d-b2a5-04f7616413e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7fffe0e-c8b7-442c-b525-b3866acf4d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 342823cb-fc23-42a9-bbb8-c9208285810b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d0c928-055e-4be7-95f9-b5b2293af3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a77cd79-2612-4b5f-a7d2-4323ebdb0926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c2e40a-e0ea-484a-8179-6d163b971874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3db660b-bb25-408c-be67-f3c14cc35b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4558f801-cccb-431c-b007-605e320052f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea7b276-9e10-413a-b5d2-3bf60a3fdc40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e3b387-4ab7-41f6-a6ed-a4e584ffe8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c8f1ba-8151-4dc6-9539-2550665d5c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac7abd3-cf60-4be0-bbc4-aaee42265a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708f84da-8fcb-486a-85ea-3b760a14a10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f736502f-7975-4244-b4ba-84386f7ac207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d003014-0cc4-4112-852d-8898ffac5da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab8043de-7ca2-4e26-8877-ef30236da1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c607788-24a3-41ca-8fac-58c382841558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed2e61bd-5cf1-4a54-9f0e-92587d5cdc9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f009cc84-c83e-4a99-b4d2-d397607c4f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5bb4145-2d8a-4e9a-af82-b674a9c66d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae45e512-c76c-4ce2-bacd-b4f750f106b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1028a33b-ef8f-4a9b-81f4-bb49048b11d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7526ae54-683e-4414-bf66-b5ab4f52bc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6189ec-5899-428e-9446-930c06912c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700f626a-dc49-42f8-ac87-ba4b5fa78daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b41da7-0e1b-4030-b00c-f6d69406d3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53055b8-e9f0-4882-91f0-b92355b44d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c02013a-aa51-41ac-a111-0a2121ecc32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ebf32b5-31e6-4308-b8bf-306a7e6172b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca94b60-902d-4efa-99d9-79256bb798bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a94d53-a53a-4d31-8fdb-d46cc7f8ffa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4388f76-77d6-4288-9a0e-9f06c5373d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4f39fa-c286-44b2-b953-64d856d6bf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ac2f0f-b3c2-4e79-af0d-55b2a06d95cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 459162f8-c7f8-4d88-a15e-50591d294191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7595f4-095b-4984-9e9d-c419e553bd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee1d8fd-2ec8-42d3-9027-2994b1bf3741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 075ab8ab-34c4-4fde-8226-0993e97a6b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7abfe8-3f68-4076-96cd-c74fa00a9074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 034b29a9-e028-4327-bc57-045310c5a439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e054601-2a33-4e1c-84e4-b47131a46ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba1c34c1-41c8-4b36-857e-f31747988f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64cf0db-6d57-489e-812c-9d4d9835a4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de45f07-1d4d-47e3-bc3d-20bb37cf916e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976f141c-1a4c-4c60-bb65-6181c4acad2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb7e5f9-09bc-499b-bad0-1c00dece5643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd78616e-6b67-4ff2-95df-5a5e28f1f0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba35a962-8172-4439-be09-d8a1b1466669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 893718b2-d9da-4710-88e6-0b447c5d8606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e58b1f05-e2cb-4bef-bd1b-89e7387519df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9892f95-beab-44ea-926b-1d0b95879c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a5ef8c1-10ee-410a-babc-67ce76b9f29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51d70ed-bfac-47b8-8cd8-af725f907e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c86028-b537-4974-b2fc-760a25570e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a0d43f7-523b-4503-adf5-a3c25c9528e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d87bb2-788c-457f-880f-1f1ed4a4da9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d2ae74-6f4a-4d6a-9df2-e97fd5820510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed09480-8f5a-4683-8a34-ae6e89600816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e94cbfa8-068f-4c3e-ba6e-a63c3513f5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e078d1-6646-404c-9d38-35f811b557eb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_68
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/test_labels.txt

📊 Raw data loaded:
   Train: X=(1040, 24), y=(1040,)
   Test:  X=(261, 24), y=(261,)

⚠️  Limiting training data: 1040 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  252 samples, 5 features
✅ Client client_68 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2462, R²: -0.0121

📊 Round 0 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2463, R²: -0.0130

============================================================
🔄 Round 4 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0981 (↓), lr=0.001000
   • Epoch   2/100: train=0.0818, val=0.0981, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0817, val=0.0985, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0814, val=0.0990, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0811, val=0.0990, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0793, val=0.1008, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 4 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0156
   Val:   Loss=0.0981, RMSE=0.3131, R²=-0.0013
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2466, R²: -0.0168

📊 Round 4 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: -0.0210

📊 Round 4 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2476, R²: -0.0250

📊 Round 4 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2480, R²: -0.0273

📊 Round 4 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2485, R²: -0.0324

============================================================
🔄 Round 10 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0872 (↓), lr=0.000250
   • Epoch   2/100: train=0.0845, val=0.0871, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0843, val=0.0869, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0842, val=0.0868, patience=3/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0841, val=0.0867 (↓), lr=0.000250
   • Epoch  11/100: train=0.0833, val=0.0862, patience=6/15, lr=0.000250
   • Epoch  21/100: train=0.0819, val=0.0863, patience=9/15, lr=0.000250
   📉 Epoch 22: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 10 Summary - Client client_68
   Epochs: 27/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0148
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0630
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2482, R²: -0.0292

============================================================
🔄 Round 11 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0822 (↓), lr=0.000125
   • Epoch   2/100: train=0.0857, val=0.0822, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0856, val=0.0820, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0855, val=0.0820, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0854, val=0.0820, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0849, val=0.0819, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 11 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0083
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0142
============================================================


============================================================
🔄 Round 13 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0898 (↓), lr=0.000063
   • Epoch   2/100: train=0.0841, val=0.0896, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0840, val=0.0896, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0840, val=0.0897, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0839, val=0.0897, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0836, val=0.0896, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 13 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0025
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0340
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 13 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 20 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0905 (↓), lr=0.000016
   • Epoch   2/100: train=0.0840, val=0.0903, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0839, val=0.0901, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0838, val=0.0900 (↓), lr=0.000016
   • Epoch   5/100: train=0.0837, val=0.0899, patience=1/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0836, val=0.0899, patience=7/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 20 Summary - Client client_68
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0044
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0267
============================================================


============================================================
🔄 Round 23 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0846 (↓), lr=0.000004
   • Epoch   2/100: train=0.0855, val=0.0845, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0855, val=0.0845, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0854, val=0.0844, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0854, val=0.0844, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0853, val=0.0843, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 23 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0152
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0054
============================================================


============================================================
🔄 Round 24 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 24 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0087
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0340
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 24 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

============================================================
🔄 Round 26 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 26 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0099
   Val:   Loss=0.0996, RMSE=0.3156, R²=-0.0256
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

============================================================
🔄 Round 32 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 32 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0144
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0111
============================================================


============================================================
🔄 Round 33 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 33 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0145
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0200
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 33 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

============================================================
🔄 Round 38 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 38 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0169
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0059
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 46 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 46 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0196
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0105
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 46 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 46 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 51 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 51 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0174
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0192
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 52 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 52 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0086
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0342
============================================================


============================================================
🔄 Round 53 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 53 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0149
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0193
============================================================


============================================================
🔄 Round 54 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 54 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0181
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0041
============================================================


============================================================
🔄 Round 56 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 56 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0138
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0179
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 56 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 56 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 60 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 60 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0137
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0126
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 60 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 62 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 62 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0177
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0098
============================================================


============================================================
🔄 Round 63 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 63 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0151
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0193
============================================================


============================================================
🔄 Round 64 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 64 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0152
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0209
============================================================


============================================================
🔄 Round 65 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 65 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0094
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0333
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

============================================================
🔄 Round 67 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 67 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0113
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0286
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 67 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 67 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0314

📊 Round 67 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 67 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 77 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 77 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0158
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0065
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 77 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

📊 Round 77 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 82 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 82 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0137
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0142
============================================================


============================================================
🔄 Round 83 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 83 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0151
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0486
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 84 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 84 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0119
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0248
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 91 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 91 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0175
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0001
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 93 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 93 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0117
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0233
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 96 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 96 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0110
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0228
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 96 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

📊 Round 96 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 103 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 103 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0148
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0082
============================================================


============================================================
🔄 Round 104 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 104 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0086
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0385
============================================================


============================================================
🔄 Round 107 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.1023 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.1022, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.1022, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.1022, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.1022, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.1021, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1023)

============================================================
📊 Round 107 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0107
   Val:   Loss=0.1023, RMSE=0.3198, R²=-0.0231
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 109 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 109 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0186
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0057
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 112 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 112 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0137
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0152
============================================================


============================================================
🔄 Round 114 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 114 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0160
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0163
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

============================================================
🔄 Round 116 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 116 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0137
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0270
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

============================================================
🔄 Round 117 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 117 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0136
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0410
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 119 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 119 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0161
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0077
============================================================


============================================================
🔄 Round 121 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 121 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0217
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0444
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

📊 Round 121 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

📊 Round 121 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

============================================================
🔄 Round 126 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 126 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0122
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0190
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0318

📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

============================================================
🔄 Round 132 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 132 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0091
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0364
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

============================================================
🔄 Round 134 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 134 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0140
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0132
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0317

============================================================
🔄 Round 135 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 135 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0090
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0323
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 136 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 136 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0118
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0241
============================================================


============================================================
🔄 Round 137 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 137 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0151
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0364
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 138 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 138 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0190
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0080
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

📊 Round 138 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 140 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 140 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0145
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0112
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 142 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 142 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0148
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0169
============================================================


============================================================
🔄 Round 143 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 143 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0139
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0350
============================================================


============================================================
🔄 Round 144 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 144 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0133
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0213
============================================================


============================================================
🔄 Round 147 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 147 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0154
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0088
============================================================


============================================================
🔄 Round 148 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 148 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0147
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0198
============================================================


============================================================
🔄 Round 149 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 149 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0090
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0478
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 151 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 151 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0184
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0053
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 152 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 152 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0204
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0137
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 153 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 153 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0162
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0227
============================================================


============================================================
🔄 Round 155 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 155 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0102
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0300
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 156 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 156 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0141
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0121
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

📊 Round 156 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0315

============================================================
🔄 Round 158 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 158 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0192
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0007
============================================================


============================================================
🔄 Round 159 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 159 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0162
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0024
============================================================


============================================================
🔄 Round 160 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 160 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0136
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0191
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 162 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 162 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0114
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0257
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 163 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 163 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0098
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0289
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 164 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 164 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0176
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0012
============================================================


============================================================
🔄 Round 167 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 167 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0142
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0336
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 170 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 170 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0157
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0114
============================================================


============================================================
🔄 Round 171 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 171 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0127
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0287
============================================================


============================================================
🔄 Round 172 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 172 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=-0.0172
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0017
============================================================


============================================================
🔄 Round 174 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 174 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0120
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0205
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

📊 Round 174 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

============================================================
🔄 Round 187 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 187 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0123
   Val:   Loss=0.0931, RMSE=0.3050, R²=-0.0191
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: -0.0316

❌ Client client_68 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_status:14, grpc_message:"Socket closed"}"
>
