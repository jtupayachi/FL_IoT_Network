[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9a458c-2bf2-4d96-a3b6-fa1b03b9e504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6202280-7fff-41f0-92a4-91cf603b7223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed3f85a-5e30-4fdf-aee2-5111cb73c1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9117021e-214b-4ad5-8025-a6101f22f8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a467d85-cc31-4e4e-881b-3b44826b1bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 262c994a-d5ee-4751-924d-d836c5358f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f69e7a-6449-43af-9730-db80eaec6c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eaec88b-ffc2-4cf4-8046-915384424aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6198a617-efdf-4b65-8e0b-3c5135b965df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c75948-aef3-460d-8c2b-bf181f44f2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d63268-94d2-47ff-b091-08de93d8d6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8276458a-1d88-4277-b92d-184aebd483cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690fd039-b7f6-4cdf-a5f0-9104c064372a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43362e24-f690-4105-832f-12d4c49f5570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6074ee-4a66-42b2-95cd-ceb396bdce87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a57b680-0459-4ca5-8ecb-c02d7500b7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3120f602-5bee-4229-82ac-d087e5c8596a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a83cb2c-8f9e-42a1-a17e-8448ec6e5395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be84164-089f-41e4-ab72-22bf456e49b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304c0087-c308-4da1-aaa6-17d64fc9ae84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79d6692a-2e48-47c1-bf3b-df8c7fc65471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f407158-3d1d-4e65-9b38-27074232bbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c509dc0c-1586-4d3c-9278-b7735596aee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 684adc91-71eb-45e3-98fe-ff634d09e96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4bfb507-6cff-47e2-bbc5-0315f7753614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa1c7a8-edb9-47db-ab20-153957c180bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95227661-77a3-420f-8922-30dd47e91a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d46e418-22fd-4d59-9c5b-d40e270561d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79f9b207-1d37-4b30-ba29-ee983ab16659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8517907e-d129-4b59-8f7e-87c0be1cd219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5f04883-e64c-42c9-b815-4da7029f7b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec34c22f-10af-445c-9457-9381031ed239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de56559e-01df-41b2-9db2-e1f653dc1068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b376ad2c-16b4-4e48-b716-c349f0e94b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fa409f-4631-47c5-b089-40cd08a8de6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ce8c58-e5b8-4cc3-93a5-421fa7ef584f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0dc8e4d-b63e-4b51-a387-3caf9ff7418e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e5541d-d501-40a0-bbe6-958c939cf921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9922f5f1-eded-4b29-b24a-1ac4fce4da31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7bafd8-46bf-4e85-bc90-7a92d0972801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76bf785f-7f44-41a5-b07d-c8c56f82c251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de37b866-4b54-4489-9a9e-ee694d1ad274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a2bb07-86ba-49cb-a848-f84b6a90dcb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b19517-930d-4a51-87c5-9a1076f91b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c38f689-5f99-4063-981c-381c13d6e8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71678ba-d415-4e57-beea-b5d79e911776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f75f19-20c9-4fa5-9c19-23dc91adfa08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c68831-ea01-4643-83fd-ceefa93141b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9c4e0d-79ff-426d-91e1-54568554620e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5206da4-50e1-4b80-a276-4e96e12931f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f752cef4-dccb-461d-82ca-ae232f26e406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 578400a5-bcac-426a-a62d-3c4302cf6000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217682f4-33ef-4d04-9f67-f6590ce9fad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a1e0dc-9397-420a-be90-854f414070db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d92c6b6-789e-4c0b-a3b8-b26042485466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be1bc5e-2996-4a66-a4dc-0a8967727ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f3756b-3674-4d20-a04d-4da3f259cdd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea4e9da-f458-4eec-b5df-b408dc1e7634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d5653d-5baa-4a1d-bbb4-79fc764e9954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5abdd5bc-94ff-4fbd-8c9f-2eb38e7ba09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 085acc40-0559-4c89-9183-d9433ebf17fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164dabc5-fb81-4866-b37d-612f0a4a5e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5aa1d52-aa94-4944-b719-4fe291246aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb84ac5-5274-4ace-a74c-bf35220c4603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36cd1146-4097-4a48-aaae-2eddec0bd4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a504ae4-9ab3-4975-ae3d-15ae5eebc100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3bfbece-d331-40a1-9d23-62391473affe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5aa806f-0694-443a-810e-fc5b6a76c895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e03693-e9c5-4662-bf4e-3951655c3af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f59bfe24-317b-4490-bf0f-a237d5eac9ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c83fad-eab0-4f1a-8484-365e992a3dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10958200-1ea1-452c-b834-8fe86c9c523d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00197d1-a57c-4b2f-8e13-4db4f530eb36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa31a123-e247-44cc-951b-31b1f8143122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac80aaf-0efe-43f9-9ae0-918959c342e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccf0e479-2420-4ab2-816e-16c0495b9670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd25f28e-b273-40a7-b4f3-990b584392f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e2274be-19dd-49be-98fc-90861396c7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5ebdaa-bec3-423c-ad2a-51aa035ed2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a39083-3f07-43cf-9666-c28c2ad4b4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61749d3-d8a9-4b55-919f-4fe1749c7b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f7f53f-6173-45d4-a1de-f2e0730c7ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bf54335-2a36-415f-8936-01edf3ad0be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d1f390-34c3-4931-b2e9-1651ceb453d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05616cca-57d7-49ab-9b0b-12c95c1f8d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b306459-8324-4086-a0d8-cd5b905d7790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc074a04-f8db-47ab-9e61-0907bd32953d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab9c615-f06c-427d-abc4-27192e1bd35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ae1884-51f4-408d-bea3-60c46d14a61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822afdb4-312a-41dd-996e-18ebc8dd60f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7496636c-5dda-42cc-a42b-d8a8abffa1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9687a67d-b6c7-4039-98fc-8b607ca55f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4d75ed-3b67-47e8-9050-6e72bb0fa8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f29a49-372f-4be7-8aa0-5b7946a09fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baee74c0-226b-4f56-9365-3d3d41386c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc8c14b-64b5-46d8-9975-d97390d7eae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13983d76-1986-4378-a816-e92f9bc5b533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d750631-646e-48ef-ab18-d19a0b076970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ee121b-eb7c-489b-b04d-451907d94ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ae0257-cdbf-480d-872c-99f4a7fe959e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d1f0f13-74db-46a7-8a27-a936a24f80ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d570a3-30ba-4831-a502-d911b11d4cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de517694-db05-4c3e-a266-36101319a690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96595b59-e96c-49b0-9d0f-61a38d523647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6a8d97-aa1a-4886-96f6-71799738c0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 184eea6b-25bb-4065-934f-eb356d3d270c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3988deab-b98a-4c9a-9579-80cc2b33d9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d349fdb9-a644-46f8-a434-e66e38f1e230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50537511-ff00-40c2-9f4b-173707c2bb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8d45058-9daf-4ded-bb24-0f62e4952210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b563b9c7-5dab-45bf-b21a-91ccb9859c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6221742c-410e-4c91-8391-3e5505e3c080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61cfb5f9-4f18-4959-8959-ad8ab54861e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a82027-eaba-47d1-8c91-453c4e7ee8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04b18d4-528e-4d0c-a7d0-b3cd968c6eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7497c789-6660-44f9-b72a-016cbce6175a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b55c3a-8977-4afe-baed-710dc17e8799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b9f7a39-3a60-4386-8e82-095ee6cef8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c87a120b-67eb-475f-a7ae-f828394a63ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d34897-8eba-43ce-95b1-38e8eba16c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0afa829b-760c-4de5-bb40-2923f5d8d866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f1e59c-39c8-4959-843a-2145c2e3d3f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87398758-ba64-4ab0-89dc-8b4f82b274b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ef1c22-6c11-43b0-9bdd-d3e07f9168c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97e7993-0626-4e8e-9cce-a8a75e0b73b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0e3c70-b3bc-4dc2-9cc9-26c84dbc4892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2b385c-705f-4f1e-8e9a-933f155dd7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb0f47b-9c6d-4def-b454-70be1de47e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137e4544-e4c3-41c1-a752-d7d2d567405c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87909f91-44b7-4c55-9d1e-ca8ea0323c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e870dda3-dbd3-4879-8bc1-58c3d0fc8f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4ebd3e-8aee-413c-a753-cc2270e267cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d427f4-31ef-49fe-9472-323e5db9e3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b58edb-e0d5-477a-8f8b-73fc619402fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80ac2da7-c873-45a5-aacf-74b657effb24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c508367-3aa2-46eb-a2b6-d4c3948e75d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f16ae57f-af0b-4144-a368-477c2ead6874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9b50efc-9454-4175-b445-9a7f5ec41b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86fd858a-cbaa-4e9a-b3af-8b58f69bcb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63dfd3fc-2b2d-429e-8e96-6f6e089564f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0fffe7-cdd1-4b2c-80a6-8878828d5737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee72c522-6ba0-42bd-a680-260da71b3d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c91365-b3cb-4dc0-af90-5441edf688a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d24a6689-1161-429d-ba41-7bf8bae15b80
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_69
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_labels.txt

📊 Raw data loaded:
   Train: X=(824, 24), y=(824,)
   Test:  X=(207, 24), y=(207,)

⚠️  Limiting training data: 824 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  198 samples, 5 features
✅ Client client_69 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0832 (↓), lr=0.001000
   • Epoch   2/100: train=0.0834, val=0.0830, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0830, val=0.0829, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0829, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0825, val=0.0828, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0819, val=0.0833, patience=10/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 4 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0017
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0072
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2594, R²: -0.0045

============================================================
🔄 Round 7 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0819 (↓), lr=0.000500
   • Epoch   2/100: train=0.0840, val=0.0818, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0836, val=0.0819, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0832, val=0.0821, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0830, val=0.0822, patience=4/15, lr=0.000500
   📉 Epoch 8: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0820, val=0.0829, patience=10/15, lr=0.000250
   📉 Epoch 16: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 7 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0016
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0139
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2591, R²: -0.0050

📊 Round 7 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2591, R²: -0.0085

============================================================
🔄 Round 10 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0912 (↓), lr=0.000125
   • Epoch   2/100: train=0.0817, val=0.0912, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0812, val=0.0911, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0809, val=0.0910, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0808, val=0.0911, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0803, val=0.0914, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 10 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0194
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0108
============================================================


============================================================
🔄 Round 14 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.000031
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0840, val=0.0832, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0838, val=0.0831, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0831, val=0.0828, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0829, val=0.0828, patience=8/15, lr=0.000008
   📉 Epoch 24: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 14 Summary - Client client_69
   Epochs: 28/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0061
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0220
============================================================


============================================================
🔄 Round 16 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0830 (↓), lr=0.000004
   • Epoch   2/100: train=0.0850, val=0.0830, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0849, val=0.0829, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0849, val=0.0829, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0848, val=0.0827, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 16 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0202
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0621
============================================================


============================================================
🔄 Round 21 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 21 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0227
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0428
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 22 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 22 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0352
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0233
============================================================


============================================================
🔄 Round 23 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 23 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0221
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0471
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 25 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 25 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0257
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0312
============================================================


============================================================
🔄 Round 27 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 27 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0281
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0206
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2590, R²: -0.0083

============================================================
🔄 Round 29 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 29 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0300
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0127
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 30 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 30 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0286
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0377
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2590, R²: -0.0082

📊 Round 30 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 32 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 32 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0205
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0623
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2590, R²: -0.0082

📊 Round 32 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 34 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 34 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0302
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0127
============================================================


============================================================
🔄 Round 35 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 35 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0275
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0365
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 36 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 36 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0302
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0127
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 39 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 39 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0248
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0365
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 42 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 42 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0295
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0174
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 44 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 44 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0279
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0266
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 47 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 47 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0357
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0028
============================================================


============================================================
🔄 Round 48 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 48 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0224
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0419
============================================================


============================================================
🔄 Round 52 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 52 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0286
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0306
============================================================


============================================================
🔄 Round 53 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 53 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0344
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0018
============================================================


============================================================
🔄 Round 54 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 54 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0318
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0454
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 57 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 57 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0248
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0376
============================================================


============================================================
🔄 Round 58 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 58 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0235
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0415
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 60 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 60 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0280
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0212
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 60 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 60 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 60 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 64 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 64 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0234
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0458
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 66 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 66 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0283
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0216
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 68 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 68 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0270
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0260
============================================================


============================================================
🔄 Round 69 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 69 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0308
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0143
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 70 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 70 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0269
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0274
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 74 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 74 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0220
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0461
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 74 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 76 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 76 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0282
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0234
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 76 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 76 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 81 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 81 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0304
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0327
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 82 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 82 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0298
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0214
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 83 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 83 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0247
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0487
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 84 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 84 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0263
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0366
============================================================


============================================================
🔄 Round 85 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 85 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0276
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0414
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 85 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 85 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 88 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 88 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0260
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0316
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 88 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 90 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 90 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0244
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0373
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 90 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 90 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 94 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 94 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0219
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0445
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 94 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 96 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 96 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0299
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0202
============================================================


============================================================
🔄 Round 98 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 98 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0274
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0424
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 98 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 103 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 103 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0260
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0295
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 103 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 103 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 103 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 111 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 111 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0283
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0252
============================================================


============================================================
🔄 Round 117 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 117 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0308
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0123
============================================================


============================================================
🔄 Round 118 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 118 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0333
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0438
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 121 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 121 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0235
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0412
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 127 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 127 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0272
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0330
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 132 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 132 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0332
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0340
============================================================


============================================================
🔄 Round 133 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 133 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0362
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0120
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 135 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 135 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0274
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0271
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

============================================================
🔄 Round 137 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 137 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0283
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0203
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 137 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 139 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 139 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0247
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0349
============================================================


============================================================
🔄 Round 140 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 140 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0252
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0362
============================================================


============================================================
🔄 Round 141 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 141 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0296
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0292
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 141 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 141 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 144 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 144 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0237
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0425
============================================================


============================================================
🔄 Round 147 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 147 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0278
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0310
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

============================================================
🔄 Round 151 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 151 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0206
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0519
============================================================


============================================================
🔄 Round 152 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 152 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0329
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0075
============================================================


============================================================
🔄 Round 153 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 153 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0327
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0298
============================================================


============================================================
🔄 Round 155 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 155 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0262
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0304
============================================================


============================================================
🔄 Round 156 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 156 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0217
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0607
============================================================


============================================================
🔄 Round 157 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 157 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0240
   Val:   Loss=0.0966, RMSE=0.3107, R²=-0.0420
============================================================


============================================================
🔄 Round 159 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 159 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0310
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0110
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

📊 Round 159 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

📊 Round 159 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

============================================================
🔄 Round 163 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 163 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0307
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0199
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

📊 Round 163 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 163 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 163 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 163 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

📊 Round 163 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0082

============================================================
🔄 Round 176 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 176 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0268
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0263
============================================================


============================================================
🔄 Round 177 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 177 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0246
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0450
============================================================


============================================================
🔄 Round 181 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 181 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0356
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0017
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

============================================================
🔄 Round 183 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 183 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0218
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0541
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2590, R²: -0.0081

============================================================
🔄 Round 188 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 188 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0266
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0294
============================================================


❌ Client client_69 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
