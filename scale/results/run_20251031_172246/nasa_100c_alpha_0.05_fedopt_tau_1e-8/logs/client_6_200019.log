[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c739e069-1f02-4218-b73b-0557dfa5b620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42eb667-35d8-4b5b-9955-07d95ee2275b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4430f8ae-b940-4956-9f91-2c8964f956f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2600844-ceca-44d9-93cb-0803f9cc12b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6449ad-8efa-4daf-8f0e-75daa4b48605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac70c47-cfc0-4172-b1ed-abed805eb820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055ea115-dea5-4526-8d15-73e15cdf5bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce99b330-e377-43cf-99b4-32ba870ef897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41608ed1-db62-4189-a4fc-26df0804cf84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1151d994-182d-4421-ab06-eda026e85853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb54e4c3-a742-4cc9-b286-0e2c216be49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595d095a-85d3-4a0d-8243-5f10b3d83e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d25990a-9527-4443-aa90-60235edc5b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c629ddea-24c3-46df-a365-e2c0c136ac24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223c8ef2-bb3f-4d5d-95ac-a447d7f80c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa639de-575c-4ea8-8cc8-f84be1a55d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6bc5186-fa02-4506-90e5-63189b7c356b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9aa569-ec92-452b-8d33-b7564f9564ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce59357f-f12e-4b49-aca1-e2f123cdb39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472ea7dd-9aa1-4f80-9094-c607295c9617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a75630a-12d3-4a13-a7f5-99731d67c4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b937d681-793e-495d-94c5-e0297092efc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7134f2f8-697d-400a-a6ed-06fc7c437f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0ee0c9-0cf3-422e-9149-99b5bcfd1edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8bfb7b2-8ee2-4679-a19f-f8b361aff64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 577d8f44-d7d7-434c-bd53-96f3710532ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a1579a9-425f-4d20-a53f-4dc3fecdcaac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc518860-7e43-4cdd-8fa5-bcb88357a244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae505d8b-ea81-4016-a642-a1a859d7208e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e301361-1d41-4a30-b00b-f235a5614370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf6c1e8c-b2f4-41fd-98fb-677b663b542b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcffa832-805d-4468-bbd9-79ffe6bd06d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530c291b-1c1f-4106-be5b-486c808c4c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c993605e-c835-421f-9b81-5741909224c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37cf381e-2976-4b9b-9fb1-8201dd50d3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 958d8a8d-180d-4926-b224-3bca3433252e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96146f8f-54f6-4b5e-82ef-082d5348faf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082f46fb-9a62-4ca9-96fc-96099ae8994d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3351ef26-c477-4eaf-b575-84a09e38f8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e46a81-803f-42e4-a777-fc63b8463393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77db762-fb33-4bc3-a856-e757ca850c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13fea9dd-445d-4d53-93f3-ece42845476f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92a29ea-953f-4e89-9278-afe44a8ea301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c84e7463-2d33-475d-9879-1161f9dbee10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd17001-728c-4ec9-a9f4-02183568cf0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3959ff53-c377-4e1b-9747-e1753563a0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a1c8f5-2059-4264-9b3c-3e606c2edcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea2678b-0abd-4e3d-b7b4-63b49e6cb8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3598aac-cadc-4270-8a46-0c00aae85761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c88e9eb-54f4-4d33-a976-9b45190510fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b7a338-24ff-43e8-b6c2-4e99fc1b7d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8b5d98-cc0d-48b6-a281-0449d32cc7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4c5498-24f8-4a4d-8a08-4bb081009a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f5c004a-4c4e-4266-bf00-6cac741c8895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ff05ff-3675-467b-8de0-cca01d408340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6036d980-3856-4852-b7ad-fb25ce61fe43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5acd33af-2e7e-4e1b-af79-cab3dd4434b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36174d4a-0007-4ddc-a017-066e463a20b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b27e7e71-212c-4da2-9709-018545176750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38d3ca6-4f68-4b49-a2d9-9ff4e980a96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eec1343-f8dd-4e53-959c-b47679ac8e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f63cef-7b6b-464b-8c17-d88c770a04d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c37bf2-9652-4361-9c0f-fe8e4d643342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683f84dd-11f2-4988-b2a8-67c0e370c21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0d7faa-45a0-4aa1-93b3-cd0cdc80f4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d53b4e5-ff0c-4370-a522-4db7fae82ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0221974-7fdf-49b5-aa99-f801e5ae965c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c776c01-a39a-401c-ba52-caeb43cd521c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac88333a-9e95-44a8-8008-377af9fed7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95bc1f1d-8d16-494a-9df2-91cd751f32a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 742b35cc-e5d5-488f-8680-ce1d95c4b1a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91de9a20-824c-470e-bba4-59404381cd26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364571aa-1869-4efd-a537-6c59541154f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62fe7601-0e14-4788-83d3-410a95fafd0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de0daa6-d4af-4b43-928a-d51b51fb4fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9255775-0bf1-4250-a978-daad2c531767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48746ef2-1183-444e-88f3-a8b1bfe21a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f6e83c-029d-42b0-bffe-c8bcf48c0852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 537b346a-1792-423b-b4df-11b534989c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c79bba1-7d2e-4c24-bfa4-24b4986e983d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86c2fb12-3a1e-4b9b-a03f-98c69d7bbcad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1edbb76e-9b22-4b64-868a-8f11cc5d7443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e05c8c-6184-4843-a5d2-d6ea9739577f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b85564-f291-47c5-9a23-3d6fef000409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc50f93f-535a-4472-bfc6-3b45bd36a66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3495aadc-3bab-41f1-875c-5ccc2b2ad938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0a6bb1-a54e-45f4-9335-ff6820998adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954c8eb2-2192-4c9a-87a1-48100e8d6dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919b4e8d-9e1e-4697-9126-1a839eff82ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c29459-ed99-4f0c-b499-8b5d51480f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a8faee-f6f9-4cff-9321-ca9af5351b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf091c1-ea33-4e5b-8f99-df57a070e7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 049ff513-c693-4d54-aec8-79aa855040de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf511ae4-574c-4900-ae3e-162074bcc0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21076682-d522-4f19-a883-4af749894049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c12816-a029-4962-87b4-b8bd78f43b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75764326-8b44-45e8-913b-30f34121b9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd810172-8669-4c64-87c0-e4187de8450b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec47f00-008f-42b6-9ed7-645852536f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c34f50fc-5441-4ec5-bff9-161bf7940af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bbfb188-0437-4049-8aeb-1c0fa7c8079e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58df7f8-fde5-4d84-aafa-33f80b2ee7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ef67b07-b82d-4055-9174-c38a2fec3fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e230ac68-4745-4c2f-a093-344647c117dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a15d3c8-0348-4896-8005-9baa6c430d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 707a9e2a-c7ce-4a1f-92ed-b7eaab38ed16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62762256-b3a2-4ed5-82b7-8ff068a90ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed62d90-c3ec-4b7a-827f-433e5fac15d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2533301-89cc-4e6f-b619-04949ea7a143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d20ae2-8e8e-41da-842e-a120d013ac74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fefe968f-7c28-4b5d-8a1a-aa9c6fd16247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105222a4-4909-4b83-9275-b6aeae20d401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f670926-0a02-4016-96c5-474c6d282757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a626a2-f923-4c13-bbe9-7c976b95564a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49413da5-fe38-41f8-b262-e364e741964c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91310155-7e2a-4489-b2b3-a1a0ec13cd2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1267fb10-638f-4d84-ab94-08e3a5c82da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0cee78e-a13e-4ea2-a28a-c8210e171dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34de98c9-e017-4c19-8c04-278696f3f3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046a2a6f-a8c6-4a94-8bc9-254c2e0809db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f73361-8660-4de5-afda-7a02e122baa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6048e8bc-acbc-454a-9755-82a213767b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab41424-ecff-434c-8683-5fdf96a1ae42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2fed86-6dcf-4cb6-966d-02c3c33f63b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41970abd-ede5-4550-8219-aca113db87ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7428d726-de46-4af6-abe9-55dd7b87bb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11eadabd-4975-44f3-84a3-1f9388e11e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68ed2c1-fca8-46c7-8201-864f2d839920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af275b3-6c49-400d-b39f-ef4901a63dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b60c58f-b02a-4931-894a-a10e728e0aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c4ef48-30bb-4baf-afd1-4408ab68b5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e84e500-dd1e-48fd-a7a9-f259abf9d326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11155d22-b260-444a-a3c0-f1e08a08eaf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07e4f13-808a-406c-a197-eb29471f03fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a482d4f1-7d35-47a4-835c-9b7cc74d0037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b48220d1-42b4-437c-8eaa-5dc1445eb496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c72adbe-53b1-47cb-9f75-a9c4592262b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f3d17d-b466-4372-a609-a821762a19e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c011b5ee-e756-41be-8c0d-b427909ef94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655fd5e4-26dc-4e4b-b573-384f09d3b13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb7beab2-c587-45b7-bebb-8efc21519329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00ff2dd-7047-4764-8d83-ac49b36c382a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50cfacc-af8e-4c4d-a25e-98fa3aa20407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 314691d0-5a92-4c7e-9553-8d3d83404e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58e9e5a-fe90-40c5-948b-d5b5ba557a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d16a76c5-ad54-4dbc-9f59-3021e2239cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b1385e-9ced-4541-83b1-cb0ba0c9a85d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8691
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(1632, 24), y=(1632,)
   Test:  X=(409, 24), y=(409,)

⚠️  Limiting training data: 1632 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  400 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2407, R²: -0.0021

============================================================
🔄 Round 3 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0880 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0818, val=0.0858 (↓), lr=0.001000
   • Epoch   3/100: train=0.0803, val=0.0889, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0792, val=0.0881, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0794, val=0.0880, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0775, val=0.0901, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 3 Summary - Client client_6
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0235
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0201
============================================================


============================================================
🔄 Round 4 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0890 (↓), lr=0.000250
   • Epoch   2/100: train=0.0789, val=0.0892, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0788, val=0.0894, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0786, val=0.0895, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0785, val=0.0897, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0780, val=0.0902, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 4 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0004
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0029
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2412, R²: -0.0057

============================================================
🔄 Round 5 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000063
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 5 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0019
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0092
============================================================


============================================================
🔄 Round 6 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000016
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 6 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0006
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0057
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2423, R²: -0.0159

📊 Round 6 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: -0.0150

📊 Round 6 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2423, R²: -0.0155

============================================================
🔄 Round 13 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0839 (↓), lr=0.000004
   • Epoch   2/100: train=0.0806, val=0.0839, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0806, val=0.0839, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0806, val=0.0839, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0806, val=0.0839, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0805, val=0.0839, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 13 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0052
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0033
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2423, R²: -0.0155

📊 Round 13 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2423, R²: -0.0159

============================================================
🔄 Round 15 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 15 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0060
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0051
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2423, R²: -0.0163

📊 Round 15 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2423, R²: -0.0163

📊 Round 15 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 15 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0080
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0134
============================================================


============================================================
🔄 Round 21 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 21 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0045
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0081
============================================================


============================================================
🔄 Round 22 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 22 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0090
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0024
============================================================


============================================================
🔄 Round 23 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 23 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0107
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0143
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 24 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 24 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0094
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0114
============================================================


============================================================
🔄 Round 25 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 25 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0060
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0128
============================================================


============================================================
🔄 Round 27 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 27 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0067
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0011
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 28 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 28 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0043
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0125
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 30 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 30 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0104
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0100
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 31 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 31 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0029
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0374
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 31 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 35 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 35 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0037
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0110
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 35 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 38 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 38 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0040
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0110
============================================================


============================================================
🔄 Round 42 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 42 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0096
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0001
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 44 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 44 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0057
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0069
============================================================


============================================================
🔄 Round 45 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 45 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0101
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0155
============================================================


============================================================
🔄 Round 46 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 46 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0068
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0008
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 46 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 49 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 49 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0091
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0031
============================================================


============================================================
🔄 Round 50 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 50 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0094
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0111
============================================================


============================================================
🔄 Round 51 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 51 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0072
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0732
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 52 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 52 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0015
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0199
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 55 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 55 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0021
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0188
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 60 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 60 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0077
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0045
============================================================


============================================================
🔄 Round 61 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 61 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0081
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0064
============================================================


============================================================
🔄 Round 62 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 62 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0042
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0112
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 62 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 62 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 68 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 68 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0080
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0049
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 68 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 68 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 68 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 81 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 81 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0036
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0177
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 84 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 84 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0087
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0076
============================================================


============================================================
🔄 Round 85 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 85 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0081
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0044
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 86 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 86 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0069
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0023
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 86 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

📊 Round 86 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 92 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 92 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0049
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0094
============================================================


============================================================
🔄 Round 94 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 94 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0048
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0075
============================================================


============================================================
🔄 Round 95 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 95 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0028
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0152
============================================================


============================================================
🔄 Round 98 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 98 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0057
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0029
============================================================


============================================================
🔄 Round 99 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 99 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0048
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0302
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 102 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 102 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0066
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0112
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 102 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 104 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 104 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0062
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0089
============================================================


============================================================
🔄 Round 105 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 105 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0030
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0140
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 105 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 112 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 112 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0043
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0089
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 115 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 115 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0014
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0208
============================================================


============================================================
🔄 Round 118 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 118 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0022
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0678
============================================================


============================================================
🔄 Round 123 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 123 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0070
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0028
============================================================


============================================================
🔄 Round 124 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 124 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0038
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0118
============================================================


============================================================
🔄 Round 125 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 125 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0069
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0019
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 128 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 128 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0062
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0007
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0165

📊 Round 128 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 131 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 131 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0068
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0000
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 132 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 132 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0124
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0177
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 133 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 133 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0074
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0042
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 133 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 137 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 137 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0027
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0300
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 139 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 139 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0113
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0192
============================================================


============================================================
🔄 Round 141 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 141 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0048
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0088
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 141 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 145 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 145 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0088
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0070
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 149 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 149 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0066
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0012
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 155 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 155 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0065
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0032
============================================================


============================================================
🔄 Round 157 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 157 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0089
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0040
============================================================


============================================================
🔄 Round 159 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 159 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0089
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0089
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 161 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 161 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0000
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0281
============================================================


============================================================
🔄 Round 162 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 162 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0022
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0162
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 162 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 164 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 164 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0033
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0159
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 171 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 171 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0075
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0273
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 171 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

📊 Round 171 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 175 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 175 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0095
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0085
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 176 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 176 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0087
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0024
============================================================


============================================================
🔄 Round 177 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 177 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0042
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0470
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 179 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 179 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0052
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0072
============================================================


============================================================
🔄 Round 181 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 181 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0085
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0198
============================================================


============================================================
🔄 Round 182 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 182 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0107
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0136
============================================================


============================================================
🔄 Round 183 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 183 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0071
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0036
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0163

============================================================
🔄 Round 186 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 186 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0034
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0120
============================================================


============================================================
🔄 Round 188 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 188 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0043
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0158
============================================================


============================================================
🔄 Round 189 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 189 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0045
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0085
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2424, R²: -0.0164

============================================================
🔄 Round 190 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 190 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0108
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0085
============================================================


❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8691 {grpc_message:"Socket closed", grpc_status:14}"
>
